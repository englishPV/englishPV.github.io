<!DOCTYPE html> 
<html lang="fr">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover, maximum-scale=1, user-scalable=no" />
  <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" />
  <title>Physique Flashcards</title>
  <style>
    /* --- VARIABLES & THEME --- */
    :root {
      --bg: #0b1020; --surface: #12172b; --card: #161c33; --text: #e6ecff; --muted: #8aa0d3;
      --primary: #6366f1; --primary-600: #5457e6; --green: #22c55e; --blue: #3b82f6; --amber: #f59e0b; --red: #ef4444;
      --border: #232a48;
      --fs-term: 20px; --fs-def: 24px; --radius-md: 14px;
      
      /* Buttons - Factorisation des styles */
      --btn-neutral-bg: rgba(255,255,255,.06); --btn-neutral-fg: #e6ecff; --btn-neutral-bd: #232a48; --btn-neutral-bg-h: rgba(255,255,255,.10);
      --btn-soft-primary-bg: color-mix(in srgb,var(--primary) 22%,transparent); --btn-soft-primary-bg-h: color-mix(in srgb,var(--primary) 34%,transparent);
      --btn-soft-primary-fg: #dbe4ff; --btn-soft-primary-bd: color-mix(in srgb,var(--primary) 55%,transparent);
      --btn-soft-red-bg: rgba(239,68,68,.18); --btn-soft-red-bg-h: rgba(239,68,68,.28); --btn-soft-red-fg: #fecaca; --btn-soft-red-bd: rgba(239,68,68,.45);
      --btn-soft-amber-bg: rgba(245,158,11,.18); --btn-soft-amber-bg-h: rgba(245,158,11,.28); --btn-soft-amber-fg: #fde68a; --btn-soft-amber-bd: rgba(245,158,11,.45);
      --btn-soft-blue-bg: rgba(59,130,246,.18); --btn-soft-blue-bg-h: rgba(59,130,246,.28); --btn-soft-blue-fg: #bfdbfe; --btn-soft-blue-bd: rgba(59,130,246,.45);
      --btn-soft-green-bg: rgba(34,197,94,.18); --btn-soft-green-bg-h: rgba(34,197,94,.28); --btn-soft-green-fg: #bbf7d0; --btn-soft-green-bd: rgba(34,197,94,.45);
      --btn-solid-primary-bg: var(--primary); --btn-solid-primary-bg-h: var(--primary-600); --btn-solid-primary-fg: #fff; --btn-solid-primary-bd: var(--primary-600);
    }
    :root[data-theme="light"] {
      --bg: linear-gradient(180deg,#f8fafc 0%,#eef2f7 100%); --surface: #fff; --card: #fff; --text: #0f172a; --muted: #475569;
      --primary: #3b82f6; --primary-600: #2563eb; --border: #cbd5e1;
      --btn-neutral-bg: #f1f5f9; --btn-neutral-fg: #0f172a; --btn-neutral-bd: #cbd5e1; --btn-neutral-bg-h: #e2e8f0;
      --btn-soft-primary-bg: color-mix(in srgb,var(--primary) 14%,white 86%); --btn-soft-primary-bg-h: color-mix(in srgb,var(--primary) 22%,white 78%);
      --btn-soft-primary-fg: color-mix(in srgb,var(--primary) 78%,black 22%); --btn-soft-primary-bd: color-mix(in srgb,var(--primary) 35%,white 65%);
      --btn-soft-red-bg: #fee2e2; --btn-soft-red-bg-h: #fecaca; --btn-soft-red-fg: #991b1b; --btn-soft-red-bd: #fca5a5;
      --btn-soft-amber-bg: #fef3c7; --btn-soft-amber-bg-h: #fde68a; --btn-soft-amber-fg: #92400e; --btn-soft-amber-bd: #fcd34d;
      --btn-soft-blue-bg: #dbeafe; --btn-soft-blue-bg-h: #bfdbfe; --btn-soft-blue-fg: #1e3a8a; --btn-soft-blue-bd: #93c5fd;
      --btn-soft-green-bg: #dcfce7; --btn-soft-green-bg-h: #bbf7d0; --btn-soft-green-fg: #14532d; --btn-soft-green-bd: #86efac;
    }
    :root[data-theme="light"] .definition, :root[data-theme="light"] .card-item .back { color: var(--text)!important; opacity: 1!important; }
    :root[data-theme="light"] .muted { color: #475569!important; }
    :root[data-theme="light"] .legend-item { color: #0f172a!important; border-color: #e2e8f0!important; background: 0 0!important; }
    :root[data-theme="light"] .revision-bar, :root[data-theme="light"] .review-actions-bar { background: rgba(241,245,249,.9)!important; border-top: 1px solid #e2e8f0!important; }
    :root[data-theme="light"] .btn--ghost { --btn-bg-h: rgba(0,0,0,.06); }
    /* Suppression code mort (.img-counter, .img-close inutiles ici ou doublons) */

    /* --- RESET & LAYOUT --- */
    * { box-sizing: border-box; }
    html, body { height: 100%; }
    body { margin: 0; background: var(--bg); color: var(--text); font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Arial, sans-serif; overflow: hidden; font-size: 17px; -webkit-font-smoothing: antialiased; }
    .wrapper { height: 100dvh; width: 100%; display: flex; align-items: center; justify-content: center; padding: env(safe-area-inset-top) env(safe-area-inset-right) env(safe-area-inset-bottom) env(safe-area-inset-left); }
    .phone { aspect-ratio: 9/16; height: 100%; width: auto; max-width: 100%; max-height: 100%; display: grid; grid-template-rows: var(--row-top,52px) var(--row-main,1fr) var(--row-actions,52px) var(--row-rev,64px); position: relative; min-height: 0; touch-action: pan-y; overflow: hidden; }
    @media(min-width: 1024px) { .phone { aspect-ratio: auto; width: 100%; height: 100dvh; } .topbar, main#view, .bottom-actions, .revision-bar { max-width: 1200px; margin: 0 auto; width: 100%; } main#view { padding: 16px 20px; } }

    /* --- COMPONENTS --- */
    .topbar { position: sticky; top: 0; z-index: 10; display: flex; align-items: center; padding: 0 10px; }
    .topbar .back { appearance: none; border: 0; outline: 0; background: 0 0; color: var(--text); padding: 8px 10px; margin-right: 4px; border-radius: 10px; display: flex; align-items: center; gap: 8px; cursor: pointer; font-weight: 700; }
    .topbar .back:hover { background: rgba(255,255,255,.06); }
    .topbar .title { font-weight: 800; font-size: 16px; margin-left: 2px; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; cursor: pointer; }
    .spacer { flex: 1; }
    
    main#view { min-height: 0; height: 100%; display: flex; flex-direction: column; overflow: hidden; padding: 8px; gap: 10px; }
    .hidden { display: none!important; } .muted { color: var(--muted); } .center { text-align: center; } .mt6 { margin-top: 6px; } .mt8 { margin-top: 8px; }
    .scroll-y { overflow: auto; -webkit-overflow-scrolling: touch; overscroll-behavior: contain; touch-action: pan-y; } .scroll-lock { overflow: hidden; touch-action: none!important; }
    .list, .flexcol { display: flex; flex-direction: column; gap: 8px; min-height: 0; } .stack { display: flex; flex-direction: column; gap: 6px; }
    .row, .grid2 { display: grid; grid-template-columns: 1fr 1fr; gap: 6px; } .grid2 { gap: 10px; } .row-4 { display: grid; grid-template-columns: repeat(4,1fr); gap: 8px; }
    .input { width: 100%; padding: 8px 10px; border-radius: 10px; border: 1px solid var(--border); background: var(--surface); color: var(--text); font-size: 14px; outline: none; appearance: none; }
    .input:focus { border-color: var(--primary); }
    
    .card, .deck-item, .review-card, .legend-item, .kpi .k, .stat, .chip { background: 0 0; border: 0; border-radius: var(--radius-md); pointer-events: auto; }
    
    /* Deck & Lists */
    .deck-item { display: flex; align-items: center; justify-content: space-between; padding: 0 8px; cursor: pointer; user-select: none; position: relative; overflow: hidden; touch-action: pan-y; transition: background-color 0.3s ease; }
    .deck-item .slide { display: flex; align-items: center; gap: 8px; padding: 8px 0; transition: transform .18s ease; will-change: transform; width: 100%; position: relative; z-index: 2; }
    .deck-item .right-action { position: absolute; top: 0; right: 0; height: 100%; width: 92px; display: flex; align-items: center; justify-content: center; z-index: 1; }
    .deck-item.reveal-delete .slide { transform: translateX(-92px); }
    .deck-item.drop-target { outline: 2px dashed var(--primary); outline-offset: -2px; border-radius: var(--radius-md); background: color-mix(in srgb,var(--primary) 8%,transparent); }
    .deck-item.dragging-origin { opacity: .3; }
    .drag-ghost { position: fixed; left: 0; top: 0; pointer-events: none; z-index: 9999; transform: translate(-9999px,-9999px) scale(1.02); box-shadow: 0 10px 30px rgba(0,0,0,.35); background: rgba(0,0,0,.08); border-radius: var(--radius-md); }
    
    .folder-badge { font-weight: bold; color: var(--primary); margin-left: 6px; font-size: 12px; }

    /* Stats & Charts */
    .section-title { font-weight: 900; font-size: 14px; color: var(--primary); letter-spacing: .3px; margin: 0 0 6px; }
    .kpi { display: grid; grid-template-columns: 1fr 1fr; gap: 8px; } .kpi .k { padding: 0; } .k .label, .stat .label { color: var(--muted); font-size: 12px; } .k .value, .val { font-weight: 900; font-size: 17px; margin-top: 2px; }
    .chip { display: inline-flex; align-items: center; gap: 8px; padding: 0; color: var(--muted); font-size: 12px; }
    .chip-pie { width: 18px; height: 18px; border-radius: 50%; background: conic-gradient(var(--primary) var(--progress,0%),var(--border) var(--progress,0%)); vertical-align: middle; display: inline-block; }
    .legend { display: grid; grid-template-columns: 1fr 1fr; gap: 6px; margin-top: 6px; position: relative; z-index: 2; }
    .legend-item { display: flex; align-items: center; gap: 6px; font-size: 13px; color: #dbe4ff; cursor: pointer; user-select: none; transition: opacity .15s; position: relative; z-index: 2; }
    .legend-item.inactive { opacity: .45; filter: grayscale(20%); }
    .legend-item .check-icon { display: inline-flex; align-items: center; justify-content: center; width: 18px; height: 18px; margin-right: 6px; border-radius: 4px; border: 2px solid var(--border); color: transparent; font-size: 12px; font-weight: 900; transition: 0.2s; }
    .legend-item:not(.inactive) .check-icon { background: var(--primary); border-color: var(--primary); color: #fff; }
    .legend-item.inactive .check-icon { background: transparent; }
    .dot { width: 10px; height: 10px; border-radius: 50%; } .dot.gray { background: #9ca3af; } .dot.red { background: var(--red); } .dot.amber { background: var(--amber); } .dot.blue { background: var(--blue); } .dot.green { background: var(--green); }
    .chart-wrap { display: flex; align-items: center; justify-content: center; height: 200px; position: relative; z-index: 1; } 
    canvas#gradeChart { width: 180px; height: 180px; pointer-events: auto; }
    canvas#bar7 { width: 100%; height: 68px; display: block; } .bar7-labels { display: grid; grid-template-columns: repeat(7,1fr); gap: 6px; margin-top: 4px; font-size: 12px; color: var(--muted); text-align: center; cursor: pointer; }
    
    main#view > .card { overflow-y: auto; -webkit-overflow-scrolling: touch; min-height: 0; }

    /* Review */
    .review-wrap { position: relative; flex: 1; display: flex; flex-direction: column; min-height: 0; overflow: hidden; }
    .review-top { display: flex; justify-content: space-between; color: var(--muted); font-size: 13px; flex-shrink: 0; padding-bottom: 4px; }
    .review-card { flex: 1; display: flex; flex-direction: column; position: relative; overflow: hidden; min-height: 0; padding: 0; transition: background-color 0.4s ease; }
    
    .review-card.tint-facile { background-color: rgba(34, 197, 94, 0.15)!important; }
    .review-card.tint-bien { background-color: rgba(59, 130, 246, 0.15)!important; }
    .review-card.tint-difficile { background-color: rgba(245, 158, 11, 0.15)!important; }
    .review-card.tint-echec { background-color: rgba(239, 68, 68, 0.15)!important; }

    .review-scroller { flex: 1; width: 100%; height: 100%; overflow-y: auto; overflow-x: hidden; -webkit-overflow-scrolling: touch; display: flex; flex-direction: column; padding: 10px; touch-action: pan-y; user-select: text; }.review-scroller > * { margin-top: auto; margin-bottom: auto; width: 100%; }
    .term, .definition { font-size: var(--fs-term)!important; font-weight: 600; text-align: center; white-space: pre-wrap; word-wrap: break-word; } 
    .definition { font-size: var(--fs-def)!important; font-weight: 900; }
    
    .preview-box { background: var(--card); border: 2px dashed var(--border); border-radius: 14px; margin: 10px 14px; padding: 20px; text-align: center; min-height: 120px; display: flex; flex-direction: column; justify-content: center; gap: 15px; }
    .preview-recto { font-size: var(--fs-term); font-weight: 600; color: var(--text); }
    .preview-verso { font-size: var(--fs-def); font-weight: 900; color: var(--primary); border-top: 1px dashed var(--border); padding-top: 10px; }

    /* MathJax & Img */
    mjx-container { overflow-x: hidden; overflow-y: hidden; max-width: 100% !important; display: inline-block !important; padding: 4px 0; white-space: normal !important; vertical-align: middle; }
    mjx-mtext { white-space: normal !important; display: inline !important; }
    mjx-math { white-space: normal !important; max-width: 100%; }
    .img-placeholder { display: block; background: rgba(255,255,255,0.05); color: #8aa0d3; padding: 15px; border: 2px dashed rgba(255,255,255,0.1); border-radius: 8px; margin: 15px auto; font-style: italic; font-size: 0.85rem; text-align: center; }
    img { display: block; max-width: 100%; height: auto; margin: 10px auto; border-radius: 8px; background: var(--border); user-select: none; object-fit: contain; }

    .bottom-actions, .revision-bar, .review-actions-bar { padding: 8px 10px calc(8px + env(safe-area-inset-bottom)); display: none; background: 0 0; border-top: 0; }
    .bottom-actions { gap: 8px; grid-template-columns: 1fr 1fr; } .review-actions-bar { grid-row: 4; backdrop-filter: blur(8px) saturate(140%); }
    
    .btn, .navbtn, .action, .rev-btn { background: var(--btn-bg,var(--btn-neutral-bg)); color: var(--btn-fg,var(--btn-neutral-fg)); border: 1px solid var(--btn-bd,var(--btn-neutral-bd)); border-radius: var(--radius-md); padding: 10px 12px; font-weight: 900; cursor: pointer; transition: .15s; width: 100%; appearance: none; outline: 0; font-size: 15px; }
    .btn:hover { background: var(--btn-bg-h,var(--btn-bg,var(--btn-neutral-bg-h))); } .btn:disabled { opacity: .6; cursor: not-allowed; }
    .btn--primary { --btn-bg: var(--btn-soft-primary-bg); --btn-bg-h: var(--btn-soft-primary-bg-h); --btn-fg: var(--btn-soft-primary-fg); --btn-bd: var(--btn-soft-primary-bd); }
    .btn--red { --btn-bg: var(--btn-soft-red-bg); --btn-bg-h: var(--btn-soft-red-bg-h); --btn-fg: var(--btn-soft-red-fg); --btn-bd: var(--btn-soft-red-bd); }
    .btn--amber { --btn-bg: var(--btn-soft-amber-bg); --btn-bg-h: var(--btn-soft-amber-bg-h); --btn-fg: var(--btn-soft-amber-fg); --btn-bd: var(--btn-soft-amber-bd); }
    .btn--blue { --btn-bg: var(--btn-soft-blue-bg); --btn-bg-h: var(--btn-soft-blue-bg-h); --btn-fg: var(--btn-soft-blue-fg); --btn-bd: var(--btn-soft-blue-bd); }
    .btn--green { --btn-bg: var(--btn-soft-green-bg); --btn-bg-h: var(--btn-soft-green-bg-h); --btn-fg: var(--btn-soft-green-fg); --btn-bd: var(--btn-soft-green-bd); }
    .btn--solid.btn--primary { --btn-bg: var(--btn-solid-primary-bg); --btn-bg-h: var(--btn-solid-primary-bg-h); --btn-fg: var(--btn-solid-primary-fg); --btn-bd: var(--btn-solid-primary-bd); }
    .btn--ghost { --btn-bg: transparent; --btn-bg-h: rgba(255,255,255,.06); --btn-fg: var(--muted); --btn-bd: var(--border); } .btn--tiny { padding: 6px 8px; font-size: 13px; border-radius: 8px; }
    
    .cards-grid { display: grid; grid-template-columns: 1fr; gap: 10px; } @media(min-width: 480px) { .cards-grid { grid-template-columns: 1fr 1fr; } }
    .card-block { position: relative; border: 2px solid transparent; border-radius: 14px; padding: 14px; background: 0 0; max-height: none; overflow: hidden; display: flex; flex-direction: column; }
    .card-block .term, .card-block .definition { margin: auto 0; width: 100%; word-break: break-word; }
    .card-block .definition { display: none; text-align: center; margin-top: 6px; } .card-block.flipped .definition { display: block; } .card-block .term { text-align: center; }
    .cb-time { position: absolute; right: 10px; bottom: 8px; font-size: 12px; color: var(--muted); }
    .card-block.grade-echec { border-color: var(--red); } .card-block.grade-difficile { border-color: var(--amber); } .card-block.grade-bien { border-color: var(--blue); } .card-block.grade-facile { border-color: var(--green); } .card-block.grade-unseen { border-color: #9ca3af; }
    
    .subject-menu { position: absolute; top: 52px; left: 10px; background: var(--surface); color: var(--text); border: 1px solid var(--border); border-radius: var(--radius-md); min-width: 220px; box-shadow: 0 10px 30px rgba(0,0,0,.35); padding: 6px; z-index: 1000; display: none; }
    .subject-item { display: flex; align-items: center; gap: 8px; padding: 8px 10px; border-radius: 10px; cursor: pointer; } .subject-item:hover { background: rgba(255,255,255,.06); } .subject-item .name { font-weight: 800; flex: 1; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; } .subject-item .meta { font-size: 12px; color: var(--muted); } .subject-item .subject-actions { margin-left: auto; display: flex; gap: 6px; }
    .wheel { display: flex; align-items: center; gap: 12px; padding: 10px 12px; border: 1px solid var(--border); border-radius: var(--radius-md); background: rgba(255,255,255,.04); touch-action: none; user-select: none; cursor: ns-resize; }
    .wheel .name, .wheel .wheel-value { font-weight: 800; font-size: 13px; } .wheel .hint { color: var(--muted); font-size: 12px; } .wheel .wheel-value { margin-left: auto; font-weight: 900; }
    .swatches { display: flex; gap: 8px; flex-wrap: wrap; } .swatch { width: 26px; height: 26px; border-radius: 8px; border: 1px solid var(--border); background: var(--sw,#6366f1); cursor: pointer; position: relative; } .swatch.is-active::after { content: ''; position: absolute; inset: -3px; border: 2px solid var(--primary); border-radius: 10px; }
    .img-lightbox { position: fixed; inset: 0; display: none; background: 0 0; z-index: 10000; } .img-lightbox.open { display: block; }
    .img-stage { position: absolute; inset: 0; width: 100%; height: 100%; overflow: hidden; touch-action: none; cursor: grab; } .img-canvas { position: absolute; top: 0; left: 0; transform-origin: 0 0; will-change: transform; }
    
    .s-control { display: flex; align-items: center; gap: 15px; padding: 0 14px 15px; }
    .s-slider-container { flex: 1; display: flex; align-items: center; height: 40px; position: relative; }
    .s-slider { -webkit-appearance: none; appearance: none; width: 100%; height: 6px; background: var(--border); border-radius: 3px; outline: none; cursor: grab; }
    .s-slider::-webkit-slider-thumb { -webkit-appearance: none; appearance: none; width: 22px; height: 22px; background: var(--primary); border-radius: 50%; cursor: pointer; border: 3px solid var(--surface); box-shadow: 0 1px 3px rgba(0,0,0,0.3); margin-top: 0; position: relative; z-index: 2; }

    .s-stepper { display: flex; align-items: center; gap: 10px; background: var(--border); border-radius: 8px; padding: 4px; margin-left: auto; }
    .step-btn { width: 32px; height: 32px; border-radius: 6px; border: none; background: var(--surface); color: var(--text); font-size: 18px; font-weight: bold; cursor: pointer; display: flex; align-items: center; justify-content: center; }
    .step-btn:active { transform: scale(0.9); background: var(--primary); color: #fff; }
    .step-val { min-width: 30px; text-align: center; font-weight: 900; font-size: 15px; }
    
    .settings-page { padding: 0 12px; }
    .settings-hero { font-size: 28px; font-weight: 900; padding: 16px 4px 12px; }
    .settings-section { background: var(--surface); border: 1px solid var(--border); border-radius: 12px; margin-bottom: 14px; overflow: hidden; }
    .settings-section .section-title { padding: 10px 14px 6px; font-size: 12px; text-transform: uppercase; letter-spacing: 0.4px; color: var(--muted); margin: 0; }
    .settings-row { display: flex; align-items: center; padding: 11px 14px; border-bottom: 1px solid var(--border); gap: 12px; cursor: pointer; transition: background 0.15s; }
    .settings-row:last-child { border-bottom: none; }
    .settings-row:active { background: rgba(255,255,255,0.04); }
    .settings-row .s-icon { width: 30px; height: 30px; border-radius: 7px; display: flex; align-items: center; justify-content: center; font-size: 16px; flex-shrink: 0; color: #fff; }
    .s-icon.blue { background: #3b82f6; } .s-icon.green { background: #22c55e; } .s-icon.red { background: #ef4444; }
    .s-icon.dynamic { background: var(--primary) !important; transition: background 0.3s ease; }
    .s-icon.danger { background: var(--red) !important; }.s-icon.purple { background: #8b5cf6; } .s-icon.orange { background: #f59e0b; } .s-icon.gray { background: #6b7280; }
    .s-icon.teal { background: #14b8a6; } .s-icon.pink { background: #ec4899; }
    .settings-row .s-label { flex: 1; min-width: 0; }
    .settings-row .s-title { font-weight: 600; font-size: 15px; }
    .settings-row .s-sub { font-size: 12px; color: var(--muted); margin-top: 1px; }
    .settings-row .s-value { color: var(--muted); font-size: 14px; }
    .settings-row .s-chevron { color: var(--muted); font-size: 16px; opacity: 0.6; }
    .s-toggle { width: 48px; height: 28px; border-radius: 14px; background: var(--border); position: relative; cursor: pointer; transition: background 0.2s; flex-shrink: 0; }
    .s-toggle.on { background: var(--primary); }
    .s-toggle::after { content: ''; position: absolute; width: 24px; height: 24px; border-radius: 50%; background: #fff; top: 2px; left: 2px; transition: transform 0.2s; box-shadow: 0 1px 3px rgba(0,0,0,0.2); }
    .s-toggle.on::after { transform: translateX(20px); }
    .settings-section .swatches { padding: 0; gap: 6px; }
    .settings-section .swatch { width: 24px; height: 24px; }
    .settings-footer { text-align: center; padding: 20px; color: var(--muted); font-size: 12px; }
    .toast { position: fixed; bottom: calc(80px + env(safe-area-inset-bottom)); left: 50%; transform: translateX(-50%) translateY(100px); background: var(--surface); color: var(--text); padding: 12px 20px; border-radius: 12px; border: 1px solid var(--border); box-shadow: 0 8px 32px rgba(0,0,0,0.3); font-weight: 600; font-size: 14px; z-index: 9999; opacity: 0; transition: transform 0.3s cubic-bezier(0.34, 1.56, 0.64, 1), opacity 0.3s; pointer-events: none; max-width: 90%; text-align: center; }
    .toast.show { transform: translateX(-50%) translateY(0); opacity: 1; }
    .toast.success { border-left: 4px solid var(--green); } .toast.error { border-left: 4px solid var(--red); } .toast.info { border-left: 4px solid var(--primary); }
    
    .progress-bar { position: absolute; top: 0; left: 0; height: 3px; background: linear-gradient(90deg, var(--primary), var(--green)); border-radius: 0 3px 3px 0; transition: width 0.4s cubic-bezier(0.34, 1.56, 0.64, 1); z-index: 5; }
    
    @keyframes fadeSlideIn { from { opacity: 0; transform: translateY(12px); } to { opacity: 1; transform: translateY(0); } }
    main#view > * { animation: fadeSlideIn 0.25s ease-out; }
    
    .card-block, .deck-item { transition: transform 0.2s, border-color 0.2s, box-shadow 0.2s, background-color 0.3s; }
    .card-block:active, .deck-item:active { transform: scale(0.98); }
    
    .skeleton { background: linear-gradient(90deg, var(--border) 25%, var(--surface) 50%, var(--border) 75%); background-size: 200% 100%; animation: skeleton-loading 1.5s infinite; border-radius: 8px; }
    @keyframes skeleton-loading { 0% { background-position: 200% 0; } 100% { background-position: -200% 0; } }
    
    .focus-mode .topbar, .focus-mode .review-top { opacity: 0.3; transition: opacity 0.3s; }
    .focus-mode .topbar:hover, .focus-mode .review-top:hover { opacity: 1; }
    
    img { opacity: 1 !important; transition: none; }
</style>
</head>
<body>
  <div class="wrapper">
    <div class="phone" id="app">
       <header class="topbar">
        <button class="back" id="backBtn" title="Retour">‚Üê Retour</button>
        <div class="title" id="title">Deck</div>
        <div class="spacer"></div>
        <a href="https://schedulepv.web.app/" target="_blank" rel="noopener" class="btn btn--primary btn--tiny" style="flex-shrink:0;text-decoration:none;width:auto;padding:6px 12px;">üìÖ</a>
      </header>
      <main id="view"></main>
      <div class="bottom-actions" id="bottomActions">
        <button class="action btn" id="cardsBtn">Cartes</button>
        <button class="action btn" id="settingsBtn">Param√®tres</button>
      </div>
      <footer class="revision-bar" id="revisionBar">
        <button id="startReviewBtn" class="rev-btn btn btn--solid btn--primary">R√©vision</button>
      </footer>
      <footer id="reviewActionsBar" class="review-actions-bar" aria-live="polite"></footer>
    </div>
  </div>

<script type="text/plain" id="rawMath">


***

**Convention typographique :** $\mathbb{K} \in \{\mathbb{R}, \mathbb{C}\}$, $E$ d√©signe un espace vectoriel norm√© (evn), sauf mention contraire. Toutes les hypoth√®ses sont n√©cessaires sauf mention explicite.

---

# CHAPITRE 1 ‚Äî Suites, fonctions de la variable r√©elle

## FLASHCARD 1 ‚Äî Th√©or√®me de Bolzano-Weierstrass

### RECTO
**Th√©or√®me 1 ‚Äî Bolzano-Weierstrass**

**Contexte :** Soit $(u_n)_{n \in \mathbb{N}}$ une suite de r√©els (ou de $\mathbb{R}^d$).

√ânoncer le th√©or√®me de Bolzano-Weierstrass avec ses hypoth√®ses exactes et sa conclusion.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $(u_n)_{n \in \mathbb{N}}$ est une suite born√©e de $\mathbb{R}^d$ (ou de $\mathbb{R}$), $d \ge 1$ fix√©.
*   ($\mathbb{R}^d$ est de dimension finie, muni d'une norme quelconque ‚Äî toutes √©quivalentes.)

**√ânonc√© formel :**

$$ \forall (u_n)_{n \in \mathbb{N}} \in (\mathbb{R}^d)^{\mathbb{N}}, \quad (u_n) \text{ born√©e} \implies \exists \varphi : \mathbb{N} \to \mathbb{N} \text{ strictement croissante}, \exists \ell \in \mathbb{R}^d, \quad u_{\varphi(n)} \xrightarrow[n \to +\infty]{} \ell $$

**D√©monstration (Esquisse) :**

*   **Cas $d=1$ :** Construction par dichotomie ‚Äî on encadre la suite dans $[a_n, b_n]$ avec $b_n - a_n \to 0$, en choisissant √† chaque √©tape le demi-intervalle contenant une infinit√© de termes. Le th√©or√®me des suites adjacentes (ou des intervalles embo√Æt√©s) donne la limite $\ell$.
*   **Cas $d \ge 2$ :** Extraction diagonale ‚Äî on extrait d'abord une sous-suite convergente pour la premi√®re coordonn√©e, puis une sous-sous-suite pour la deuxi√®me, etc. (proc√©d√© diagonal, voir √Ä conna√Ætre 1).
*   **Outil cl√© :** Compl√©tude de $\mathbb{R}$ + caract√©risation des compacts de $\mathbb{R}^d$ (ferm√©s born√©s).

### 
**Subtilit√©s :**

*   Le th√©or√®me est faux en dimension infinie : dans un evn de dimension infinie, la boule unit√© ferm√©e n'est pas compacte (th√©or√®me de Riesz). La suite $(e_n)$ des vecteurs de base dans $\ell^2(\mathbb{N})$ est born√©e mais n'admet aucune sous-suite convergente.
*   La borne est indispensable : $(u_n) = n$ est non born√©e et n'admet aucune sous-suite convergente dans $\mathbb{R}$.
*   La limite $\ell$ n'est pas n√©cessairement unique (la suite peut avoir plusieurs valeurs d'adh√©rence) ; le th√©or√®me affirme l'existence d'une valeur d'adh√©rence.
*   **Valeurs d'adh√©rence :** L'ensemble des limites de sous-suites extraites de $(u_n)$ est un ferm√© born√© non vide de $\mathbb{R}^d$.

**Extensions :**

*   Valable dans tout espace m√©trique compact (c'est m√™me une caract√©risation √©quivalente de la compacit√© s√©quentielle).
*   En dimension infinie, il faut remplacer par la compacit√© faible (th√©or√®me de Banach-Alaoglu), hors programme MP*.
*   Dans $\mathbb{C}^d \simeq \mathbb{R}^{2d}$ : le th√©or√®me s'applique directement.

**Pi√®ges classiques :**
*   ‚ùå Confondre ¬´ born√©e ¬ª et ¬´ convergente ¬ª : une suite born√©e n'est pas n√©cessairement convergente (ex : $u_n = (-1)^n$).
*   ‚ùå Oublier que l'extraction $\varphi$ doit √™tre strictement croissante (d√©finition de sous-suite).
*   ‚ùå Appliquer ce th√©or√®me dans un evn de dimension infinie sans v√©rification de compacit√©.
*   ‚ùå Confondre ¬´ admet une sous-suite convergente ¬ª et ¬´ est de Cauchy ¬ª.

---

## FLASHCARD 2 ‚Äî √Ä conna√Ætre 1 : Proc√©d√© diagonal

### RECTO
**√Ä conna√Ætre 1 ‚Äî Proc√©d√© diagonal de Cantor**

**Contexte :** On dispose d'une suite $(u_n)_{n \in \mathbb{N}}$ et d'une famille d√©nombrable de propri√©t√©s $\mathcal{P}_k$, $k \in \mathbb{N}$.

√ânoncer le proc√©d√© d'extraction diagonale et son utilit√© principale.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $(u_n)_{n \in \mathbb{N}}$ est une suite dans un ensemble $X$.
*   Pour chaque $k \in \mathbb{N}$, il existe une extractrice $\varphi_k : \mathbb{N} \to \mathbb{N}$ strictement croissante telle que la sous-suite $(u_{\varphi_k(n)})_n$ v√©rifie la propri√©t√© $\mathcal{P}_k$.

**√ânonc√© formel :**

On construit par r√©currence une suite d'extractrices embo√Æt√©es :
$$ \varphi_0, \quad \varphi_1 = \psi_1 \circ \varphi_0, \quad \varphi_2 = \psi_2 \circ \varphi_1, \dots $$
telles que $(u_{\varphi_k(n)})_n$ v√©rifie $\mathcal{P}_0, \mathcal{P}_1, \dots, \mathcal{P}_k$ simultan√©ment.

La suite diagonale est d√©finie par :
$$ \sigma(n) = \varphi_n(n), \quad n \in \mathbb{N}. $$
Alors $\sigma$ est strictement croissante et $(u_{\sigma(n)})_{n \in \mathbb{N}}$ v√©rifie simultan√©ment toutes les propri√©t√©s $\mathcal{P}_k$, $k \in \mathbb{N}$.

**D√©monstration (Esquisse) :**

*   **Construction :** $\varphi_0$ extrait une sous-suite v√©rifiant $\mathcal{P}_0$ ; $\varphi_1$ extrait de $\varphi_0$ une sous-suite v√©rifiant $\mathcal{P}_1$ (elle v√©rifie encore $\mathcal{P}_0$ par sous-extraction), etc.
*   **Diagonale :** Pour $n \ge k$, $\sigma(n) = \varphi_n(n)$ est une extraction de $\varphi_k$, donc v√©rifie $\mathcal{P}_k$. Ainsi $(u_{\sigma(n)})_{n \ge k}$ v√©rifie $\mathcal{P}_k$, ce qui est suffisant pour les propri√©t√©s asymptotiques.
*   **Stricte croissance de $\sigma$ :** Se v√©rifie par construction embo√Æt√©e.

### 
**Subtilit√©s :**

*   La propri√©t√© $\mathcal{P}_k$ n'est v√©rifi√©e par la suite diagonale qu'√† partir du rang $k$ ‚Äî suffisant pour les limites.
*   Le proc√©d√© n√©cessite une famille d√©nombrable de propri√©t√©s. Pour une famille ind√©nombrable, il √©choue en g√©n√©ral.
*   **Usage typique :** Bolzano-Weierstrass en dimension $d$ (extraction coordonn√©e par coordonn√©e), compacit√© s√©quentielle, normalit√© des familles de fonctions (Arzel√†-Ascoli, hors programme).

**Extensions :**

*   Fondamental en analyse fonctionnelle (extraction d'une sous-suite faiblement convergente).
*   Utilis√© dans la preuve du th√©or√®me d'Arzel√†-Ascoli.

**Pi√®ges classiques :**
*   ‚ùå Croire que la suite diagonale v√©rifie $\mathcal{P}_k$ d√®s $n=0$ ‚Äî elle ne le v√©rifie que pour $n \ge k$.
*   ‚ùå Oublier de v√©rifier que $\sigma$ est bien strictement croissante.
*   ‚ùå Appliquer le proc√©d√© √† une famille non d√©nombrable.

---

## FLASHCARD 3 ‚Äî Th√©or√®me 2 : Limite monotone

### RECTO
**Th√©or√®me 2 ‚Äî Th√©or√®me de la limite monotone**

**Contexte :** Soit $(u_n)_{n \in \mathbb{N}}$ une suite r√©elle.

√ânoncer le th√©or√®me de la limite monotone dans ses deux cas, avec conclusion pr√©cise sur la valeur de la limite.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $(u_n)_{n \in \mathbb{N}} \in \mathbb{R}^{\mathbb{N}}$, suite de r√©els.
*   $(u_n)$ est monotone (croissante ou d√©croissante au sens large).

**√ânonc√© formel :**

Si $(u_n)$ est croissante :
$$ u_n \xrightarrow[n \to +\infty]{} \sup_{n \in \mathbb{N}} u_n \in \mathbb{R} \cup \{+\infty\}. $$

Si $(u_n)$ est d√©croissante :
$$ u_n \xrightarrow[n \to +\infty]{} \inf_{n \in \mathbb{N}} u_n \in \mathbb{R} \cup \{-\infty\}. $$

Plus pr√©cis√©ment :

*   Si $(u_n)$ est croissante et major√©e, alors $(u_n)$ converge dans $\mathbb{R}$ vers $\sup_n u_n$.
*   Si $(u_n)$ est croissante et non major√©e, alors $u_n \to +\infty$.

**D√©monstration (Esquisse) :**

Soit $\ell = \sup_n u_n \in \mathbb{R} \cup \{+\infty\}$.
*   Si $\ell \in \mathbb{R}$ : par d√©finition du supremum, $\forall \varepsilon > 0, \exists N, u_N > \ell - \varepsilon$. Par croissance, $\forall n \ge N, \ell - \varepsilon < u_N \le u_n \le \ell$, donc $|u_n - \ell| < \varepsilon$.
*   Si $\ell = +\infty$ : $\forall M > 0, \exists N, u_N > M$, donc $\forall n \ge N, u_n \ge u_N > M$.

### 
**Subtilit√©s :**

*   Ce th√©or√®me est une cons√©quence directe de la propri√©t√© de la borne sup√©rieure de $\mathbb{R}$ (compl√©tude archim√©dienne) ‚Äî c'est m√™me quasi-√©quivalent.
*   Monotonie au sens large suffit (pas besoin de stricte).
*   Le th√©or√®me est faux dans $\mathbb{Q}$ : une suite croissante born√©e de rationnels peut converger vers un irrationnel (donc pas de limite dans $\mathbb{Q}$).

**Extensions :**

*   Analogue pour les fonctions monotones : Toute fonction $f : \mathbb{R} \to \mathbb{R}$ monotone admet des limites √† gauche et √† droite en tout point (th√©or√®me de la limite monotone pour les fonctions).
*   Pas d'analogue direct en dimension $\ge 2$ (la notion d'ordre total dispara√Æt).

**Pi√®ges classiques :**
*   ‚ùå Oublier que la limite peut √™tre $+\infty$ ou $-\infty$ (la suite converge dans $\overline{\mathbb{R}}$ toujours).
*   ‚ùå Confondre la limite avec la valeur atteinte : $\sup_n u_n$ peut ne pas √™tre atteint.
*   ‚ùå Utiliser ce th√©or√®me sans v√©rifier la monotonie (une suite born√©e non monotone n'est pas n√©cessairement convergente).

---

## FLASHCARD 4 ‚Äî Th√©or√®me 3 : Limite par encadrement / minoration / majoration

### RECTO
**Th√©or√®me 3 ‚Äî Limite par encadrement, minoration, majoration (Gendarmes)**

**Contexte :** Soient $(u_n), (v_n), (w_n)$ des suites r√©elles.

√ânoncer les trois versions du th√©or√®me des gendarmes (encadrement, minoration vers $+\infty$, majoration vers $-\infty$) avec hypoth√®ses exactes.

### VERSO
**Hypoth√®ses et √©nonc√© formel :**

**Version 1 ‚Äî Encadrement (convergence) :**
$$ (\exists N_0 \in \mathbb{N}, \forall n \ge N_0, v_n \le u_n \le w_n) \text{ et } (v_n \to \ell \text{ et } w_n \to \ell, \ell \in \mathbb{R}) \implies u_n \to \ell. $$

**Version 2 ‚Äî Minoration (limite $+\infty$) :**
$$ (\exists N_0 \in \mathbb{N}, \forall n \ge N_0, u_n \ge v_n) \text{ et } (v_n \to +\infty) \implies u_n \to +\infty. $$

**Version 3 ‚Äî Majoration (limite $-\infty$) :**
$$ (\exists N_0 \in \mathbb{N}, \forall n \ge N_0, u_n \le w_n) \text{ et } (w_n \to -\infty) \implies u_n \to -\infty. $$

**D√©monstration (Esquisse) :**

*   **Version 1 :** $|u_n - \ell| \le \max(|v_n - \ell|, |w_n - \ell|) \to 0$ (car $v_n \le u_n \le w_n$ et $v_n, w_n \to \ell$).
*   **Version 2 :** $\forall M > 0, \exists N_1$ tel que $n \ge N_1 \implies v_n > M$, donc $u_n \ge v_n > M$ pour $n \ge \max(N_0, N_1)$.

### 
**Subtilit√©s :**

*   L'encadrement n'est requis qu'√† partir d'un certain rang $N_0$ (condition asymptotique).
*   Les limites de $v_n$ et $w_n$ doivent √™tre √©gales (m√™me valeur $\ell \in \mathbb{R}$) pour la version convergence. Si $v_n \to \ell_1 \neq \ell_2 \leftarrow w_n$, on ne peut rien conclure.
*   **Version vectorielle :** Le th√©or√®me d'encadrement n'existe pas directement en dimension $\ge 2$ (pas d'ordre total), mais on peut l'appliquer coordonn√©e par coordonn√©e ou via la norme : si $\|u_n - \ell\| \le w_n \to 0$, alors $u_n \to \ell$.

**Extensions :**

*   Analogue pour les fonctions : si $v(x) \le f(x) \le w(x)$ au voisinage de $a$ et $v(x), w(x) \to \ell$, alors $f(x) \to \ell$.
*   Utilis√© massivement pour prouver $n^{1/n} \to 1$, $\frac{\ln n}{n} \to 0$, etc.

**Pi√®ges classiques :**
*   ‚ùå Appliquer l'encadrement avec $v_n \to \ell_1$ et $w_n \to \ell_2$ avec $\ell_1 \neq \ell_2$ ‚Äî invalide.
*   ‚ùå Oublier que la conclusion ne donne pas $v_n \le u_n \le w_n$ pour tout $n$, seulement pour $n$ assez grand.
*   ‚ùå Confondre avec le th√©or√®me de comparaison (qui ne donne qu'une in√©galit√© sur les limites, pas une √©galit√©).

---

## FLASHCARD 5 ‚Äî Th√©or√®me 4 : Valeurs interm√©diaires

### RECTO
**Th√©or√®me 4 ‚Äî Th√©or√®me des valeurs interm√©diaires (TVI)**

**Contexte :** Soit $f : I \to \mathbb{R}$ une fonction d√©finie sur un intervalle $I \subseteq \mathbb{R}$.

√ânoncer le TVI avec hypoth√®ses exactes. Donner √©galement la version avec $f(a) \cdot f(b) < 0$.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $I \subseteq \mathbb{R}$ est un intervalle (connexe par arcs dans $\mathbb{R}$).
*   $f : I \to \mathbb{R}$ est continue sur $I$.
*   $a, b \in I$ avec $a < b$.

**√ânonc√© formel :**

$$ \forall \gamma \text{ compris entre } f(a) \text{ et } f(b), \quad \exists c \in [a, b], \quad f(c) = \gamma. $$

Formellement : si $f(a) \le f(b)$,
$$ \forall \gamma \in [f(a), f(b)], \quad \exists c \in [a, b], \quad f(c) = \gamma. $$

**Corollaire imm√©diat (annulation) :**
$$ f(a) \cdot f(b) < 0 \implies \exists c \in ]a, b[, \quad f(c) = 0. $$

**D√©monstration (Esquisse) :**

*   **M√©thode de la borne sup√©rieure :** Poser $c = \sup \{x \in [a, b] \mid f(x) \le \gamma\}$. Par continuit√© de $f$ et d√©finition du supremum, $f(c) = \gamma$.
*   **Alternative (dichotomie) :** Construire des suites adjacentes par dichotomie ; par compl√©tude de $\mathbb{R}$ et continuit√© de $f$, la limite commune v√©rifie $f(c) = \gamma$.
*   **Cl√© :** Connexit√© par arcs de $[a, b]$ + continuit√© $\implies$ l'image est un intervalle.

### 
**Subtilit√©s :**

*   $c$ n'est pas n√©cessairement unique (peut y en avoir plusieurs).
*   L'intervalle est indispensable : sur $\mathbb{Q}$ (non connexe), le TVI est faux (ex : $f(x) = x^2$ sur $\mathbb{Q}$, $\gamma = 2$, pas d'ant√©c√©dent rationnel).
*   Le TVI garantit l'existence mais pas la constructivit√© de $c$ (en g√©n√©ral).
*   Dans le corollaire : on peut affirmer $c \in ]a, b[$ (ouvert) car $f(a)$ et $f(b)$ sont de signes strictement oppos√©s, donc $f(c) = 0 \neq f(a)$ et $\neq f(b)$.

**Extensions :**

*   **Version vectorielle :** Le TVI se g√©n√©ralise : si $f : [a, b] \to \mathbb{R}^d$ est continue, l'image $f([a, b])$ est un connexe par arcs de $\mathbb{R}^d$ (mais pas n√©cessairement un intervalle en dimension $\ge 2$).
*   **Version topologique :** L'image continue d'un connexe est connexe.
*   Le TVI est √† la base des m√©thodes de dichotomie num√©rique.

**Pi√®ges classiques :**
*   ‚ùå Appliquer le TVI √† une fonction d√©finie sur une r√©union d'intervalles disjoints (pas un intervalle).
*   ‚ùå Conclure √† l'unicit√© de $c$ sans hypoth√®se suppl√©mentaire (stricte monotonie).
*   ‚ùå Oublier la continuit√© ‚Äî une fonction discontinue peut ne pas prendre toutes les valeurs interm√©diaires.
*   ‚ùå √âcrire $c \in [a, b]$ alors que $f(a) \cdot f(b) < 0$ assure $c \in ]a, b[$.

---

## FLASHCARD 6 ‚Äî Corollaire 1

### RECTO
**Corollaire 1 ‚Äî Image d'un intervalle par une fonction continue**

**Contexte :** Soit $f : I \to \mathbb{R}$ continue sur un intervalle $I$.

√ânoncer le corollaire sur l'image d'un intervalle par une fonction continue. Traiter le cas compact s√©par√©ment.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $I \subseteq \mathbb{R}$ est un intervalle (quelconque : ouvert, ferm√©, born√©, non born√©).
*   $f : I \to \mathbb{R}$ est continue sur $I$.

**√ânonc√© formel :**

$$ f(I) \text{ est un intervalle de } \mathbb{R}. $$

**Cas particulier fondamental (compact) :**

Si de plus $I = [a, b]$ est un segment ($a < b$, $a, b \in \mathbb{R}$), alors :
$$ f([a, b]) = [m, M] \quad \text{avec } m = \min_{[a, b]} f \in \mathbb{R}, \quad M = \max_{[a, b]} f \in \mathbb{R}. $$
En particulier, $f$ est born√©e et atteint ses bornes sur $[a, b]$.

**D√©monstration (Esquisse) :**

*   **$f(I)$ est un intervalle :** D√©coule directement du TVI (toute valeur entre $f(a)$ et $f(b)$ est atteinte, pour tous $a<b$ dans $I$).
*   **Cas compact :** $f([a, b])$ est une partie compacte de $\mathbb{R}$ (image continue d'un compact), donc ferm√©e et born√©e, donc de la forme $[m, M]$.

### 
**Subtilit√©s :**

*   Sur un intervalle ouvert ou non born√©, $f$ continue n'est pas n√©cessairement born√©e ni n'atteint ses bornes : ex. $f(x) = x$ sur $]0, 1[$, $f(x) = 1/x$ sur $]0, 1]$.
*   L'image est un intervalle mais pas n√©cessairement ferm√©/born√©.
*   Le fait que $m$ et $M$ soient atteints (et non seulement des bornes infimales) est crucial ‚Äî c'est le **th√©or√®me de Weierstrass**.

**Extensions :**

*   En dimension $\ge 2$ : l'image d'un connexe par arcs est un connexe par arcs ; l'image d'un compact est un compact.

**Pi√®ges classiques :**
*   ‚ùå Conclure que $f$ est born√©e sur un intervalle quelconque sans hypoth√®se de compacit√©.
*   ‚ùå Confondre ¬´ $f(I)$ est un intervalle ¬ª et ¬´ $f$ est injective ¬ª.

---

## FLASHCARD 7 ‚Äî Proposition 1

### RECTO
**Proposition 1 ‚Äî Continuit√© des fonctions monotones, r√©ciproque d'une bijection continue**

**Contexte :** Soit $f : I \to \mathbb{R}$ d√©finie sur un intervalle $I \subseteq \mathbb{R}$.

√ânoncer la proposition sur la continuit√© d'une fonction monotone sur un intervalle et le th√©or√®me de la bijection r√©ciproque.

### VERSO
**Hypoth√®ses et √©nonc√© :**

**Partie 1 ‚Äî Discontinuit√©s d'une fonction monotone :**

$f : I \to \mathbb{R}$ monotone. Alors $f$ admet en tout point $x_0 \in I$ des limites √† gauche et √† droite (dans $\overline{\mathbb{R}}$), et l'ensemble des points de discontinuit√© de $f$ est au plus d√©nombrable.

**Partie 2 ‚Äî Th√©or√®me de la bijection :**

$$ f : [a, b] \to \mathbb{R} \text{ continue et strictement monotone} \implies f \text{ est un hom√©omorphisme de } [a, b] \text{ sur } [f(a), f(b)] \text{ (ou } [f(b), f(a)]). $$

Plus pr√©cis√©ment :

*   $f$ est bijective de $[a, b]$ sur $f([a, b]) = [\min(f(a), f(b)), \max(f(a), f(b))]$.
*   La r√©ciproque $f^{-1}$ est continue et strictement monotone (m√™me sens de variation).

**D√©monstration (Esquisse) :**

*   **Injectivit√© :** Stricte monotonie $\implies$ injectivit√© imm√©diate.
*   **Surjectivit√© :** TVI donne que l'image est un intervalle ; la stricte monotonie identifie cet intervalle √† $[f(a), f(b)]$.
*   **Continuit√© de $f^{-1}$ :** Image d'un compact par $f$ est un compact ; $f$ est un hom√©omorphisme (image d'un ouvert relatif = ouverte relative, car $f$ strictement monotone sur un intervalle).

### 
**Subtilit√©s :**

*   La continuit√© de $f^{-1}$ est automatique ici (pas besoin de la v√©rifier s√©par√©ment) car $[a, b]$ est compact ‚Äî c'est une propri√©t√© g√©n√©rale : une bijection continue d'un compact dans un s√©par√© est un hom√©omorphisme.
*   Sur un intervalle ouvert ou non compact, la r√©ciproque d'une bijection continue peut ne pas √™tre continue (contre-exemple non trivial hors programme).
*   L'hypoth√®se ¬´ strictement monotone ¬ª est indispensable pour l'injectivit√©.

**Extensions :**

*   En dimension $\ge 2$, le th√©or√®me de la fonction inverse (Cauchy-Lipschitz diff√©rentiel) g√©n√©ralise ce r√©sultat.

**Pi√®ges classiques :**
*   ‚ùå Confondre monotonie (au sens large) et stricte monotonie pour la bijectivit√©.
*   ‚ùå Oublier de pr√©ciser l'intervalle d'arriv√©e exact.

---

## FLASHCARD 8 ‚Äî Th√©or√®me 5 : Continuit√© uniforme (Heine)

### RECTO
**Th√©or√®me 5 ‚Äî Th√©or√®me de Heine (continuit√© uniforme sur un segment)**

**Contexte :** Soit $f : [a, b] \to E$ une fonction d√©finie sur un segment.

√ânoncer le th√©or√®me de Heine avec hypoth√®ses exactes, en pr√©cisant l'espace d'arriv√©e.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $a < b$, $a, b \in \mathbb{R}$ (segment $[a, b]$ compact).
*   $E$ est un espace m√©trique (ou evn) quelconque (pas n√©cessairement de dimension finie).
*   $f : [a, b] \to E$ est continue sur $[a, b]$.

**√ânonc√© formel :**

$f$ est **uniform√©ment continue** sur $[a, b]$ :
$$ \forall \varepsilon > 0, \exists \delta > 0, \forall x, y \in [a, b], \quad |x - y| < \delta \implies d(f(x), f(y)) < \varepsilon. $$

**D√©monstration (Esquisse) :**

*   **Par l'absurde :** Si $f$ n'est pas uniform√©ment continue, $\exists \varepsilon_0 > 0, \exists (x_n), (y_n) \in [a, b]$ avec $|x_n - y_n| < 1/n$ et $d(f(x_n), f(y_n)) \ge \varepsilon_0$.
*   **Bolzano-Weierstrass :** $(x_n)$ born√©e, on extrait $x_{\varphi(n)} \to c \in [a, b]$. Alors $y_{\varphi(n)} \to c$ aussi.
*   **Continuit√© de $f$ en $c$ :** $d(f(x_{\varphi(n)}), f(y_{\varphi(n)})) \le d(f(x_{\varphi(n)}), f(c)) + d(f(c), f(y_{\varphi(n)})) \to 0$ ‚Äî contradiction.

### 
**Subtilit√©s :**

*   La compacit√© de $[a, b]$ est essentielle : $f(x) = 1/x$ est continue sur $]0, 1]$ mais pas uniform√©ment continue.
*   Le th√©or√®me s'√©tend √† tout espace m√©trique compact (pas seulement $[a, b]$).
*   L'espace d'arriv√©e $E$ peut √™tre un evn quelconque (de dimension finie ou infinie) ‚Äî la preuve ne l'utilise que comme espace m√©trique.

**Extensions :**

*   **Caract√©risation :** Sur $]a, b[$, $f$ est uniform√©ment continue $\iff f$ se prolonge par continuit√© en $a$ et en $b$.
*   L'uniforme continuit√© implique : $f$ transforme les suites de Cauchy en suites de Cauchy, permettant le prolongement aux compl√©t√©s.

**Pi√®ges classiques :**
*   ‚ùå Confondre continuit√© et continuit√© uniforme : la continuit√© uniforme est plus forte et est une propri√©t√© globale.
*   ‚ùå Oublier que $\delta$ ne d√©pend pas du point $x$ (uniformit√©).
*   ‚ùå Appliquer Heine sur un intervalle ouvert ou non born√©.

---

## FLASHCARD 9 ‚Äî Th√©or√®me 6 : CNS d'extremum local (point int√©rieur)

### RECTO
**Th√©or√®me 6 ‚Äî Condition n√©cessaire d'extremum local en un point int√©rieur (scalaire)**

**Contexte :** Soit $f : I \to \mathbb{R}$ d√©rivable sur un intervalle ouvert $I$.

√ânoncer la condition n√©cessaire d'extremum local pour une fonction d√©rivable en un point int√©rieur.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $I \subseteq \mathbb{R}$ est un intervalle ouvert.
*   $f : I \to \mathbb{R}$ est d√©rivable en $x_0 \in I$.
*   $x_0$ est un extremum local de $f$ (maximum ou minimum local).

**√ânonc√© formel :**

$$ f'(x_0) = 0. $$

**D√©monstration (Esquisse) :**

Si $x_0$ est un minimum local : $\forall h > 0$ assez petit, $\frac{f(x_0+h)-f(x_0)}{h} \ge 0$ et $\frac{f(x_0-h)-f(x_0)}{-h} \le 0$. En passant √† la limite, $f'(x_0) \ge 0$ et $f'(x_0) \le 0$, donc $f'(x_0) = 0$.

### 
**Subtilit√©s :**

*   C'est une condition n√©cessaire, non suffisante : $f(x) = x^3$ en $x_0=0$ v√©rifie $f'(0)=0$ sans √™tre un extremum local.
*   Le point doit √™tre **int√©rieur** : en un point fronti√®re (ex : $x_0=a$ dans $[a, b]$), $f'(a)=0$ n'est pas n√©cessaire pour un extremum.
*   La d√©rivabilit√© est indispensable : $f(x) = |x|$ admet un minimum en $0$ sans √™tre d√©rivable en $0$.
*   Les points o√π $f'(x_0)=0$ s'appellent **points critiques** (ou stationnaires).

**Extensions :**

*   Condition suffisante d'ordre 2 : Si $f''(x_0) > 0$, alors $x_0$ est un minimum local strict (voir Thm 45).
*   En dimension $\ge 2$ : CNS $\implies df(x_0) = 0$ (diff√©rentielle nulle), voir Thm 42.

**Pi√®ges classiques :**
*   ‚ùå Confondre CNS et condition suffisante.
*   ‚ùå Oublier de v√©rifier que $x_0$ est int√©rieur √† $I$.
*   ‚ùå Conclure √† un extremum d√®s que $f'(x_0)=0$.

---

## FLASHCARD 10 ‚Äî Th√©or√®me 7 : Rolle

### RECTO
**Th√©or√®me 7 ‚Äî Th√©or√®me de Rolle**

**Contexte :** Soit $f : [a, b] \to \mathbb{R}$, avec $a < b$.

√ânoncer le th√©or√®me de Rolle avec toutes ses hypoth√®ses et sa conclusion pr√©cise.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $-\infty < a < b < +\infty$ (segment born√©).
*   $f : [a, b] \to \mathbb{R}$ est continue sur $[a, b]$.
*   $f$ est d√©rivable sur $]a, b[$ (ouvert strict).
*   $f(a) = f(b)$.

**√ânonc√© formel :**

$$ \exists c \in ]a, b[, \quad f'(c) = 0. $$

**D√©monstration (Esquisse) :**

Par le th√©or√®me de Weierstrass, $f$ atteint son maximum $M$ et son minimum $m$ sur $[a, b]$.
*   **Cas trivial :** Si $M=m$, $f$ est constante, $f' \equiv 0$ et tout $c \in ]a, b[$ convient.
*   **Cas non trivial :** $M \neq m$. L'un au moins (disons $M$) est atteint en un $c \in ]a, b[$ (car $f(a)=f(b)$, si $M=f(a)$ alors $m$ est atteint √† l'int√©rieur). Par le Th√©or√®me 6, $f'(c)=0$.

### 
**Subtilit√©s :**

*   $c \in ]a, b[$ : l'intervalle est ouvert ‚Äî la conclusion ne dit rien sur les bords.
*   Les trois hypoth√®ses sont indispensables : continuit√© sur $[a, b]$, d√©rivabilit√© sur $]a, b[$, et $f(a)=f(b)$.
*   Contre-exemple si $f$ non continue en $a$ ou $b$ : $f(x) = \begin{cases} x & x \in ]0, 1[ \\ 0 & x=0, 1 \end{cases}$.
*   Contre-exemple si $f$ non d√©rivable en un point : $f(x) = |x - 1/2|$ sur $[0, 1]$.

**Extensions :**

*   R√¥le central : sert √† d√©montrer le th√©or√®me des accroissements finis (TAF), Taylor-Lagrange, in√©galit√© de TAF.
*   **Rolle et z√©ros :** Si $P$ est un polyn√¥me de degr√© $n$, $P'$ a au moins $n-1$ z√©ros r√©els (si $P$ a $n$ z√©ros r√©els distincts). Application : $P$ a au plus $n$ z√©ros.
*   Pas de g√©n√©ralisation vectorielle directe : si $f : [a, b] \to \mathbb{R}^d$ avec $d \ge 2$, Rolle est faux en g√©n√©ral (ex : $f(t) = (\cos 2\pi t, \sin 2\pi t)$, $f(0)=f(1)$ mais $f'(t) \neq 0$ pour tout $t$).

**Pi√®ges classiques :**
*   ‚ùå Appliquer Rolle √† $f : [a, b] \to \mathbb{R}^d$ avec $d \ge 2$ ‚Äî invalide.
*   ‚ùå Oublier que la d√©rivabilit√© n'est requise que sur $]a, b[$ (ouvert), pas en $a$ et $b$.
*   ‚ùå Confondre Rolle et TAF (TAF ne demande pas $f(a)=f(b)$).

---

## FLASHCARD 11 ‚Äî Th√©or√®me 8 : Accroissements finis

### RECTO
**Th√©or√®me 8 ‚Äî Th√©or√®me des accroissements finis (TAF)**

**Contexte :** Soit $f : [a, b] \to \mathbb{R}$, avec $a < b$.

√ânoncer le TAF (version √©galit√©) avec hypoth√®ses exactes. Pr√©ciser l'ouverture de l'intervalle o√π vit $c$.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $-\infty < a < b < +\infty$.
*   $f : [a, b] \to \mathbb{R}$ continue sur $[a, b]$.
*   $f$ d√©rivable sur $]a, b[$.

**√ânonc√© formel :**

$$ \exists c \in ]a, b[, \quad f(b) - f(a) = f'(c)(b - a). $$

**D√©monstration (Esquisse) :**
Appliquer le th√©or√®me de Rolle √† la fonction auxiliaire :
$$ g(x) = f(x) - \frac{f(b)-f(a)}{b-a}(x-a). $$
On v√©rifie $g(a) = f(a) = g(b)$ (en d√©veloppant), $g$ est continue sur $[a, b]$ et d√©rivable sur $]a, b[$. Rolle donne $c \in ]a, b[$ avec $g'(c)=0$, i.e., $f'(c) = \frac{f(b)-f(a)}{b-a}$.

### 
**Subtilit√©s :**

*   $c \in ]a, b[$ strict ‚Äî jamais en $a$ ou $b$.
*   **Pas de g√©n√©ralisation en dimension $\ge 2$ (version √©galit√©) :** si $f : [a, b] \to \mathbb{R}^d$, il n'existe pas n√©cessairement de $c$ tel que $f(b) - f(a) = f'(c)(b - a)$ (contre-exemple : courbe de Rolle). C'est pourquoi l'in√©galit√© des accroissements finis (Thm 9) est fondamentale.
*   Le TAF (version √©galit√©) est strictement r√©el-scalaire.

**Extensions :**

*   Donne imm√©diatement : si $f' \ge 0$ sur $]a, b[$, alors $f$ est croissante sur $[a, b]$.
*   Utilis√© pour l'unicit√© dans Cauchy-Lipschitz.

**Pi√®ges classiques :**
*   ‚ùå Appliquer le TAF (version √©galit√©) √† des fonctions √† valeurs vectorielles.
*   ‚ùå Oublier la continuit√© sur $[a, b]$ (ferm√©) et ne garder que la d√©rivabilit√© sur $]a, b[$.
*   ‚ùå Confondre TAF et Rolle.

---

## FLASHCARD 12 ‚Äî Th√©or√®me 9 : In√©galit√© des accroissements finis

### RECTO
**Th√©or√®me 9 ‚Äî In√©galit√© des accroissements finis (IAF)**

**Contexte :** Soit $f : [a, b] \to E$ o√π $E$ est un espace vectoriel norm√©.

√ânoncer l'in√©galit√© des accroissements finis dans le cadre vectoriel, avec hypoth√®ses exactes.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $-\infty < a < b < +\infty$.
*   $E$ est un espace vectoriel norm√© quelconque (dimension finie ou infinie).
*   $f : [a, b] \to E$ est continue sur $[a, b]$ et d√©rivable sur $]a, b[$.
*   Il existe $M \ge 0$ tel que $\forall t \in ]a, b[, \|f'(t)\| \le M$.

**√ânonc√© formel :**

$$ \|f(b) - f(a)\| \le M(b - a). $$

**D√©monstration (Esquisse) :**

*   Appliquer le TAF r√©el √† la fonction r√©elle $\varphi(t) = \|\cdot\| \circ f$ ne fonctionne pas directement (la norme n'est pas d√©rivable en g√©n√©ral).
*   **M√©thode correcte :** Pour tout $\xi \in E^*$ avec $\|\xi\| \le 1$, la fonction $t \mapsto \xi(f(t))$ est r√©elle, continue sur $[a, b]$, d√©rivable sur $]a, b[$, avec $|\xi(f(t))'| = |\xi(f'(t))| \le \|\xi\|\|f'(t)\| \le M$. Le TAF scalaire donne $|\xi(f(b)) - \xi(f(a))| \le M(b-a)$. On conclut par $\|f(b) - f(a)\| = \sup_{\|\xi\| \le 1} |\xi(f(b) - f(a))|$ (Hahn-Banach ou caract√©risation de la norme).
*   **Alternative en dimension finie :** Taylor reste int√©gral donne $f(b) - f(a) = \int_a^b f'(t) dt$ et $\|f(b) - f(a)\| \le \int_a^b \|f'(t)\| dt \le M(b-a)$.

### 
**Subtilit√©s :**

*   C'est le **bon √©nonc√© vectoriel** : contrairement au TAF (version √©galit√©), l'IAF est valable pour $f$ √† valeurs dans un evn quelconque, y compris dimension infinie.
*   La borne $M$ doit majorer $\|f'(t)\|$ sur tout $]a, b[$.
*   **In√©galit√© stricte :** Si $\|f'(t)\| < M$ sur $]a, b[$, on peut avoir √©galit√© dans l'IAF (ex : $f$ lin√©aire).

**Extensions :**

*   Utilis√© massivement : unicit√© Cauchy-Lipschitz, majoration d'erreurs, continuit√© lipschitzienne.
*   Corollaire : Si $f' \equiv 0$ sur $]a, b[$, alors $f$ est constante sur $[a, b]$ (prendre $M=0$).
*   **Version int√©grale :** $\|f(b) - f(a)\| \le \int_a^b \|f'(t)\| dt$ (plus pr√©cis, cf. Taylor reste int√©gral).

**Pi√®ges classiques :**
*   ‚ùå Utiliser le TAF (version √©galit√©) pour les fonctions vectorielles.
*   ‚ùå Majorer $\|f'(t)\|$ seulement en certains points ‚Äî la borne doit √™tre uniforme.
*   ‚ùå Oublier que l'IAF n√©cessite quand m√™me la continuit√© sur $[a, b]$ et la d√©rivabilit√© sur $]a, b[$.

---

## FLASHCARD 13 ‚Äî Th√©or√®me 10 : Limite de la d√©riv√©e, prolongement $C^1$

### RECTO
**Th√©or√®me 10 ‚Äî Th√©or√®me de la limite de la d√©riv√©e / Prolongement $C^1$**

**Contexte :** Soit $f : ]a, b[ \to E$ (ou $f : [a, b[ \to E$) d√©rivable.

√ânoncer le th√©or√®me de la limite de la d√©riv√©e et le th√©or√®me de prolongement $C^1$.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $E$ est un espace vectoriel norm√© complet (de Banach) ‚Äî dimension quelconque.
*   $f : ]a, b[ \to E$ (ou $[a, b[$) est d√©rivable sur $]a, b[$ (resp. $]a, b[$).
*   $f$ est continue en $a$ (si on traite $[a, b[$, sinon on suppose $f$ prolongeable par continuit√© en $a$).
*   $f'$ admet une limite $\ell \in E$ en $a^+$ : $\lim_{t \to a^+} f'(t) = \ell$.

**√ânonc√© formel (prolongement $C^1$) :**

On d√©finit $\tilde{f}(a) = \lim_{t \to a^+} f(t) \in E$ (limite qui existe par IAF).
Alors $\tilde{f}$ est d√©rivable en $a$ √† droite et $\tilde{f}'(a) = \ell$.

En particulier, si $f$ est continue sur $[a, b]$, d√©rivable sur $]a, b[$, et si $f'$ admet une limite $\ell$ en $a^+$ (resp. $b^-$), alors :
$f$ est d√©rivable en $a$ (resp. $b$) et $f'(a) = \ell$ (resp. $f'(b) = \ell$).

**Corollaire (crit√®re $C^1$) :**

Si $f : [a, b] \to E$ est continue sur $[a, b]$, d√©rivable sur $]a, b[$, et si $f'$ se prolonge par continuit√© sur $[a, b]$, alors $f \in C^1([a, b], E)$.

**D√©monstration (Esquisse) :**

Pour $x > a$, $\frac{f(x) - f(a)}{x - a} = \frac{1}{x-a} \int_a^x f'(t) dt \to \ell$ par le lemme de la moyenne (si $f' \to \ell$ uniform√©ment, on peut intervertir limite et int√©grale).
Alternativement : IAF appliqu√© √† $f(x) - f(a) - \ell(x-a)$ donne $\|f(x) - f(a) - \ell(x-a)\| \le \sup_{]a, x[} \|f'(t) - \ell\| \cdot (x-a) = o(x-a)$.

### 
**Subtilit√©s :**

*   La compl√©tude de $E$ est utilis√©e pour garantir l'existence de la limite $\lim_{t \to a^+} f(t)$ via l'IAF (suite de Cauchy).
*   Ce th√©or√®me est fondamental pour v√©rifier la r√©gularit√© $C^1$ en pratique : on d√©rive, on regarde la limite de la d√©riv√©e.
*   **Attention :** La limite de $f'$ en $a$ implique la d√©rivabilit√© de $f$ en $a$ et $f'(a) = \lim f'$ ‚Äî mais on a besoin de la continuit√© de $f$ en $a$ ou de l'existence de la limite de $f$ en $a$.

**Extensions :**

*   G√©n√©ralisation aux fonctions $C^k$ : si $f^{(k)}$ admet une limite continue, alors $f \in C^k$.
*   Utilis√© pour prouver la r√©gularit√© des s√©ries de fonctions et des int√©grales √† param√®tre.

**Pi√®ges classiques :**
*   ‚ùå Oublier de v√©rifier la continuit√© de $f$ en $a$ (ou l'existence de $\lim_{t \to a^+} f(t)$).
*   ‚ùå Appliquer √† $E$ non complet (alors la limite de $f$ en $a$ peut ne pas exister dans $E$).
*   ‚ùå Confondre ¬´ $f'$ admet une limite ¬ª et ¬´ $f'$ est continue ¬ª ‚Äî ce sont des propri√©t√©s √©quivalentes ici (c'est le c≈ìur du th√©or√®me).

---

## FLASHCARD 14 ‚Äî Th√©or√®me 11 : Taylor reste int√©gral

### RECTO
**Th√©or√®me 11 ‚Äî Formule de Taylor avec reste int√©gral**

**Contexte :** Soit $f : I \to E$, $I$ intervalle de $\mathbb{R}$, $E$ evn.

√ânoncer la formule de Taylor avec reste int√©gral, en pr√©cisant la r√©gularit√© requise, la nature de l'intervalle, et l'espace d'arriv√©e.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $I \subseteq \mathbb{R}$ intervalle, $a, b \in I$.
*   $E$ est un espace vectoriel norm√© (dimension quelconque, mais $E$ doit permettre l'int√©gration ‚Äî e.g., $E$ de Banach).
*   $f \in C^{n+1}(I, E)$ : $f$ est $(n+1)$ fois contin√ªment d√©rivable sur $I$.

**√ânonc√© formel :**

$$ f(b) = \sum_{k=0}^n \frac{(b-a)^k}{k!} f^{(k)}(a) + \int_a^b \frac{(b-t)^n}{n!} f^{(n+1)}(t) dt. $$

Le terme $R_n(b) = \int_a^b \frac{(b-t)^n}{n!} f^{(n+1)}(t) dt$ est le reste int√©gral d'ordre $n$.

**D√©monstration (Esquisse) :**
R√©currence sur $n$, en appliquant une int√©gration par parties au reste :
$$ \int_a^b \frac{(b-t)^n}{n!} f^{(n+1)}(t) dt = \left[ - \frac{(b-t)^{n+1}}{(n+1)!} f^{(n+1)}(t) \right]_a^b + \int_a^b \frac{(b-t)^{n+1}}{(n+1)!} f^{(n+2)}(t) dt $$
Le terme √©valu√© donne $\frac{(b-a)^{n+1}}{(n+1)!} f^{(n+1)}(a)$ et le reste se d√©place √† l'ordre $n+1$.

### 
**Subtilit√©s :**

*   La r√©gularit√© requise est $f \in C^{n+1}$ (pas seulement $C^n$) ‚Äî la d√©riv√©e d'ordre $n+1$ doit exister et √™tre continue.
*   Formule valable pour $E$ evn quelconque (vectoriel) ‚Äî c'est l'un des grands avantages du reste int√©gral sur le reste de Lagrange.
*   Le reste int√©gral donne une majoration imm√©diate : $\|R_n(b)\| \le \frac{|b-a|^{n+1}}{(n+1)!} \sup_{t \in [a, b]} \|f^{(n+1)}(t)\|$ (Thm 12).

**Extensions :**

*   **Formule de Taylor-Lagrange (Thm 12) :** in√©galit√© d√©duite du reste int√©gral par majoration.
*   **Taylor-Young (Thm 13) :** formule asymptotique avec reste en $o((b-a)^n)$, ne requiert que $C^n$ (ou $n$ fois d√©rivable).
*   La formule s'√©tend aux fonctions de plusieurs variables (Taylor en dimension $d$, Prop 29).

**Pi√®ges classiques :**
*   ‚ùå Confondre les ordres : Taylor reste int√©gral √† l'ordre $n$ n√©cessite $f \in C^{n+1}$, pas $C^n$.
*   ‚ùå Penser que le reste de Lagrange (scalaire) s'applique au cas vectoriel ‚Äî faux, seul le reste int√©gral fonctionne en g√©n√©ral.
*   ‚ùå Oublier le facteur $\frac{(b-t)^n}{n!}$ (et non $\frac{(b-t)^{n+1}}{(n+1)!}$) dans l'int√©grant.

---

## FLASHCARD 15 ‚Äî Th√©or√®me 12 : In√©galit√© de Taylor-Lagrange

### RECTO
**Th√©or√®me 12 ‚Äî In√©galit√© de Taylor-Lagrange**

**Contexte :** Soit $f : I \to E$, $E$ evn.

√ânoncer l'in√©galit√© de Taylor-Lagrange avec hypoth√®ses exactes. Pr√©ciser la nature de $E$.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $I \subseteq \mathbb{R}$ intervalle, $a, b \in I$ (avec $a \le b$ ou $b \le a$ ‚Äî la formule est sym√©trique en $|b-a|$).
*   $E$ espace vectoriel norm√©.
*   $f \in C^{n+1}(I, E)$.
*   $M_{n+1} = \sup_{t \in [a, b]} \|f^{(n+1)}(t)\| < +\infty$ (borne bien d√©finie par continuit√© sur le compact $[a, b]$ si $I$ contient $[a, b]$).

**√ânonc√© formel :**

$$ \left\| f(b) - \sum_{k=0}^n \frac{(b-a)^k}{k!} f^{(k)}(a) \right\| \le \frac{|b-a|^{n+1}}{(n+1)!} \cdot M_{n+1}. $$

**D√©monstration (Esquisse) :**
Majorer le reste int√©gral (Thm 11) :
$$ \|R_n(b)\| = \left\| \int_a^b \frac{(b-t)^n}{n!} f^{(n+1)}(t) dt \right\| \le \int_a^b \frac{|b-t|^n}{n!} \|f^{(n+1)}(t)\| dt $$
$$ \le M_{n+1} \int_a^b \frac{(b-t)^n}{n!} dt = \frac{|b-a|^{n+1}}{(n+1)!} M_{n+1}. $$

### 
**Subtilit√©s :**

*   La majoration est valable dans tout evn $E$ (vectoriel, dimension quelconque).
*   La constante $(n+1)!$ au d√©nominateur est cruciale pour les estimations de convergence de s√©ries enti√®res.
*   Si $M_{n+1} \to 0$ quand $n \to \infty$ (√† $b-a$ fix√©), la s√©rie de Taylor converge vers $f$.

**Extensions :**

*   Cas $n=0$ : $\|f(b) - f(a)\| \le M_1 |b-a|$ ‚Äî c'est l'IAF.
*   Donne des bornes d'erreur explicites pour l'approximation polynomiale.

**Pi√®ges classiques :**
*   ‚ùå Oublier le facteur $(n+1)!$ (et non $n!$).
*   ‚ùå Utiliser cette in√©galit√© sans avoir v√©rifi√© que $\sup \|f^{(n+1)}\| < +\infty$ sur $[a, b]$.

---

## FLASHCARD 16 ‚Äî Th√©or√®me 13 : Taylor-Young

### RECTO
**Th√©or√®me 13 ‚Äî Formule de Taylor-Young**

**Contexte :** Soit $f : I \to \mathbb{R}$ (ou $f : I \to E$, $E$ evn) de classe $C^n$ (ou seulement $n$ fois d√©rivable en $a$).

√ânoncer la formule de Taylor-Young √† l'ordre $n$ en $a$, avec la r√©gularit√© minimale requise et la pr√©cision du reste.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $I \subseteq \mathbb{R}$ intervalle ouvert, $a \in I$.
*   $f : I \to E$ est $n$ fois d√©rivable en $a$ (condition plus faible que $C^n$).

**√ânonc√© formel :**

$$ f(a+h) = \sum_{k=0}^n \frac{h^k}{k!} f^{(k)}(a) + o(h^n) \quad \text{quand } h \to 0. $$

Autrement dit :
$$ f(x) = \sum_{k=0}^n \frac{(x-a)^k}{k!} f^{(k)}(a) + o((x-a)^n) \quad \text{quand } x \to a. $$

**D√©monstration (Esquisse) :**
Par r√©currence sur $n$, en utilisant la r√®gle de L'H√¥pital ou une r√©currence sur le reste. La cl√© est :
$$ r_n(h) = f(a+h) - \sum_{k=0}^n \frac{h^k}{k!} f^{(k)}(a), \quad \lim_{h \to 0} \frac{r_n(h)}{h^n} = 0. $$
On prouve cela par r√©currence : $r_n'(h) = r_{n-1}'(h) - \frac{h^n}{n!} f^{(n)}(a)$ n'est pas correct.
Correction : $r_n'(h) = f'(a+h) - \sum_{k=1}^n \frac{h^{k-1}}{(k-1)!} f^{(k)}(a)$. Le terme de degr√© $n$ de la somme d√©riv√©e devient le terme de degr√© $n-1$ de la d√©riv√©e. Et $r_{n-1}(h) = o(h^{n-1})$ par hypoth√®se de r√©currence.

### 
**Subtilit√©s :**

*   **R√©gularit√© minimale :** Il suffit que $f$ soit $n$ fois d√©rivable en $a$ (pas n√©cessairement $C^n$ au voisinage de $a$). C'est plus faible que Taylor reste int√©gral (qui demande $C^{n+1}$).
*   Le reste est $o(h^n)$ et non $O(h^{n+1})$ ‚Äî si $f \in C^{n+1}$, on peut pr√©ciser $O(h^{n+1})$ via l'in√©galit√© de Taylor-Lagrange.
*   **Unicit√© du DL :** Le polyn√¥me de Taylor $\sum_{k=0}^n \frac{(x-a)^k}{k!} f^{(k)}(a)$ est l'unique polyn√¥me $P$ de degr√© $\le n$ tel que $f(x) = P(x) + o((x-a)^n)$.
*   **Cas vectoriel :** La formule est valable pour $f : I \to E$ si $f$ est $n$ fois d√©rivable en $a$ (avec $E$ evn quelconque).

**Extensions :**

*   **DL compos√©s, produits, quotients :** Toutes les op√©rations sur les DL sont licites √† l'ordre $n$.
*   **Lien avec les s√©ries enti√®res :** Si $f$ est d√©veloppable en s√©rie enti√®re au voisinage de $a$, le DL co√Øncide avec la s√©rie enti√®re.

**Pi√®ges classiques :**
*   ‚ùå √âcrire $o(h^n)$ quand on a prouv√© seulement $O(h^n)$ (pas pareil).
*   ‚ùå Confondre Taylor-Young ($o(h^n)$, faible r√©gularit√©) et Taylor reste int√©gral ($C^{n+1}$, reste explicite).
*   ‚ùå Oublier que le DL est unique ‚Äî on peut identifier les coefficients terme √† terme.
*   ‚ùå D√©river terme √† terme un DL sans justification (on ne peut d√©river un DL que si la fonction est $C^{n+1}$, sinon c'est faux en g√©n√©ral).

---

# CHAPITRE 2 ‚Äî Suites et s√©ries, familles sommables

## FLASHCARD 17 ‚Äî Proposition 2 : Formule de Stirling

### RECTO
**Proposition 2 ‚Äî Formule de Stirling**

√ânoncer la formule de Stirling avec l'√©quivalent exact et le d√©veloppement asymptotique.

### VERSO
**√ânonc√© formel :**

$$ n! \underset{n \to +\infty}{\sim} \sqrt{2\pi n} \left( \frac{n}{e} \right)^n. $$

Plus pr√©cis√©ment, il existe un d√©veloppement asymptotique :
$$ n! = \sqrt{2\pi n} \left( \frac{n}{e} \right)^n \exp\left( \frac{1}{12n} + O\left(\frac{1}{n^2}\right) \right). $$

**D√©monstration (Esquisse, id√©e principale) :**

*   Poser $u_n = \frac{n!}{n^n e^{-n} \sqrt{n}}$. Montrer que $\ln u_n$ converge (calcul via $\sum \ln k - \int \ln$, ou via la formule de Wallis).
*   La constante $\sqrt{2\pi}$ est d√©termin√©e en utilisant l'int√©grale de Wallis :
    $$ \frac{\pi}{2} = \lim_{n \to \infty} \frac{[(2n)!!]^2}{[(2n-1)!!]^2 \cdot (2n+1)}, \text{ combin√© √† Stirling.} $$

### 
**Subtilit√©s :**

*   La constante $\sqrt{2\pi}$ n'est pas triviale ‚Äî c'est la m√™me que dans la densit√© gaussienne.
*   **Utilisations fr√©quentes :**
    *   $\binom{2n}{n} \sim \frac{4^n}{\sqrt{\pi n}}$
    *   $\frac{1}{\sqrt{n}} \binom{n}{k}$ pour le TCL discret
    *   Rayon de convergence de s√©ries enti√®res via la r√®gle de d'Alembert.
*   Logarithme : $\ln(n!) = n \ln n - n + \frac{1}{2} \ln(2\pi n) + O(1/n)$.

**Pi√®ges classiques :**
*   ‚ùå Oublier le facteur $\sqrt{2\pi n}$ (et √©crire seulement $(n/e)^n$).
*   ‚ùå Utiliser Stirling sans pr√©ciser qu'on travaille avec un √©quivalent (et non une √©galit√©).

---

## FLASHCARD 18 ‚Äî √Ä conna√Ætre 2 : D√©veloppement asymptotique de $H_n$

### RECTO
**√Ä conna√Ætre 2 ‚Äî D√©veloppement asymptotique de la s√©rie harmonique $H_n$**

Donner le d√©veloppement asymptotique de $H_n = \sum_{k=1}^n \frac{1}{k}$ quand $n \to +\infty$, en pr√©cisant la constante d'Euler-Mascheroni.

### VERSO
**√ânonc√© formel :**

$$ H_n = \sum_{k=1}^n \frac{1}{k} = \ln n + \gamma + \frac{1}{2n} - \frac{1}{12n^2} + O\left(\frac{1}{n^4}\right), $$

o√π $\gamma$ est la constante d'Euler-Mascheroni :
$$ \gamma = \lim_{n \to +\infty} (H_n - \ln n) \approx 0,5772\dots $$

**√Ä conna√Ætre imp√©rativement :**
$$ H_n = \ln n + \gamma + o(1) \quad (n \to +\infty), $$
$$ H_n - \ln n \xrightarrow[n \to +\infty]{} \gamma > 0. $$

**D√©monstration (Esquisse) :**
Par comparaison s√©rie-int√©grale (Proposition 3) : $\sum_{k=1}^n \frac{1}{k} - \int_1^n \frac{dt}{t}$ est une suite croissante born√©e (ou d√©croissante selon l'ordre), donc converge vers $\gamma$.

### 
**Subtilit√©s :**

*   $\gamma$ est une constante transcendante (conjecture) ‚Äî on ne sait toujours pas si elle est irrationnelle.
*   $H_n \to +\infty$ (la s√©rie harmonique diverge), mais tr√®s lentement : $H_n \sim \ln n$.
*   Utilisations : convergence de s√©ries, √©quivalents, d√©veloppements asymptotiques de sommes.

**Pi√®ges classiques :**
*   ‚ùå Penser que $H_n$ converge.
*   ‚ùå Confondre $\gamma$ avec $e$ ou $\pi$ ‚Äî c'est une constante distincte.

---

## FLASHCARD 19 ‚Äî Th√©or√®me 14 : Crit√®re des s√©ries altern√©es (Leibniz)

### RECTO
**Th√©or√®me 14 ‚Äî Crit√®re des s√©ries altern√©es (Leibniz)**

**Contexte :** Soit $\sum (-1)^n a_n$ une s√©rie altern√©e.

√ânoncer le crit√®re des s√©ries altern√©es avec hypoth√®ses exactes et conclure sur la convergence et la qualit√© des restes.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $(a_n)_{n \ge 0}$ est une suite de r√©els positifs : $a_n \ge 0$ pour tout $n$.
*   $(a_n)$ est d√©croissante (au sens large) : $a_{n+1} \le a_n$ pour tout $n$.
*   $a_n \xrightarrow[n \to +\infty]{} 0$.

**√ânonc√© formel :**

La s√©rie $\sum_{n \ge 0} (-1)^n a_n$ est convergente.

De plus, si $S = \sum_{n=0}^{+\infty} (-1)^n a_n$ et $S_N = \sum_{n=0}^N (-1)^n a_n$, alors :
$$ \forall N \in \mathbb{N}, \quad |S - S_N| \le a_{N+1}. $$
Et le reste $S - S_N$ est du signe de $(-1)^{N+1} a_{N+1}$ (signe du premier terme n√©glig√©).

**D√©monstration (Esquisse) :**

Les suites des sommes partielles d'indices pairs $(S_{2p})$ et impairs $(S_{2p+1})$ sont respectivement croissante et d√©croissante, et encadrent $S$. Elles sont adjacentes (leur diff√©rence $a_{2p+1} \to 0$), donc convergent vers la m√™me limite $S$.
$$ |S - S_N| \le |S_{N+1} - S_N| = a_{N+1}. $$

### 
**Subtilit√©s :**

*   Les trois conditions (positivit√©, d√©croissance, limite nulle) sont toutes n√©cessaires : la d√©croissance seule ne suffit pas si $a_n \not\to 0$.
*   La d√©croissance n'est requise qu'√† partir d'un certain rang (condition asymptotique).
*   Le crit√®re de Leibniz ne donne que la convergence, pas la convergence absolue : $\sum (-1)^n / n$ converge mais $\sum 1/n$ diverge.
*   **Majoration du reste :** $|S - S_N| \le a_{N+1}$ est une majoration effective et simple ‚Äî tr√®s utilis√©e en pratique.

**Extensions :**

*   **Crit√®re de Dirichlet (g√©n√©ralisation) :** $\sum a_n b_n$ converge si $(a_n)$ d√©cro√Æt vers $0$ et les sommes partielles de $(b_n)$ sont born√©es.
*   Le crit√®re de Leibniz est un cas particulier de Dirichlet avec $b_n = (-1)^n$.

**Pi√®ges classiques :**
*   ‚ùå Oublier la condition de positivit√© ($a_n \ge 0$).
*   ‚ùå Confondre convergence et convergence absolue.
*   ‚ùå Oublier que la majoration du reste est $a_{N+1}$ (le premier terme non inclus dans $S_N$).

---

## FLASHCARD 20 ‚Äî Th√©or√®me 15 : Comparaison √† une s√©rie absolument convergente, s√©ries de Riemann

### RECTO
**Th√©or√®me 15 ‚Äî Comparaison √† une s√©rie absolument convergente / S√©ries de Riemann**

**Contexte :** Soit $\sum u_n$ une s√©rie de termes r√©els ou complexes.

√ânoncer le crit√®re de comparaison pour les s√©ries √† termes positifs et les s√©ries de Riemann $\sum 1/n^\alpha$.

### VERSO
**Hypoth√®ses et √©nonc√© :**

**Partie 1 ‚Äî Crit√®re de comparaison (termes positifs) :**

Soient $(u_n), (v_n)$ des suites de r√©els positifs avec $0 \le u_n \le v_n$ √† partir d'un certain rang.

*   $\sum v_n \text{ converge} \implies \sum u_n \text{ converge.}$
*   $\sum u_n \text{ diverge} \implies \sum v_n \text{ diverge.}$

**Partie 2 ‚Äî R√®gle de comparaison (√©quivalents, $\sim$) :**

Si $u_n \sim v_n$ ($u_n, v_n > 0$) :
$\sum u_n$ et $\sum v_n$ ont m√™me nature.

**Partie 3 ‚Äî S√©ries de Riemann :**

$$ \sum_{n=1}^{+\infty} \frac{1}{n^\alpha} \begin{cases} \text{converge} & \text{si } \alpha > 1 \\ \text{diverge} & \text{si } \alpha \le 1. \end{cases} $$

**D√©monstration (Riemann, esquisse) :**
Par comparaison s√©rie-int√©grale (Prop 3) : $\int_1^{+\infty} t^{-\alpha} dt$ converge $\iff \alpha > 1$.

### 
**Subtilit√©s :**

*   Le crit√®re de comparaison requiert des termes positifs (ou l'application √† $|u_n|$ pour la convergence absolue).
*   Pour $\alpha = 1$ : $\sum 1/n$ diverge (s√©rie harmonique) ‚Äî cas limite souvent pi√©geux.
*   Si $u_n = O(v_n)$ avec $\sum v_n$ convergente $\implies \sum u_n$ absolument convergente.
*   Si $u_n \sim v_n$ mais que $u_n$ change de signe, la comparaison n'implique pas la m√™me nature pour les s√©ries.

**Extensions :**

*   **S√©ries de Bertrand (√Ä conna√Ætre 3) :** cas limite $\alpha=1$ avec logarithmes.

**Pi√®ges classiques :**
*   ‚ùå Appliquer la comparaison √† des s√©ries de signe quelconque.
*   ‚ùå Oublier le cas $\alpha=1$ (s√©rie harmonique diverge).
*   ‚ùå Confondre $u_n = O(v_n)$ et $u_n \le v_n$.

---

## FLASHCARD 21 ‚Äî √Ä conna√Ætre 3 : S√©ries de Bertrand

### RECTO
**√Ä conna√Ætre 3 ‚Äî S√©ries de Bertrand**

√ânoncer la condition de convergence des s√©ries de Bertrand $\sum \frac{1}{n^\alpha (\ln n)^\beta}$.

### VERSO
**√ânonc√© formel :**

$$ \sum_{n=2}^{+\infty} \frac{1}{n^\alpha (\ln n)^\beta} \begin{cases} \text{converge} & \text{si } \alpha > 1, \text{ ou si } \alpha = 1 \text{ et } \beta > 1, \\ \text{diverge} & \text{si } \alpha < 1, \text{ ou si } \alpha = 1 \text{ et } \beta \le 1. \end{cases} $$

**D√©monstration (Esquisse) :**

*   $\alpha \neq 1$ : comparaison aux s√©ries de Riemann.
*   $\alpha = 1$ : comparaison s√©rie-int√©grale avec $\int_2^{+\infty} \frac{dt}{t (\ln t)^\beta}$, qui converge $\iff \beta > 1$ (changement de variable $u = \ln t$, int√©grale de Riemann en $u$).

### 
**Subtilit√©s :**

*   La somme commence √† $n=2$ car $\ln 1 = 0$.
*   Cas $\alpha=1, \beta=1$ : $\sum \frac{1}{n \ln n}$ diverge (par comparaison avec $\int \frac{dt}{t \ln t} = \ln(\ln t) \to +\infty$).

**Pi√®ges classiques :**
*   ‚ùå Oublier la restriction au cas $\alpha=1$ pour la distinction par $\beta$.
*   ‚ùå Commencer la somme √† $n=1$ (division par $\ln 1 = 0$).

---

## FLASHCARD 22 ‚Äî Th√©or√®me 16 : Sommation des relations de comparaison

### RECTO
**Th√©or√®me 16 ‚Äî Sommation des relations de comparaison**

**Contexte :** Soient $\sum u_n$ et $\sum v_n$ des s√©ries √† termes positifs.

√ânoncer le th√©or√®me de sommation des relations de comparaison ($u_n = O(v_n), u_n = o(v_n), u_n \sim v_n$) en termes de restes ou de sommes partielles.

### VERSO
**Hypoth√®ses :** $(u_n), (v_n)$ suites de r√©els strictement positifs √† partir d'un certain rang.

**√ânonc√© formel :**

Notons $U_n = \sum_{k=0}^n u_k$, $V_n = \sum_{k=0}^n v_k$, $R_n = \sum_{k=n+1}^{+\infty} u_k$ (reste si $\sum u_k < +\infty$).

**Cas $\sum v_n$ diverge :**
*   $u_n \underset{n \to \infty}{\sim} v_n \implies U_n \underset{n \to \infty}{\sim} V_n$.
*   $u_n = o(v_n) \implies U_n = o(V_n)$.

**Cas $\sum v_n$ converge (et $\sum u_n$ converge aussi) :**
*   $u_n \underset{n \to \infty}{\sim} v_n \implies R_n^u \underset{n \to \infty}{\sim} R_n^v$ (restes √©quivalents).
*   $u_n = o(v_n) \implies R_n^u = o(R_n^v)$.

**D√©monstration (Esquisse) :**
Th√©or√®me de Ces√†ro ou lemme de Stolz-Ces√†ro : si $u_n/v_n \to \ell$, alors $U_n/V_n \to \ell$ (sous $V_n \to +\infty$).

### 
**Subtilit√©s :**

*   Les deux cas (convergent/divergent) donnent des r√©sultats diff√©rents ‚Äî il faut distinguer.
*   La positivit√© des termes est cruciale (pour les restes et la monotonie des sommes partielles).
*   Ce th√©or√®me est tr√®s utilis√© pour trouver des √©quivalents de sommes partielles ou de restes.

**Pi√®ges classiques :**
*   ‚ùå Appliquer √† des s√©ries de signe quelconque.
*   ‚ùå Confondre le cas divergent et le cas convergent.

---

## FLASHCARD 23 ‚Äî √Ä conna√Ætre 4 : Croissance sur/sous-g√©om√©trique

### RECTO
**√Ä conna√Ætre 4 ‚Äî Croissance sur-g√©om√©trique et sous-g√©om√©trique**

√ânoncer les crit√®res de croissance sur-g√©om√©trique et sous-g√©om√©trique d'une suite $(u_n)$ en termes de $u_{n+1}/u_n$, et en d√©duire la nature de la s√©rie $\sum u_n$.

### VERSO
**√ânonc√© formel :**

Soit $(u_n)$ une suite de r√©els strictement positifs.

**Sous-g√©om√©trique (convergence) :**
$$ \exists q \in [0, 1[, \exists N \in \mathbb{N}, \forall n \ge N, \frac{u_{n+1}}{u_n} \le q \implies \sum u_n \text{ converge}. $$

Plus g√©n√©ralement (r√®gle de d'Alembert) :
$$ \limsup_{n \to \infty} \frac{u_{n+1}}{u_n} < 1 \implies \sum u_n \text{ converge absolument}. $$

**Sur-g√©om√©trique (divergence) :**
$$ \exists q > 1, \exists N \in \mathbb{N}, \forall n \ge N, \frac{u_{n+1}}{u_n} \ge q \implies u_n \not\to 0 \implies \sum u_n \text{ diverge}. $$

Plus g√©n√©ralement :
$$ \liminf_{n \to \infty} \frac{u_{n+1}}{u_n} > 1 \implies \sum u_n \text{ diverge}. $$

### 
**Subtilit√©s :**

*   Si $u_{n+1}/u_n \to 1$ : aucune conclusion possible avec ce crit√®re seul.
*   La r√®gle de d'Alembert est stricte : limite strictement $<1$ ou $>1$.
*   **R√®gle de la racine (Cauchy) :** $\limsup (u_n)^{1/n} < 1 \implies$ convergence ; $> 1 \implies$ divergence (plus puissante que d'Alembert).

**Pi√®ges classiques :**
*   ‚ùå Conclure sur la nature de $\sum u_n$ quand $u_{n+1}/u_n \to 1$.
*   ‚ùå Oublier que ces crit√®res supposent $u_n > 0$.

---

## FLASHCARD 24 ‚Äî Proposition 3 : Comparaison s√©rie-int√©grale

### RECTO
**Proposition 3 ‚Äî Comparaison s√©rie-int√©grale**

**Contexte :** Soit $f : [1, +\infty[ \to \mathbb{R}$ une fonction.

√ânoncer la proposition de comparaison s√©rie-int√©grale, avec hypoth√®ses exactes et double in√©galit√©.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $f : [1, +\infty[ \to \mathbb{R}_+$ est positive, continue (ou localement int√©grable) et d√©croissante sur $[1, +\infty[$.

**√ânonc√© formel :**

Pour tout $n \ge 1$ :
$$ \int_1^{n+1} f(t) dt \le \sum_{k=1}^n f(k) \le f(1) + \int_1^n f(t) dt. $$

**Cons√©quence ‚Äî nature de la s√©rie :**
$$ \sum_{n \ge 1} f(n) \text{ converge} \iff \int_1^{+\infty} f(t) dt \text{ converge}. $$

**D√©monstration (Esquisse) :**
Par d√©croissance de $f$ : sur $[k, k+1]$, $f(k+1) \le f(t) \le f(k)$. Int√©grer sur $[k, k+1]$ donne $f(k+1) \le \int_k^{k+1} f(t) dt \le f(k)$. Sommer pour $k=1, \dots, n$.

### 
**Subtilit√©s :**

*   La d√©croissance est essentielle. Pour $f$ non monotone, le r√©sultat peut √™tre faux.
*   La comparaison donne aussi des √©quivalents : si $\int_1^n f(t) dt \sim g(n)$ et $f$ d√©croissante, alors $\sum_{k=1}^n f(k) \sim g(n)$.
*   **Applications :** S√©ries de Riemann ($f(t) = t^{-\alpha}$), $H_n \sim \ln n$.

**Pi√®ges classiques :**
*   ‚ùå Appliquer √† une fonction non monotone.
*   ‚ùå Oublier que les in√©galit√©s sont $\le$ (pas strictes).
*   ‚ùå Confondre les bornes de la double in√©galit√©.

---

## FLASHCARD 25 ‚Äî Proposition 4 : Sommation par paquets, somme double

### RECTO
**Proposition 4 ‚Äî Sommation par paquets et somme double**

**Contexte :** Familles sommables de r√©els positifs.

√ânoncer la proposition de Fubini-Tonelli discr√®te (permutation des sommations pour des termes positifs) et le th√©or√®me de sommation par paquets.

### VERSO
**Partie 1 ‚Äî Sommation par paquets :**

Soit $\sum u_n$ une s√©rie √† termes r√©els. Soit $(I_k)_{k \in \mathbb{N}}$ une partition de $\mathbb{N}$ en intervalles entiers cons√©cutifs $I_k = \{n_k, n_k+1, \dots, n_{k+1}-1\}$.

$$ \sum_{n=0}^{+\infty} u_n \text{ converge} \implies \sum_{k=0}^{+\infty} \left( \sum_{n \in I_k} u_n \right) \text{ converge et vaut } \sum_{n=0}^{+\infty} u_n. $$

R√©ciproque : vraie si les $u_n$ sont de signe constant sur chaque $I_k$ (ou termes positifs).

**Partie 2 ‚Äî Fubini discret (termes positifs) :**

Soit $(a_{i,j})_{(i,j) \in \mathbb{N}^2}$ une famille de r√©els positifs.

$$ \sum_{(i,j) \in \mathbb{N}^2} a_{i,j} = \sum_{i=0}^{+\infty} \left( \sum_{j=0}^{+\infty} a_{i,j} \right) = \sum_{j=0}^{+\infty} \left( \sum_{i=0}^{+\infty} a_{i,j} \right) \in [0, +\infty]. $$

Si l'une de ces sommes est finie, elles sont toutes √©gales et finies (famille sommable).

Pour des termes quelconques : la permutation est licite si la famille est absolument sommable : $\sum_{i,j} |a_{i,j}| < +\infty$.

### 
**Subtilit√©s :**

*   Pour les termes de signe quelconque, la permutation des sommations peut √™tre fausse si la famille n'est pas absolument sommable (contre-exemple : $a_{i,j} = 1_{i=j} - 1_{i=j+1}$).
*   La sommation par paquets est une op√©ration sur une s√©rie qui regroupe des termes ‚Äî licite si la s√©rie converge absolument, ou si les paquets sont cons√©cutifs et la s√©rie converge (par d√©finition de la convergence).

**Pi√®ges classiques :**
*   ‚ùå Permuter les sommes sans v√©rifier l'absolue sommabilit√©.
*   ‚ùå Oublier que la sommation par paquets est licite dans un sens mais pas n√©cessairement dans l'autre pour des s√©ries conditionnellement convergentes.

---

## FLASHCARD 26 ‚Äî √Ä conna√Ætre 5 : Th√©or√®me de convergence domin√©e sur les s√©ries

### RECTO
**√Ä conna√Ætre 5 ‚Äî Th√©or√®me de convergence domin√©e discret (s√©ries)**

**Contexte :** Soit $(u_n(x))_{n \in \mathbb{N}}$ une famille de fonctions.

√ânoncer le th√©or√®me de convergence domin√©e dans le cadre discret (s√©ries), avec hypoth√®ses exactes.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $X$ est un ensemble (typiquement un intervalle ou $\mathbb{N}$).
*   Pour chaque $n \in \mathbb{N}$, $u_n : X \to \mathbb{R}$ (ou $\mathbb{C}$).
*   **Convergence ponctuelle :** $\forall x \in X, u_n(x) \xrightarrow[n \to \infty]{} \ell(x)$.
*   **Domination :** $\exists (v_n)_{n \in \mathbb{N}}$ suite de r√©els positifs telle que $\forall x \in X, \forall n \in \mathbb{N}, |u_n(x)| \le v_n$, et $\sum_n v_n < +\infty$.

**√ânonc√© formel :**

$\sum_{n=0}^{+\infty} u_n(x)$ converge absolument et normalement en $x \in X$,
et
$$ \sum_{n=0}^{+\infty} \ell(x) = \lim_{N \to \infty} \sum_{n=0}^N \ell(x). $$

Plus pr√©cis√©ment :
$$ \lim_{N \to \infty} \sum_{n=0}^N u_n(x) = \sum_{n=0}^{+\infty} u_n(x) \quad \text{uniform√©ment en } x \in X. $$

Et : $\sum_{n=0}^{+\infty} u_n(x) \xrightarrow{?} \sum_{n=0}^{+\infty} \ell(x)$ (permutation limite et s√©rie possible sous hypoth√®ses suppl√©mentaires).

### 
**Subtilit√©s :**

*   La domination $|u_n(x)| \le v_n$ avec $\sum v_n < +\infty$ garantit la convergence normale de la s√©rie $\sum u_n$.
*   Ce r√©sultat est la version discr√®te du th√©or√®me de convergence domin√©e de Lebesgue (Thm 31).

**Pi√®ges classiques :**
*   ‚ùå Oublier que la suite dominante $(v_n)$ doit √™tre ind√©pendante de $x$.
*   ‚ùå Confondre convergence normale et convergence uniforme.

---

# CHAPITRE 3 ‚Äî Int√©gration

## FLASHCARD 27 ‚Äî Proposition 5 : Convergence des sommes de Riemann

### RECTO
**Proposition 5 ‚Äî Convergence des sommes de Riemann**

**Contexte :** Soit $f : [a, b] \to \mathbb{R}$ (ou $\mathbb{C}$).

√ânoncer la proposition sur la convergence des sommes de Riemann vers l'int√©grale, avec hypoth√®ses minimales.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $f : [a, b] \to \mathbb{R}$ est continue sur $[a, b]$ (ou, plus g√©n√©ralement, Riemann-int√©grable).

**√ânonc√© formel :**

$$ \frac{b-a}{n} \sum_{k=0}^{n-1} f\left(a + k \frac{b-a}{n}\right) \xrightarrow[n \to +\infty]{} \int_a^b f(t) dt. $$

Plus g√©n√©ralement, pour une subdivision $a = x_0 < x_1 < \dots < x_n = b$ de pas $\delta_n = \max_k (x_{k+1} - x_k) \to 0$ :
$$ \sum_{k=0}^{n-1} f(\xi_k)(x_{k+1} - x_k) \xrightarrow[n \to +\infty]{} \int_a^b f(t) dt, $$
pour tout choix de $\xi_k \in [x_k, x_{k+1}]$.

**D√©monstration (Esquisse) :**
Par uniforme continuit√© de $f$ sur $[a, b]$ (Heine), pour $\varepsilon > 0$, $\exists \delta > 0$ tel que $|x-y| < \delta \implies |f(x) - f(y)| < \varepsilon$. Si le pas $\delta_n < \delta$, alors la somme de Riemann est √† distance $< \varepsilon(b-a)$ de $\int_a^b f$.

### 
**Subtilit√©s :**

*   La continuit√© n'est pas indispensable : $f$ Riemann-int√©grable suffit (mais MP* traite surtout $C^0$).
*   La vitesse de convergence est $O(1/n)$ si $f \in C^1$ (par Euler-Maclaurin).
*   **Application :** Calculer $\lim_{n \to \infty} \frac{1}{n} \sum_{k=1}^n f(k/n) = \int_0^1 f(t) dt$ ‚Äî technique classique de concours.

**Pi√®ges classiques :**
*   ‚ùå Appliquer √† une fonction non born√©e.
*   ‚ùå Oublier d'identifier la somme comme une somme de Riemann (erreur de cadrage).

---

## FLASHCARD 28 ‚Äî Th√©or√®me 17 : Comparaison √† une fonction int√©grable, int√©grales de Riemann

### RECTO
**Th√©or√®me 17 ‚Äî Comparaison √† une fonction int√©grable / Int√©grales de Riemann**

**Contexte :** Soit $f : [a, +\infty[ \to \mathbb{R}$ (int√©grale impropre).

√ânoncer le crit√®re de comparaison pour les int√©grales impropres et donner la nature des int√©grales de Riemann $\int_1^{+\infty} t^{-\alpha} dt$.

### VERSO
**Partie 1 ‚Äî Crit√®re de comparaison :**

Soient $f, g : [a, +\infty[ \to \mathbb{R}_+$ continues (ou localement int√©grables), avec $0 \le f(t) \le g(t)$ au voisinage de $+\infty$.

*   $\int_a^{+\infty} g(t) dt \text{ converge} \implies \int_a^{+\infty} f(t) dt \text{ converge.}$
*   $\int_a^{+\infty} f(t) dt \text{ diverge} \implies \int_a^{+\infty} g(t) dt \text{ diverge.}$

Si $f(t) \sim g(t)$ en $+\infty$ ($f, g > 0$) : m√™me nature.

**Partie 2 ‚Äî Int√©grales de Riemann :**

$$ \int_1^{+\infty} \frac{dt}{t^\alpha} \begin{cases} \text{converge} & \text{si } \alpha > 1, \\ \text{diverge} & \text{si } \alpha \le 1. \end{cases} $$

$$ \int_0^1 \frac{dt}{t^\alpha} \begin{cases} \text{converge} & \text{si } \alpha < 1, \\ \text{diverge} & \text{si } \alpha \ge 1. \end{cases} $$

### 
**Subtilit√©s :**

*   Int√©grale en $0^+$ et en $+\infty$ : Les conditions de convergence sont oppos√©es ($\alpha < 1$ vs $\alpha > 1$). Ne pas confondre.
*   La comparaison s'applique au voisinage de la singularit√© (pas n√©cessairement sur tout $[a, +\infty[$).

**Pi√®ges classiques :**
*   ‚ùå Inverser les conditions pour $0^+$ et $+\infty$.
*   ‚ùå Appliquer la comparaison √† des fonctions de signe quelconque.

---

## FLASHCARD 29 ‚Äî √Ä conna√Ætre 6 : Int√©grales de Bertrand

### RECTO
**√Ä conna√Ætre 6 ‚Äî Int√©grales de Bertrand**

Donner la condition de convergence de $\int_2^{+\infty} \frac{dt}{t^\alpha (\ln t)^\beta}$ et de $\int_a^b \frac{dt}{(t-a)^\alpha |\ln(t-a)|^\beta}$ (ou analogue en $0^+$).

### VERSO
**√ânonc√© formel :**

$$ \int_2^{+\infty} \frac{dt}{t^\alpha (\ln t)^\beta} \begin{cases} \text{converge} & \text{si } \alpha > 1, \text{ ou } \alpha = 1 \text{ et } \beta > 1, \\ \text{diverge} & \text{si } \alpha < 1, \text{ ou } \alpha = 1 \text{ et } \beta \le 1. \end{cases} $$

$$ \int_e^{+\infty} \frac{dt}{t (\ln t)^\beta} \begin{cases} \text{converge} & \text{si } \beta > 1, \\ \text{diverge} & \text{si } \beta \le 1. \end{cases} $$

**Analogie avec les s√©ries de Bertrand :** M√™me condition que pour $\sum \frac{1}{n^\alpha (\ln n)^\beta}$.

**D√©monstration :** Comparaison s√©rie-int√©grale / calcul direct par changement de variable $u = \ln t$.

### 
**Subtilit√©s :**

*   La borne inf√©rieure doit √™tre choisie pour que $\ln t > 0$ (d'o√π $t > 1$, et en pratique on prend $t \ge 2$ ou $t \ge e$).

**Pi√®ges classiques :**
*   ‚ùå Oublier que la borne doit √™tre $> 1$ pour que $\ln t$ soit d√©fini et positif.

---

## FLASHCARD 30 ‚Äî Proposition 6 : Int√©gration des relations de comparaison

### RECTO
**Proposition 6 ‚Äî Int√©gration des relations de comparaison**

**Contexte :** Soit $f, g : [a, +\infty[ \to \mathbb{R}_+$ continues.

√ânoncer la proposition permettant de d√©duire des √©quivalents d'int√©grales √† partir d'√©quivalents de fonctions.

### VERSO
**Hypoth√®ses :** $f, g > 0$ sur $[a, +\infty[$, continues.

**√ânonc√© formel :**

**Cas divergent :** Si $\int_a^x f(t) dt \xrightarrow[x \to +\infty]{} +\infty$ et $f(t) \underset{t \to +\infty}{\sim} g(t)$, alors :
$$ \int_a^x f(t) dt \underset{x \to +\infty}{\sim} \int_a^x g(t) dt. $$

**Cas convergent :** Si $\int_a^{+\infty} g(t) dt < +\infty$ et $f(t) \underset{t \to +\infty}{\sim} g(t)$, alors $\int_a^{+\infty} f(t) dt < +\infty$ et :
$$ \int_x^{+\infty} f(t) dt \underset{x \to +\infty}{\sim} \int_x^{+\infty} g(t) dt. $$

### 
**Subtilit√©s :**

*   Strictement analogue √† la sommation des relations de comparaison pour les s√©ries.
*   La positivit√© est indispensable pour la transitivit√© des √©quivalents.

**Pi√®ges classiques :**
*   ‚ùå Oublier que l'√©quivalence $f \sim g$ doit √™tre au voisinage de la singularit√© (pas n'importe o√π).
*   ‚ùå Appliquer √† des fonctions de signe quelconque.

---

## FLASHCARD 31 ‚Äî Proposition 7 : Crit√®re de Cauchy pour les int√©grales impropres

### RECTO
**Proposition 7 ‚Äî Crit√®re de Cauchy pour les int√©grales impropres**

**Contexte :** Soit $f : [a, +\infty[ \to E$ ($E$ evn complet) localement int√©grable.

√ânoncer le crit√®re de Cauchy pour la convergence d'une int√©grale impropre.

### VERSO
**Hypoth√®ses :**

*   $f : [a, +\infty[ \to E$ ($E$ de Banach) est localement int√©grable (int√©grable sur tout $[a, X]$).

**√ânonc√© formel :**

$$ \int_a^{+\infty} f(t) dt \text{ converge} \iff \forall \varepsilon > 0, \exists X_0 \ge a, \forall X, Y \ge X_0, \left\| \int_X^Y f(t) dt \right\| \le \varepsilon. $$

**D√©monstration :** Caract√©risation de Cauchy dans $E$ complet, appliqu√©e √† la fonction $F(X) = \int_a^X f(t) dt$.

### 
**Subtilit√©s :**

*   N√©cessite la compl√©tude de $E$ (crit√®re de Cauchy dans un espace complet).
*   Utile pour prouver la convergence d'int√©grales √† param√®tre.

**Pi√®ges classiques :**
*   ‚ùå Oublier que $X_0$ ne d√©pend pas de $X, Y$ (c'est un crit√®re uniforme en $(X, Y)$).

---

## FLASHCARD 32 ‚Äî Proposition 8 : Int√©gration par parties

### RECTO
**Proposition 8 ‚Äî Int√©gration par parties (IPP) pour les int√©grales impropres**

**Contexte :** Soit $f, g : [a, b] \to \mathbb{R}$ (ou $[a, +\infty[$) de classe $C^1$.

√ânoncer la formule d'int√©gration par parties pour les int√©grales impropres, avec les hypoth√®ses de convergence.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $f, g : [a, +\infty[ \to \mathbb{R}$ de classe $C^1$ sur $[a, +\infty[$.
*   L'int√©grale $\int_a^{+\infty} f'(t) g(t) dt$ converge.
*   $f(t)g(t)$ admet une limite finie en $+\infty$ : $\lim_{t \to +\infty} f(t)g(t) = \ell \in \mathbb{R}$.

**√ânonc√© formel :**

$$ \int_a^{+\infty} f'(t) g(t) dt = [\ell - f(a)g(a)] - \int_a^{+\infty} f(t) g'(t) dt, $$

i.e., $\int_a^{+\infty} f'(t) g(t) dt = [f(t)g(t)]_a^{+\infty} - \int_a^{+\infty} f(t) g'(t) dt$,

√† condition que $\int_a^{+\infty} f(t) g'(t) dt$ converge (ou √©quivalence des deux convergences).

**Cas du segment $[a, b]$ :** Toujours valable sans condition suppl√©mentaire :
$$ \int_a^b f'(t) g(t) dt = [f(t)g(t)]_a^b - \int_a^b f(t) g'(t) dt. $$

### 
**Subtilit√©s :**

*   Pour les int√©grales impropres, il faut v√©rifier la convergence du terme $[fg]_a^{+\infty}$ (existence de la limite) ET d'une des deux int√©grales.
*   La convergence de l'une n'implique pas l'autre en g√©n√©ral ‚Äî les deux doivent √™tre √©tudi√©es conjointement.

**Pi√®ges classiques :**
*   ‚ùå Appliquer IPP √† des int√©grales impropres sans v√©rifier la convergence du crochet.
*   ‚ùå Oublier le signe $-$ devant la seconde int√©grale.

---

## FLASHCARD 33 ‚Äî Th√©or√®me 18 : Changement de variable

### RECTO
**Th√©or√®me 18 ‚Äî Changement de variable dans une int√©grale**

**Contexte :** Soit $\varphi : [\alpha, \beta] \to \mathbb{R}$ et $f$ d√©finie sur $\varphi([\alpha, \beta])$.

√ânoncer le th√©or√®me de changement de variable pour les int√©grales (cas $C^1$), en pr√©cisant les hypoth√®ses sur $\varphi$ et $f$.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $\varphi : [\alpha, \beta] \to \mathbb{R}$ est de classe $C^1$ sur $[\alpha, \beta]$ (pas n√©cessairement injective, pas n√©cessairement monotone).
*   $f : I \to \mathbb{R}$ est continue sur $I$, o√π $I$ est un intervalle contenant $\varphi([\alpha, \beta])$.

**√ânonc√© formel :**

$$ \int_\alpha^\beta f(\varphi(t)) \varphi'(t) dt = \int_{\varphi(\alpha)}^{\varphi(\beta)} f(u) du. $$

**Cas de la variable impropre :**

Si $\varphi : [\alpha, +\infty[ \to \mathbb{R}$ est $C^1$, $\varphi(t) \to L$ quand $t \to +\infty$, et l'int√©grale converge :
$$ \int_\alpha^{+\infty} f(\varphi(t)) \varphi'(t) dt = \int_{\varphi(\alpha)}^L f(u) du. $$

**D√©monstration (Esquisse) :**
Soit $F$ une primitive de $f$. Alors $\frac{d}{dt} [F(\varphi(t))] = F'(\varphi(t))\varphi'(t) = f(\varphi(t))\varphi'(t)$. Int√©grer de $\alpha$ √† $\beta$ donne le r√©sultat par le th√©or√®me fondamental du calcul.

### 
**Subtilit√©s :**

*   $\varphi$ n'a pas besoin d'√™tre bijective pour le th√©or√®me : si $\varphi$ n'est pas injective, l'int√©grale de droite est bien $\int_{\varphi(\alpha)}^{\varphi(\beta)} f$ avec les bornes alg√©briques.
*   Si $\varphi$ est une bijection $C^1$ √† d√©riv√©e non nulle, le changement de variable est r√©versible.
*   La continuit√© de $f$ est suffisante (pas besoin de $C^1$).
*   **Attention :** $\int_{\varphi(\alpha)}^{\varphi(\beta)}$ est une int√©grale de Riemann avec bornes orient√©es (alg√©briques) ‚Äî si $\varphi(\beta) < \varphi(\alpha)$, l'int√©grale est n√©gative.

**Extensions :**

*   Valable pour $f : I \to E$ ($E$ evn), en rempla√ßant $f$ par une fonction vectorielle continue.

**Pi√®ges classiques :**
*   ‚ùå Oublier $\varphi'(t)$ dans l'int√©grande.
*   ‚ùå Confondre les bornes : ce sont $\varphi(\alpha)$ et $\varphi(\beta)$ (pas $\alpha$ et $\beta$).
*   ‚ùå Exiger la bijectivit√© de $\varphi$ ‚Äî inutile pour la formule.

---

## FLASHCARD 34 ‚Äî √Ä conna√Ætre 7 : In√©galit√© de Cauchy-Schwarz int√©grale

### RECTO
**√Ä conna√Ætre 7 ‚Äî In√©galit√© de Cauchy-Schwarz pour les int√©grales**

**Contexte :** Soient $f, g : [a, b] \to \mathbb{R}$ (ou $\mathbb{C}$).

√ânoncer l'in√©galit√© de Cauchy-Schwarz int√©grale avec condition d'√©galit√©.

### VERSO
**Hypoth√®ses :** $f, g : [a, b] \to \mathbb{R}$ (ou $\mathbb{C}$) continues (ou de carr√© int√©grable).

**√ânonc√© formel :**

$$ \left| \int_a^b f(t) \overline{g(t)} dt \right|^2 \le \left( \int_a^b |f(t)|^2 dt \right) \left( \int_a^b |g(t)|^2 dt \right). $$

**Condition d'√©galit√© :** √âgalit√© si et seulement si $f$ et $g$ sont colin√©aires au sens $L^2$ : $\exists (\lambda, \mu) \neq (0, 0), \lambda f = \mu g$ p.p. (i.e., $f$ et $g$ sont proportionnelles).

**D√©monstration (Esquisse) :**
Consid√©rer le discriminant du polyn√¥me $\lambda \mapsto \int_a^b |f(t) + \lambda g(t)|^2 dt \ge 0$. Ce trin√¥me en $\lambda$ (r√©el) est $\ge 0$ pour tout $\lambda$, donc son discriminant est $\le 0$.

### 
**Subtilit√©s :**

*   C'est l'in√©galit√© de Cauchy-Schwarz dans l'espace de Hilbert $L^2([a, b])$.
*   La condition d'√©galit√© est souvent demand√©e en concours.

**Pi√®ges classiques :**
*   ‚ùå Oublier les valeurs absolues dans le membre de gauche.
*   ‚ùå Oublier que $|f|^2$ (et non $f^2$) dans le cas complexe.

---

## FLASHCARD 35 ‚Äî √Ä conna√Ætre 8 : Int√©grale et valeur absolue / positivit√©

### RECTO
**√Ä conna√Ætre 8 ‚Äî In√©galit√© triangulaire int√©grale et positivit√©**

√ânoncer l'in√©galit√© triangulaire pour les int√©grales et la propri√©t√© de positivit√©.

### VERSO
**√ânonc√©s :**

**Positivit√© :**
$$ f : [a, b] \to \mathbb{R} \text{ continue}, f \ge 0, \int_a^b f(t) dt \ge 0. $$
Si de plus $f \ge 0$ et $\int_a^b f(t) dt = 0 \implies f \equiv 0$ sur $[a, b]$.

**In√©galit√© triangulaire :**

Pour $f : [a, b] \to E$ ($E$ evn) continue :
$$ \left\| \int_a^b f(t) dt \right\| \le \int_a^b \|f(t)\| dt \le (b-a) \sup_{t \in [a, b]} \|f(t)\|. $$

### 
**Subtilit√©s :**

*   La positivit√© avec √©galit√© n√©cessite la continuit√© : sans elle, on peut avoir $f \ge 0$ non nulle et $\int f = 0$ (pour des fonctions non mesurables, hors programme).
*   L'in√©galit√© triangulaire est valable en dimension infinie.

**Pi√®ges classiques :**
*   ‚ùå Conclure $f \equiv 0$ depuis $\int f = 0$ sans hypoth√®se de continuit√© et de positivit√©.

---

## FLASHCARD 36 ‚Äî √Ä conna√Ætre 9 : Lemme de Riemann-Lebesgue

### RECTO
**√Ä conna√Ætre 9 ‚Äî Lemme de Riemann-Lebesgue**

**Contexte :** Soit $f : [a, b] \to \mathbb{R}$ (ou $f : \mathbb{R} \to \mathbb{R}$ int√©grable).

√ânoncer le lemme de Riemann-Lebesgue et ses deux formes usuelles (segment et droite r√©elle).

### VERSO
**Hypoth√®ses :**

*   **Cas du segment :** $f : [a, b] \to \mathbb{R}$ continue (ou Riemann-int√©grable).
*   **Cas de la droite :** $f : \mathbb{R} \to \mathbb{R}$ int√©grable ($\int_{-\infty}^{+\infty} |f(t)| dt < +\infty$).

**√ânonc√© formel :**

**Cas du segment :**
$$ \int_a^b f(t) e^{i\lambda t} dt \xrightarrow[\lambda \to \pm\infty]{} 0. $$

√âquivalent : $\int_a^b f(t) \cos(\lambda t) dt \to 0$ et $\int_a^b f(t) \sin(\lambda t) dt \to 0$ quand $\lambda \to \pm\infty$.

**Cas de la droite ($f \in L^1(\mathbb{R})$) :**
$$ \hat{f}(\lambda) = \int_{-\infty}^{+\infty} f(t) e^{-i\lambda t} dt \xrightarrow[|\lambda| \to +\infty]{} 0. $$

**D√©monstration (Esquisse, cas $C^1$) :**
IPP : $\int_a^b f(t) e^{i\lambda t} dt = \left[ \frac{f(t)e^{i\lambda t}}{i\lambda} \right]_a^b - \frac{1}{i\lambda} \int_a^b f'(t) e^{i\lambda t} dt = O(1/\lambda) \to 0$.

Cas g√©n√©ral (Riemann-int√©grable) : Approximation par des fonctions en escaliers + passage √† la limite.

### 
**Subtilit√©s :**

*   La vitesse de convergence vers $0$ d√©pend de la r√©gularit√© de $f$ : si $f \in C^k$, alors $\hat{f}(\lambda) = O(\lambda^{-k})$.
*   Le lemme de Riemann-Lebesgue est fondamental en analyse de Fourier.
*   La r√©ciproque est fausse : $\hat{f}(\lambda) \to 0$ n'implique pas $f \in L^1$.

**Pi√®ges classiques :**
*   ‚ùå Penser que la convergence est vers $0$ avec une vitesse universelle ‚Äî elle d√©pend de $f$.
*   ‚ùå Confondre avec la convergence de la transform√©e de Fourier (qui est un r√©sultat diff√©rent).

---

# CHAPITRE 4 ‚Äî Suites de fonctions, approximation

## FLASHCARD 37 ‚Äî Th√©or√®me 19 : Continuit√© de la limite uniforme

### RECTO
**Th√©or√®me 19 ‚Äî Continuit√© de la limite uniforme**

**Contexte :** Soit $(f_n)$ une suite de fonctions $f_n : X \to E$.

√ânoncer le th√©or√®me de continuit√© de la limite uniforme, avec hypoth√®ses exactes sur $X$, $E$, la suite $(f_n)$.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $X$ est un espace m√©trique (ou topologique), $E$ est un espace m√©trique complet (evn).
*   Pour tout $n \in \mathbb{N}$, $f_n : X \to E$ est continue sur $X$.
*   $(f_n)$ converge uniform√©ment vers $f$ sur $X$ :
    $$ \sup_{x \in X} d(f_n(x), f(x)) \xrightarrow[n \to \infty]{} 0. $$

**√ânonc√© formel :**

$$ f : X \to E \text{ est continue sur } X. $$

**D√©monstration (Esquisse) :**
Soit $x_0 \in X$ et $\varepsilon > 0$. Choisir $N$ tel que $\sup_x d(f_n(x), f(x)) < \varepsilon/3$ pour $n \ge N$. Par continuit√© de $f_N$ en $x_0$, $\exists \delta > 0$ tel que $d(x, x_0) < \delta \implies d(f_N(x), f_N(x_0)) < \varepsilon/3$. Alors :
$$ d(f(x), f(x_0)) \le d(f(x), f_N(x)) + d(f_N(x), f_N(x_0)) + d(f_N(x_0), f(x_0)) < \varepsilon. $$

### 
**Subtilit√©s :**

*   La convergence uniforme est indispensable : la limite d'une suite de fonctions continues convergent simplement peut ne pas √™tre continue (ex : $f_n(x) = x^n$ sur $[0, 1]$, limite = $1_{\{x=1\}}$, discontinue).
*   La compl√©tude de $E$ n'est pas n√©cessaire pour la continuit√© de la limite (seulement pour l'existence de la limite dans $E$, si $E$ est de Banach).
*   Le th√©or√®me est valable sur tout espace m√©trique $X$ (pas seulement des intervalles).

**Extensions :**

*   Si chaque $f_n \in C^k$, la convergence uniforme ne garantit pas que $f \in C^k$ (il faut la convergence uniforme des d√©riv√©es ‚Äî voir Thm 22).
*   **Convergence uniforme sur les compacts :** si la convergence est seulement locale uniforme, la limite est quand m√™me continue.

**Pi√®ges classiques :**
*   ‚ùå Conclure √† la continuit√© depuis la convergence simple.
*   ‚ùå Oublier de v√©rifier l'uniformit√© de la convergence (erreur la plus fr√©quente en concours).
*   ‚ùå Confondre convergence uniforme sur $X$ et convergence uniforme sur tout compact de $X$.

---

## FLASHCARD 38 ‚Äî Th√©or√®me 20 : Double limite

### RECTO
**Th√©or√®me 20 ‚Äî Th√©or√®me de la double limite**

**Contexte :** Soit $f_n : X \to E$, $x_0$ point adh√©rent √† $X$.

√ânoncer le th√©or√®me de la double limite (permutation de la limite en $x$ et de la limite en $n$), avec toutes les hypoth√®ses.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $X$ espace m√©trique, $x_0$ point adh√©rent √† $X$ (ou $x_0 \in \overline{X}$), $E$ espace m√©trique complet.
*   Pour tout $n \in \mathbb{N}$, $\lim_{x \to x_0} f_n(x) = \ell_n \in E$ (limite de $f_n$ en $x_0$).
*   $(f_n)$ converge uniform√©ment vers $f$ sur $X \setminus \{x_0\}$ (ou sur $X$) : $\sup_{x \in X} d(f_n(x), f(x)) \to 0$.

**√ânonc√© formel :**

$$ \lim_{n \to \infty} \ell_n = \ell \in E \quad \text{et} \quad \lim_{x \to x_0} f(x) = \ell. $$

Autrement dit :
$$ \lim_{n \to \infty} \left( \lim_{x \to x_0} f_n(x) \right) = \lim_{x \to x_0} \left( \lim_{n \to \infty} f_n(x) \right) = \lim_{x \to x_0} f(x) = \ell. $$

**D√©monstration (Esquisse) :**
$d(\ell_m, \ell_n) \le d(\ell_m, f_m(x)) + d(f_m(x), f_n(x)) + d(f_n(x), \ell_n)$ ‚Äî pour $x$ proche de $x_0$ et $m, n$ grands, chaque terme est petit par uniforme convergence et existence de $\ell_n$.

### 
**Subtilit√©s :**

*   L'uniforme convergence est la cl√© permettant de permuter les deux limites.
*   Sans uniforme convergence, la double limite peut ne pas exister ou donner deux valeurs diff√©rentes selon l'ordre (contre-exemple : $f_n(x) = x^n$ sur $[0, 1[$, $\lim_n \lim_{x \to 1^-} f_n(x) = 1$ mais $\lim_{x \to 1^-} \lim_n f_n(x) = 0$).

**Extensions :**

*   Analogue pour les s√©ries : si $\sum f_n$ converge uniform√©ment et chaque $f_n$ admet une limite en $x_0$, alors $\lim_{x \to x_0} \sum f_n(x) = \sum \lim_{x \to x_0} f_n(x)$.

**Pi√®ges classiques :**
*   ‚ùå Permuter les limites sans uniforme convergence.
*   ‚ùå Oublier de v√©rifier l'existence de chaque $\ell_n$.

---

## FLASHCARD 39 ‚Äî Th√©or√®me 21 : Permutation limite-int√©grale (convergence uniforme sur un segment)

### RECTO
**Th√©or√®me 21 ‚Äî Permutation limite-int√©grale (convergence uniforme sur un segment)**

‚ö†Ô∏è TH√âOR√àME ¬´ DANGEREUX ¬ª : les hypoth√®ses sont strictes.

**Contexte :** Soit $(f_n)$ une suite de fonctions sur $[a, b]$.

√ânoncer le th√©or√®me de permutation limite-int√©grale par convergence uniforme, avec hypoth√®ses exactes. Identifier pourquoi il est qualifi√© de ¬´ dangereux ¬ª.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $[a, b]$ est un segment (compact, $a < b$, $a, b \in \mathbb{R}$).
*   Pour tout $n \in \mathbb{N}$, $f_n : [a, b] \to E$ est continue (ou Riemann-int√©grable) sur $[a, b]$.
*   $(f_n)$ converge uniform√©ment vers $f$ sur $[a, b]$.

**√ânonc√© formel :**

$$ \int_a^b f_n(t) dt \xrightarrow[n \to \infty]{} \int_a^b f(t) dt. $$

Autrement dit :
$$ \lim_{n \to \infty} \int_a^b f_n(t) dt = \int_a^b \lim_{n \to \infty} f_n(t) dt. $$

**Majoration :**
$$ \left| \int_a^b f_n(t) dt - \int_a^b f(t) dt \right| \le (b-a) \sup_{t \in [a, b]} |f_n(t) - f(t)| \to 0. $$

**D√©monstration (Esquisse) :**
In√©galit√© triangulaire + uniforme convergence : $\|\int_a^b (f_n - f)\| \le (b-a) \sup |f_n - f| \to 0$.

### 
**Subtilit√©s :**

*   **Pourquoi ¬´ dangereux ¬ª ?** Car sur un segment, la convergence simple ne suffit pas : ex. $f_n(x) = nxe^{-nx}$ sur $[0, 1]$, $f_n \to 0$ simplement mais $\int_0^1 f_n = 1 - e^{-n} \to 1 \neq 0$.
*   La convergence uniforme sur tout $[a, b]$ est requise ‚Äî pas seulement sur un compact inclus dans $]a, b[$.
*   Pour les int√©grales impropres, la convergence uniforme sur $[a, b]$ ne suffit pas : il faut une domination uniforme (th√©or√®me de convergence domin√©e, Thm 31) ou la convergence normale.
*   Segment born√© ferm√© : la borne $(b-a)$ est finie ‚Äî crucial pour la majoration.

**Extensions :**

*   Sur un intervalle non compact : ce th√©or√®me ne s'applique pas directement ; utiliser le TCD (Thm 31) ou la convergence normale.

**Pi√®ges classiques :**
*   ‚ùå Permuter limite et int√©grale avec seulement la convergence simple.
*   ‚ùå Appliquer sur un intervalle ouvert ou non born√© sans v√©rification compl√©mentaire.
*   ‚ùå Oublier le facteur $(b-a)$ dans la majoration (qui peut √™tre grand).

---

## FLASHCARD 40 ‚Äî Th√©or√®me 22 : R√©gularit√© $C^1$ d'une suite de fonctions

### RECTO
**Th√©or√®me 22 ‚Äî R√©gularit√© $C^1$ de la limite d'une suite de fonctions**

**Contexte :** Soit $(f_n)$ une suite de fonctions de classe $C^1$ sur un intervalle $I$.

√ânoncer le th√©or√®me de r√©gularit√© $C^1$ pour les suites de fonctions, en pr√©cisant les deux hypoth√®ses de convergence distinctes.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $I \subseteq \mathbb{R}$ intervalle (ouvert ou ferm√©, born√© ou non).
*   Pour tout $n \in \mathbb{N}$, $f_n \in C^1(I, E)$ ($E$ evn de Banach).
*   **Hypoth√®se 1 :** $(f_n)$ converge simplement (ou en un point $x_0 \in I$) vers une fonction $f$.
*   **Hypoth√®se 2 :** $(f_n')$ converge uniform√©ment sur tout segment $[a, b] \subset I$ vers une fonction $g : I \to E$.

**√ânonc√© formel :**

$$ f \in C^1(I, E) \quad \text{et} \quad f' = g. $$

Autrement dit : $(f_n)$ converge uniform√©ment sur tout compact de $I$ vers $f$, et $f' = \lim_n f_n'$ (uniform√©ment sur les compacts).

**D√©monstration (Esquisse) :**
Pour $x, x_0 \in I$ :
$$ f_n(x) - f_n(x_0) = \int_{x_0}^x f_n'(t) dt. $$
Par convergence uniforme de $(f_n')$ vers $g$, on peut passer √† la limite (Thm 21) :
$$ f(x) - f(x_0) = \int_{x_0}^x g(t) dt. $$
Donc $f$ est d√©rivable et $f' = g \in C^0$ (limite uniforme de $C^0$), donc $f \in C^1$.

### 
**Subtilit√©s :**

*   Les deux conditions sont ind√©pendantes et toutes deux n√©cessaires :
    *   $(f_n)$ converge simplement : pour fixer la limite (sans quoi $f$ n'est pas d√©termin√©e).
    *   $(f_n')$ converge uniform√©ment sur les compacts : pour passer la d√©riv√©e sous la limite.
*   La convergence simple de $(f_n)$ suffit (pas besoin de convergence uniforme de $(f_n)$) ‚Äî elle est automatiquement uniforme sur les compacts une fois qu'on a la convergence simple + convergence uniforme des d√©riv√©es.
*   Si $I$ est non compact, la convergence de $(f_n')$ doit √™tre uniforme sur tout segment $[a, b] \subset I$ (convergence localement uniforme), pas n√©cessairement sur $I$ entier.

**Extensions :**

*   **Thm 23 :** version $C^k$ (par r√©currence sur $k$).
*   Analogue pour les s√©ries (Thm 29).

**Pi√®ges classiques :**
*   ‚ùå Exiger la convergence uniforme de $(f_n)$ au lieu de la convergence simple (condition trop forte et inutile).
*   ‚ùå Oublier que la convergence de $(f_n')$ doit √™tre uniforme (pas simple) sur les compacts.
*   ‚ùå Confondre ¬´ convergence simple de $f_n$ ¬ª et ¬´ convergence uniforme de $f_n$ ¬ª.

---

## FLASHCARD 41 ‚Äî Th√©or√®me 23 : R√©gularit√© $C^k$

### RECTO
**Th√©or√®me 23 ‚Äî R√©gularit√© $C^k$ de la limite d'une suite de fonctions**

**Contexte :** Soit $(f_n)$ une suite de fonctions de classe $C^k$.

√ânoncer le th√©or√®me de r√©gularit√© $C^k$, en pr√©cisant les hypoth√®ses pour chaque ordre de d√©rivation.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $I \subseteq \mathbb{R}$ intervalle, $E$ evn de Banach, $k \ge 1$.
*   Pour tout $n \in \mathbb{N}$, $f_n \in C^k(I, E)$.
*   Pour $j=1, \dots, k$ : $(f_n^{(j)})$ converge uniform√©ment sur tout segment $[a, b] \subset I$.
*   Pour $j=0$ : $(f_n)$ converge simplement sur $I$ (ou en un point de $I$).

**√ânonc√© formel :**

$$ f = \lim_n f_n \in C^k(I, E) \quad \text{et} \quad \forall j \in \{0, 1, \dots, k\}, \quad f^{(j)} = \lim_n f_n^{(j)}. $$

(Les limites $\lim_n f_n^{(j)}$ sont localement uniformes sur $I$.)

**D√©monstration (Esquisse) :** R√©currence sur $k$ en appliquant le Thm 22 √† chaque √©tape.

### 
**Subtilit√©s :**

*   La condition de convergence uniforme des d√©riv√©es jusqu'√† l'ordre $k$ est n√©cessaire ‚Äî la convergence simple de $f_n^{(k)}$ ne suffit pas.
*   La convergence de $f_n$ elle-m√™me peut √™tre seulement simple (ou en un point).

**Extensions :**

*   Cas $k=+\infty$ ($C^\infty$) : si les hypoth√®ses valent pour tout $k$, alors $f \in C^\infty$.

**Pi√®ges classiques :**
*   ‚ùå Oublier de v√©rifier la convergence uniforme de toutes les d√©riv√©es jusqu'√† l'ordre $k$.

---

## FLASHCARD 42 ‚Äî Th√©or√®me 24 : Approximation par des fonctions en escalier

### RECTO
**Th√©or√®me 24 ‚Äî Approximation par des fonctions en escalier**

**Contexte :** Soit $f : [a, b] \to \mathbb{R}$ continue.

√ânoncer le th√©or√®me d'approximation d'une fonction continue par des fonctions en escalier au sens de la norme uniforme.

### VERSO
**Hypoth√®ses :**

*   $f : [a, b] \to \mathbb{R}$ est continue sur le segment $[a, b]$.

**√ânonc√© formel :**

$$ \forall \varepsilon > 0, \exists \varphi : [a, b] \to \mathbb{R} \text{ en escalier}, \quad \|f - \varphi\|_\infty = \sup_{[a, b]} |f - \varphi| \le \varepsilon. $$

**D√©monstration (Esquisse) :**
Par le th√©or√®me de Heine, $f$ est uniform√©ment continue. Pour $\varepsilon > 0$, prendre $\delta > 0$ associ√©. Subdiviser $[a, b]$ en sous-intervalles de longueur $< \delta$, et d√©finir $\varphi$ constante (valeur de $f$ en un point de chaque sous-intervalle).

### 
**Subtilit√©s :**

*   Ce th√©or√®me utilise Heine (uniforme continuit√©) de mani√®re essentielle.
*   L'espace des fonctions en escalier est dense dans $(C^0([a, b]), \|\cdot\|_\infty)$.
*   Fondement de la th√©orie de l'int√©grale de Riemann.

**Pi√®ges classiques :**
*   ‚ùå Appliquer sans hypoth√®se de compacit√© (intervalle non born√© : faux en g√©n√©ral).

---

## FLASHCARD 43 ‚Äî Th√©or√®me 25 : Th√©or√®me de Weierstrass (approximation polynomiale)

### RECTO
**Th√©or√®me 25 ‚Äî Th√©or√®me d'approximation de Weierstrass**

**Contexte :** Soit $f : [a, b] \to \mathbb{R}$ continue.

√ânoncer le th√©or√®me de Weierstrass sur l'approximation uniforme par des polyn√¥mes.

### VERSO
**Hypoth√®ses :**

*   $f : [a, b] \to \mathbb{R}$ est continue sur $[a, b]$ ($a < b$, $a, b \in \mathbb{R}$).

**√ânonc√© formel :**

$$ \forall \varepsilon > 0, \exists P \in \mathbb{R}[X] \text{ (polyn√¥me)}, \quad \sup_{t \in [a, b]} |f(t) - P(t)| \le \varepsilon. $$

Autrement dit, l'espace $\mathbb{R}[X]|_{[a, b]}$ est dense dans $(C^0([a, b]), \|\cdot\|_\infty)$.

**D√©monstration (Esquisse ‚Äî via polyn√¥mes de Bernstein, voir √Ä conna√Ætre 11) :**
Pour $f : [0, 1] \to \mathbb{R}$, poser $B_n(f)(x) = \sum_{k=0}^n f(k/n) \binom{n}{k} x^k (1-x)^{n-k}$. Montrer $\|B_n(f) - f\|_\infty \to 0$ en utilisant la loi des grands nombres probabiliste (ou un calcul direct).

### 
**Subtilit√©s :**

*   Le degr√© du polyn√¥me approximant n'est pas born√© a priori ‚Äî on ne peut pas approcher uniform√©ment par des polyn√¥mes de degr√© fix√©.
*   Faux sur $\mathbb{R}$ entier : $e^x$ ne peut pas √™tre approch√©e uniform√©ment sur $\mathbb{R}$ par des polyn√¥mes.
*   **Weierstrass trigonom√©trique (√Ä conna√Ætre 13) :** les polyn√¥mes trigonom√©triques sont denses dans $C_{2\pi}^0$.
*   Le r√©sultat est un cas particulier du th√©or√®me de Stone-Weierstrass (alg√®bre de fonctions s√©parant les points).

**Extensions :**

*   **Stone-Weierstrass :** Sur tout espace compact $K$, toute sous-alg√®bre de $C^0(K, \mathbb{R})$ contenant les constantes et s√©parant les points est dense.

**Pi√®ges classiques :**
*   ‚ùå Croire qu'on peut approcher $f$ par un polyn√¥me de degr√© fix√©.
*   ‚ùå √âtendre le r√©sultat √† $\mathbb{R}$ entier sans condition de croissance.

---

## FLASHCARD 44 ‚Äî √Ä conna√Ætre 10 : Moments

### RECTO
**√Ä conna√Ætre 10 ‚Äî Probl√®me des moments**

**Contexte :** Approximation de Weierstrass et identification de mesures par leurs moments.

√ânoncer la propri√©t√© de densit√© li√©e aux moments : si $\int_0^1 f(t) t^n dt = 0$ pour tout $n$, que peut-on conclure ?

### VERSO
**√ânonc√© formel :**

Soit $f \in C^0([0, 1], \mathbb{R})$ (ou $f$ Riemann-int√©grable).

$$ \forall n \in \mathbb{N}, \quad \int_0^1 f(t) t^n dt = 0 \implies f \equiv 0 \text{ sur } [0, 1]. $$

**D√©monstration (Esquisse) :**
Par lin√©arit√©, $\int_0^1 f(t) P(t) dt = 0$ pour tout polyn√¥me $P$. Par Weierstrass, $\forall \varepsilon > 0, \exists P$ tel que $\|f - P\|_\infty \le \varepsilon$. Alors :
$$ \int_0^1 f(t)^2 dt = \int_0^1 f(t)(f(t) - P(t)) dt + \int_0^1 f(t)P(t) dt \le \|f\|_\infty \cdot \varepsilon \cdot 1 + 0. $$
Donc $\int_0^1 f^2 = 0$, donc $f \equiv 0$ (par continuit√© et positivit√©).

### 
**Subtilit√©s :**

*   Ce r√©sultat montre que les moments caract√©risent les fonctions continues sur $[0, 1]$.
*   **G√©n√©ralisation :** Sur $[a, b]$, si $\int_a^b f(t) t^n dt = 0$ pour tout $n \ge 0$, alors $f \equiv 0$.
*   Utilis√© pour : montrer l'injectivit√© de la transform√©e de Laplace, identifier des lois de probabilit√© par leurs moments.

**Pi√®ges classiques :**
*   ‚ùå Oublier que le r√©sultat n√©cessite la continuit√© de $f$ (ou au moins l'int√©grabilit√© au carr√©) pour conclure $f \equiv 0$.

---

## FLASHCARD 45 ‚Äî √Ä conna√Ætre 11 : Weierstrass via Bernstein

### RECTO
**√Ä conna√Ætre 11 ‚Äî Polyn√¥mes de Bernstein et preuve de Weierstrass**

D√©finir les polyn√¥mes de Bernstein $B_n(f)$ et expliquer pourquoi $B_n(f) \to f$ uniform√©ment sur $[0, 1]$.

### VERSO
**D√©finition :**

Pour $f : [0, 1] \to \mathbb{R}$, le $n$-i√®me polyn√¥me de Bernstein est :
$$ B_n(f)(x) = \sum_{k=0}^n f\left(\frac{k}{n}\right) \binom{n}{k} x^k (1-x)^{n-k}, \quad x \in [0, 1]. $$

**Propri√©t√© :**

$$ \|B_n(f) - f\|_\infty \xrightarrow[n \to \infty]{} 0 \quad \text{pour tout } f \in C^0([0, 1]). $$

**D√©monstration (Id√©e) :**
Si $X_1, \dots, X_n \sim \text{Bernoulli}(x)$ i.i.d., alors $B_n(f)(x) = \mathbb{E}[f(\bar{X}_n)]$ o√π $\bar{X}_n = \frac{1}{n} \sum X_i$. Par la LGN et la continuit√© uniforme de $f$ (Heine), $\mathbb{E}[f(\bar{X}_n)] \to f(x)$ uniform√©ment.

### 
**Subtilit√©s :**

*   $B_n(f)$ est un polyn√¥me de degr√© $\le n$.
*   $B_n$ est un op√©rateur positif et lin√©aire : $f \ge 0 \implies B_n(f) \ge 0$.
*   La preuve via la LGN est probabiliste et tr√®s √©l√©gante.

**Pi√®ges classiques :**
*   ‚ùå Croire que $B_n(f)(k/n) = f(k/n)$ ‚Äî faux en g√©n√©ral (les polyn√¥mes de Bernstein n'interpolent pas $f$).

---

## FLASHCARD 46 ‚Äî √Ä conna√Ætre 12 : Weierstrass par convolution

### RECTO
**√Ä conna√Ætre 12 ‚Äî Approximation de l'identit√© et Weierstrass par convolution**

√ânoncer la m√©thode de convolution pour approcher une fonction continue par des fonctions r√©guli√®res, et son lien avec Weierstrass.

### VERSO
**Id√©e centrale ‚Äî Approximation de l'identit√© :**

Soit $(\rho_n)$ une suite de fonctions positives sur $\mathbb{R}$ telles que :
*   $\int_{-\infty}^{+\infty} \rho_n(t) dt = 1$,
*   $\forall \delta > 0, \int_{|t| \ge \delta} \rho_n(t) dt \to 0$ (concentration au voisinage de $0$).

Pour $f : \mathbb{R} \to \mathbb{R}$ continue et born√©e, le produit de convolution :
$$ (f \star \rho_n)(x) = \int_{-\infty}^{+\infty} f(x-t)\rho_n(t) dt $$
converge uniform√©ment vers $f$ sur tout compact.

**Lien avec Weierstrass :** Prendre $\rho_n$ polynomiale (ex : $\rho_n(t) = c_n(1-t^2)^n$ sur $[-1, 1]$) ‚Äî la convolution de $f$ avec $\rho_n$ est un polyn√¥me.

### 
**Subtilit√©s :**

*   La r√©gularit√© de $f \star \rho_n$ est celle de $\rho_n$ (si $\rho_n \in C^\infty$, alors $f \star \rho_n \in C^\infty$).
*   Fondement des fonctions test en analyse fonctionnelle.
*   **Weierstrass trigonom√©trique :** m√™me principe avec le noyau de Fej√©r.

**Pi√®ges classiques :**
*   ‚ùå Oublier que la r√©gularit√© de la convolution est donn√©e par le terme le plus r√©gulier.

---

## FLASHCARD 47 ‚Äî √Ä conna√Ætre 13 : Th√©or√®me de Weierstrass trigonom√©trique

### RECTO
**√Ä conna√Ætre 13 ‚Äî Th√©or√®me de Weierstrass trigonom√©trique**

**Contexte :** Fonctions continues et $2\pi$-p√©riodiques.

√ânoncer le th√©or√®me de Weierstrass trigonom√©trique : densit√© des polyn√¥mes trigonom√©triques dans $(C_{2\pi}^0, \|\cdot\|_\infty)$.

### VERSO
**Hypoth√®ses :**

*   $f : \mathbb{R} \to \mathbb{R}$ (ou $\mathbb{C}$) continue et $2\pi$-p√©riodique.

**√ânonc√© formel :**

$$ \forall \varepsilon > 0, \exists T \text{ polyn√¥me trigonom√©trique}, \quad \sup_{t \in \mathbb{R}} |f(t) - T(t)| \le \varepsilon. $$

O√π un polyn√¥me trigonom√©trique est une combinaison lin√©aire finie de $t \mapsto e^{ikt}$, $k \in \mathbb{Z}$ (ou $\cos(kt), \sin(kt), k \in \mathbb{N}$).

**D√©monstration (Esquisse) :**
Via le noyau de Fej√©r (moyennes de Ces√†ro des sommes partielles de Fourier) : les moyennes de Ces√†ro $\sigma_n(f)$ sont des polyn√¥mes trigonom√©triques convergeant uniform√©ment vers $f$. Ceci utilise des propri√©t√©s du noyau de Fej√©r (positif, int√©grale 1, concentr√© en 0).

### 
**Subtilit√©s :**

*   Les sommes partielles de Fourier $S_n(f)$ ne convergent pas n√©cessairement uniform√©ment (ph√©nom√®ne de Gibbs) ‚Äî il faut les moyennes de Ces√†ro ($\sigma_n(f)$).
*   Ce th√©or√®me est la base de l'analyse de Fourier : les s√©ries de Fourier approchent les fonctions continues en moyenne, et les polyn√¥mes trigonom√©triques en norme uniforme (via Ces√†ro).

**Pi√®ges classiques :**
*   ‚ùå Confondre convergence des sommes de Fourier (conditionnelle) et densit√© des polyn√¥mes trigonom√©triques (uniforme, via Ces√†ro).

---

# CHAPITRE 5 ‚Äî S√©ries de fonctions

## FLASHCARD 48 ‚Äî Th√©or√®me 26 : Convergence normale implique uniforme

### RECTO
**Th√©or√®me 26 ‚Äî Convergence normale implique convergence uniforme**

**Contexte :** Soit $\sum f_n$ une s√©rie de fonctions $f_n : X \to E$.

D√©finir la convergence normale et √©noncer l'implication vers la convergence uniforme.

### VERSO
**D√©finition ‚Äî Convergence normale :**

La s√©rie $\sum f_n$ converge normalement sur $X$ si :
$$ \sum_{n=0}^{+\infty} \sup_{x \in X} \|f_n(x)\| < +\infty. $$

**√ânonc√© formel :**

$$ \sum f_n \text{ converge normalement sur } X \implies \sum f_n \text{ converge absolument et uniform√©ment sur } X. $$

C'est-√†-dire : $\forall x \in X, \sum \|f_n(x)\| < +\infty$, et $\sup_{x \in X} \left\| \sum_{n > N} f_n(x) \right\| \to 0$.

**D√©monstration :**
$$ \sup_{x \in X} \left\| \sum_{n=N+1}^M f_n(x) \right\| \le \sum_{n=N+1}^M \sup_{x \in X} \|f_n(x)\| \to 0 \quad (M, N \to \infty) $$
par convergence de $\sum \sup_x \|f_n(x)\|$.

### 
**Subtilit√©s :**

*   Convergence normale $\implies$ convergence uniforme $\implies$ convergence absolue ponctuelle (toutes les implications sont strictes).
*   **R√©ciproque fausse :** $\sum f_n$ peut converger uniform√©ment sans converger normalement (ex : s√©ries altern√©es).
*   La convergence normale est une propri√©t√© tr√®s forte ‚Äî elle s'applique facilement avec les s√©ries enti√®res (dans le disque de convergence strict) et les int√©grales √† param√®tre.

**Pi√®ges classiques :**
*   ‚ùå Confondre convergence normale et convergence uniforme.
*   ‚ùå V√©rifier la convergence uniforme via la convergence normale quand cette derni√®re n'est pas valable.

---

## FLASHCARD 49 ‚Äî Th√©or√®me 27 : Double limite pour les s√©ries

### RECTO
**Th√©or√®me 27 ‚Äî Th√©or√®me de la double limite pour les s√©ries de fonctions**

**Contexte :** Soit $\sum_{n \ge 0} f_n$ une s√©rie de fonctions $f_n : X \to E$.

√ânoncer le th√©or√®me de la double limite pour une s√©rie de fonctions convergeant uniform√©ment.

### VERSO
**Hypoth√®ses :**

*   Pour tout $n \in \mathbb{N}$, $f_n : X \to E$ admet une limite $\ell_n = \lim_{x \to x_0} f_n(x)$.
*   La s√©rie $\sum f_n$ converge uniform√©ment sur $X$ (ou au voisinage de $x_0$).

**√ânonc√© formel :**

$$ \lim_{x \to x_0} \sum_{n=0}^{+\infty} f_n(x) = \sum_{n=0}^{+\infty} \ell_n = \sum_{n=0}^{+\infty} \lim_{x \to x_0} f_n(x). $$

(Les deux membres sont bien d√©finis et √©gaux.)

**D√©monstration :** Analogue au Thm 20 ‚Äî utiliser l'uniforme convergence pour permuter la limite et la somme.

### 
**Subtilit√©s et pi√®ges :**

*   Strictement analogue au Thm 20 pour les suites.
*   ‚ùå Permuter sans v√©rifier la convergence uniforme.

---

## FLASHCARD 50 ‚Äî Th√©or√®me 28 : Permutation s√©rie-int√©grale (convergence uniforme sur un segment)

### RECTO
**Th√©or√®me 28 ‚Äî Permutation s√©rie-int√©grale (convergence uniforme sur un segment)**

‚ö†Ô∏è TH√âOR√àME ¬´ DANGEREUX ¬ª

**Contexte :** Soit $\sum f_n$ une s√©rie de fonctions sur $[a, b]$.

√ânoncer le th√©or√®me de permutation s√©rie-int√©grale sous hypoth√®se de convergence uniforme.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $[a, b]$ segment compact ($a < b$).
*   Pour tout $n$, $f_n : [a, b] \to E$ continue (ou Riemann-int√©grable).
*   $\sum f_n$ converge uniform√©ment sur $[a, b]$.

**√ânonc√© formel :**

$$ \int_a^b \left( \sum_{n=0}^{+\infty} f_n(t) \right) dt = \sum_{n=0}^{+\infty} \int_a^b f_n(t) dt. $$

**D√©monstration :** Application du Thm 21 aux sommes partielles $S_N = \sum_{n=0}^N f_n$ qui convergent uniform√©ment vers $\sum f_n$.

### 
**Subtilit√©s :**

*   **Pourquoi ¬´ dangereux ¬ª ?** Car on ne peut pas permuter sur un intervalle non compact sans hypoth√®se suppl√©mentaire (convergence domin√©e ou normale).
*   La convergence normale (√Ä conna√Ætre 14) suffit et est plus facile √† v√©rifier.

**Pi√®ges classiques :**
*   ‚ùå Permuter sur un intervalle non born√© avec seulement la convergence uniforme.
*   ‚ùå Oublier de v√©rifier la convergence uniforme (et non seulement ponctuelle).

---

## FLASHCARD 51 ‚Äî Th√©or√®me 29 : R√©gularit√© $C^1$ d'une s√©rie de fonctions

### RECTO
**Th√©or√®me 29 ‚Äî R√©gularit√© $C^1$ d'une s√©rie de fonctions**

**Contexte :** Soit $\sum f_n$ une s√©rie de fonctions $C^1$.

√ânoncer le th√©or√®me de r√©gularit√© $C^1$ pour les s√©ries de fonctions, avec hypoth√®ses exactes.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $I \subseteq \mathbb{R}$ intervalle, $E$ evn de Banach.
*   Pour tout $n$, $f_n \in C^1(I, E)$.
*   **H1 :** $\sum f_n$ converge simplement sur $I$ (ou en un point).
*   **H2 :** $\sum f_n'$ converge uniform√©ment sur tout segment $[a, b] \subset I$.

**√ânonc√© formel :**

$$ f = \sum_{n=0}^{+\infty} f_n \in C^1(I, E) \quad \text{et} \quad f' = \sum_{n=0}^{+\infty} f_n'. $$

**D√©monstration :** Application du Thm 22 aux sommes partielles.

### 
**Subtilit√©s :**

*   H1 porte sur $\sum f_n$, H2 porte sur $\sum f_n'$ : deux conditions sur deux s√©ries diff√©rentes.
*   La convergence uniforme de $\sum f_n$ sur les compacts est une cons√©quence, pas une hypoth√®se.
*   **Pratique :** En g√©n√©ral, on v√©rifie H2 par convergence normale de $\sum f_n'$.

**Pi√®ges classiques :**
*   ‚ùå Exiger la convergence uniforme de $\sum f_n$ au lieu de la simple convergence.
*   ‚ùå Oublier de v√©rifier la convergence de $\sum f_n$ (m√™me simple) s√©par√©ment de celle de $\sum f_n'$.
*   ‚ùå Ne pas v√©rifier H2 sur les segments et se contenter de la convergence simple de $\sum f_n'$.

---

## FLASHCARD 52 ‚Äî Th√©or√®me 30 : R√©gularit√© $C^k$ d'une s√©rie de fonctions

### RECTO
**Th√©or√®me 30 ‚Äî R√©gularit√© $C^k$ d'une s√©rie de fonctions**

√ânoncer le th√©or√®me de r√©gularit√© $C^k$ pour les s√©ries de fonctions.

### VERSO
**Hypoth√®ses compl√®tes :**

*   $I$ intervalle, $E$ Banach, $k \ge 1$.
*   Pour tout $n$, $f_n \in C^k(I, E)$.
*   Pour $j=1, \dots, k$ : $\sum f_n^{(j)}$ converge uniform√©ment sur tout segment de $I$.
*   Pour $j=0$ : $\sum f_n$ converge simplement (ou en un point).

**√ânonc√© formel :**

$$ \sum f_n \in C^k(I, E) \quad \text{et} \quad \forall j \le k, \left( \sum f_n \right)^{(j)} = \sum f_n^{(j)}. $$

**D√©monstration :** R√©currence sur $k$ via le Thm 29.

### 
**Pi√®ges classiques :**
*   ‚ùå Oublier de v√©rifier la convergence uniforme sur les compacts de toutes les s√©ries d√©riv√©es $\sum f_n^{(j)}$ jusqu'√† l'ordre $k$.

---

# CHAPITRE 6 ‚Äî S√©ries enti√®res

## FLASHCARD 53 ‚Äî Lemme 1 : Lemme d'Abel

### RECTO
**Lemme 1 ‚Äî Lemme d'Abel (s√©ries enti√®res)**

**Contexte :** Soit $\sum a_n z^n$ une s√©rie enti√®re.

√ânoncer le lemme d'Abel : que peut-on d√©duire de la convergence (ou du caract√®re born√©) de $\sum a_n z_0^n$ pour les $z$ avec $|z| < |z_0|$ ?

### VERSO
**Hypoth√®ses et √©nonc√© formel :**

Soit $\sum a_n z^n$ une s√©rie enti√®re ($a_n \in \mathbb{C}$, ou dans un evn de Banach).

**Version 1 (convergence) :**
$$ \sum a_n z_0^n \text{ converge} \implies \forall z \text{ avec } |z| < |z_0|, \quad \sum a_n z^n \text{ converge absolument.} $$

**Version 2 (termes born√©s) :**
$$ \exists M > 0, \forall n \in \mathbb{N}, |a_n z_0^n| \le M \implies \forall z \text{ avec } |z| < |z_0|, \quad \sum a_n z^n \text{ converge absolument.} $$

**D√©monstration (Esquisse ‚Äî version 2) :**
$$ |a_n z^n| = |a_n z_0^n| \cdot \left| \frac{z}{z_0} \right|^n \le M \cdot r^n, \quad r = \frac{|z|}{|z_0|} < 1. $$
La s√©rie $\sum M r^n$ est convergente (g√©om√©trique).

### 
**Subtilit√©s :**

*   Le lemme d'Abel justifie l'existence d'un rayon de convergence $R \in [0, +\infty]$ tel que :
    *   $|z| < R$ : convergence absolue.
    *   $|z| > R$ : divergence.
    *   $|z| = R$ : pas de conclusion g√©n√©rale.
*   Convergence normale sur tout disque ferm√© $\bar{D}(0, r)$ avec $r < R$.

**Extensions :**

*   Le rayon de convergence est donn√© par $R = \frac{1}{\limsup_{n \to \infty} |a_n|^{1/n}}$ (formule de Hadamard).

**Pi√®ges classiques :**
*   ‚ùå Conclure sur la convergence sur le cercle $|z| = |z_0|$ ‚Äî le lemme ne dit rien.
*   ‚ùå Oublier que la convergence absolue est garantie, pas seulement simple.

---

## FLASHCARD 54 ‚Äî Proposition 9 : R√®gle de d'Alembert pour les s√©ries enti√®res

### RECTO
**Proposition 9 ‚Äî R√®gle de d'Alembert pour les s√©ries enti√®res**

**Contexte :** Soit $\sum a_n z^n$ une s√©rie enti√®re √† coefficients $a_n \in \mathbb{C}$, de rayon de convergence $R$.

**Question :** √ânoncer la r√®gle de d'Alembert pour les s√©ries enti√®res : si le rapport $|a_{n+1}|/|a_n|$ converge, que peut-on conclure sur $R$ ?

### VERSO
**Hypoth√®ses compl√®tes**
*   $\sum a_n z^n$ est une s√©rie enti√®re √† coefficients dans $\mathbb{C}$.
*   Les coefficients $a_n$ sont non nuls √† partir d'un certain rang (pour que le rapport soit d√©fini).
*   La limite $\ell = \lim_{n \to +\infty} \frac{|a_{n+1}|}{|a_n|}$ existe dans $[0, +\infty]$.

**√ânonc√© formel**
Si $\ell = \lim_{n \to +\infty} \frac{|a_{n+1}|}{|a_n|} \in [0, +\infty]$, alors $R = \frac{1}{\ell}$
avec les conventions $\frac{1}{0} = +\infty$ et $\frac{1}{+\infty} = 0$.

**Pr√©cision sur la convergence :**

$$ \forall z \in \mathbb{C}, \quad \left| \frac{a_{n+1} z^{n+1}}{a_n z^n} \right| = \frac{|a_{n+1}|}{|a_n|} \cdot |z| \xrightarrow[n \to +\infty]{} \ell |z| $$

*   Si $\ell |z| < 1$, i.e. $|z| < \frac{1}{\ell} = R$ : la s√©rie $\sum a_n z^n$ est absolument convergente (r√®gle de d'Alembert pour les s√©ries num√©riques).
*   Si $\ell |z| > 1$, i.e. $|z| > R$ : le terme g√©n√©ral ne tend pas vers $0$, donc la s√©rie diverge grossi√®rement.
*   Si $\ell |z| = 1$, i.e. $|z| = R$ : aucune conclusion g√©n√©rale.

**D√©monstration (Esquisse)**
*   **R√©duction √† d'Alembert num√©rique :** Pour $z$ fix√©, on pose $u_n = a_n z^n$. On calcule $\left| \frac{u_{n+1}}{u_n} \right| = \frac{|a_{n+1}|}{|a_n|} \cdot |z| \to \ell |z|$.
*   **Application de la r√®gle de d'Alembert pour les s√©ries num√©riques :** Si $\ell |z| < 1$, alors $\sum |u_n|$ converge ; si $\ell |z| > 1$, alors $|u_n| \to +\infty$.
*   **Identification avec $R$ :** Par d√©finition de $R = \sup \{|z| : \sum a_n z^n \text{ converge}\}$ (formule de Hadamard : $1/R = \limsup |a_n|^{1/n}$), et comme $\limsup |a_n|^{1/n} = \lim |a_n|^{1/n}$ lorsque $\lim |a_{n+1}|/|a_n|$ existe (et vaut la m√™me limite), on conclut $R = 1/\ell$.

### 
**Subtilit√©s**
*   La r√®gle de d'Alembert ne donne que $R$, pas le comportement sur le cercle $|z| = R$. Le cercle de convergence est toujours √† traiter √† part, et c'est souvent l√† que se joue la finesse du probl√®me de concours.
*   **La limite doit exister.** Si $\frac{|a_{n+1}|}{|a_n|}$ n'a pas de limite (par exemple si les $a_n$ oscillent), la r√®gle de d'Alembert ne s'applique pas, et il faut recourir √† la formule de Hadamard : $1/R = \limsup_{n \to +\infty} |a_n|^{1/n}$, qui est toujours valide.
*   **Condition ¬´ non nuls √† partir d'un certain rang ¬ª :** Si $a_n = 0$ infiniment souvent (e.g. s√©ries enti√®res en $z^2$), le rapport $|a_{n+1}|/|a_n|$ n'est pas d√©fini. Il faut alors utiliser Hadamard ou traiter directement la s√©rie avec le changement $w = z^2$.
*   **Cas $\ell = 0$ :** $R = +\infty$, la s√©rie enti√®re est une fonction enti√®re (ex : $e^z$, $\sin z$).
*   **Cas $\ell = +\infty$ :** $R = 0$, la s√©rie ne converge qu'en $z=0$.

**Extensions**
*   Validit√© pour $a_n \in \mathbb{C}$ : Oui, totalement. La r√®gle s'applique en toute g√©n√©ralit√© dans $\mathbb{C}$.
*   Lien avec la formule de Hadamard : La formule de Hadamard $1/R = \limsup |a_n|^{1/n}$ est toujours vraie (sans hypoth√®se sur la convergence du rapport). D'Alembert est un cas particulier (corollaire) de Hadamard, valable uniquement lorsque la limite du rapport existe, car :
    $$ \lim_{n \to +\infty} \frac{|a_{n+1}|}{|a_n|} = \ell \implies \lim_{n \to +\infty} |a_n|^{1/n} = \ell $$
    (lemme classique : si $u_{n+1}/u_n \to \ell$ alors $u_n^{1/n} \to \ell$).
*   Ne pas confondre avec la r√®gle de d'Alembert pour les s√©ries num√©riques $\sum u_n$ : ici on calcule le rayon, et on retrouve ensuite d'Alembert num√©rique pour chaque $z$ fix√©.

**Pi√®ges classiques**
*   ‚ùå Oublier de v√©rifier le cercle $|z| = R$ : √âcrire ¬´ la s√©rie converge pour $|z| \le R$ ¬ª est faux en g√©n√©ral. La r√®gle de d'Alembert ne dit rien sur $|z| = R$.
*   ‚ùå Confondre $R$ et $1/R$ : Tr√®s fr√©quent sous pression. M√©moriser : $R = 1/\ell$, donc si $|a_{n+1}/a_n| \to 2$, alors $R = 1/2$, pas $2$.
*   ‚ùå Appliquer la r√®gle quand la limite n'existe pas : Si $a_n = 1 + (-1)^n$, le rapport oscille. Il faut imp√©rativement passer √† Hadamard.
*   ‚ùå Oublier la convention $1/0 = +\infty$ : Si $\ell = 0$ (coefficients d√©croissant tr√®s vite), la s√©rie converge partout. Si $\ell = +\infty$, elle ne converge qu'en $0$.
*   ‚ùå Croire que d'Alembert est √©quivalent √† Hadamard : D'Alembert est une condition suffisante pour calculer $R$ (elle implique Hadamard), mais Hadamard est toujours applicable. D'Alembert est un outil pratique, pas un outil universel.

---

## FLASHCARD 55 ‚Äî Proposition 10 : Produit de Cauchy de deux s√©ries enti√®res

### RECTO
**Proposition 10 ‚Äî Produit de Cauchy de deux s√©ries enti√®res**

**Contexte :** Soient $\sum a_n z^n$ et $\sum b_n z^n$ deux s√©ries enti√®res √† coefficients complexes, de rayons de convergence $R_1$ et $R_2$ respectivement.

**Question :** √ânoncer la proposition sur le produit de Cauchy de deux s√©ries enti√®res : d√©finition des coefficients, rayon de convergence du produit, et √©galit√© des sommes.

### VERSO
**Hypoth√®ses compl√®tes**
*   $\sum_{n=0}^{+\infty} a_n z^n$ s√©rie enti√®re de rayon $R_1 \in (0, +\infty]$.
*   $\sum_{n=0}^{+\infty} b_n z^n$ s√©rie enti√®re de rayon $R_2 \in (0, +\infty]$.
*   $a_n, b_n \in \mathbb{C}$ pour tout $n \in \mathbb{N}$.

**√ânonc√© formel**
On d√©finit les coefficients du produit de Cauchy par :
$$ \forall n \in \mathbb{N}, \quad c_n = \sum_{k=0}^n a_k b_{n-k} $$

Alors la s√©rie enti√®re $\sum c_n z^n$ v√©rifie :
$$ R_{\text{produit}} \ge \min(R_1, R_2) $$

et pour tout $z \in \mathbb{C}$ avec $|z| < \min(R_1, R_2)$ :
$$ \left( \sum_{n=0}^{+\infty} a_n z^n \right) \cdot \left( \sum_{n=0}^{+\infty} b_n z^n \right) = \sum_{n=0}^{+\infty} c_n z^n $$

**Cas d'√©galit√© du rayon :** Si $R_1 \neq R_2$, alors $R_{\text{produit}} = \min(R_1, R_2)$.

**D√©monstration (Esquisse)**
*   **Convergence absolue :** Pour $|z| < \min(R_1, R_2)$, les deux s√©ries $\sum a_n z^n$ et $\sum b_n z^n$ convergent absolument. C'est la condition requise pour le produit de Cauchy de s√©ries num√©riques.
*   **Produit de Cauchy de s√©ries absolument convergentes :** Si $\sum \alpha_n$ et $\sum \beta_n$ convergent absolument, leur produit de Cauchy $\sum \gamma_n$ (avec $\gamma_n = \sum_{k=0}^n \alpha_k \beta_{n-k}$) converge absolument, et sa somme est $(\sum \alpha_n)(\sum \beta_n)$.
*   **Application :** On pose $\alpha_n = a_n z^n$, $\beta_n = b_n z^n$, $\gamma_n = c_n z^n$, d'o√π le r√©sultat pour tout $|z| < \min(R_1, R_2)$, ce qui donne $R_{\text{produit}} \ge \min(R_1, R_2)$.

### 
**Subtilit√©s**
*   **In√©galit√© et non √©galit√© du rayon :** En g√©n√©ral, $R_{\text{produit}} \ge \min(R_1, R_2)$. Il peut √™tre strictement plus grand : si $R_1 = R_2 = R$ et que les singularit√©s des deux s√©ries se ¬´ compensent ¬ª, le produit peut avoir un rayon plus grand. Exemple classique : $\sum (-1)^n z^n$ (rayon 1) fois $\sum (-1)^n z^n$ (rayon 1) donne $\sum c_n z^n$ o√π le rayon peut d√©passer 1.
*   **Si $R_1 \neq R_2$ :** Le rayon du produit vaut exactement $\min(R_1, R_2)$, car la singularit√© de la s√©rie de plus petit rayon ne peut pas √™tre annul√©e par l'autre.
*   **Condition d'application :** L'√©galit√© des sommes $(\sum a_n z^n)(\sum b_n z^n) = \sum c_n z^n$ n√©cessite la convergence absolue de l'une des deux s√©ries (ou des deux). Pour les s√©ries num√©riques, le produit de Cauchy de deux s√©ries simplement convergentes peut diverger (contre-exemple de Cauchy lui-m√™me).

**Extensions**
*   **Produit de Cauchy en s√©rie enti√®re vs s√©rie num√©rique :** La situation est plus favorable pour les s√©ries enti√®res que pour les s√©ries num√©riques g√©n√©rales, car dans le disque ouvert de convergence, les s√©ries enti√®res convergent absolument, ce qui rend le produit de Cauchy licite automatiquement.
*   **Application importante :** On utilise ce r√©sultat pour multiplier des d√©veloppements en s√©ries enti√®res : $(e^z)^2 = e^{2z}$, ou pour calculer $\tan z$ √† partir des s√©ries de $\sin z$ et $\cos z$ (division formelle).

**Pi√®ges classiques**
*   ‚ùå √âcrire $R_{\text{produit}} = \min(R_1, R_2)$ sans justification : C'est vrai si $R_1 \neq R_2$, mais c'est une in√©galit√© large si $R_1 = R_2$. Ne pas affirmer l'√©galit√© dans le cas $R_1 = R_2$ sans argument suppl√©mentaire.
*   ‚ùå Confondre produit de Cauchy et produit terme √† terme : $c_n = \sum_{k=0}^n a_k b_{n-k}$ est une convolution, pas $a_n b_n$.
*   ‚ùå Oublier la convergence absolue comme pr√©requis : Le produit de Cauchy de deux s√©ries simplement convergentes peut ne pas converger. C'est la convergence absolue (garantie dans le disque ouvert pour les s√©ries enti√®res) qui sauve la situation.
*   **Sens de l'application :** Le produit de Cauchy donne la s√©rie enti√®re du produit des sommes. Pour diviser deux s√©ries enti√®res (e.g. $\tan z = \sin z / \cos z$), il faut r√©soudre $\sum c_n z^n \cdot \sum b_n z^n = \sum a_n z^n$ par identification des coefficients ‚Äî ce n'est pas imm√©diat.

---

## FLASHCARD 56 ‚Äî Proposition 11 : R√©gularit√© de la somme d'une s√©rie enti√®re

### RECTO
**Proposition 11 ‚Äî R√©gularit√© de la somme d'une s√©rie enti√®re**

**Contexte :** Soit $f(z) = \sum_{n=0}^{+\infty} a_n z^n$ une s√©rie enti√®re √† coefficients $a_n \in \mathbb{C}$, de rayon de convergence $R > 0$.

**Question :** √ânoncer les propri√©t√©s de r√©gularit√© (continuit√©, d√©rivabilit√©, classe $C^\infty$, formule des coefficients) de la somme $f$ sur son disque ouvert de convergence.

### VERSO
**Hypoth√®ses compl√®tes**
*   $\sum_{n=0}^{+\infty} a_n z^n$ s√©rie enti√®re √† coefficients $a_n \in \mathbb{C}$, de rayon de convergence $R \in (0, +\infty]$.
*   On note $D = \{z \in \mathbb{C} : |z| < R\}$ le disque ouvert de convergence (ou $I = (-R, R)$ si on se restreint aux r√©els).

**√ânonc√© formel**
1.  **Convergence normale sur tout compact :**
    $$ \forall r \in (0, R), \sum_{n=0}^{+\infty} a_n z^n \text{ converge normalement sur } \{|z| \le r\} $$
    car $\sum |a_n| r^n < +\infty$ pour $r < R$.

2.  **Continuit√© :**
    $f : z \mapsto \sum_{n=0}^{+\infty} a_n z^n$ est continue sur $D$.

3.  **D√©rivabilit√© terme √† terme (cas r√©el ou complexe) :**
    La s√©rie d√©riv√©e $\sum_{n=1}^{+\infty} n a_n z^{n-1}$ a le m√™me rayon de convergence $R$, et :
    $$ \forall z \in D, \quad f'(z) = \sum_{n=1}^{+\infty} n a_n z^{n-1} = \sum_{n=0}^{+\infty} (n+1) a_{n+1} z^n $$

4.  **R√©gularit√© $C^\infty$ :**
    $$ f \in C^\infty(D, \mathbb{C}) \quad (\text{ou } C^\infty((-R, R), \mathbb{C}) \text{ sur } \mathbb{R}) $$
    et $\forall k \in \mathbb{N}$ :
    $$ f^{(k)}(z) = \sum_{n=k}^{+\infty} \frac{n!}{(n-k)!} a_n z^{n-k} $$

5.  **Formule des coefficients (identification) :**
    $$ \forall n \in \mathbb{N}, \quad a_n = \frac{f^{(n)}(0)}{n!} $$

**D√©monstration (Esquisse)**
*   **Convergence normale sur $|z| \le r < R$ :** Pour $r < R$, $r$ est dans le disque de convergence, donc $\sum |a_n| r^n < +\infty$, et $\sup_{|z| \le r} |a_n z^n| \le |a_n| r^n$. La s√©rie des majorants converge, d'o√π la convergence normale.
*   **Continuit√© :** Cons√©quence directe de la convergence uniforme sur tout compact (limite uniforme de fonctions continues est continue).
*   **D√©rivabilit√© :** On montre que la s√©rie d√©riv√©e $\sum n a_n z^{n-1}$ a le m√™me rayon $R$ (car $\limsup |n a_n|^{1/n} = \limsup |a_n|^{1/n}$ puisque $n^{1/n} \to 1$). On applique le th√©or√®me de d√©rivation terme √† terme (convergence normale sur tout compact $\implies$ permutation d√©riv√©e/somme).
*   **It√©ration :** En it√©rant la d√©rivation, on obtient $C^\infty$ et la formule des coefficients en √©valuant en $0$.

### 
**Subtilit√©s**
*   **Le rayon de la s√©rie d√©riv√©e est exactement $R$ :** C'est un point crucial. La d√©rivation ne change pas le rayon de convergence. La preuve repose sur $\lim n^{1/n} = 1$, donc $\limsup |n a_n|^{1/n} = \limsup |a_n|^{1/n}$. Mais attention : le comportement sur le cercle $|z| = R$ peut changer (une s√©rie peut converger en un point du cercle, mais sa d√©riv√©e non).
*   **Convergence normale vs uniforme :** La convergence est normale (donc uniforme) sur tout compact inclus dans $D$, mais pas uniforme sur $D$ tout entier en g√©n√©ral (sauf si $R=+\infty$).
*   **La formule $a_n = f^{(n)}(0)/n!$ est fondamentale :** Elle signifie que si deux s√©ries enti√®res co√Øncident sur un voisinage de $0$, elles ont les m√™mes coefficients (unicit√© du d√©veloppement en s√©rie enti√®re).
*   **D√©rivabilit√© complexe (holomorphie) :** Dans $\mathbb{C}$, $f$ est non seulement $C^\infty$ au sens r√©el mais holomorphe (analytique complexe) sur $D$. C'est un r√©sultat bien plus fort que la simple r√©gularit√© r√©elle.

**Extensions**
*   **Primitivation terme √† terme :** De m√™me, $\sum \frac{a_n}{n+1} z^{n+1}$ est une primitive de $f$ sur $D$, avec le m√™me rayon $R$.
*   Une fonction $C^\infty$ r√©elle n'est pas n√©cessairement d√©veloppable en s√©rie enti√®re (exemple : $e^{-1/x^2}$ prolong√©e par $0$ en $0$). La proposition 11 va dans l'autre sens : une s√©rie enti√®re est toujours $C^\infty$.
*   **En dimension infinie :** Ces r√©sultats restent valables pour des s√©ries enti√®res √† valeurs dans un espace de Banach $E$ (avec $|a_n|$ remplac√© par $\|a_n\|$), pourvu que la notion de d√©rivabilit√© soit bien d√©finie.

**Pi√®ges classiques**
*   ‚ùå Croire que la d√©rivation peut changer le rayon : Non. $R_{\text{d√©riv√©e}} = R_{\text{originale}}$. Ce qui peut changer, c'est la convergence sur le cercle $|z| = R$.
*   ‚ùå Confondre convergence uniforme sur $D$ et sur les compacts de $D$ : La convergence est uniforme sur tout compact, pas sur $D$ ouvert en g√©n√©ral.
*   ‚ùå Oublier la formule des coefficients : En concours, quand on demande de prouver que deux d√©veloppements co√Øncident ou d'identifier une s√©rie enti√®re, la formule $a_n = f^{(n)}(0)/n!$ est l'outil d√©cisif.
*   ‚ùå D√©river sans v√©rifier le rayon : Avant de d√©river terme √† terme, il faut s'assurer qu'on est bien dans le disque ouvert de convergence. Le r√©sultat ne s'applique pas directement sur le bord.

---

## FLASHCARD 57 ‚Äî Proposition 12 : D√©veloppements en s√©rie enti√®re au programme

### RECTO
**Proposition 12 ‚Äî D√©veloppements en s√©rie enti√®re au programme**

**Contexte :** On consid√®re les fonctions usuelles d√©finies sur $\mathbb{R}$ ou $\mathbb{C}$.

**Question :** Donner les d√©veloppements en s√©rie enti√®re au programme (exponentielle, sinus, cosinus, logarithme, puissance, g√©om√©trique), avec les rayons de convergence exacts et les domaines de validit√©.

### VERSO
**√ânonc√© formel ‚Äî D√©veloppements au programme**

1.  **Exponentielle :**
    $$ \forall z \in \mathbb{C}, \quad e^z = \sum_{n=0}^{+\infty} \frac{z^n}{n!}, \quad R = +\infty $$

2.  **Cosinus et Sinus :**
    $$ \forall z \in \mathbb{C}, \quad \cos z = \sum_{n=0}^{+\infty} (-1)^n \frac{z^{2n}}{(2n)!}, \quad R = +\infty $$
    $$ \forall z \in \mathbb{C}, \quad \sin z = \sum_{n=0}^{+\infty} (-1)^n \frac{z^{2n+1}}{(2n+1)!}, \quad R = +\infty $$

3.  **Cosinus hyperbolique et Sinus hyperbolique :**
    $$ \forall z \in \mathbb{C}, \quad \cosh z = \sum_{n=0}^{+\infty} \frac{z^{2n}}{(2n)!}, \quad R = +\infty $$
    $$ \forall z \in \mathbb{C}, \quad \sinh z = \sum_{n=0}^{+\infty} \frac{z^{2n+1}}{(2n+1)!}, \quad R = +\infty $$

4.  **S√©rie g√©om√©trique :**
    $$ \forall z \in \mathbb{C}, \ |z| < 1, \quad \frac{1}{1-z} = \sum_{n=0}^{+\infty} z^n, \quad R = 1 $$

5.  **Logarithme :**
    $$ \forall x \in (-1, 1], \quad \ln(1+x) = \sum_{n=1}^{+\infty} (-1)^{n-1} \frac{x^n}{n} = x - \frac{x^2}{2} + \frac{x^3}{3} - \dots, \quad R = 1 $$
    (Valide en $x=1$ par le th√©or√®me d'Abel, non valide en $x=-1$.)

6.  **Puissance $(1+x)^\alpha$ pour $\alpha \in \mathbb{R}$ :**
    $$ \forall x \in (-1, 1), \quad (1+x)^\alpha = \sum_{n=0}^{+\infty} \binom{\alpha}{n} x^n, \quad R = 1 $$
    o√π $\binom{\alpha}{n} = \frac{\alpha(\alpha-1)\dots(\alpha-n+1)}{n!}$ (coefficient binomial g√©n√©ralis√©).
    (En $x=\pm 1$ : d√©pend de $\alpha$, cas particuliers.)

7.  **Arctangente :**
    $$ \forall x \in [-1, 1], \quad \arctan x = \sum_{n=0}^{+\infty} (-1)^n \frac{x^{2n+1}}{2n+1}, \quad R = 1 $$
    (Valide aux deux bornes $\pm 1$ par Abel.)

### 
**Subtilit√©s**
*   **Domaine de $\ln(1+x)$ :** La s√©rie converge pour $x \in (-1, 1]$. En $x=1$ : convergence (s√©rie altern√©e) vers $\ln 2$. En $x=-1$ : divergence (s√©rie harmonique). Ne jamais √©crire $|x| \le 1$ sans pr√©ciser $x \neq -1$.
*   **Domaine de $(1+x)^\alpha$ aux bornes :**
    *   $x=1$ : converge si $\alpha > -1$, diverge si $\alpha \le -1$.
    *   $x=-1$ : converge si $\alpha > 0$, diverge sinon.
    Ces cas limites sont hors programme strict mais peuvent appara√Ætre en oral X/ENS.
*   **S√©rie g√©om√©trique :** Valide pour $|z| < 1$ dans $\mathbb{C}$. En $|z|=1$, la s√©rie diverge (terme g√©n√©ral ne tend pas vers $0$).
*   **D√©veloppement de $\arctan$ en $\pm 1$ :** Valide par le th√©or√®me d'Abel. En $x=1$ : $\arctan 1 = \pi/4 = \sum \frac{(-1)^n}{2n+1}$ (formule de Leibniz).

**Extensions**
*   **D√©veloppements d√©riv√©s :** On peut d√©river terme √† terme dans $(-1, 1)$ pour retrouver :
    $$ \frac{1}{1+x} = \sum_{n=0}^{+\infty} (-1)^n x^n, \quad \frac{1}{(1-x)^2} = \sum_{n=1}^{+\infty} n x^{n-1} $$
*   **Fonctions trigonom√©triques inverses :** $\arcsin x = \sum_{n=0}^{+\infty} \binom{2n}{n} \frac{x^{2n+1}}{4^n(2n+1)}$ pour $|x| < 1$, obtenu en int√©grant $1/\sqrt{1-x^2}$.

**Pi√®ges classiques**
*   ‚ùå **Indice de d√©part :** $\sum_{n=0}$ pour $e^z, \cos, \cosh, \frac{1}{1-z}$. $\sum_{n=1}$ pour $\ln(1+x)$ (premier terme est $n=1$). Confondre les indices fait perdre des points.
*   ‚ùå **Signe dans $\ln(1+x)$ :** $(-1)^{n-1}/n$ et non $(-1)^n/n$. V√©rifier en $n=1$ : $+x$. ‚úì
*   ‚ùå **Domaine de validit√© du logarithme :** √âcrire $|x| < 1$ sans inclure $x=1$ est incomplet (la convergence en $x=1$ est un r√©sultat non trivial).
*   ‚ùå **Coefficient binomial g√©n√©ralis√© :** $\binom{\alpha}{0} = 1, \binom{\alpha}{1} = \alpha, \binom{\alpha}{2} = \frac{\alpha(\alpha-1)}{2}$. Pour $\alpha=-1$ : $\binom{-1}{n} = (-1)^n$, d'o√π $\frac{1}{1+x} = \sum (-1)^n x^n$. V√©rifier la coh√©rence avec la s√©rie g√©om√©trique.
*   ‚ùå **Oublier qu'on d√©veloppe en puissances de $x$, pas de $x-a$ :** Ces d√©veloppements sont centr√©s en $0$. Si on veut d√©velopper $f$ au voisinage de $a \neq 0$, il faut √©crire $f(a+h)$ et d√©velopper en $h$.

---

## FLASHCARD 58 ‚Äî √Ä conna√Ætre 14 : Convergence normale d'une s√©rie enti√®re

### RECTO
**√Ä conna√Ætre 14 ‚Äî Convergence normale d'une s√©rie enti√®re**

**Contexte :** Soit $\sum a_n z^n$ une s√©rie enti√®re √† coefficients $a_n \in \mathbb{C}$, de rayon de convergence $R > 0$.

**Question :** Sur quel type de domaine la s√©rie enti√®re converge-t-elle normalement ? √ânoncer pr√©cis√©ment le r√©sultat avec les bonnes quantifications.

### VERSO
**Hypoth√®ses compl√®tes**
*   $\sum a_n z^n$ s√©rie enti√®re, $a_n \in \mathbb{C}$, rayon de convergence $R \in (0, +\infty]$.
*   $r \in \mathbb{R}$ avec $0 \le r < R$.

**√ânonc√© formel**
$$ \forall r \in [0, R), \quad \sum_{n=0}^{+\infty} \sup_{|z| \le r} |a_n z^n| = \sum_{n=0}^{+\infty} |a_n| r^n < +\infty $$

**Autrement dit :**

La s√©rie enti√®re $\sum a_n z^n$ converge normalement sur tout disque ferm√© $\overline{D}(0, r) = \{z \in \mathbb{C} : |z| \le r\}$ pour tout $r < R$.

**Cons√©quences imm√©diates :**

*   Convergence uniforme sur $\overline{D}(0, r)$ pour tout $r < R$.
*   La somme $f(z) = \sum_{n=0}^{+\infty} a_n z^n$ est continue sur $D(0, R)$.
*   La convergence n'est pas normale sur $D(0, R)$ ouvert en g√©n√©ral.

**D√©monstration (Esquisse)**
*   **Choix de $r' \in (r, R)$ :** Puisque $r < R$, il existe $r' \in (r, R)$ tel que $\sum |a_n| (r')^n < +\infty$.
*   **Majoration :** $|a_n| r^n = |a_n| (r')^n \cdot \left( \frac{r}{r'} \right)^n \le |a_n| (r')^n$ puisque $r/r' < 1$.
*   **Convergence de la s√©rie majorante :** $\sum |a_n| r^n \le \sum |a_n| (r')^n < +\infty$.

### 
**Subtilit√©s**
*   **Convergence normale sur $\overline{D}(0, r)$ mais pas sur $D(0, R)$ :** C'est la distinction fondamentale. L'ouvert $D(0, R)$ est recouvert par une famille croissante de ferm√©s $\overline{D}(0, r)$ pour $r \to R^-$. La convergence est uniforme sur chacun, mais pas globalement sur l'ouvert.
*   **"Compact" vs "disque ferm√©" :** En pratique, on dit que la s√©rie converge normalement sur tout compact inclus dans $D(0, R)$. Tout compact de $\mathbb{C}$ inclus dans $D(0, R)$ est contenu dans un $\overline{D}(0, r)$ pour un certain $r < R$.
*   **Sur le cercle $|z| = R$ :** La convergence doit √™tre √©tudi√©e au cas par cas (Abel, crit√®re des s√©ries altern√©es, etc.). La convergence normale ne s'√©tend pas automatiquement.

**Extensions**
*   **Analogue pour les s√©ries de fonctions :** Ce r√©sultat est l'analogue exact, pour les s√©ries enti√®res, du th√©or√®me de r√©gularit√© $C^k$ des s√©ries de fonctions : convergence normale sur tout compact $\implies$ permutation limite/d√©riv√©e.
*   **Int√©gration terme √† terme :** La convergence normale sur $\overline{D}(0, r)$ permet d'int√©grer terme √† terme sur tout chemin inclus dans $D(0, R)$.

**Pi√®ges classiques**
*   ‚ùå **Affirmer la convergence normale sur $D(0, R)$ ouvert :** Faux en g√©n√©ral. Exemple : $\sum z^n$ converge normalement sur $\overline{D}(0, r)$ pour $r < 1$, mais $\sum \sup_{|z|<1} |z^n| = \sum 1 = +\infty$.
*   ‚ùå **Oublier que $r < R$ est strict :** La convergence de $\sum |a_n| r^n$ pour $r < R$ est garantie par d√©finition de $R$, mais peut diverger pour $r=R$.
*   ‚ùå **Confondre convergence normale et convergence absolue :** La convergence absolue est en un point ; la convergence normale est uniforme sur un ensemble (et implique la convergence absolue en chaque point).

---

## FLASHCARD 59 ‚Äî Proposition 13 : Lemme d'Abel radial (Th√©or√®me d'Abel)

### RECTO
**Proposition 13 ‚Äî Lemme d'Abel radial**

**Contexte :** Soit $\sum_{n=0}^{+\infty} a_n$ une s√©rie √† coefficients $a_n \in \mathbb{C}$, suppos√©e convergente (de somme $S$). On consid√®re la s√©rie enti√®re r√©elle $f(x) = \sum_{n=0}^{+\infty} a_n x^n$, de rayon de convergence $R \ge 1$.

**Question :** √ânoncer le lemme d'Abel radial : que peut-on dire du comportement de $f(x)$ quand $x \to 1^-$ ?

### VERSO
**Hypoth√®ses compl√®tes**
*   $\sum_{n=0}^{+\infty} a_n$ est une s√©rie convergente (au sens usuel des s√©ries num√©riques dans $\mathbb{C}$), de somme $S = \sum_{n=0}^{+\infty} a_n$.
*   La s√©rie enti√®re $f(x) = \sum_{n=0}^{+\infty} a_n x^n$ a un rayon de convergence $R \ge 1$ (garanti par la convergence de $\sum a_n$).

**√ânonc√© formel**
$$ \lim_{\substack{x \to 1 \\ x < 1}} f(x) = \lim_{x \to 1^-} \sum_{n=0}^{+\infty} a_n x^n = \sum_{n=0}^{+\infty} a_n = S $$

Autrement dit : on peut permuter la limite $x \to 1^-$ et la sommation, et la somme de la s√©rie enti√®re en $x=1$ co√Øncide avec la limite radiale.

**Formulation √©quivalente :** Si $f : [0, 1) \to \mathbb{C}$ est d√©finie par $f(x) = \sum_{n \ge 0} a_n x^n$ et si $\sum a_n$ converge, alors $f$ est prolongeable par continuit√© en $x=1$ et $f(1^-) = \sum_{n \ge 0} a_n$.

**D√©monstration (Esquisse)**
*   **Transformation d'Abel (sommation par parties) :** On pose $S_N = \sum_{n=0}^N a_n$ et $S_{-1} = 0$. On √©crit :
    $$ f(x) = \sum_{n=0}^N a_n x^n + R_N(x) = \sum_{n=0}^N (S_n - S_{n-1}) x^n + R_N(x) $$
    En sommant par parties, on obtient une expression faisant appara√Ætre $(1-x) \sum S_n x^n$.
*   **Convergence de $S_n \to S$ :** On d√©compose $f(x) - S = (1-x) \sum_{n=0}^{+\infty} (S_n - S) x^n$ et on montre que cette expression tend vers $0$ quand $x \to 1^-$, en utilisant que $S_n - S \to 0$ et que $(1-x) \sum x^n = 1$.
*   **Conclusion :** $|f(x) - S| \le \varepsilon$ pour $x$ assez proche de $1$, d'o√π la limite.

### 
**Subtilit√©s**
*   **La r√©ciproque est fausse :** Si $\lim_{x \to 1^-} f(x) = L$, on ne peut pas conclure que $\sum a_n$ converge et vaut $L$. Contre-exemple classique : $\sum (-1)^n x^n = \frac{1}{1+x} \to 1/2$ quand $x \to 1^-$, alors que $\sum (-1)^n$ diverge. On dit que $\sum (-1)^n$ est somme d'Abel $1/2$.
*   **Sens de la limite :** radial (le long de l'axe r√©el). Le lemme d'Abel radial ne dit rien de la limite selon d'autres directions dans $\mathbb{C}$. La version plus forte (lemme d'Abel non tangentiel) est plus d√©licate.
*   **Rayon $R \ge 1$ est automatique :** Si $\sum a_n$ converge, alors $a_n \to 0$, donc $(a_n)$ est born√©e, donc $\limsup |a_n|^{1/n} \le 1$, donc $R \ge 1$. La convergence de $\sum a_n$ garantit que le point $x=1$ est au moins sur le cercle de convergence.
*   **Application principale :** prolongement par continuit√©. Si on conna√Æt la s√©rie enti√®re sur $(-1, 1)$ et que la s√©rie $\sum a_n$ converge, on peut calculer la valeur en $x=1$ par continuit√© radiale.

**Extensions**
*   **Th√©or√®me de Tauber (r√©ciproque partielle) :** Si $f(x) \to L$ quand $x \to 1^-$ ET si $n a_n \to 0$, alors $\sum a_n$ converge et vaut $L$. C'est un r√©sultat profond (hors programme, mais connu des meilleurs √©l√®ves).
*   **Lemme d'Abel sur le cercle $|z| = R$ :** Plus g√©n√©ralement, si $\sum a_n z_0^n$ converge pour $|z_0| = R$, alors $f(r z_0) \to \sum a_n z_0^n$ quand $r \to 1^-$ (en approchant radialement $z_0$).

**Applications classiques :**
*   $\ln 2 = \sum_{n=1}^{+\infty} \frac{(-1)^{n-1}}{n}$ (Abel sur $\ln(1+x)$ en $x=1$).
*   $\frac{\pi}{4} = \sum_{n=0}^{+\infty} \frac{(-1)^n}{2n+1}$ (formule de Leibniz, Abel sur $\arctan$ en $x=1$).

**Pi√®ges classiques**
*   ‚ùå **Appliquer Abel sans v√©rifier la convergence de $\sum a_n$ :** C'est l'hypoth√®se cl√©. Si $\sum a_n$ diverge, on ne peut pas conclure sur $\lim_{x \to 1^-} f(x)$ via Abel.
*   ‚ùå **Confondre ¬´ la s√©rie converge en $x=1$ ¬ª et ¬´ la limite radiale existe ¬ª :** Ce sont deux choses diff√©rentes. Abel dit : convergence de $\sum a_n \implies$ limite radiale = $\sum a_n$. Mais la limite radiale peut exister sans que la s√©rie converge en $1$ (exemple $\sum (-1)^n x^n$).
*   ‚ùå **Oublier que la limite est unilat√©rale $x \to 1^-$ :** On approche $1$ par valeurs inf√©rieures (dans le disque de convergence). Ce n'est pas une limite bilat√©rale.
*   ‚ùå **Tenter d'appliquer Abel √† une s√©rie divergente pour ¬´ sommer ¬ª une s√©rie divergente :** La somme d'Abel est un proc√©d√© de sommation r√©gulier, pas une somme ordinaire. Les confondre est une faute grave.

---

## FLASHCARD 60 ‚Äî √Ä conna√Ætre 15 : Formule int√©grale de Cauchy

### RECTO
**√Ä conna√Ætre 15 ‚Äî Formule int√©grale de Cauchy**

**Contexte :** Soit $f : U \to \mathbb{C}$ une fonction holomorphe sur un ouvert $U$ de $\mathbb{C}$. Soit $\gamma$ un lacet (chemin ferm√©) inclus dans $U$, de classe $C^1$ par morceaux, d'indice $\text{Ind}(\gamma, a) = 1$ autour d'un point $a \in U \setminus \gamma$.

**Question :** √ânoncer la formule int√©grale de Cauchy (pour $f(a)$ et pour les d√©riv√©es $f^{(n)}(a)$).

### VERSO
**Hypoth√®ses compl√®tes**
*   $U \subset \mathbb{C}$ ouvert.
*   $f : U \to \mathbb{C}$ holomorphe sur $U$ (i.e., $\mathbb{C}$-diff√©rentiable en tout point de $U$).
*   $\gamma : [0, 1] \to U$ lacet de classe $C^1$ par morceaux, √† valeurs dans $U$, tel que $a \notin \gamma([0, 1])$ et $\text{Ind}(\gamma, a) = \frac{1}{2\pi i} \int_\gamma \frac{dz}{z-a} = 1$.
*   (Cas pratique le plus courant : $\gamma$ est le cercle $\gamma(t) = a + r e^{2\pi i t}$, $t \in [0, 1]$, parcouru une fois dans le sens direct, avec $\overline{D}(a, r) \subset U$.)

**√ânonc√© formel**
**Formule de Cauchy pour $f(a)$ :**
$$ f(a) = \frac{1}{2\pi i} \int_\gamma \frac{f(z)}{z-a} dz $$

**Formule de Cauchy pour les d√©riv√©es :**
$$ \forall n \in \mathbb{N}, \quad f^{(n)}(a) = \frac{n!}{2\pi i} \int_\gamma \frac{f(z)}{(z-a)^{n+1}} dz $$

**In√©galit√©s de Cauchy :** Si $|f(z)| \le M$ sur $\gamma =$ cercle de rayon $r$ centr√© en $a$ :
$$ |f^{(n)}(a)| \le \frac{n! M}{r^n} $$

**D√©monstration (Esquisse)**
*   **Pour $f(a)$ :** On √©crit $\frac{f(z)}{z-a} = \frac{f(z)-f(a)}{z-a} + \frac{f(a)}{z-a}$. L'holomorphie assure que $\frac{f(z)-f(a)}{z-a}$ se prolonge en une fonction holomorphe, dont l'int√©grale sur $\gamma$ est nulle (th√©or√®me de Cauchy). L'int√©grale de $\frac{f(a)}{z-a}$ vaut $f(a) \cdot 2\pi i$ (calcul direct ou indice).
*   **Pour $f^{(n)}(a)$ :** On d√©rive sous le signe int√©grale $n$ fois par rapport √† $a$ (licite car la convergence est uniforme en $z$ sur $\gamma$) : $\frac{d^n}{da^n} \frac{1}{z-a} = \frac{n!}{(z-a)^{n+1}}$.
*   **In√©galit√©s de Cauchy :** Majoration directe : $|f^{(n)}(a)| \le \frac{n!}{2\pi} \cdot \frac{M}{r^{n+1}} \cdot 2\pi r = \frac{n! M}{r^n}$.

### 
**Subtilit√©s**
*   **Holomorphie est indispensable :** La formule est fausse pour une simple fonction $C^\infty$ r√©elle. Elle repose fondamentalement sur la $\mathbb{C}$-diff√©rentiabilit√©.
*   **L'indice doit valoir 1 :** Si $\text{Ind}(\gamma, a) = k$, la formule devient $f(a) = \frac{1}{2\pi i k} \int_\gamma \frac{f(z)}{z-a} dz$... ou plus pr√©cis√©ment $\int_\gamma \frac{f(z)}{z-a} dz = 2\pi i \cdot \text{Ind}(\gamma, a) \cdot f(a)$.
*   **Cons√©quence majeure :** toute fonction holomorphe est analytique. La formule de Cauchy permet de d√©velopper $f$ en s√©rie enti√®re autour de $a$ (en d√©veloppant $\frac{1}{z-a}$ en s√©rie de $\frac{z_0-a}{z-a}$), ce qui d√©montre que holomorphe $\iff$ analytique en analyse complexe.
*   **In√©galit√©s de Cauchy :** Elles permettent de prouver le th√©or√®me de Liouville : toute fonction holomorphe born√©e sur $\mathbb{C}$ est constante (en faisant $r \to +\infty$, on obtient $|f^{(1)}(a)| \le M/r \to 0$).

**Extensions**
*   **Formule de Cauchy et calcul de r√©sidus :** Si $f$ a un p√¥le d'ordre $n+1$ en $a$, on peut relier les r√©sidus √† la formule de Cauchy pour les d√©riv√©es.
*   **D√©veloppement en s√©rie de Laurent :** La formule int√©grale de Cauchy sert de base √† la th√©orie des s√©ries de Laurent pour les fonctions m√©romorphes.
*   **Hors programme mais connu en oral ENS :** La formule de repr√©sentation int√©grale est la base de la th√©orie $H^p$ des espaces de Hardy et de nombreux r√©sultats d'approximation.

**Pi√®ges classiques**
*   ‚ùå **Oublier le $n!$ dans la formule pour $f^{(n)}$ :** C'est $\frac{n!}{2\pi i}$, pas $\frac{1}{2\pi i}$.
*   ‚ùå **Confondre $(z-a)^{n+1}$ et $(z-a)^n$ :** Pour $f^{(n)}$, le d√©nominateur est $(z-a)^{n+1}$ (exposant $n+1$, non $n$).
*   ‚ùå **Croire que la formule s'applique √† $C^\infty$ r√©el :** Elle est sp√©cifique √† l'analyse complexe. Une fonction $C^\infty$ r√©elle ne satisfait pas une telle formule int√©grale.
*   ‚ùå **Oublier la condition $\overline{D}(a, r) \subset U$ :** La formule n√©cessite que le disque ferm√© soit enti√®rement dans le domaine d'holomorphie.

---

## FLASHCARD 61 ‚Äî √Ä conna√Ætre 16 : √âquivalent d'une s√©rie enti√®re √† partir des coefficients

### RECTO
**√Ä conna√Ætre 16 ‚Äî √âquivalent d'une s√©rie enti√®re √† partir des coefficients**

**Contexte :** Soit $f(x) = \sum_{n=0}^{+\infty} a_n x^n$ une s√©rie enti√®re r√©elle de rayon de convergence $R > 0$. On suppose que le premier coefficient non nul est $a_N$ (i.e., $a_0 = a_1 = \dots = a_{N-1} = 0$ et $a_N \neq 0$).

**Question :** Donner l'√©quivalent de $f(x)$ au voisinage de $0$, et l'√©quivalent de $f(x)$ au voisinage du bord $x \to R^-$ lorsque $a_n \sim c \cdot r^{-n}$ pour un certain $r < R$.

### VERSO
**√ânonc√© formel**
1.  **√âquivalent en $0$ (ordre du z√©ro) :**
    Si $a_0 = \dots = a_{N-1} = 0$ et $a_N \neq 0$, alors :
    $$ f(x) \underset{x \to 0}{=} a_N x^N + o(x^N), \quad \text{i.e., } f(x) \underset{x \to 0}{\sim} a_N x^N $$
    C'est une cons√©quence directe de la continuit√© et de la formule $a_n = f^{(n)}(0)/n!$.

2.  **√âquivalent en $x \to R^-$ (singularit√© dominante) :**
    Si les coefficients satisfont $a_n \sim c \cdot \rho^{-n}$ quand $n \to +\infty$ (avec $\rho = R$, i.e., $\rho^{-1} = R^{-1}$ est le rayon), alors le comportement de $f(x)$ pr√®s de $x=R$ est dict√© par la singularit√© dominante. Cas typique :
    *   Si $a_n \sim \frac{c}{R^n}$ (tous les $a_n$ du m√™me signe, positifs), alors $f(x) \to +\infty$ quand $x \to R^-$ et :
        $$ f(x) \underset{x \to R^-}{\sim} \frac{c}{1 - x/R} \cdot \frac{1}{R^n} \dots $$
        (Le comportement exact d√©pend de la nature de la singularit√©.)
    *   **Cas particulier fondamental :** Si $a_n \sim \frac{C}{n^\alpha R^n}$ pour $\alpha > 0$, alors
        $$ f(x) \sim C \cdot \frac{(-\ln(1-x/R))^{\alpha-1}}{(\alpha-1)!} $$
        (li√© aux s√©ries de Bertrand au bord).

3.  **Lemme de transfert (cas √©l√©mentaire) :**
    Si $f(x) = \sum_{n=0}^{+\infty} a_n x^n$ avec $a_n \ge 0$ et $a_n \sim \frac{c}{R^n}$ quand $n \to \infty$, alors :
    $$ f(x) \underset{x \to R^-}{\sim} \frac{c R}{R-x} $$
    car $\sum_{n \ge 0} x^n / R^n = \frac{R}{R-x} \to +\infty$.

**D√©monstration (Esquisse)**
*   **Pour l'√©quivalent en $0$ :** D√©veloppement de Taylor √† l'ordre $N$ : $f(x) = a_N x^N + a_{N+1} x^{N+1} + \dots = a_N x^N(1 + O(x))$.
*   **Pour l'√©quivalent au bord :** On utilise la comparaison $\sum a_n x^n \sim c \sum (x/R)^n \cdot \dots$ (somme g√©om√©trique) lorsque $a_n$ est √©quivalent √† un terme g√©om√©trique, et le r√©sultat de sommation des √©quivalents de s√©ries √† termes positifs.

### 
**Subtilit√©s**
*   L'√©quivalent en $0$ est imm√©diat mais l'√©quivalent au bord est subtil et d√©pend du type de singularit√© (p√¥le simple $\leftrightarrow \frac{c}{R-x}$, singularit√© logarithmique $\leftrightarrow \ln \frac{1}{R-x}$, etc.).
*   La ¬´ singularit√© dominante ¬ª est la singularit√© de $f$ la plus proche de $0$ dans $\mathbb{C}$. Pour une s√©rie enti√®re r√©elle, c'est g√©n√©ralement le point $x=R$ ou $x=-R$ (ou un point du cercle $|z|=R$).
*   **Attention aux s√©ries enti√®res lacunaires :** Si $f(x) = \sum a_{2n} x^{2n}$ (s√©rie en $x^2$), l'√©quivalent en $0$ commence au premier terme non nul, et la singularit√© est √† $|z|=R$ mais peut √™tre atteinte pour $x=R$ et $x=-R$ (ou $iz = \pm R$).

**Extensions**
*   **Th√©orie de Darboux / m√©thode des singularit√©s (combinatoire analytique) :** Dans le cadre de la combinatoire analytique (Flajolet-Sedgewick), on extrait des √©quivalents des coefficients $a_n$ √† partir du type de singularit√© de $f$. C'est une g√©n√©ralisation syst√©matique de ces id√©es.
*   **S√©ries g√©n√©ratrices :** En combinatoire, $f(x) = \sum a_n x^n$ o√π $a_n$ compte des structures de taille $n$. L'√©quivalent de $a_n$ (comportement asymptotique du nombre de structures) est d√©duit du type de singularit√© de $f$.

**Pi√®ges classiques**
*   ‚ùå **Confondre ¬´ rayon de convergence ¬ª et ¬´ singularit√© ¬ª :** La singularit√© de $f$ est au rayon $R$, mais $f$ peut √™tre analytique en certains points du cercle et singuli√®re en d'autres.
*   ‚ùå **Sommation abusive des √©quivalents :** Pour passer de $a_n \sim b_n$ √† $\sum a_n x^n \sim \sum b_n x^n$, il faut des hypoth√®ses (termes de m√™me signe, ou convergence domin√©e). Ce n'est pas automatique pour des s√©ries altern√©es.
*   ‚ùå **Oublier que l'√©quivalent en $0$ est $a_N x^N$ et non $a_N x^N + a_{N+1} x^{N+1}$ :** L'√©quivalent est le terme dominant. Le suivant est un $o$.

---

## FLASHCARD 62 ‚Äî Th√©or√®me 31 : Th√©or√®me de convergence domin√©e (mesure de Lebesgue)

### RECTO
**Th√©or√®me 31 ‚Äî Th√©or√®me de convergence domin√©e**

**Contexte :** Soit $(f_n)_{n \in \mathbb{N}}$ une suite de fonctions mesurables sur un espace mesur√© $(\Omega, \mathcal{A}, \mu)$ (en pratique : $\Omega \subset \mathbb{R}$, $\mu = \text{mesure de Lebesgue}$ ou mesure de comptage).

**Question :** √ânoncer le th√©or√®me de convergence domin√©e (TCD) avec ses hypoth√®ses exactes et ses conclusions (convergence de l'int√©grale, permutation limite-int√©grale, convergence $L^1$).

### VERSO
**Hypoth√®ses compl√®tes**
*   $(\Omega, \mathcal{A}, \mu)$ espace mesur√© ($\Omega$ intervalle de $\mathbb{R}$, $\mu = \text{mesure de Lebesgue}$, ou $\Omega = \mathbb{N}$, $\mu = \text{mesure de comptage}$).
*   $(f_n)_{n \in \mathbb{N}}$ suite de fonctions mesurables $f_n : \Omega \to \mathbb{R}$ (ou $\mathbb{C}$).
*   **Convergence presque partout :** $f_n \xrightarrow[n \to +\infty]{} f$ p.p. sur $\Omega$ (i.e., $\mu$-presque partout).
*   **Domination :** $\exists g : \Omega \to [0, +\infty]$ int√©grable (i.e., $\int_\Omega g d\mu < +\infty$) telle que :
    $$ \forall n \in \mathbb{N}, \quad |f_n| \le g \quad \mu\text{-p.p.} $$

**√ânonc√© formel**
Sous ces hypoth√®ses :

1.  $f$ est int√©grable : $f \in L^1(\Omega, \mu)$.
2.  **Convergence $L^1$ :**
    $$ \lim_{n \to +\infty} \int_\Omega |f_n - f| d\mu = 0 $$
3.  **Permutation limite-int√©grale :**
    $$ \lim_{n \to +\infty} \int_\Omega f_n d\mu = \int_\Omega f d\mu = \int_\Omega \lim_{n \to +\infty} f_n d\mu $$

**D√©monstration (Esquisse)**
*   **Lemme de Fatou :** Pour des fonctions positives mesurables $(h_n) \ge 0$ : $\int \liminf h_n \le \liminf \int h_n$.
*   **Application √† $g - f_n \ge 0$ et $g + f_n \ge 0$ :** On applique Fatou √† ces deux suites positives (qui convergent p.p. vers $g-f$ et $g+f$) pour obtenir des in√©galit√©s dans les deux sens.
*   **Conclusion :** On d√©duit $\limsup \int f_n \le \int f \le \liminf \int f_n$, donc $\int f_n \to \int f$. La convergence $L^1$ s'obtient en appliquant le m√™me raisonnement √† $|f_n - f| \le 2g$.

### 
**Subtilit√©s**
*   **La domination doit √™tre par une fonction $g$ int√©grable, pas seulement born√©e.** Si $\Omega = \mathbb{R}$ et $|f_n| \le 1$, on ne peut pas appliquer TCD directement car la fonction constante 1 n'est pas int√©grable sur $\mathbb{R}$ (mais elle l'est sur un segment $[a, b]$).
*   **Convergence p.p. et non convergence partout :** Il suffit que $f_n \to f$ hors d'un ensemble de mesure nulle. En pratique, si on a la convergence partout, c'est encore mieux.
*   La limite $f$ est bien mesurable (limite p.p. de fonctions mesurables est mesurable).
*   **TCD sur $\mathbb{N}$ (mesure de comptage) :** Le TCD appliqu√© √† $\Omega = \mathbb{N}$, $\mu = \text{mesure de comptage}$ donne : si $u_{n,k} \to v_k$ pour tout $k$ et $|u_{n,k}| \le w_k$ avec $\sum w_k < +\infty$, alors $\sum_k u_{n,k} \to \sum_k v_k$. C'est le th√©or√®me de convergence domin√©e pour les s√©ries (√Ä conna√Ætre 5).
*   **Pas d'hypoth√®se de monotonie :** Contrairement au th√©or√®me de convergence monotone (TCM), TCD n'exige pas la monotonie des $f_n$.

**Extensions**
*   **Cas $L^p$ :** Si $|f_n|^p \le g \in L^1$, on obtient $f_n \to f$ dans $L^p$.
*   **TCD √† param√®tre continu :** Si $f_n$ est remplac√©e par $f_t$ avec $t \to t_0$ continu, l'analogue du TCD (Th√©or√®me 32) s'applique avec les m√™mes hypoth√®ses (convergence p.p. remplac√©e par convergence p.p. pour $t \to t_0$, et domination uniforme en $t$).
*   **Relation avec l'int√©grale de Riemann :** Pour les fonctions Riemann-int√©grables sur $[a, b]$, le TCD (dans sa version Lebesgue) est plus puissant. Les th√©or√®mes 21 et 28 (convergence uniforme sur un segment) sont des cas particuliers o√π la domination est triviale (borne uniforme sur un compact).

**Pi√®ges classiques**
*   ‚ùå **Oublier de v√©rifier l'int√©grabilit√© de $g$ :** La dominante doit √™tre int√©grable. Une dominante born√©e ne suffit pas sur un domaine non born√©.
*   ‚ùå **Confondre convergence p.p. et convergence uniforme :** TCD n'exige pas la convergence uniforme (c'est son avantage sur les th√©or√®mes du chapitre 4). La convergence p.p. suffit.
*   ‚ùå **Appliquer TCD sans dominante :** Si on ne peut pas exhiber de dominante int√©grable, TCD ne s'applique pas. Il faut chercher une autre m√©thode (TCM, Fatou, int√©gration par parties, etc.).
*   ‚ùå **Oublier que la conclusion inclut la convergence $L^1$** (pas seulement la permutation limite-int√©grale). En concours, on peut demander les deux.
*   ‚ùå **Ne pas v√©rifier la mesurabilit√© de $f_n$ :** TCD s'applique aux fonctions mesurables. En pratique, les fonctions continues, continues par morceaux, ou limites de telles fonctions sont mesurables ‚Äî mais il faut le mentionner.

---

## FLASHCARD 63 ‚Äî Th√©or√®me 32 : TCD √† param√®tre continu

### RECTO
**Th√©or√®me 32 ‚Äî Th√©or√®me de convergence domin√©e √† param√®tre continu**

**Contexte :** Soit $f : \Omega \times I \to \mathbb{R}$ (ou $\mathbb{C}$) o√π $(\Omega, \mathcal{A}, \mu)$ est un espace mesur√© et $I$ est un intervalle de $\mathbb{R}$ (ou un espace m√©trique). On pose $F(t) = \int_\Omega f(x, t) d\mu(x)$.

**Question :** √ânoncer le th√©or√®me de convergence domin√©e √† param√®tre continu (continuit√© de $F$ et permutation limite-int√©grale).

### VERSO
**Hypoth√®ses compl√®tes**
1.  **Continuit√© en $t$ :** Pour $\mu$-presque tout $x \in \Omega$, la fonction $t \mapsto f(x, t)$ est continue en $t_0 \in I$ (ou sur $I$).
2.  **Domination uniforme en $t$ :** $\exists g \in L^1(\Omega, \mu)$, $g \ge 0$, telle que :
    $$ \forall t \in I, \quad |f(x, t)| \le g(x) \quad \mu\text{-p.p. en } x $$
3.  Pour tout $t \in I$, $x \mapsto f(x, t)$ est mesurable.

**√ânonc√© formel**
**Continuit√© de $F$ en $t_0$ :**
$$ F(t) = \int_\Omega f(x, t) d\mu(x) \xrightarrow[t \to t_0]{} \int_\Omega f(x, t_0) d\mu(x) = F(t_0) $$

Autrement dit, on peut permuter la limite et l'int√©grale :
$$ \lim_{t \to t_0} \int_\Omega f(x, t) d\mu(x) = \int_\Omega \lim_{t \to t_0} f(x, t) d\mu(x) $$

Si de plus la continuit√© en $t_0$ est valable pour tout $t_0 \in I$, alors $F$ est continue sur $I$.

**D√©monstration (Esquisse)**
*   **R√©duction √† TCD discret :** Pour toute suite $t_n \to t_0$, on pose $f_n(x) = f(x, t_n)$. Alors $f_n(x) \to f(x, t_0)$ p.p. (par hypoth√®se de continuit√© p.p.) et $|f_n(x)| \le g(x)$ p.p.
*   **Application du TCD (discret, Th√©or√®me 31) :** On conclut $\int f_n d\mu \to \int f(\cdot, t_0) d\mu$, i.e., $F(t_n) \to F(t_0)$.
*   **Caract√©risation s√©quentielle de la continuit√© :** Comme toute suite $t_n \to t_0$ donne $F(t_n) \to F(t_0)$, $F$ est continue en $t_0$.

### 
**Subtilit√©s**
*   **La domination doit √™tre uniforme en $t$ :** $|f(x, t)| \le g(x)$ pour tous les $t \in I$. Si la domination n'est uniforme que sur un voisinage de $t_0$, c'est suffisant pour la continuit√© en $t_0$.
*   **Continuit√© p.p. et non partout :** Il suffit que $t \mapsto f(x, t)$ soit continue en $t_0$ pour $\mu$-presque tout $x$. En pratique, souvent continue partout.
*   **Lien avec le Th√©or√®me 36 (continuit√© des int√©grales √† param√®tre) :** Le Th√©or√®me 36 du chapitre 8 est pr√©cis√©ment ce r√©sultat dans le cadre des int√©grales √† param√®tre (√©ventuellement impropres). Le Th√©or√®me 32 est la version abstraite (mesure quelconque).

**Extensions**
*   **Version pour la d√©rivabilit√© :** C'est l'objet du Th√©or√®me 37. On remplace la continuit√© en $t$ par la d√©rivabilit√© en $t$, et on ajoute une domination de $\partial_t f$.
*   **Param√®tre dans $\mathbb{R}^d$ :** Le th√©or√®me s'√©tend √† $t \in U \subset \mathbb{R}^d$ (ou espace m√©trique quelconque) avec la m√™me preuve (caract√©risation s√©quentielle).

**Pi√®ges classiques**
*   ‚ùå **Domination locale vs globale :** Pour la continuit√© en $t_0$, une domination locale (sur un voisinage de $t_0$) suffit. Pour la continuit√© sur tout $I$, il faut une domination globale uniforme sur $I$.
*   ‚ùå **Oublier de v√©rifier la mesurabilit√© :** $x \mapsto f(x, t)$ doit √™tre mesurable pour chaque $t$. C'est souvent √©vident (fonctions continues, etc.) mais doit √™tre mentionn√©.
*   ‚ùå **Confondre ce th√©or√®me avec le th√©or√®me de r√©gularit√© $C^1$ :** Ce th√©or√®me donne la continuit√© de $F$. Pour la d√©rivabilit√©, il faut le Th√©or√®me 37 avec des hypoth√®ses suppl√©mentaires sur $\partial_t f$.

---

## FLASHCARD 64 ‚Äî Th√©or√®me 33 : TCD appliqu√© aux sommes partielles (permutation s√©rie-int√©grale)

### RECTO
**Th√©or√®me 33 ‚Äî Th√©or√®me de convergence domin√©e appliqu√© aux sommes partielles**

**Contexte :** Soit $(u_n)_{n \in \mathbb{N}}$ une suite de fonctions mesurables sur $(\Omega, \mathcal{A}, \mu)$.

**Question :** √ânoncer le th√©or√®me permettant de permuter une somme de s√©rie et une int√©grale, en pr√©cisant les hypoth√®ses exactes (convergence p.p., domination int√©grable de la somme partielle).

### VERSO
**Hypoth√®ses compl√®tes**
*   $u_n : \Omega \to \mathbb{R}$ (ou $\mathbb{C}$) mesurables pour tout $n \in \mathbb{N}$.
*   La s√©rie $\sum_{n=0}^{+\infty} u_n(x)$ converge p.p. sur $\Omega$.
*   **Domination (convergence domin√©e) :** $\exists g \in L^1(\Omega, \mu)$, $g \ge 0$, telle que :
    $$ \forall N \in \mathbb{N}, \quad \left| \sum_{n=0}^N u_n(x) \right| \le g(x) \quad \mu\text{-p.p.} $$
    (En pratique : il suffit que $\sum_{n=0}^{+\infty} |u_n(x)| \le g(x)$ p.p., ce qui est une condition suffisante.)

**√ânonc√© formel**
Sous ces hypoth√®ses :

$$ \int_\Omega \sum_{n=0}^{+\infty} u_n(x) d\mu(x) = \sum_{n=0}^{+\infty} \int_\Omega u_n(x) d\mu(x) $$

De plus, chaque $u_n$ est int√©grable et la s√©rie $\sum \int_\Omega u_n d\mu$ converge absolument.

**Condition suffisante pratique (domination par la somme des valeurs absolues) :**

Si $\sum_{n=0}^{+\infty} \int_\Omega |u_n(x)| d\mu(x) < +\infty$, alors les hypoth√®ses du th√©or√®me sont satisfaites et la permutation est licite.

**D√©monstration (Esquisse)**
*   **Application du TCD aux sommes partielles :** On pose $F_N(x) = \sum_{n=0}^N u_n(x)$. Par hypoth√®se, $F_N(x) \to F(x) = \sum_{n=0}^{+\infty} u_n(x)$ p.p., et $|F_N(x)| \le g(x) \in L^1$.
*   **TCD (Th√©or√®me 31) :** $\int F_N d\mu \to \int F d\mu$, i.e., $\sum_{n=0}^N \int u_n d\mu \to \int \sum_{n=0}^{+\infty} u_n d\mu$.
*   **Condition suffisante :** Si $\sum \int |u_n| < +\infty$, on peut prendre $g(x) = \sum_{n=0}^{+\infty} |u_n(x)|$ (int√©grable par Beppo-Levi / TCM), et la domination est satisfaite.

### 
**Subtilit√©s**
*   La condition pratique $\sum \int |u_n| < +\infty$ est suffisante mais pas n√©cessaire. La condition n√©cessaire est la domination des sommes partielles par une fonction int√©grable.
*   **Lien avec le Th√©or√®me 35 (sommation $L^1$) :** Le Th√©or√®me 35 (Fubini-Tonelli pour les s√©ries) est pr√©cis√©ment l'application de ce r√©sultat dans un cadre productif.
*   **Lien avec les Th√©or√®mes 26-30 (s√©ries de fonctions) :** La convergence normale d'une s√©rie de fonctions sur $[a, b]$ implique la domination par $\sum \|u_n\|_\infty \le M < +\infty$ (int√©grable sur $[a, b]$), donc la permutation est licite ‚Äî c'est la preuve sous-jacente du Th√©or√®me 28.

**Pi√®ges classiques**
*   ‚ùå **Permuter s√©rie et int√©grale sans v√©rifier la domination :** C'est la faute la plus commune. Sans domination, la permutation peut √™tre fausse.
*   ‚ùå **Confondre $\sum \int |u_n| < +\infty$ et $\int \sum |u_n| < +\infty$ :** Par Beppo-Levi (TCM), ces deux conditions sont √©quivalentes (lorsque $u_n \ge 0$), mais il faut le justifier.
*   ‚ùå **Oublier que chaque $\int u_n$ doit exister** (i.e., $u_n \in L^1$) : c'est garanti par la domination $|u_n| \le g \in L^1$.

---

## FLASHCARD 65 ‚Äî Th√©or√®me 34 : Th√©or√®me de convergence monotone (Beppo-Levi)

### RECTO
**Th√©or√®me 34 ‚Äî Th√©or√®me de convergence monotone (Beppo-Levi)**

**Contexte :** Soit $(f_n)_{n \in \mathbb{N}}$ une suite de fonctions mesurables positives sur $(\Omega, \mathcal{A}, \mu)$.

**Question :** √ânoncer le th√©or√®me de convergence monotone avec ses hypoth√®ses exactes et sa conclusion (sans hypoth√®se d'int√©grabilit√© de la dominante).

### VERSO
**Hypoth√®ses compl√®tes**
*   $(f_n)_{n \in \mathbb{N}}$ suite de fonctions mesurables et positives ($f_n : \Omega \to [0, +\infty]$).
*   **Monotonie croissante :** $f_n \le f_{n+1}$ $\mu$-p.p. pour tout $n \in \mathbb{N}$.
*   **Convergence p.p. :** $f_n \xrightarrow[n \to +\infty]{} f$ p.p. (avec $f = \sup_n f_n$).

**√ânonc√© formel**
$$ \lim_{n \to +\infty} \int_\Omega f_n d\mu = \int_\Omega \lim_{n \to +\infty} f_n d\mu = \int_\Omega f d\mu $$

Les deux membres peuvent valoir $+\infty$ simultan√©ment. En particulier :
$$ \int_\Omega \sup_n f_n d\mu = \sup_n \int_\Omega f_n d\mu $$

**Corollaire (Beppo-Levi pour les s√©ries) :** Si $u_n \ge 0$ mesurables, alors :
$$ \int_\Omega \sum_{n=0}^{+\infty} u_n d\mu = \sum_{n=0}^{+\infty} \int_\Omega u_n d\mu $$
(m√™me si les deux membres valent $+\infty$).

**D√©monstration (Esquisse)**
*   **In√©galit√© $\le$ :** Puisque $f_n \le f$ p.p., $\int f_n \le \int f$, donc $\lim \int f_n \le \int f$.
*   **In√©galit√© $\ge$ (via fonctions √©tag√©es) :** Pour toute fonction √©tag√©e $\phi \le f$ et tout $\alpha \in (0, 1)$, les ensembles $A_n = \{f_n \ge \alpha \phi\}$ croissent vers $\Omega$. On montre $\int f_n \ge \alpha \int_{A_n} \phi \to \alpha \int \phi$. En faisant $\alpha \to 1$ et en prenant le sup sur $\phi$, on obtient $\lim \int f_n \ge \int f$.

### 
**Subtilit√©s**
*   **Positivit√© indispensable :** Le TCM exige $f_n \ge 0$. Pour des suites non positives, on utilise TCD (avec domination int√©grable).
*   **Pas besoin d'int√©grabilit√© :** Contrairement √† TCD, le TCM ne suppose pas $f \in L^1$. Si $\int f = +\infty$, le th√©or√®me dit simplement $\int f_n \to +\infty$.
*   **TCM vs TCD :** TCD est plus fort (s'applique sans monotonie) mais exige une domination int√©grable. TCM est plus faible (monotonie requise) mais sans condition d'int√©grabilit√©.

**Pi√®ges classiques**
*   ‚ùå **Appliquer TCM √† des fonctions non positives :** Exemple classique o√π √ßa √©choue : $f_n = -1/n \cdot 1_{[0, n]}$ est croissante (vers $0$), n√©gative. TCM ne s'applique pas directement.
*   ‚ùå **Confondre TCM et TCD :** TCM ne donne aucun r√©sultat de convergence $L^1$ ; il donne seulement la permutation limite-int√©grale (avec possibilit√© de $+\infty$).
*   ‚ùå **N√©gliger le corollaire de Beppo-Levi :** La permutation s√©rie-int√©grale pour des fonctions positives est toujours licite (sans aucune hypoth√®se suppl√©mentaire), ce qui est tr√®s puissant.

---

## FLASHCARD 66 ‚Äî Th√©or√®me 35 : Th√©or√®me de sommation $L^1$ (Fubini-Tonelli pour les s√©ries)

### RECTO
**Th√©or√®me 35 ‚Äî Th√©or√®me de sommation $L^1$**

**Contexte :** Soit $(u_{n, k})_{n, k \in \mathbb{N}}$ un tableau de r√©els (ou complexes). On veut intervertir l'ordre de deux sommes $\sum_n \sum_k$ et $\sum_k \sum_n$.

**Question :** √ânoncer le th√©or√®me de Fubini-Tonelli pour les s√©ries doubles (sommation $L^1$) : sous quelle condition peut-on intervertir les deux signes $\sum$ ?

### VERSO
**Hypoth√®ses compl√®tes**
*   $(u_{n, k})_{n, k \in \mathbb{N}}$ famille de complexes.
*   **Condition de sommabilit√© absolue :**
    $$ \sum_{n=0}^{+\infty} \sum_{k=0}^{+\infty} |u_{n, k}| < +\infty \quad (\text{ou √©quivalemment : } \sum_k \sum_n |u_{n, k}| < +\infty) $$

**√ânonc√© formel**
Si $\sum_{n, k} |u_{n, k}| < +\infty$ (sommabilit√© absolue), alors :

$$ \sum_{n=0}^{+\infty} \sum_{k=0}^{+\infty} u_{n, k} = \sum_{k=0}^{+\infty} \sum_{n=0}^{+\infty} u_{n, k} $$

De plus, toutes les sommes partielles, it√©r√©es et doubles, convergent absolument, et la famille $(u_{n, k})_{n, k}$ est sommable.

**Version avec int√©grale (Fubini-Tonelli) :** Sur $(\Omega_1 \times \Omega_2, \mu_1 \otimes \mu_2)$, si $\iint |f| d\mu_1 d\mu_2 < +\infty$, alors on peut intervertir les deux int√©grales.

**D√©monstration (Esquisse)**
*   **TCM (Beppo-Levi) :** On applique Beppo-Levi √† $\sum_{n, k} |u_{n, k}|$ pour garantir la sommabilit√© absolue.
*   **TCD :** La domination $|\sum_k u_{n, k}| \le \sum_k |u_{n, k}|$ et la convergence de $\sum_n \sum_k |u_{n, k}|$ permettent d'appliquer TCD.
*   **Interversion :** On conclut que l'ordre de sommation est indiff√©rent.

### 
**Subtilit√©s**
*   **La condition est la sommabilit√© absolue, pas la convergence des s√©ries it√©r√©es.** Il existe des exemples de s√©ries doublement convergentes (pour lesquelles $\sum_n \sum_k u_{n, k}$ et $\sum_k \sum_n u_{n, k}$ convergent toutes deux) mais donnant des valeurs diff√©rentes, si $\sum_{n, k} |u_{n, k}| = +\infty$.
*   **Exemple classique de non-interversion :** $u_{n, k} = \begin{cases} 1 & \text{si } k=n \\ -1 & \text{si } k=n+1 \\ 0 & \text{sinon} \end{cases}$. Alors $\sum_n \sum_k u_{n, k} = 0$ mais $\sum_k \sum_n u_{n, k} = -1$ (en supposant les s√©ries bien d√©finies). Cela montre la n√©cessit√© de la sommabilit√© absolue.

**Pi√®ges classiques**
*   ‚ùå **Intervertir deux $\sum$ sans v√©rification :** C'est la faute la plus grave et la plus fr√©quente. Il faut toujours v√©rifier $\sum_{n, k} |u_{n, k}| < +\infty$ avant d'intervertir.
*   ‚ùå **Confondre avec la Proposition 4 (sommation par paquets) :** La Proposition 4 traite du regroupement de termes d'une seule s√©rie. Ici, on traite d'une double s√©rie.
*   ‚ùå **Oublier la version Fubini pour les int√©grales :** La condition d'int√©grabilit√© de $|f|$ est l'analogue exact de la sommabilit√© absolue pour les s√©ries.

---

## FLASHCARD 67 ‚Äî Th√©or√®me 36 : Continuit√© des int√©grales √† param√®tre

### RECTO
**Th√©or√®me 36 ‚Äî Continuit√© des int√©grales √† param√®tre**

**Contexte :** Soit $f : \Omega \times I \to \mathbb{R}$ (ou $\mathbb{C}$), o√π $\Omega$ est un espace mesur√© et $I$ un intervalle de $\mathbb{R}$. On pose $F(t) = \int_\Omega f(x, t) d\mu(x)$.

**Question :** √ânoncer le th√©or√®me de continuit√© de $F$ en un point $t_0 \in I$, avec les hypoth√®ses exactes.

### VERSO
**Hypoth√®ses compl√®tes**
*   **(H1) Continuit√© en $t$ :** Pour $\mu$-presque tout $x \in \Omega$, la fonction $t \mapsto f(x, t)$ est continue en $t_0$.
*   **(H2) Int√©grabilit√© pour chaque $t$ :** Pour tout $t \in I$, $x \mapsto f(x, t)$ est mesurable et $\int_\Omega |f(x, t)| d\mu(x) < +\infty$.
*   **(H3) Domination int√©grable :** $\exists g \in L^1(\Omega, \mu)$, $g \ge 0$, telle que pour tout $t$ dans un voisinage $V$ de $t_0$ dans $I$ :
    $$ |f(x, t)| \le g(x) \quad \mu\text{-p.p. en } x $$

**√ânonc√© formel**
Sous (H1), (H2), (H3) :

$F$ est continue en $t_0$, i.e.,
$$ \lim_{t \to t_0} \int_\Omega f(x, t) d\mu(x) = \int_\Omega f(x, t_0) d\mu(x) $$

**Cas pratique ‚Äî Int√©grale sur un segment $[a, b]$ :**

Si $f : [a, b] \times I \to \mathbb{R}$ est continue (condition plus forte que (H1)), alors (H3) est automatiquement satisfaite avec $g(x) = \sup_{t \in K} |f(x, t)|$ pour tout compact $K \subset I$ (par continuit√©, $f$ est born√©e sur $[a, b] \times K$). Donc $F$ est continue sur $I$.

**D√©monstration (Esquisse)**
Application directe du Th√©or√®me 32 (TCD √† param√®tre continu) :
Pour toute suite $t_n \to t_0$ dans $I$, $f(x, t_n) \to f(x, t_0)$ p.p. (par (H1)) et $|f(x, t_n)| \le g(x)$ p.p. (par (H3)). Donc par TCD : $F(t_n) \to F(t_0)$. D'o√π la continuit√© par caract√©risation s√©quentielle.

### 
**Subtilit√©s**
*   **La domination peut √™tre locale** (sur un voisinage de $t_0$) : Pour la continuit√© en $t_0$, il suffit que (H3) tienne sur un voisinage de $t_0$, pas n√©cessairement sur tout $I$.
*   **Cas de l'int√©grale impropre :** Si $\Omega = [a, +\infty[$ et l'int√©grale est impropre, la domination $|f(x, t)| \le g(x)$ avec $g \in L^1([a, +\infty[)$ est la condition cl√©. Sans cette domination, il faut √©tudier soigneusement la convergence uniforme en $t$ de l'int√©grale impropre.
*   **Exemple type :** $F(t) = \int_0^{+\infty} e^{-tx} \frac{\sin x}{x} dx$. Pour √©tudier la continuit√© en $t_0 > 0$, on cherche $g(x) = e^{-t_0 x/2}/|x|$ (par exemple) int√©grable sur $(0, +\infty)$.

**Pi√®ges classiques**
*   ‚ùå **Appliquer le th√©or√®me sans v√©rifier la domination :** Toujours exhiber explicitement $g$ et v√©rifier $g \in L^1$.
*   ‚ùå **Confondre continuit√© en $t_0$ (domination locale) et continuit√© sur $I$ (domination globale) :** Pour la continuit√© sur tout $I$, il faut une domination uniforme sur tout $I$ (ou travailler sur des compacts de $I$).
*   ‚ùå **N√©gliger la mesurabilit√© de $x \mapsto f(x, t)$ :** Hypoth√®se n√©cessaire mais souvent implicite (fonctions continues, etc.).

---

## FLASHCARD 68 ‚Äî Th√©or√®me 37 : R√©gularit√© $C^1$ des int√©grales √† param√®tre

### RECTO
**Th√©or√®me 37 ‚Äî R√©gularit√© $C^1$ des int√©grales √† param√®tre**

**Contexte :** Soit $f : \Omega \times I \to \mathbb{R}$, $F(t) = \int_\Omega f(x, t) d\mu(x)$, o√π $I$ est un intervalle ouvert de $\mathbb{R}$.

**Question :** √ânoncer le th√©or√®me de d√©rivabilit√© de $F$ sous le signe int√©grale, avec les hypoth√®ses exactes sur $f$ et $\partial_t f$.

### VERSO
**Hypoth√®ses compl√®tes**
*   **(H1) Int√©grabilit√© initiale :** Pour tout $t \in I$, $x \mapsto f(x, t) \in L^1(\Omega, \mu)$.
*   **(H2) D√©rivabilit√© en $t$ :** Pour $\mu$-presque tout $x \in \Omega$, $t \mapsto f(x, t)$ est d√©rivable sur $I$, et la d√©riv√©e partielle $\frac{\partial f}{\partial t}(x, t)$ est mesurable en $x$ pour tout $t$.
*   **(H3) Domination de la d√©riv√©e :** $\exists g \in L^1(\Omega, \mu)$, $g \ge 0$, telle que :
    $$ \forall t \in I, \quad \left| \frac{\partial f}{\partial t}(x, t) \right| \le g(x) \quad \mu\text{-p.p. en } x $$

**√ânonc√© formel**
Sous (H1), (H2), (H3) :

$F$ est d√©rivable sur $I$.

**D√©rivation sous le signe int√©grale :**
$$ \forall t \in I, \quad F'(t) = \int_\Omega \frac{\partial f}{\partial t}(x, t) d\mu(x) $$

$F \in C^1(I)$ si de plus $t \mapsto \frac{\partial f}{\partial t}(x, t)$ est continue en tout $t \in I$ p.p. en $x$ (ce qui assure la continuit√© de $F'$ par le Th√©or√®me 36).

**D√©monstration (Esquisse)**
*   **Taux d'accroissement :** Pour $t, t+h \in I$, $h \neq 0$ :
    $$ \frac{F(t+h) - F(t)}{h} = \int_\Omega \frac{f(x, t+h) - f(x, t)}{h} d\mu(x) $$
*   **Th√©or√®me des accroissements finis :** $\left| \frac{f(x, t+h) - f(x, t)}{h} \right| \le \sup_{s \in I} \left| \frac{\partial f}{\partial t}(x, s) \right| \le g(x)$.
*   **TCD (Th√©or√®me 31) :** Quand $h \to 0$, $\frac{f(x, t+h) - f(x, t)}{h} \to \frac{\partial f}{\partial t}(x, t)$ p.p., domin√© par $g \in L^1$. Donc $\frac{F(t+h) - F(t)}{h} \to \int \frac{\partial f}{\partial t}(x, t) d\mu(x)$.

### 
**Subtilit√©s**
*   **La domination porte sur $\partial_t f$, pas sur $f$ elle-m√™me.** Pour la d√©rivabilit√©, c'est la d√©riv√©e partielle qui doit √™tre domin√©e. Pour la continuit√© (Th√©or√®me 36), c'est $f$ elle-m√™me.
*   **$F \in C^1$ si $\partial_t f$ est continue en $t$ p.p. :** On applique le Th√©or√®me 36 √† $\partial_t f$ pour obtenir la continuit√© de $F' = \int \partial_t f$.
*   **It√©ration :** En it√©rant (Th√©or√®me 38), si $\partial_t^k f$ est domin√©e pour tout $k \le n$, alors $F \in C^n(I)$ et $F^{(k)}(t) = \int \partial_t^k f(x, t) d\mu$.
*   **Cas de l'int√©grale sur un segment $[a, b]$ :** Si $f \in C^1([a, b] \times I)$, alors $\partial_t f$ est continue sur le compact $[a, b] \times [t_0 - \varepsilon, t_0 + \varepsilon]$, donc born√©e, donc la domination (H3) est automatique. $F \in C^1(I)$.

**Pi√®ges classiques**
*   ‚ùå **Oublier de v√©rifier la domination de $\partial_t f$ (et non de $f$) :** L'erreur la plus fr√©quente. On v√©rifie la domination de la mauvaise fonction.
*   ‚ùå **Confondre d√©rivabilit√© et $C^1$ :** La d√©rivabilit√© de $F$ est donn√©e par (H1)+(H2)+(H3). La classe $C^1$ n√©cessite en plus la continuit√© de $F'$, qui demande une hypoth√®se suppl√©mentaire sur la continuit√© de $\partial_t f$ en $t$.
*   ‚ùå **Oublier l'hypoth√®se (H1) :** $F(t)$ doit exister (i.e., $f(\cdot, t) \in L^1$) pour que la d√©riv√©e ait un sens.
*   ‚ùå **TAF dans la d√©monstration :** On utilise le TAF (accroissements finis) pour majorer le taux d'accroissement par la d√©riv√©e. Ne pas utiliser TCD directement sur le taux d'accroissement sans cette majoration.

---

## FLASHCARD 69 ‚Äî Th√©or√®me 38 : R√©gularit√© $C^k$ des int√©grales √† param√®tre

### RECTO
**Th√©or√®me 38 ‚Äî R√©gularit√© $C^k$ des int√©grales √† param√®tre**

**Contexte :** Soit $f : \Omega \times I \to \mathbb{R}$, $F(t) = \int_\Omega f(x, t) d\mu(x)$, $I$ intervalle ouvert.

**Question :** √ânoncer le th√©or√®me de r√©gularit√© $C^k$ de $F$, en pr√©cisant les hypoth√®ses sur les d√©riv√©es partielles d'ordre $\le k$.

### VERSO
**Hypoth√®ses compl√®tes**
Pour un entier $k \ge 1$ :

*   **(H1)** Pour tout $t \in I$ et tout $j \in \{0, 1, \dots, k\}$, $x \mapsto \frac{\partial^j f}{\partial t^j}(x, t)$ est mesurable et int√©grable.
*   **(H2)** Pour $\mu$-p.p. $x$, $t \mapsto f(x, t)$ est de classe $C^k$ sur $I$.
*   **(H3) Domination :** $\forall j \in \{0, 1, \dots, k\}$, $\exists g_j \in L^1(\Omega, \mu)$, $g_j \ge 0$, telle que :
    $$ \forall t \in I, \quad \left| \frac{\partial^j f}{\partial t^j}(x, t) \right| \le g_j(x) \quad \mu\text{-p.p.} $$
    (En pratique, on n'a besoin de dominer que la d√©riv√©e d'ordre $k$ : si $\partial_t^k f$ est domin√©e et continue en $t$ p.p., on peut se ramener par it√©ration.)

**√ânonc√© formel**
Sous (H1), (H2), (H3) :

$$ F \in C^k(I) \quad \text{et} \quad \forall j \in \{1, \dots, k\}, \quad F^{(j)}(t) = \int_\Omega \frac{\partial^j f}{\partial t^j}(x, t) d\mu(x) $$

**D√©monstration (Esquisse)**
Par r√©currence sur $k$ en appliquant le Th√©or√®me 37 √† chaque √©tape : on montre que $F' = \int \partial_t f$, puis que $F'' = (F')' = \int \partial_t^2 f$, etc.

### 
**Subtilit√©s**
*   En pratique, on v√©rifie les hypoth√®ses au rang $k$ seulement, et on prouve par r√©currence que $F \in C^k$.
*   **Le cas $k=+\infty$ :** Si pour tout $j \in \mathbb{N}$, $\partial_t^j f$ est domin√©e par une fonction int√©grable (uniforme en $t$), alors $F \in C^\infty(I)$. C'est le cas typique pour les fonctions de Laplace, Fourier, Gamma, etc.
*   **Exemple fondamental ‚Äî Fonction Gamma :** $\Gamma(s) = \int_0^{+\infty} x^{s-1} e^{-x} dx$ est de classe $C^\infty$ sur $(0, +\infty)$, car $\partial_s^k (x^{s-1} e^{-x}) = (\ln x)^k x^{s-1} e^{-x}$, qui est int√©grable sur $(0, +\infty)$ pour $s > 0$ (domination par $x^{s_0/2-1} e^{-x/2}$ sur un voisinage compact de $s_0$).

**Pi√®ges classiques**
*   ‚ùå **N√©gliger la v√©rification pour chaque ordre de d√©rivation :** Il faut v√©rifier la domination pour toutes les d√©riv√©es d'ordre $0$ √† $k$, pas seulement pour la d√©riv√©e d'ordre $k$.
*   ‚ùå **Oublier que le domaine de d√©finition de $F$ peut changer :** Si $f(x, t)$ n'est int√©grable que pour $t \in (a, b)$, alors $F$ n'est d√©finie (et $C^k$) que sur $(a, b)$.
*   ‚ùå **Confondre $C^k$ en $t$ de $f$ et $C^k$ de $F$ :** Ce sont deux choses diff√©rentes. La r√©gularit√© de $F$ est une cons√©quence de la r√©gularit√© de $f$ en $t$ combin√©e √† la domination, mais elle n'est pas √©vidente a priori.

---

# CHAPITRE 8 ‚Äî Topologie

## FLASHCARD 70 ‚Äî Proposition 14 : Caract√©risation des ouverts et ferm√©s (topologie des espaces m√©triques)

### RECTO
**Proposition 14 ‚Äî Caract√©risation des ouverts et ferm√©s dans un espace m√©trique**

**Contexte :** Soit $(E, d)$ un espace m√©trique. Soit $A \subset E$.

**Question :** Donner les caract√©risations √©quivalentes des ouverts et des ferm√©s (en termes de boules, d'int√©rieur, d'adh√©rence, de compl√©mentaire, et de suites).

### VERSO
**√ânonc√© formel**

**Caract√©risation des ouverts :**
$A$ est ouvert si et seulement si l'une des conditions √©quivalentes suivantes est satisfaite :
*   $\forall x \in A, \exists r > 0, B(x, r) \subset A$ (toute boule ouverte centr√©e en $x$ est incluse dans $A$).
*   $A = \mathring{A}$ (l'int√©rieur de $A$ est $A$ lui-m√™me).
*   $E \setminus A$ est ferm√©.

**Caract√©risation des ferm√©s :**
$F$ est ferm√© si et seulement si :
*   $E \setminus F$ est ouvert.
*   $F = \bar{F}$ (l'adh√©rence de $F$ est $F$ lui-m√™me).
*   **Caract√©risation s√©quentielle :** Toute suite $(x_n)$ d'√©l√©ments de $F$ qui converge dans $E$ a sa limite dans $F$ :
    $$ [(x_n) \subset F \text{ et } x_n \to \ell \in E] \implies \ell \in F $$

**Rappels :**
*   $\mathring{A} = \{x \in A : \exists r > 0, B(x, r) \subset A\}$ (int√©rieur).
*   $\bar{A} = \{x \in E : \forall r > 0, B(x, r) \cap A \neq \emptyset\}$ (adh√©rence).
*   $\partial A = \bar{A} \setminus \mathring{A}$ (fronti√®re).

### 
**Subtilit√©s**
*   La caract√©risation s√©quentielle des ferm√©s est valable dans les espaces m√©triques (et plus g√©n√©ralement dans les espaces √† base d√©nombrable de voisinages). Dans un espace topologique g√©n√©ral (non m√©trique), il faut utiliser les filtres ou les nets.
*   $\emptyset$ et $E$ sont √† la fois ouverts et ferm√©s (clopen). Dans $\mathbb{R}$, ce sont les seuls, mais dans un espace non connexe, il peut y en avoir d'autres.
*   L'int√©rieur est le plus grand ouvert inclus dans $A$ ; l'adh√©rence est le plus petit ferm√© contenant $A$.

**Pi√®ges classiques**
*   ‚ùå **"Ni ouvert ni ferm√©" vs "ouvert et ferm√©" :** $[a, b)$ dans $\mathbb{R}$ est ni ouvert ni ferm√©. Ne pas confondre les deux situations.
*   ‚ùå **En dimension infinie**, les boules ferm√©es ne sont pas compactes (Riesz) ‚Äî mais elles restent ferm√©es au sens topologique.
*   ‚ùå **Caract√©risation s√©quentielle :** Elle s'applique aux espaces m√©triques mais pas aux espaces topologiques g√©n√©raux. En concours, toujours pr√©ciser qu'on est dans un espace m√©trique.

---

## FLASHCARD 71 ‚Äî Proposition 15 : Propri√©t√©s des ouverts et ferm√©s (stabilit√©)

### RECTO
**Proposition 15 ‚Äî Stabilit√© par op√©rations des ouverts et ferm√©s**

**Contexte :** $(E, d)$ espace m√©trique. $(U_i)_{i \in I}$ famille d'ouverts, $(F_j)_{j \in J}$ famille de ferm√©s.

**Question :** √ânoncer les r√®gles de stabilit√© des ouverts et ferm√©s par unions et intersections (finie, d√©nombrable, quelconque), en pr√©cisant les cas o√π la stabilit√© est perdue.

### VERSO
**√ânonc√© formel**

**Pour les ouverts :**
*   **Union quelconque d'ouverts est ouverte :**
    $$ \bigcup_{i \in I} U_i \text{ est ouvert} $$
    (sans restriction sur la cardinalit√© de $I$).
*   **Intersection finie d'ouverts est ouverte :**
    $$ U_1 \cap U_2 \cap \dots \cap U_n \text{ est ouvert} $$
*   **Intersection infinie d'ouverts peut ne pas √™tre ouverte :**
    $\bigcap_{n=1}^{+\infty} (-1/n, 1/n) = \{0\}$, qui est ferm√©.

**Pour les ferm√©s :**
*   **Intersection quelconque de ferm√©s est ferm√©e :**
    $$ \bigcap_{j \in J} F_j \text{ est ferm√©} $$
*   **Union finie de ferm√©s est ferm√©e :**
    $$ F_1 \cup F_2 \cup \dots \cup F_n \text{ est ferm√©} $$
*   **Union infinie de ferm√©s peut ne pas √™tre ferm√©e :**
    $\bigcup_{n=1}^{+\infty} [1/n, 1] = (0, 1]$, qui n'est pas ferm√© dans $\mathbb{R}$.

### 
**Subtilit√©s**
*   La r√®gle mn√©motechnique : "Union quelconque d'ouverts, intersection finie d'ouverts. Intersection quelconque de ferm√©s, union finie de ferm√©s."
*   Les contre-exemples sont fondamentaux : $\bigcap_{n \ge 1} (-1/n, 1/n) = \{0\}$ (intersection infinie d'ouverts = ferm√©) et $\bigcup_{n \ge 1} [1/n, 1] = (0, 1]$ (union infinie de ferm√©s = ni ouvert ni ferm√©).

**Pi√®ges classiques**
*   ‚ùå Croire que l'intersection d√©nombrable d'ouverts est ouverte : Faux. C'est une confusion tr√®s fr√©quente.
*   ‚ùå Croire que l'union d√©nombrable de ferm√©s est ferm√©e : Faux. (Cf. contre-exemple.)
*   ‚ùå Confondre les r√®gles pour ouverts et ferm√©s : Elles sont "duales" (compl√©mentaire d'un ouvert = ferm√©), donc les r√®gles se correspondent par passage au compl√©mentaire.

---

## FLASHCARD 72 ‚Äî Proposition 16 : Caract√©risation s√©quentielle (continuit√©, limite, adh√©rence)

### RECTO
**Proposition 16 ‚Äî Caract√©risation s√©quentielle dans les espaces m√©triques**

**Contexte :** $(E, d_E)$ et $(F, d_F)$ deux espaces m√©triques, $f : E \to F$, $A \subset E$, $a \in E$.

**Question :** √ânoncer les caract√©risations s√©quentielles de : (1) l'adh√©rence d'une partie, (2) la continuit√© d'une fonction en un point, (3) la limite d'une fonction.

### VERSO
**√ânonc√© formel**

1.  **Caract√©risation s√©quentielle de l'adh√©rence :**
    $$ x \in \bar{A} \iff \exists (a_n)_{n \in \mathbb{N}} \subset A, \quad a_n \xrightarrow[n \to +\infty]{} x $$

2.  **Caract√©risation s√©quentielle de la continuit√© en $a$ :**
    $$ f \text{ est continue en } a \iff \forall (x_n) \subset E, \quad x_n \to a \implies f(x_n) \to f(a) $$

3.  **Caract√©risation s√©quentielle de la limite :**
    $$ \lim_{x \to a} f(x) = \ell \iff \forall (x_n) \subset E \setminus \{a\}, \quad x_n \to a \implies f(x_n) \to \ell $$
    (La condition $x_n \neq a$ est essentielle dans la d√©finition de la limite, mais pas dans celle de la continuit√© si $f(a) = \ell$.)

### 
**Subtilit√©s**
*   Ces caract√©risations sont propres aux espaces m√©triques (et plus g√©n√©ralement aux espaces √† base d√©nombrable de voisinages, i.e., les espaces "√† topologie s√©quentielle"). Dans un espace topologique g√©n√©ral, elles peuvent √™tre fausses.
*   **Utilisation cl√© :** Ces caract√©risations permettent de ramener des propri√©t√©s topologiques √† des propri√©t√©s de suites, ce qui est souvent plus maniable en analyse.
*   **Continuit√© s√©quentielle $\neq$ continuit√© en g√©n√©ral :** Dans un espace non m√©trique, la continuit√© s√©quentielle (image de toute suite convergente est convergente) n'implique pas la continuit√©. Dans un espace m√©trique, les deux sont √©quivalentes.

**Pi√®ges classiques**
*   ‚ùå **Oublier $x_n \neq a$ dans la limite :** La limite de $f$ en $a$ ne suppose pas que $f$ est d√©finie en $a$ ni que $f(a) = \ell$.
*   ‚ùå **Confondre limite et continuit√© :** $f$ est continue en $a$ si $f(a)$ est d√©finie et $\lim_{x \to a} f(x) = f(a)$.
*   ‚ùå **Appliquer la caract√©risation s√©quentielle hors du cadre m√©trique :** En topologie g√©n√©rale, la caract√©risation s√©quentielle peut √™tre mise en d√©faut.

---

## FLASHCARD 73 ‚Äî Proposition 17 : √âquivalence des normes en dimension finie

### RECTO
**Proposition 17 ‚Äî √âquivalence des normes en dimension finie**

**Contexte :** Soit $E$ un espace vectoriel sur $\mathbb{K} \in \{\mathbb{R}, \mathbb{C}\}$, de dimension finie $n \ge 1$, muni de deux normes $\|\cdot\|_a$ et $\|\cdot\|_b$.

**Question :** √ânoncer la proposition d'√©quivalence des normes en dimension finie, avec ses hypoth√®ses exactes et sa conclusion.

### VERSO
**Hypoth√®ses compl√®tes**
*   $\mathbb{K} \in \{\mathbb{R}, \mathbb{C}\}$
*   $E$ est un $\mathbb{K}$-espace vectoriel de dimension finie $n \in \mathbb{N}^*$
*   $\|\cdot\|_a$ et $\|\cdot\|_b$ sont deux normes quelconques sur $E$

**√ânonc√© formel**
$$ \exists \alpha, \beta \in \mathbb{R}_{>0}, \forall x \in E, \quad \alpha \|x\|_a \le \|x\|_b \le \beta \|x\|_a $$

Autrement dit, toutes les normes sur un espace vectoriel de dimension finie sont √©quivalentes : elles d√©finissent la m√™me topologie (m√™mes ouverts, m√™mes suites convergentes, m√™mes suites de Cauchy).

**D√©monstration (Esquisse)**
1.  **R√©duction √† la norme canonique.** Il suffit de montrer que toute norme $\|\cdot\|$ sur $E$ est √©quivalente √† la norme $\|\cdot\|_1$ (ou $\|\cdot\|_\infty$) associ√©e √† une base fix√©e $(e_1, \dots, e_n)$. L'√©quivalence est alors une relation d'√©quivalence, ce qui conclut par transitivit√©.
2.  **Majoration (continuit√©).** Si $x = \sum_{i=1}^n x_i e_i$, par l'in√©galit√© triangulaire et l'homog√©n√©it√© :
    $$ \|x\| \le \sum_{i=1}^n |x_i| \|e_i\| \le (\max_i \|e_i\|) \cdot \|x\|_1 $$
    ce qui donne $\|x\| \le \beta \|x\|_1$ avec $\beta = \sum_{i=1}^n \|e_i\|$. Cela √©tablit la continuit√© de $\|\cdot\|$ pour la topologie de $\|\cdot\|_1$.
3.  **Minoration (compacit√©).** La sph√®re unit√© $S = \{x \in E : \|x\|_1 = 1\}$ est compacte pour $\|\cdot\|_1$ (ferm√©e et born√©e en dimension finie, par Bolzano-Weierstrass). La fonction $x \mapsto \|x\|$ est continue (d'apr√®s l'√©tape 2) et strictement positive sur $S$ (car $\|x\|=0 \implies x=0 \notin S$). Par le th√©or√®me des bornes atteintes sur un compact, elle atteint son minimum $\alpha > 0$ sur $S$ :
    $$ \forall x \in S, \|x\| \ge \alpha > 0 $$
    Par homog√©n√©it√©, $\forall x \in E, \|x\| \ge \alpha \|x\|_1$.

### 
**Subtilit√©s**
*   **La dimension finie est absolument indispensable.** En dimension infinie, deux normes peuvent √™tre non √©quivalentes, m√™me sur le m√™me espace : sur $C([0, 1], \mathbb{R})$, les normes $\|\cdot\|_\infty$ et $\|\cdot\|_1 = \int_0^1 |f|$ ne sont pas √©quivalentes (on peut construire des suites convergeant pour $\|\cdot\|_1$ mais pas pour $\|\cdot\|_\infty$).
*   L'argument de compacit√© de la sph√®re unit√© est le c≈ìur de la preuve. Cette compacit√© repose elle-m√™me sur le th√©or√®me de Bolzano-Weierstrass (ou sur le fait que $(\mathbb{K}^n, \|\cdot\|_\infty)$ est complet et que la boule ferm√©e est compacte).
*   **Cons√©quences topologiques exactes :** deux normes √©quivalentes d√©finissent :
    *   les m√™mes ouverts et ferm√©s,
    *   les m√™mes suites convergentes (avec la m√™me limite),
    *   les m√™mes suites de Cauchy,
    *   les m√™mes ensembles born√©s,
    *   les m√™mes parties compactes.
*   **Attention √† la constante :** $\alpha$ et $\beta$ d√©pendent en g√©n√©ral de $n$ et de la base choisie. Lorsque $n \to \infty$, les constantes peuvent d√©g√©n√©rer, ce qui explique l'√©chec en dimension infinie.

**Extensions**
*   **En dimension infinie :** faux en g√©n√©ral. Le th√©or√®me de Riesz (√Ä conna√Ætre 18) montre que la boule unit√© ferm√©e d'un evn de dimension infinie n'est jamais compacte, ce qui bloque pr√©cis√©ment l'argument de minoration.
*   **Corollaire fondamental :** Tout sous-espace vectoriel de dimension finie d'un evn est ferm√© (car il est complet pour la norme induite, et une suite convergente dans l'evn ambiant qui est dans le sous-espace converge dans le sous-espace).
*   **Corollaire :** En dimension finie, toute application lin√©aire est continue (quel que soit le choix de normes sur l'espace de d√©part et d'arriv√©e, pourvu qu'ils soient de dimension finie).

**Pi√®ges classiques**
*   ‚ö†Ô∏è **Oublier que $\alpha > 0$ gr√¢ce √† la compacit√©.** Sans la compacit√©, on ne peut pas garantir que le minimum sur la sph√®re est atteint (et a fortiori qu'il est $> 0$). Ne pas √©crire $\inf_S \|x\| > 0$ sans justifier que cet inf est un min atteint.
*   ‚ö†Ô∏è Confondre √©quivalence de normes et √©galit√©. Deux normes √©quivalentes ne sont pas n√©cessairement proportionnelles.
*   ‚ö†Ô∏è Croire que le r√©sultat s'applique √† un evn quelconque parce que l'espace ¬´ ressemble ¬ª √† $\mathbb{R}^n$. La dimension finie doit √™tre v√©rifi√©e explicitement.
*   ‚ö†Ô∏è Omettre la transitivit√© dans la d√©monstration : on montre l'√©quivalence avec $\|\cdot\|_1$, et on conclut pour deux normes quelconques par transitivit√©. Ne pas oublier de le mentionner explicitement en copie.

---

## FLASHCARD 74 ‚Äî ### RECTO
**Proposition 18 ‚Äî Caract√©risation des parties compactes en dimension finie (Heine-Borel-Lebesgue)**

**Contexte :** Soit $(E, \|\cdot\|)$ un espace vectoriel norm√© sur $\mathbb{K}$, de dimension finie $n \ge 1$.

**Question :** √ânoncer la caract√©risation des parties compactes en dimension finie, avec ses hypoth√®ses exactes et sa conclusion.

### VERSO
**Hypoth√®ses compl√®tes**
*   $\mathbb{K} \in \{\mathbb{R}, \mathbb{C}\}$
*   $E$ est un $\mathbb{K}$-evn de dimension finie $n \in \mathbb{N}^*$
*   $A \subseteq E$ une partie quelconque

**√ânonc√© formel**
$$ A \text{ est compacte} \iff A \text{ est ferm√©e et born√©e} $$

Plus pr√©cis√©ment :
*   **$A$ est born√©e :** $\exists M > 0, \forall x \in A, \|x\| \le M$
*   **$A$ est ferm√©e :** $A$ est ferm√©e dans $(E, \|\cdot\|)$
*   **$A$ est compacte :** de toute suite $(x_n)_{n \ge 0}$ √† valeurs dans $A$, on peut extraire une sous-suite convergente dans $A$ (compacit√© s√©quentielle)

**D√©monstration (Esquisse)**
*   $(\Rightarrow)$ Compact $\implies$ ferm√© et born√©. Tout compact est ferm√© (dans un espace m√©trique s√©par√©) et born√© (recouvert par des boules finies).
*   $(\Leftarrow)$ Ferm√© et born√© $\implies$ compact.
    *   Par √©quivalence des normes (Proposition 17), on se ram√®ne √† $(\mathbb{K}^n, \|\cdot\|_\infty)$.
    *   $A$ born√©e : $\exists M > 0, A \subseteq [-M, M]^n$ (en consid√©rant les coordonn√©es dans une base).
    *   On applique le th√©or√®me de Bolzano-Weierstrass par un proc√©d√© diagonal : toute suite de $[-M, M]^n$ admet une sous-suite convergente dans $[-M, M]^n$.
    *   Comme $A$ est ferm√©e, la limite est dans $A$.

### 
**Subtilit√©s**
*   **Ce r√©sultat est faux en dimension infinie.** La boule unit√© ferm√©e $\bar{B}(0, 1)$ d'un evn de dimension infinie n'est jamais compacte (th√©or√®me de Riesz, √Ä conna√Ætre 18). Exemple : dans $\ell^2(\mathbb{N})$, la suite $(e_n)$ des vecteurs de base est dans $\bar{B}(0, 1)$ mais n'admet aucune sous-suite convergente (car $\|e_n - e_m\|_2 = \sqrt{2}$ pour $n \neq m$).
*   **√âquivalence des normes est cruciale :** la propri√©t√© ¬´ ferm√©e et born√©e ¬ª d√©pend a priori de la norme choisie, mais comme toutes les normes sont √©quivalentes en dimension finie, cette notion ne d√©pend que de la structure vectorielle de dimension finie.
*   **Compacit√© s√©quentielle = compacit√©** dans les espaces m√©triques. Ne pas confondre avec la compacit√© par recouvrements ouverts (ces deux notions co√Øncident dans les espaces m√©triques).

**Extensions**
*   En dimension infinie, les parties compactes sont ferm√©es et born√©es mais la r√©ciproque est strictement fausse.
*   Dans $\mathbb{R}^n$ muni de $\|\cdot\|_2$ (ou toute norme √©quivalente), on retrouve le th√©or√®me de Heine-Borel classique.

**Pi√®ges classiques**
*   ‚ö†Ô∏è **Appliquer ce th√©or√®me en dimension infinie :** erreur r√©dhibitoire. Toujours v√©rifier que l'espace est bien de dimension finie.
*   ‚ö†Ô∏è **Oublier la fermeture :** un ensemble born√© non ferm√© n'est pas compact ($]0, 1[$ dans $\mathbb{R}$ est born√© mais non compact).
*   ‚ö†Ô∏è **Confondre ¬´ born√© ¬ª et ¬´ compact ¬ª dans un raisonnement :** une suite born√©e en dimension finie admet une sous-suite convergente (Bolzano-Weierstrass), mais la limite n'appartient √† l'ensemble que si celui-ci est ferm√©.

---

## FLASHCARD 75 ‚Äî Th√©or√®me 39 : Compacit√© (th√©or√®me des bornes atteintes et de Heine)

### RECTO
**Th√©or√®me 39 ‚Äî Compacit√© : th√©or√®me des bornes atteintes et th√©or√®me de Heine**

**Contexte :** Soit $(E, d_E)$ et $(F, d_F)$ deux espaces m√©triques, $K \subseteq E$ un compact non vide, et $f : K \to F$ une application continue.

**Question :** √ânoncer les deux grandes cons√©quences de la compacit√© pour les fonctions continues (bornes atteintes, continuit√© uniforme), avec les hypoth√®ses exactes et les conclusions.

### VERSO
**Hypoth√®ses compl√®tes**
*   $(E, d_E)$ espace m√©trique, $K \subseteq E$ compact non vide
*   $(F, d_F)$ espace m√©trique
*   $f : K \to F$ continue sur $K$

**√ânonc√© formel**
1.  **L'image d'un compact est compacte :**
    $$ f(K) \text{ est un compact de } F $$

2.  **Th√©or√®me des bornes atteintes (cas $F = \mathbb{R}$) :**
    Si $f : K \to \mathbb{R}$ est continue, alors :
    $$ \exists x_{\min} \in K, \exists x_{\max} \in K, \quad f(x_{\min}) = \min_{x \in K} f(x) \text{ et } f(x_{\max}) = \max_{x \in K} f(x) $$
    En particulier, $f$ est born√©e sur $K$ et atteint ses bornes.

3.  **Th√©or√®me de Heine (continuit√© uniforme) :**
    $$ f \text{ est uniform√©ment continue sur } K $$
    c'est-√†-dire :
    $$ \forall \varepsilon > 0, \exists \delta > 0, \forall x, y \in K, \quad d_E(x, y) < \delta \implies d_F(f(x), f(y)) < \varepsilon $$

**D√©monstration (Esquisse)**
*   **Pour 1 :** Soit $(y_n)$ une suite dans $f(K)$ ; √©crire $y_n = f(x_n)$ avec $x_n \in K$. Par compacit√© de $K$, extraire $(x_{\varphi(n)})$ convergeant vers $\ell \in K$. Par continuit√©, $y_{\varphi(n)} = f(x_{\varphi(n)}) \to f(\ell) \in f(K)$.
*   **Pour 2 :** $f(K)$ est un compact de $\mathbb{R}$, donc ferm√© et born√©, donc il admet un min et un max (atteints car $f(K)$ est ferm√©).
*   **Pour 3 (Heine) :** Par l'absurde. Si $f$ n'est pas uniform√©ment continue :
    $\exists \varepsilon_0 > 0, \forall n \in \mathbb{N}^*, \exists x_n, y_n \in K, d_E(x_n, y_n) < 1/n \text{ et } d_F(f(x_n), f(y_n)) \ge \varepsilon_0$.
    Par compacit√©, extraire $x_{\varphi(n)} \to \ell \in K$. Alors $y_{\varphi(n)} \to \ell$ aussi. Par continuit√© : $d_F(f(x_{\varphi(n)}), f(y_{\varphi(n)})) \to 0$, contradiction.

### 
**Subtilit√©s**
*   $K$ doit √™tre **compact**, pas seulement ferm√© ou born√©. En dimension infinie, ferm√© et born√© ne suffit pas. Le th√©or√®me de Heine requiert explicitement la compacit√©.
*   Le th√©or√®me des bornes atteintes n√©cessite $F = \mathbb{R}$ (ou $\mathbb{R} \cup \{-\infty, +\infty\}$) et $f$ continue. La borne sup√©rieure d'une fonction continue sur un compact est un **maximum** (pas seulement un sup).
*   **Heine :** $\delta$ ne d√©pend pas de $x, y$. C'est la diff√©rence fondamentale entre continuit√© simple et uniforme. Sur $]0, 1[$, $x \mapsto 1/x$ est continue mais pas uniform√©ment continue.
*   Heine n√©cessite la compacit√© et pas seulement la continuit√© uniforme locale. Une fonction continue sur $\mathbb{R}$ n'est pas n√©cessairement uniform√©ment continue (ex : $x \mapsto x^2$).

**Extensions**
*   **Th√©or√®me de Heine en dimension finie :** Si $f : A \subseteq \mathbb{R}^n \to \mathbb{R}^m$ est continue sur $A$ ferm√© born√© (compact), alors $f$ est uniform√©ment continue.
*   **En dimension infinie :** Le m√™me √©nonc√© reste valable √† condition que $K$ soit compact (au sens s√©quentiel/topologique). Mais les compacts sont plus rares.
*   **Fonctions √† valeurs vectorielles :** Le th√©or√®me des bornes atteintes ne s'applique directement qu'√† $F = \mathbb{R}$. Pour $F=E$ evn, on peut dire que $x \mapsto \|f(x)\|$ atteint son maximum.

**Pi√®ges classiques**
*   ‚ö†Ô∏è Utiliser le th√©or√®me des bornes atteintes sur un intervalle ouvert $]a, b[$, qui n'est pas compact : grave erreur. V√©rifier que le domaine est bien ferm√© et born√© (en dimension finie) ou compact.
*   ‚ö†Ô∏è Confondre ¬´ $f$ atteint sa borne sup ¬ª et ¬´ $\sup f < +\infty$ ¬ª : sur un compact, les deux sont vrais et li√©s, mais ce n'est pas imm√©diat sur un ensemble non compact.
*   ‚ö†Ô∏è Oublier que $f(K)$ est ferm√© (et pas seulement born√©) : ce point est utilis√© pour affirmer que le sup est atteint.
*   ‚ö†Ô∏è Invoquer Heine pour justifier qu'une int√©grale √† param√®tre est continue sans avoir v√©rifi√© la compacit√© du domaine d'int√©gration.

---

## FLASHCARD 76 ‚Äî √Ä conna√Ætre 17 : Caract√©risation s√©quentielle de la compacit√© et exemples

### RECTO
**√Ä conna√Ætre 17 ‚Äî Caract√©risation s√©quentielle de la compacit√© dans un espace m√©trique**

**Contexte :** Soit $(E, d)$ un espace m√©trique et $K \subseteq E$.

**Question :** Donner la caract√©risation s√©quentielle de la compacit√© dans un espace m√©trique, et lister les exemples fondamentaux de compacts √† conna√Ætre en MP*.

### VERSO
**Hypoth√®ses compl√®tes**
*   $(E, d)$ espace m√©trique
*   $K \subseteq E$ une partie

**√ânonc√© formel**
Dans un espace m√©trique, les trois propri√©t√©s suivantes sont √©quivalentes :

(i) **$K$ est compact** (tout recouvrement ouvert de $K$ admet un sous-recouvrement fini)

(ii) **$K$ est s√©quentiellement compact :**
$$ \forall (x_n)_{n \ge 0} \in K^{\mathbb{N}}, \exists \varphi : \mathbb{N} \to \mathbb{N} \text{ strictement croissante}, x_{\varphi(n)} \xrightarrow[n \to +\infty]{} \ell \in K $$

(iii) **$K$ est pr√©compact et complet :**
*   **Pr√©compact :** $\forall \varepsilon > 0$, $K$ peut √™tre recouvert par un nombre fini de boules ouvertes de rayon $\varepsilon$
*   **Complet :** toute suite de Cauchy dans $K$ converge dans $K$

**Exemples fondamentaux de compacts**
*   **$\mathbb{R}^n$ (ou $\mathbb{C}^n$) :** Ferm√©s born√©s
*   **$C([a, b], \mathbb{R})$ :** Caract√©ris√©s par Arzel√†-Ascoli (√©quicontinuit√© + bornement uniforme)
*   **Tout evn de dimension finie :** Ferm√©s born√©s
*   **$\mathbb{K}^{\mathbb{N}}$ :** Produits de compacts (Tychonov)

**D√©monstration (Esquisse)**
L'√©quivalence (i) $\iff$ (ii) dans les espaces m√©triques :
*   (i) $\Rightarrow$ (ii) : si $(x_n)$ n'a pas de valeur d'adh√©rence dans $K$, chaque $x \in K$ a un voisinage contenant au plus finiment des $x_n$, formant un recouvrement ouvert sans sous-recouvrement fini.
*   (ii) $\Rightarrow$ (i) : par l'absurde, un recouvrement sans sous-recouvrement fini permet de construire une suite sans valeur d'adh√©rence.

### 
**Subtilit√©s**
*   Dans un espace m√©trique, compacit√© et compacit√© s√©quentielle sont √©quivalentes. Ce n'est plus vrai dans un espace topologique g√©n√©ral.
*   La compl√©tude seule ne suffit pas pour la compacit√© (exemple : $\mathbb{R}$ est complet mais non compact).
*   La pr√©compacit√© seule ne suffit pas : $]0, 1[$ est pr√©compact (dans $\mathbb{R}$) mais non compact (non complet).

**Extensions**
*   **Th√©or√®me d'Arzel√†-Ascoli :** donne une caract√©risation des compacts de $(C([a, b], \mathbb{R}), \|\cdot\|_\infty)$ (√©quicontinuit√© uniforme + bornement uniforme). Indispensable en analyse fonctionnelle.
*   **Th√©or√®me de Tychonov :** un produit quelconque de compacts est compact (pour la topologie produit). En dimension finie, cela donne que $[a_1, b_1] \times \dots \times [a_n, b_n]$ est compact dans $\mathbb{R}^n$.

**Pi√®ges classiques**
*   ‚ö†Ô∏è **Oublier que la limite de la sous-suite doit √™tre dans $K$ :** la compacit√© s√©quentielle exige $\ell \in K$, pas seulement $\ell \in E$.
*   ‚ö†Ô∏è Confondre pr√©compact et compact dans un espace de dimension infinie.
*   ‚ö†Ô∏è Croire qu'un ferm√© dans un compact est compact : c'est vrai ! (un ferm√© d'un compact est compact), mais un ferm√© dans un espace non compact peut tr√®s bien ne pas √™tre compact.

---

## FLASHCARD 77 ‚Äî Proposition 20 : Continuit√© et compacit√©, applications

### RECTO
**Proposition 20 ‚Äî Image d'un compact par une application continue ; hom√©omorphisme sur un compact**

**Contexte :** Soit $(E, d_E)$ et $(F, d_F)$ deux espaces m√©triques, $K \subseteq E$ un compact non vide, $f : K \to F$ continue et bijective.

**Question :** √ânoncer la proposition sur l'image d'un compact par une application continue et la proposition sur les hom√©omorphismes d√©finis sur un compact.

### VERSO
**Hypoth√®ses compl√®tes**
*   $(E, d_E)$, $(F, d_F)$ espaces m√©triques
*   $K \subseteq E$ compact non vide
*   $f : K \to F$ continue

**√ânonc√© formel**
**Proposition A :** L'image d'un compact par une application continue est compacte :
$$ f \text{ continue}, K \text{ compact} \implies f(K) \text{ compact} $$

**Proposition B (Hom√©omorphisme sur un compact) :**
Si de plus $f : K \to f(K)$ est bijective, alors :
$$ f^{-1} : f(K) \to K \text{ est continue} $$
autrement dit, $f$ est un hom√©omorphisme de $K$ sur $f(K)$.

**D√©monstration (Esquisse)**
*   **Prop. A :** D√©j√† esquiss√©e (Th√©or√®me 39, flashcard 75).
*   **Prop. B :** Soit $(y_n)$ une suite dans $f(K)$ convergeant vers $y \in f(K)$. √âcrire $y_n = f(x_n)$ et $y = f(x)$ avec $x_n, x \in K$. Supposons par l'absurde que $f^{-1}(y_n) = x_n \not\to x$. Alors il existe $\varepsilon_0 > 0$ et une sous-suite $(x_{\varphi(n)})$ avec $d_E(x_{\varphi(n)}, x) \ge \varepsilon_0$. Par compacit√© de $K$, extraire $(x_{\varphi \circ \psi(n)})$ convergeant vers $\ell \in K$. Par continuit√© de $f$ : $f(x_{\varphi \circ \psi(n)}) \to f(\ell) = y$. Comme $f$ est injective, $\ell = x$, contradiction avec $d_E(x_{\varphi(n)}, x) \ge \varepsilon_0$.

### 
**Subtilit√©s**
*   **La compacit√© est essentielle pour Prop. B.** Sans elle, une bijection continue peut ne pas √™tre un hom√©omorphisme. Exemple classique : $\theta \mapsto e^{i\theta}$ de $[0, 2\pi[$ sur $\mathbb{U}$ est continue et bijective, mais son inverse n'est pas continue (en $1 = e^{i \cdot 0}$). Ici $[0, 2\pi[$ n'est pas compact.
*   **Prop. B :** pas de structure suppl√©mentaire requise sur $F$. On n'a pas besoin de $F$ de dimension finie, juste que $f(K)$ soit compact (ce qui d√©coule de Prop. A).

**Extensions**
*   **En dimension finie :** toute bijection lin√©aire continue entre evn de m√™me dimension finie est un hom√©omorphisme lin√©aire (son inverse est automatiquement continue, car toute application lin√©aire en dimension finie est continue).
*   **Application en pratique :** pour montrer qu'une bijection continue $f : K \to L$ entre deux compacts est un hom√©omorphisme, il suffit de v√©rifier la continuit√© de $f$ (pas de $f^{-1}$ s√©par√©ment).

**Pi√®ges classiques**
*   ‚ö†Ô∏è Appliquer Prop. B sans v√©rifier la bijectivit√© ou sans v√©rifier que le domaine est compact.
*   ‚ö†Ô∏è Confondre hom√©omorphisme et isom√©trie : un hom√©omorphisme pr√©serve la topologie mais pas n√©cessairement les distances.
*   ‚ö†Ô∏è Croire que la continuit√© de $f^{-1}$ est automatique sans compacit√© : contre-exemple ci-dessus √† conna√Ætre par c≈ìur.

---

## FLASHCARD 78 ‚Äî √Ä conna√Ætre 18 : Th√©or√®me de Riesz (non-compacit√© de la boule en dimension infinie)

### RECTO
**√Ä conna√Ætre 18 ‚Äî Th√©or√®me de Riesz : la boule unit√© ferm√©e d'un evn est compacte si et seulement si l'espace est de dimension finie**

**Contexte :** Soit $(E, \|\cdot\|)$ un espace vectoriel norm√© sur $\mathbb{K}$.

**Question :** √ânoncer le th√©or√®me de Riesz sur la compacit√© de la boule unit√© ferm√©e, avec ses hypoth√®ses exactes et sa conclusion.

### VERSO
**Hypoth√®ses compl√®tes**
*   $(E, \|\cdot\|)$ un $\mathbb{K}$-espace vectoriel norm√© ($\mathbb{K} = \mathbb{R}$ ou $\mathbb{C}$), de dimension quelconque (finie ou infinie)
*   $\bar{B}(0, 1) = \{x \in E : \|x\| \le 1\}$ la boule unit√© ferm√©e

**√ânonc√© formel**
$$ \bar{B}(0, 1) \text{ est compacte dans } E \iff \dim E < +\infty $$

**Lemme de Riesz (utilis√© pour la direction $\Leftarrow$ en dimension infinie) :**
$$ \forall F \subsetneq E \text{ sous-espace ferm√© strict de } E, \forall \varepsilon \in ]0, 1[, \exists x_\varepsilon \in E, \|x_\varepsilon\| = 1 \text{ et } d(x_\varepsilon, F) \ge 1 - \varepsilon $$

**D√©monstration (Esquisse)**
*   $(\Rightarrow)$ dim finie $\implies$ boule compacte : Heine-Borel en dimension finie (ferm√© et born√© $\implies$ compact).
*   $(\Leftarrow)$ dim infinie $\implies$ boule non compacte : On construit inductivement une suite $(x_n)_{n \ge 1}$ dans $\bar{B}(0, 1)$ telle que $\|x_n - x_m\| \ge 1/2$ pour tout $n \neq m$.
    *   Prendre $x_1 \in \bar{B}(0, 1)$ quelconque, $\|x_1\| = 1$.
    *   Supposant $x_1, \dots, x_n$ construits, poser $F_n = \text{Vect}(x_1, \dots, x_n)$ (ferm√© car dimension finie). Par lemme de Riesz avec $\varepsilon = 1/2$, $\exists x_{n+1}$ avec $\|x_{n+1}\| = 1$ et $d(x_{n+1}, F_n) \ge 1/2$.
    *   Ainsi $\|x_{n+1} - x_k\| \ge 1/2$ pour tout $k \le n$.
    *   La suite $(x_n)$ est dans $\bar{B}(0, 1)$ mais n'admet aucune sous-suite de Cauchy, donc aucune sous-suite convergente.

### 
**Subtilit√©s**
*   Le lemme de Riesz n'atteint pas $\varepsilon = 0$ en g√©n√©ral. En dimension finie, on peut atteindre exactement la distance (car le minimum est atteint sur le compact $F \cap \bar{B}$), mais en dimension infinie, seule l'approximation √† $1-\varepsilon$ est garantie.
*   **Exception remarquable :** Dans un espace de Hilbert (evn complet √† produit scalaire), si $F$ est un sous-espace ferm√©, la projection orthogonale r√©alise exactement la distance, mais cela ne contredit pas Riesz (la boule reste non compacte en dimension infinie).
*   **Cons√©quence fondamentale :** En dimension infinie, les boules ferm√©es ne sont pas compactes. Cela implique qu'on ne peut pas directement utiliser les th√©or√®mes de type ¬´ suite born√©e $\implies$ sous-suite convergente ¬ª (Bolzano-Weierstrass), sauf dans des cadres fonctionnels sp√©cifiques (compacit√© faible, Arzel√†-Ascoli, etc.).

**Extensions**
*   En dimension infinie, il existe des notions de compacit√© plus faibles : compacit√© faible (topologie faible $\sigma(E, E')$), compacit√© relative. Ces notions sont au c≈ìur de l'analyse fonctionnelle.
*   Le th√©or√®me de Riesz est la raison pour laquelle les √©quations int√©grales et les EDP n√©cessitent des arguments sp√©cifiques (th√©or√®me de Lax-Milgram, th√©or√®me spectral en dimension infinie, etc.).

**Pi√®ges classiques**
*   ‚ö†Ô∏è **Utiliser un argument de ¬´ suite born√©e admet une sous-suite convergente ¬ª** dans un evn de dimension infinie sans pr√©caution : faux en g√©n√©ral.
*   ‚ö†Ô∏è **Confondre le lemme de Riesz avec le th√©or√®me de repr√©sentation de Riesz** (qui concerne les formes lin√©aires continues dans un Hilbert ‚Äî Th√©or√®me 58 dans ce cours). Ce sont deux r√©sultats distincts portant le m√™me nom.
*   ‚ö†Ô∏è **Oublier que le lemme de Riesz requiert $\varepsilon \in ]0, 1[$ strictement :** on ne peut pas prendre $\varepsilon = 0$ en g√©n√©ral.

---

## FLASHCARD 79 ‚Äî Proposition 21 : Parties denses, approximation

### RECTO
**Proposition 21 ‚Äî Caract√©risation d'une partie dense dans un espace m√©trique**

**Contexte :** Soit $(E, d)$ un espace m√©trique et $D \subseteq E$.

**Question :** √ânoncer la proposition de caract√©risation d'une partie dense, avec plusieurs caract√©risations √©quivalentes.

### VERSO
**Hypoth√®ses compl√®tes**
*   $(E, d)$ espace m√©trique
*   $D \subseteq E$ une partie

**√ânonc√© formel ‚Äî Caract√©risations √©quivalentes de ¬´ $D$ est dense dans $E$ ¬ª**
Les propri√©t√©s suivantes sont √©quivalentes :

(i) **$\bar{D} = E$** (l'adh√©rence de $D$ est $E$ entier)

(ii) **$\forall x \in E, \forall \varepsilon > 0, \exists d \in D, d(x, d) < \varepsilon$** (tout point de $E$ est approch√© arbitrairement par des √©l√©ments de $D$)

(iii) **$\forall x \in E, \exists (d_n)_{n \ge 0} \in D^{\mathbb{N}}, d_n \xrightarrow[n \to +\infty]{} x$** (tout point de $E$ est limite d'une suite de $D$)

(iv) **Tout ouvert non vide de $E$ rencontre $D$ :**
    $$ \forall U \text{ ouvert de } E, U \neq \emptyset \implies U \cap D \neq \emptyset $$

**Exemples fondamentaux √† conna√Ætre**
*   $(\mathbb{R}, |\cdot|) \quad \mathbb{Q}$
*   $(C([a, b], \mathbb{R}), \|\cdot\|_\infty) \quad \text{Polyn√¥mes (Weierstrass), fonctions en escalier}$
*   $(C_{2\pi}^0, \|\cdot\|_\infty) \quad \text{Polyn√¥mes trigonom√©triques (Weierstrass trig.)}$
*   $L^2([a, b]) \quad C([a, b], \mathbb{R}), \text{ polyn√¥mes}$

### 
**Subtilit√©s**
*   La densit√© d√©pend de la topologie (donc de la norme ou de la distance). $\mathbb{Q}$ est dense dans $\mathbb{R}$ pour $|\cdot|$, mais ce n'est pas une notion alg√©brique.
*   **Densit√© $\neq$ √©galit√© :** $D$ dense dans $E$ ne signifie pas $D=E$ (exemple : $\mathbb{Q} \neq \mathbb{R}$).
*   La compos√©e de densit√©s : si $D_1$ est dense dans $D_2$ et $D_2$ est dense dans $E$, alors $D_1$ est dense dans $E$.

**Extensions**
*   **S√©parabilit√© :** Un espace m√©trique est dit s√©parable s'il admet une partie dense d√©nombrable. Exemple : $\mathbb{R}^n$ est s√©parable ($\mathbb{Q}^n$ dense), $C([a, b])$ est s√©parable (polyn√¥mes √† coefficients rationnels).
*   **Importance en approximation :** La densit√© est le fondement des th√©or√®mes d'approximation (Weierstrass, Fourier) : on approche une fonction continue par des objets plus simples (polyn√¥mes, polyn√¥mes trig.).

**Pi√®ges classiques**
*   ‚ö†Ô∏è Confondre ¬´ dense ¬ª et ¬´ ouvert dense ¬ª (notion plus forte, li√©e au th√©or√®me de Baire).
*   ‚ö†Ô∏è Utiliser la densit√© sans pr√©ciser la topologie (la norme par rapport √† laquelle on parle de densit√©).
*   ‚ö†Ô∏è Oublier de v√©rifier la densit√© avant d'invoquer un th√©or√®me d'approximation (ex : Weierstrass) pour passer d'une propri√©t√© sur les polyn√¥mes √† une propri√©t√© sur $C([a, b])$.

---

## FLASHCARD 80 ‚Äî √Ä conna√Ætre 19 : Espaces complets, th√©or√®me de Baire

### RECTO
**√Ä conna√Ætre 19 ‚Äî Espaces complets (espaces de Banach) et th√©or√®me de Baire**

**Contexte :** Soit $(E, d)$ un espace m√©trique complet (espace de Banach si $E$ est un evn complet).

**Question :** √ânoncer le th√©or√®me de Baire et ses principales cons√©quences en analyse.

### VERSO
**Hypoth√®ses compl√®tes**
*   $(E, d)$ espace m√©trique complet (ou espace localement compact)
*   $(U_n)_{n \ge 0}$ une suite d'ouverts denses de $E$

**√ânonc√© formel ‚Äî Th√©or√®me de Baire**
$$ \bigcap_{n=0}^{+\infty} U_n \text{ est dense dans } E $$

**Reformulation (en termes de ferm√©s) :** Si $(F_n)_{n \ge 0}$ est une suite de ferm√©s d'int√©rieur vide ($\mathring{F_n} = \emptyset$) dans $E$ complet, alors :
$$ \left( \bigcup_{n=0}^{+\infty} F_n \right)^\circ = \emptyset $$
(l'union d√©nombrable de ferm√©s d'int√©rieur vide a un int√©rieur vide)

**Cons√©quence n√©gative :** Un espace de Banach non r√©duit √† $\{0\}$ ne peut pas √™tre r√©union d√©nombrable de ferm√©s d'int√©rieur vide.

**Exemples d'applications**
*   **$\mathbb{R}$ n'est pas d√©nombrable :** Si $\mathbb{R} = \bigcup_n \{x_n\}$, chaque $\{x_n\}$ est ferm√© d'int√©rieur vide, mais leur union est $\mathbb{R}$ qui est d'int√©rieur non vide : contradiction.
*   Il existe des fonctions continues nulle part d√©rivables (par un argument de Baire sur $C([0, 1])$).
*   Th√©or√®me de Banach-Steinhaus (principe d'uniforme bornitude) utilise Baire.

**D√©monstration (Esquisse)**
Soit $x_0 \in E$ et $\varepsilon_0 > 0$. On construit inductivement une suite de Cauchy restant dans $\bigcap_n U_n$ :
*   $U_0$ dense et ouvert : $\exists x_1 \in U_0, \bar{B}(x_1, r_1) \subseteq U_0 \cap B(x_0, \varepsilon_0)$ avec $r_1 \le 1$.
*   $U_1$ dense et ouvert : $\exists x_2 \in U_1, \bar{B}(x_2, r_2) \subseteq U_1 \cap B(x_1, r_1)$ avec $r_2 \le 1/2$.
*   Par compl√©tude, $(x_n)$ converge vers $\ell \in \bigcap_n U_n \cap B(x_0, \varepsilon_0)$.

### 
**Subtilit√©s**
*   **Baire requiert la compl√©tude** (ou la compacit√© locale) : le th√©or√®me est faux pour $\mathbb{Q}$ (qui est un espace m√©trique non complet). En effet, $\mathbb{Q} = \bigcup_{q \in \mathbb{Q}} \{q\}$, union d√©nombrable de ferm√©s d'int√©rieur vide.
*   Baire est un outil d'existence, non constructif. Il prouve l'existence d'un point dans l'intersection, mais ne le construit pas explicitement.
*   **Union d√©nombrable seulement :** Le th√©or√®me porte sur des unions d√©nombrables. Une union non d√©nombrable de ferm√©s d'int√©rieur vide peut tr√®s bien couvrir $E$.

**Extensions**
*   **Espaces de Banach :** $C([a, b], \mathbb{R})$ muni de $\|\cdot\|_\infty$ est un espace de Banach (complet) ; Baire y est applicable.
*   **Th√©or√®me de Banach-Steinhaus :** Si $(T_n)$ est une suite d'applications lin√©aires continues $E \to F$ (Banach) telle que $\sup_n \|T_n(x)\| < +\infty$ pour tout $x \in E$, alors $\sup_n \|T_n\| < +\infty$. Preuve par Baire.
*   **Th√©or√®me du graphe ferm√© et th√©or√®me de l'application ouverte :** deux autres grands th√©or√®mes de l'analyse fonctionnelle reposant sur Baire.

**Pi√®ges classiques**
*   ‚ö†Ô∏è **Appliquer Baire √† $\mathbb{Q}$ ou √† un espace non complet :** erreur.
*   ‚ö†Ô∏è **Confondre ¬´ ferm√© d'int√©rieur vide ¬ª et ¬´ ferm√© ¬ª :** un ferm√© peut tr√®s bien avoir un int√©rieur non vide (exemple : $[0, 1] \subseteq \mathbb{R}$).
*   ‚ö†Ô∏è **Croire que Baire donne une conclusion sur une union finie :** le r√©sultat est sp√©cifique aux unions d√©nombrables infinies.

---

## FLASHCARD 81 ‚Äî √Ä conna√Ætre 20 : Espaces de Banach et exemples fondamentaux

### RECTO
**√Ä conna√Ætre 20 ‚Äî Espaces de Banach : d√©finition et exemples fondamentaux**

**Contexte :** Soit $(E, \|\cdot\|)$ un espace vectoriel norm√© sur $\mathbb{K} \in \{\mathbb{R}, \mathbb{C}\}$.

**Question :** D√©finir un espace de Banach et lister les espaces de Banach fondamentaux √† conna√Ætre en MP*, avec leurs normes.

### VERSO
**D√©finition**
$(E, \|\cdot\|)$ est un espace de Banach si et seulement si il est complet : toute suite de Cauchy converge dans $E$.

$$ \forall (x_n)_{n \ge 0} \in E^{\mathbb{N}}, \quad (\forall \varepsilon > 0, \exists N \in \mathbb{N}, \forall p, q \ge N, \|x_p - x_q\| < \varepsilon) \implies \exists \ell \in E, x_n \to \ell $$

**Exemples fondamentaux**
*   $\mathbb{K}^n$, toute norme : **Oui**
*   $C([a, b], \mathbb{K})$, $\|\cdot\|_\infty$ : **Oui**
*   $C([a, b], \mathbb{K})$, $\|\cdot\|_1 = \int_a^b \|f\|$ : **Non** (non complet)
*   $C^k([a, b], \mathbb{K})$, $\sum_{j=0}^k \|f^{(j)}\|_\infty$ : **Oui**
*   $\ell^p(\mathbb{N})$, $p \in [1, +\infty]$, $\|\cdot\|_p$ : **Oui**
*   $L^p([a, b])$, $p \in [1, +\infty]$, $\|\cdot\|_p$ : **Oui** (Riesz-Fischer)
*   Polyn√¥mes $\mathbb{K}[X]$, $\|\cdot\|_\infty$ sur $[a, b]$ : **Non** (non complet)

**Crit√®re de compl√©tude pratique**
$(E, \|\cdot\|)$ est complet $\iff$ toute s√©rie absolument convergente est convergente :
$$ \sum_{n=0}^{+\infty} \|u_n\| < +\infty \implies \sum_{n=0}^{+\infty} u_n \text{ converge dans } E $$

### 
**Subtilit√©s**
*   $(C([a, b]), \|\cdot\|_1)$ n'est pas complet : on peut approcher en norme $L^1$ des fonctions discontinues par des fonctions continues (penser √† des fonctions ¬´ cr√©neau ¬ª). La compl√©tion de $(C([a, b]), \|\cdot\|_1)$ est $L^1([a, b])$.
*   $\mathbb{K}[X]$ n'est pas complet pour aucune norme naturelle : la s√©rie $\sum x^n/n!$ converge (vers $e^x$) mais $e^x \notin \mathbb{K}[X]$.
*   Le crit√®re de compl√©tude par les s√©ries est tr√®s utile en pratique pour montrer qu'un espace est de Banach (notamment pour $\ell^p$ et $L^p$).

**Extensions**
*   **Espace de Hilbert :** Banach avec une norme issue d'un produit scalaire. Exemples : $\mathbb{K}^n, L^2([a, b]), \ell^2(\mathbb{N})$.
*   **Compl√©tion :** Tout evn admet une compl√©tion unique (√† isom√©trie isomorphe pr√®s), qui est un espace de Banach.

**Pi√®ges classiques**
*   ‚ö†Ô∏è **Confondre ¬´ suite born√©e ¬ª et ¬´ suite de Cauchy ¬ª :** une suite de Cauchy est born√©e, mais une suite born√©e n'est pas n√©cessairement de Cauchy.
*   ‚ö†Ô∏è **Croire que $(C([a, b]), \|\cdot\|_2)$ est complet :** faux, la compl√©tion est $L^2([a, b])$.
*   ‚ö†Ô∏è Oublier de v√©rifier la compl√©tude avant d'appliquer Baire, Banach-Steinhaus ou le th√©or√®me du point fixe de Banach.

---

## FLASHCARD 82 ‚Äî √Ä conna√Ætre 21 : Th√©or√®me du point fixe de Banach (applications contractantes)

### RECTO
**√Ä conna√Ætre 21 ‚Äî Th√©or√®me du point fixe de Banach (ou de Picard)**

**Contexte :** Soit $(E, d)$ un espace m√©trique complet et $f : E \to E$ une application.

**Question :** √ânoncer le th√©or√®me du point fixe de Banach avec ses hypoth√®ses exactes et ses conclusions (existence, unicit√©, convergence des it√©r√©es).

### VERSO
**Hypoth√®ses compl√®tes**
*   $(E, d)$ espace m√©trique complet
*   $f : E \to E$ contractante : $\exists k \in [0, 1[$ tel que :
    $$ \forall x, y \in E, \quad d(f(x), f(y)) \le k \cdot d(x, y) $$

**√ânonc√© formel**
1.  **Existence et unicit√© :**
    $$ \exists ! x^* \in E, \quad f(x^*) = x^* $$
2.  **Convergence des it√©r√©es :** Pour tout $x_0 \in E$, la suite d√©finie par $x_{n+1} = f(x_n)$ converge vers $x^*$ :
    $$ x_n \xrightarrow[n \to +\infty]{} x^* $$
3.  **Estimation de l'erreur :**
    $$ d(x_n, x^*) \le \frac{k^n}{1-k} d(x_1, x_0) $$

**D√©monstration (Esquisse)**
*   **La suite $(x_n)$ est de Cauchy :** Pour $p \ge 1$,
    $$ d(x_{n+p}, x_n) \le \frac{k^n(1-k^p)}{1-k} d(x_1, x_0) \xrightarrow[n \to +\infty]{} 0 $$
    par la raison g√©om√©trique et $k < 1$.
*   **Convergence :** Par compl√©tude, $x_n \to x^* \in E$.
*   **$x^*$ est point fixe :** $f(x^*) = f(\lim x_n) = \lim f(x_n) = \lim x_{n+1} = x^*$ (continuit√© de $f$, qui est lipschitzienne).
*   **Unicit√© :** Si $f(y) = y$ et $f(x^*) = x^*$, alors $d(x^*, y) = d(f(x^*), f(y)) \le k \cdot d(x^*, y)$, donc $(1-k) d(x^*, y) \le 0$, d'o√π $d(x^*, y) = 0$ et $x^* = y$.

### 
**Subtilit√©s**
*   **$k < 1$ est indispensable.** Une contraction non stricte ($k=1$, i.e., application 1-lipschitzienne) peut ne pas avoir de point fixe : $f : \mathbb{R} \to \mathbb{R}, f(x) = x+1$ est isom√©trique mais sans point fixe.
*   **La compl√©tude est indispensable.** Sur $]0, 1[$ (non complet), $f(x) = x/2$ est contractante ($k=1/2$) mais le point fixe $0 \notin ]0, 1[$.
*   Pas besoin que $E$ soit un espace vectoriel : le th√©or√®me s'applique dans tout espace m√©trique complet.
*   Le choix de $x_0$ est arbitraire : la convergence vers $x^*$ est ind√©pendante du point de d√©part.

**Extensions**
*   **Application √† Cauchy-Lipschitz :** Le th√©or√®me de Cauchy-Lipschitz (Th√©or√®me 40) repose sur le th√©or√®me du point fixe de Banach appliqu√© √† l'op√©rateur int√©gral de Picard dans l'espace $(C([t_0-\delta, t_0+\delta], E), \|\cdot\|_\infty)$ (qui est un Banach).
*   **Contractions sur une boule ferm√©e :** Si $f : \bar{B}(x_0, r) \to \bar{B}(x_0, r)$ est contractante et $\bar{B}(x_0, r)$ est complet (ferm√©e dans un Banach), le th√©or√®me s'applique.
*   **Th√©or√®me de Brouwer :** G√©n√©ralisation topologique (toute application continue d'un compact convexe dans lui-m√™me a un point fixe), mais sans taux de convergence.

**Pi√®ges classiques**
*   ‚ö†Ô∏è **Confondre contractante ($k < 1$) et lipschitzienne ($k$ quelconque) :** une application lipschitzienne de constante $\ge 1$ n'est pas contractante.
*   ‚ö†Ô∏è **Oublier que $k$ doit √™tre uniforme** (la m√™me constante pour tous $x, y$) : une contraction locale (contractante au voisinage du point fixe) ne suffit pas en g√©n√©ral.
*   ‚ö†Ô∏è **Ne pas v√©rifier que $f$ envoie l'espace dans lui-m√™me** avant d'appliquer le th√©or√®me.
*   ‚ö†Ô∏è **Confondre la vitesse de convergence :** la convergence est g√©om√©trique de raison $k$, ce qui est tr√®s rapide en pratique.

---

## FLASHCARD 83 ‚Äî Proposition 22 : Connexit√© par arcs, connexit√©

### RECTO
**Proposition 22 ‚Äî Connexit√© et connexit√© par arcs**

**Contexte :** Soit $(E, d)$ un espace m√©trique (ou un espace topologique) et $A \subseteq E$.

**Question :** D√©finir la connexit√© et la connexit√© par arcs, √©noncer le lien entre ces deux notions, et donner les exemples et contre-exemples fondamentaux.

### VERSO
**D√©finitions**
*   **Connexit√© par arcs :** $A$ est connexe par arcs si :
    $$ \forall x, y \in A, \exists \gamma : [0, 1] \to A \text{ continue}, \gamma(0) = x \text{ et } \gamma(1) = y $$
*   **Connexit√© :** $A$ est connexe si $A$ ne peut pas √™tre partitionn√© en deux ouverts non vides disjoints de $A$ :
    $$ A = U \sqcup V, U, V \text{ ouverts de } A, U \cap V = \emptyset \implies U = \emptyset \text{ ou } V = \emptyset $$

**√ânonc√© formel ‚Äî Lien entre les deux notions**
$$ A \text{ connexe par arcs} \implies A \text{ connexe} $$

La r√©ciproque est fausse en g√©n√©ral. Contre-exemple classique : le peigne du topologiste (ou la r√©union du graphe de $\sin(1/x)$ sur $]0, 1]$ et du segment $\{0\} \times [-1, 1]$) est connexe mais non connexe par arcs.

**Dans les evn (cas pratique en MP*)**
Dans un espace vectoriel norm√©, les parties connexes par arcs sont exactement les parties connexes pour les ouverts :
$$ U \subseteq E \text{ ouvert, connexe} \iff U \text{ ouvert, connexe par arcs} $$

**Exemples fondamentaux**
*   **Connexes par arcs :** tout convexe, toute boule ouverte ou ferm√©e, $\mathbb{K}^n$, $GL_n(\mathbb{C})$.
*   **Non connexes :** $\mathbb{R} \setminus \{0\}$, $GL_n(\mathbb{R})$ (deux composantes connexes : $\det > 0$ et $\det < 0$).

**Th√©or√®me fondamental**
L'image d'un connexe (resp. connexe par arcs) par une application continue est connexe (resp. connexe par arcs) :
$$ f : A \to F \text{ continue}, A \text{ connexe} \implies f(A) \text{ connexe} $$

### 
**Subtilit√©s**
*   Dans $\mathbb{R}$, les parties connexes sont exactement les intervalles (finis ou infinis, ouverts, ferm√©s ou semi-ouverts). Cela donne le th√©or√®me des valeurs interm√©diaires comme cons√©quence de la connexit√©.
*   $GL_n(\mathbb{R})$ n'est pas connexe ($n \ge 1$) : les matrices de d√©terminant $> 0$ et celles de d√©terminant $< 0$ forment deux composantes connexes. En revanche, $GL_n(\mathbb{C})$ est connexe par arcs.
*   $GL_n^+(\mathbb{R}) = \{M \in GL_n(\mathbb{R}) : \det M > 0\}$ est connexe par arcs (tout √©l√©ment peut √™tre joint √† l'identit√© par un chemin continu dans $GL_n^+(\mathbb{R})$, par exemple via la d√©composition polaire ou la triangularisation).

**Extensions**
*   **Composantes connexes :** tout espace m√©trique est partitionn√© en composantes connexes (les plus grandes parties connexes), qui sont ferm√©es.
*   **Convexit√© $\implies$ connexit√© par arcs :** tout convexe (m√™me en dimension infinie) est connexe par arcs (l'arc est le segment $\gamma(t) = (1-t)x + ty$).

**Pi√®ges classiques**
*   ‚ö†Ô∏è **Croire que connexe $\implies$ connexe par arcs en g√©n√©ral :** faux (contre-exemple du peigne).
*   ‚ö†Ô∏è **Oublier de v√©rifier que l'image d'un connexe est dans l'espace d'arriv√©e** avant d'invoquer la connexit√© de l'image.
*   ‚ö†Ô∏è **Confondre ¬´ $A$ connexe ¬ª et ¬´ $A$ convexe ¬ª :** la convexit√© est une propri√©t√© plus forte et plus maniable, mais n'est d√©finie que dans un espace vectoriel.

---

## FLASHCARD 84 ‚Äî Proposition 23 : Th√©or√®me des valeurs interm√©diaires (version topologique)

### RECTO
**Proposition 23 ‚Äî Th√©or√®me des valeurs interm√©diaires (version topologique g√©n√©rale)**

**Contexte :** Soit $(E, d)$ un espace m√©trique, $A \subseteq E$ une partie connexe, et $f : A \to \mathbb{R}$ une application continue.

**Question :** √ânoncer le th√©or√®me des valeurs interm√©diaires dans sa version topologique g√©n√©rale, avec ses hypoth√®ses exactes et sa conclusion.

### VERSO
**Hypoth√®ses compl√®tes**
*   $(E, d)$ espace m√©trique
*   $A \subseteq E$ connexe (non vide)
*   $f : A \to \mathbb{R}$ continue

**√ânonc√© formel**
$$ \forall x, y \in A, \forall \lambda \in \mathbb{R}, \quad f(x) \le \lambda \le f(y) \implies \exists z \in A, f(z) = \lambda $$

Autrement dit : $f(A)$ est un intervalle de $\mathbb{R}$ (l'image d'un connexe par une application continue √† valeurs r√©elles est un intervalle).

**Cas particulier fondamental (le plus utilis√© en MP*)**
Th√©or√®me des valeurs interm√©diaires classique :

Soit $f : [a, b] \to \mathbb{R}$ continue ($[a, b]$ est connexe par arcs, donc connexe). Alors :
$$ \forall \lambda \in [f(a), f(b)] \text{ (ou } [\min(f(a), f(b)), \max(f(a), f(b))]), \quad \exists c \in [a, b], f(c) = \lambda $$

**D√©monstration (Esquisse)**
$f(A)$ est l'image d'un connexe par $f$ continue, donc $f(A)$ est connexe dans $\mathbb{R}$. Or, les connexes de $\mathbb{R}$ sont exactement les intervalles. Donc $f(A)$ est un intervalle. Toute valeur entre $f(x)$ et $f(y)$ appartient √† $f(A)$, ce qui donne l'existence de $z$.

### 
**Subtilit√©s**
*   **La connexit√© de $A$ est indispensable.** Si $A$ n'est pas connexe, le TVI peut √©chouer. Exemple : $f : \{-1\} \cup \{1\} \to \mathbb{R}$, $f(-1) = -1, f(1) = 1$, $f$ continue sur son domaine non connexe ; $0$ n'est pas atteint.
*   Le TVI ne donne pas l'unicit√© de $z$. Il garantit l'existence d'un $z$, mais peut y en avoir plusieurs.
*   **Version quantitative (pour les √©preuves) :** Si $f$ est continue sur $[a, b]$, $f(a) \cdot f(b) < 0$, alors $\exists c \in ]a, b[, f(c) = 0$. (Le z√©ro est dans l'int√©rieur si les signes sont strictement oppos√©s.)
*   La conclusion ¬´ $f(A)$ est un intervalle ¬ª est la formulation la plus puissante. Elle s'applique m√™me si $A$ n'est pas un intervalle de $\mathbb{R}$ (ex : $A \subseteq \mathbb{R}^n$ connexe).

**Extensions**
*   **Fonctions √† valeurs vectorielles :** Le TVI ne s'√©tend pas directement √† $f : A \to \mathbb{R}^n$ pour $n \ge 2$ (on ne peut pas d√©finir une relation d'ordre total sur $\mathbb{R}^n$).
*   **TVI + compacit√© :** Si $f : [a, b] \to \mathbb{R}$ est continue, alors $f([a, b]) = [\min f, \max f]$ (image exactement un segment, par compacit√© + connexit√©).
*   **Application topologique :** Le TVI permet de montrer que $[0, 1]$ et $[0, 1[$ ne sont pas hom√©omorphes (en retirant un point int√©rieur, l'un reste connexe, l'autre non).

**Pi√®ges classiques**
*   ‚ö†Ô∏è **Invoquer le TVI sans v√©rifier la continuit√© de $f$** sur tout l'intervalle $[a, b]$ (pas seulement aux extr√©mit√©s).
*   ‚ö†Ô∏è **Confondre TVI et th√©or√®me du point fixe de Brouwer :** le TVI est plus √©l√©mentaire et sp√©cifique √† $\mathbb{R}$.
*   ‚ö†Ô∏è **Oublier que le TVI donne une existence, pas une construction :** pour trouver num√©riquement $c$, il faut la dichotomie ou la m√©thode de Newton.
*   ‚ö†Ô∏è **Appliquer le TVI √† une fonction d√©finie sur un ensemble non connexe :** v√©rifier toujours que le domaine est un intervalle (ou au moins connexe).

---

## FLASHCARD 85 ‚Äî √Ä conna√Ætre 22 : Lemme de Gronwall

### RECTO
**Lemme de Gronwall (versions int√©grale et diff√©rentielle)**

Soit $I = [a, b]$ un segment de $\mathbb{R}$, et $u, v : I \to \mathbb{R}$ des fonctions continues, avec $v \ge 0$.

**Question :** √ânoncer le lemme de Gronwall sous sa forme int√©grale. En d√©duire la version diff√©rentielle.

### VERSO
**Hypoth√®ses (forme int√©grale) :**
*   $a, b \in \mathbb{R}, a < b$
*   $u, v : [a, b] \to \mathbb{R}$ continues
*   $v \ge 0$ sur $[a, b]$
*   $C \in \mathbb{R}$ (constante)
    $$ \forall t \in [a, b], \quad u(t) \le C + \int_a^t v(s) u(s) ds $$

**Conclusion :**
$$ \forall t \in [a, b], \quad u(t) \le C \exp \left( \int_a^t v(s) ds \right) $$

**Forme diff√©rentielle :**
*   $u$ de classe $C^1$ sur $[a, b]$, $\alpha \in \mathbb{R}, \beta \ge 0$
    $$ \forall t \in [a, b], \quad u'(t) \le \beta u(t) + \alpha $$

**Alors :**
$$ \forall t \in [a, b], \quad u(t) \le \left( u(a) + \frac{\alpha}{\beta} \right) e^{\beta(t-a)} - \frac{\alpha}{\beta} $$
(si $\beta > 0$; si $\beta = 0$, $u(t) \le u(a) + \alpha(t-a)$).

**D√©monstration (esquisse) :**
Poser $\varphi(t) = C + \int_a^t v(s) u(s) ds$. Alors $\varphi' = v \cdot u \le v \cdot \varphi$.
Multiplier par le facteur int√©grant $e^{-\int_a^t v}$ : on montre que $t \mapsto \varphi(t) e^{-\int_a^t v(s) ds}$ est d√©croissante.
D'o√π $\varphi(t) \le \varphi(a) e^{\int_a^t v} = C e^{\int_a^t v}$, et $u \le \varphi$ donne la conclusion.

### 
**Subtilit√©s :**
*   L'hypoth√®se $v \ge 0$ est cruciale : sans elle, le facteur int√©grant ne donne pas le bon sens de monotonie.
*   La constante $C$ peut √™tre n√©gative : le lemme reste vrai.
*   Sur un intervalle non born√© $[a, +\infty[$, le lemme reste valable pour tout $t$ fix√© (on l'applique sur $[a, t]$).

**Extensions :**
*   Valable pour $u, v$ seulement continues par morceaux (voire $L^1_{loc}$), ce qui est utile en EDO.
*   S'applique aux fonctions √† valeurs dans un evn via $\|y(t)\|$ (on majore la norme, qui est une fonction r√©elle).

**Pi√®ges classiques :**
*   Oublier $v \ge 0$ et appliquer aveugl√©ment.
*   Confondre le sens de l'in√©galit√© : le lemme donne une majoration.
*   En concours, le lemme sert le plus souvent √† prouver l'unicit√© des solutions d'un probl√®me de Cauchy : si $y_1, y_2$ sont deux solutions, on montre $\|y_1 - y_2\|$ v√©rifie une in√©galit√© de Gronwall avec $C=0$, d'o√π $y_1 = y_2$.

---

## FLASHCARD 86 ‚Äî Lemme 2 : Forme int√©grale d'un probl√®me de Cauchy

### RECTO
**Forme int√©grale d'un probl√®me de Cauchy**

Soit $I$ un intervalle de $\mathbb{R}$, $t_0 \in I$, $y_0 \in E$ (espace vectoriel norm√© de dimension finie), et $f : I \times E \to E$.

**Question :** √ânoncer l'√©quivalence entre le probl√®me de Cauchy $y' = f(t, y), y(t_0) = y_0$ et sa formulation int√©grale.

### VERSO
**Hypoth√®ses :**
*   $I$ intervalle de $\mathbb{R}$, $t_0 \in I$
*   $E = \mathbb{R}^n$ (ou $E$ evn de dimension finie)
*   $f : I \times E \to E$ continue
*   $y : J \to E$ avec $J \subset I$ intervalle contenant $t_0$

**√ânonc√© :**
$y$ est de classe $C^1$ sur $J$ et v√©rifie :
$$ \begin{cases} y'(t) = f(t, y(t)) \\ y(t_0) = y_0 \end{cases} \quad \forall t \in J $$
si et seulement si $y$ est continue sur $J$ et :
$$ \forall t \in J, \quad y(t) = y_0 + \int_{t_0}^t f(s, y(s)) ds $$

**D√©monstration (esquisse) :**
*   $(\Rightarrow)$ : Int√©grer $y' = f(\cdot, y(\cdot))$ entre $t_0$ et $t$, utiliser $y(t_0) = y_0$.
*   $(\Leftarrow)$ : Si $y$ continue, $s \mapsto f(s, y(s))$ est continue (compos√©e), donc $y$ est $C^1$ par le th√©or√®me fondamental de l'analyse, et $y'(t) = f(t, y(t))$. √âvaluer en $t_0$ donne $y(t_0) = y_0$.

### 
**Subtilit√©s :**
*   La continuit√© de $f$ en les deux variables est n√©cessaire pour que $s \mapsto f(s, y(s))$ soit int√©grable.
*   La formulation int√©grale ne requiert que la continuit√© de $y$, pas sa d√©rivabilit√© a priori : c'est la formulation int√©grale qui produit la r√©gularit√© $C^1$.
*   Ce lemme est la pierre angulaire de la d√©monstration du th√©or√®me de Cauchy-Lipschitz (m√©thode du point fixe de Picard).

**Extensions :**
*   Valable en dimension infinie si $E$ est un espace de Banach (hors programme MP, mais utile conceptuellement).

**Pi√®ges classiques :**
*   Oublier de v√©rifier que $f$ est continue (et pas seulement en $t$ ou en $y$ s√©par√©ment).
*   Confondre ¬´ solution au sens classique ¬ª ($C^1$) et ¬´ solution au sens int√©gral ¬ª (continue) : ici elles co√Øncident gr√¢ce √† la continuit√© de $f$.

---

## FLASHCARD 87 ‚Äî Th√©or√®me 40 : Cauchy-Lipschitz lin√©aire

### RECTO
**Th√©or√®me de Cauchy-Lipschitz lin√©aire**

Soit $I$ un intervalle ouvert de $\mathbb{R}$, $A : I \to M_n(\mathbb{K})$ et $B : I \to \mathbb{K}^n$ continues, avec $\mathbb{K} = \mathbb{R}$ ou $\mathbb{C}$.

**Question :** √ânoncer le th√©or√®me de Cauchy-Lipschitz pour le syst√®me diff√©rentiel lin√©aire $Y' = A(t)Y + B(t), Y(t_0) = Y_0$.

### VERSO
**Hypoth√®ses :**
*   $I$ intervalle (ouvert, ferm√©, ou quelconque) de $\mathbb{R}$
*   $A : I \to M_n(\mathbb{K})$ continue
*   $B : I \to \mathbb{K}^n$ continue
*   $t_0 \in I, Y_0 \in \mathbb{K}^n$

**Conclusion :**
Le probl√®me de Cauchy :
$$ \begin{cases} Y'(t) = A(t)Y(t) + B(t) \\ Y(t_0) = Y_0 \end{cases} $$
admet une unique solution $Y : I \to \mathbb{K}^n$ de classe $C^1$, d√©finie sur $I$ tout entier (solution globale).

**Cons√©quences :**
*   L'ensemble des solutions de l'√©quation homog√®ne $Y' = A(t)Y$ est un sous-espace vectoriel de dimension $n$ de $C^1(I, \mathbb{K}^n)$.
*   L'ensemble des solutions de $Y' = A(t)Y + B(t)$ est un sous-espace affine de dimension $n$, dirig√© par le pr√©c√©dent.

**D√©monstration (esquisse) :**
Reformulation int√©grale : $Y(t) = Y_0 + \int_{t_0}^t [A(s)Y(s) + B(s)] ds$.
On d√©finit l'op√©rateur $\Phi(Y)(t) = Y_0 + \int_{t_0}^t [A(s)Y(s) + B(s)] ds$.
On montre que $\Phi^k$ est contractante pour la norme $\|\cdot\|_\infty$ sur tout segment $[t_0-\delta, t_0+\delta] \subset I$ (ou via le lemme de Gronwall pour l'unicit√©).
Le caract√®re global vient de la lin√©arit√© : $f(t, Y) = A(t)Y + B(t)$ est lipschitzienne en $Y$ sur tout segment, ce qui emp√™che l'explosion en temps fini.

### 
**Subtilit√©s :**
*   Le r√©sultat essentiel est le caract√®re global : la solution est d√©finie sur $I$ tout entier, pas seulement localement. C'est une propri√©t√© sp√©cifique aux EDO lin√©aires.
*   $I$ n'a pas besoin d'√™tre ouvert : le th√©or√®me vaut sur tout intervalle (segment, semi-ouvert‚Ä¶), avec d√©riv√©e √† droite/gauche aux bords si n√©cessaire.
*   Le th√©or√®me est valable pour $\mathbb{K} = \mathbb{R}$ ou $\mathbb{C}$ indiff√©remment.

**Extensions :**
*   En dimension infinie ($E$ espace de Banach), le th√©or√®me reste vrai si $A(t) \in \mathcal{L}(E)$ et $t \mapsto A(t)$ est continue pour la topologie de la norme d'op√©rateur (hors programme MP strict).

**Pi√®ges classiques :**
*   Oublier que la dimension de l'espace des solutions de l'homog√®ne est $n$ (et non $n+1$ ou autre).
*   Confondre avec le Cauchy-Lipschitz non lin√©aire o√π la solution n'est que locale.
*   Ne pas v√©rifier la continuit√© de $A$ et $B$ (si elles ne sont que continues par morceaux, il faut recoller).
*   Attention : pour une √©quation scalaire d'ordre $n$, on se ram√®ne √† un syst√®me de dimension $n$, et l'espace des solutions de l'homog√®ne est de dimension $n$.

---

## FLASHCARD 88 ‚Äî Th√©or√®me 41 : Cauchy-Lipschitz pour les EDL d'ordre $n$

### RECTO
**Th√©or√®me de Cauchy-Lipschitz pour les √©quations diff√©rentielles lin√©aires scalaires d'ordre $n$**

Soit $I$ un intervalle de $\mathbb{R}$, $a_0, \dots, a_{n-1}, b : I \to \mathbb{K}$ continues.

**Question :** √ânoncer le th√©or√®me d'existence et d'unicit√© pour l'√©quation :
$$ y^{(n)} + a_{n-1}(t) y^{(n-1)} + \dots + a_0(t) y = b(t) $$
avec conditions initiales prescrites.

### VERSO
**Hypoth√®ses :**
*   $I$ intervalle de $\mathbb{R}$, $\mathbb{K} = \mathbb{R}$ ou $\mathbb{C}$
*   $a_0, \dots, a_{n-1} : I \to \mathbb{K}$ continues
*   $b : I \to \mathbb{K}$ continue
*   $t_0 \in I, (y_0, y_1, \dots, y_{n-1}) \in \mathbb{K}^n$

**Conclusion :**
Le probl√®me de Cauchy :
$$ \begin{cases} y^{(n)}(t) + a_{n-1}(t) y^{(n-1)}(t) + \dots + a_0(t) y(t) = b(t) \\ y(t_0) = y_0, \quad y'(t_0) = y_1, \quad \dots, \quad y^{(n-1)}(t_0) = y_{n-1} \end{cases} $$
admet une unique solution $y : I \to \mathbb{K}$ de classe $C^n$, d√©finie sur $I$ tout entier.

L'espace des solutions de l'√©quation homog√®ne est un $\mathbb{K}$-espace vectoriel de dimension $n$.

**D√©monstration (esquisse) :**
Se ramener au th√©or√®me pr√©c√©dent (Th√©or√®me 40) en posant $Y = (y, y', \dots, y^{(n-1)})^T \in \mathbb{K}^n$, ce qui donne $Y' = A(t)Y + B(t)$ avec $A(t)$ la matrice compagnon associ√©e.

### 
**Subtilit√©s :**
*   Le coefficient dominant doit √™tre normalis√© √† 1 (ou non nul). Si l'√©quation est $a_n(t) y^{(n)} + \dots = b(t)$ avec $a_n$ pouvant s'annuler, le th√©or√®me ne s'applique pas directement : il faut travailler sur les intervalles o√π $a_n \neq 0$.
*   Le wronskien des solutions de l'homog√®ne est soit identiquement nul, soit jamais nul sur $I$ (caract√©rise si les solutions forment une base ou non).

**Pi√®ges classiques :**
*   Diviser par $a_n(t)$ sans v√©rifier que $a_n$ ne s'annule pas sur $I$.
*   Oublier qu'il faut $n$ conditions initiales (et non $n-1$ ou $n+1$).
*   Sur un probl√®me concret, oublier de v√©rifier que les $a_k$ sont bien continues sur l'intervalle consid√©r√© (ex : $1/t$ non continue en $0$).

---

## FLASHCARD 89 ‚Äî √Ä conna√Ætre 23 : Wronskien et structure des solutions

### RECTO
**Wronskien et structure des solutions d'une EDL d'ordre $n$**

Soit $y_1, \dots, y_n$ des solutions de l'√©quation homog√®ne $y^{(n)} + a_{n-1}(t) y^{(n-1)} + \dots + a_0(t) y = 0$ sur un intervalle $I$.

**Question :** D√©finir le wronskien de $(y_1, \dots, y_n)$. √ânoncer la caract√©risation d'un syst√®me fondamental de solutions via le wronskien. Donner la formule de Liouville (ou d'Abel).

### VERSO
**D√©finition :**
$$ W(t) = \det \begin{pmatrix} y_1(t) & \dots & y_n(t) \\ y_1'(t) & \dots & y_n'(t) \\ \vdots & & \vdots \\ y_1^{(n-1)}(t) & \dots & y_n^{(n-1)}(t) \end{pmatrix} $$

**Caract√©risation :**
$(y_1, \dots, y_n)$ est un syst√®me fondamental de solutions (i.e. une base de l'espace des solutions) si et seulement si $W(t_0) \neq 0$ pour un (et alors tout) $t_0 \in I$.

**Alternative de wronskien :** $W$ est soit identiquement nul sur $I$, soit ne s'annule jamais sur $I$.

**Formule d'Abel‚ÄìLiouville :**
$$ \forall t \in I, \quad W(t) = W(t_0) \exp \left( - \int_{t_0}^t a_{n-1}(s) ds \right) $$

**D√©monstration (esquisse) :**
On d√©rive $W$ : par multilin√©arit√© du d√©terminant, seule la ligne des d√©riv√©es d'ordre maximal contribue, ce qui donne $W'(t) = - a_{n-1}(t) W(t)$.
EDL d'ordre 1 en $W \to$ formule exponentielle.

### 
**Subtilit√©s :**
*   L'alternative du wronskien est sp√©cifique aux solutions d'une m√™me EDL. Pour des fonctions quelconques, le wronskien peut s'annuler en certains points sans √™tre identiquement nul.
*   La formule d'Abel ne fait intervenir que $a_{n-1}$ (coefficient de $y^{(n-1)}$), pas les autres.

**Pi√®ges classiques :**
*   Calculer un wronskien de fonctions qui ne sont pas solutions d'une m√™me EDL et en tirer des conclusions fausses.
*   Confondre ¬´ famille libre de $C^n(I)$ ¬ª et ¬´ syst√®me fondamental ¬ª : une famille de solutions peut √™tre libre sans √™tre un SFS si elle ne comporte pas $n$ √©l√©ments.

---

## FLASHCARD 90 ‚Äî Proposition 24 : Variation des constantes (√©quation scalaire d'ordre 2)

### RECTO
**Variation des constantes pour une √©quation scalaire d'ordre 2**

Soit l'√©quation $y'' + a(t)y' + b(t)y = c(t)$ sur un intervalle $I$, avec $a, b, c : I \to \mathbb{K}$ continues, et $(y_1, y_2)$ un syst√®me fondamental de solutions de l'homog√®ne.

**Question :** √ânoncer la m√©thode de variation des constantes : sous quelle forme cherche-t-on une solution particuli√®re ? Quel syst√®me v√©rifient les fonctions inconnues ?

### VERSO
**Hypoth√®ses :**
*   $I$ intervalle de $\mathbb{R}$, $\mathbb{K} = \mathbb{R}$ ou $\mathbb{C}$
*   $a, b, c : I \to \mathbb{K}$ continues
*   $(y_1, y_2)$ syst√®me fondamental de solutions de $y'' + ay' + by = 0$
*   $W = y_1 y_2' - y_1' y_2$ le wronskien (ne s'annule jamais)

**M√©thode :**
On cherche une solution particuli√®re sous la forme :
$$ y_p(t) = \lambda_1(t) y_1(t) + \lambda_2(t) y_2(t) $$
avec $\lambda_1, \lambda_2 : I \to \mathbb{K}$ de classe $C^1$.

**Syst√®me de Cramer :**
$$ \begin{cases} \lambda_1'(t) y_1(t) + \lambda_2'(t) y_2(t) = 0 \\ \lambda_1'(t) y_1'(t) + \lambda_2'(t) y_2'(t) = c(t) \end{cases} $$

**Solution :**
$$ \lambda_1'(t) = \frac{-y_2(t) c(t)}{W(t)}, \quad \lambda_2'(t) = \frac{y_1(t) c(t)}{W(t)} $$
Puis on int√®gre pour obtenir $\lambda_1$ et $\lambda_2$.

**D√©monstration (esquisse) :**
On pose la contrainte de jauge $\lambda_1' y_1 + \lambda_2' y_2 = 0$ pour que $y_p' = \lambda_1 y_1' + \lambda_2 y_2'$ (simplification).
On d√©rive une seconde fois et on injecte dans l'√©quation : les termes en $\lambda_1, \lambda_2$ (sans prime) disparaissent car $y_1, y_2$ sont solutions de l'homog√®ne.
Il reste $\lambda_1' y_1' + \lambda_2' y_2' = c$, et le syst√®me est inversible car $W \neq 0$.

### 
**Subtilit√©s :**
*   La premi√®re √©quation $\lambda_1' y_1 + \lambda_2' y_2 = 0$ est une convention de calcul (condition de jauge), pas une cons√©quence de l'√©quation. Elle simplifie $y_p''$.
*   La m√©thode se g√©n√©ralise √† l'ordre $n$ : on a $n$ inconnues $\lambda_k'$ et $n$ √©quations, dont $n-1$ conditions de jauge et la derni√®re vient de l'EDL.

**Pi√®ges classiques :**
*   Oublier de normaliser l'√©quation (le coefficient de $y''$ doit √™tre 1, sinon le second membre est $c(t)/a_2(t)$).
*   Se tromper de signe dans les formules de Cramer.
*   Oublier que la solution g√©n√©rale est $y = y_p + \alpha y_1 + \beta y_2$, pas juste $y_p$.

---

## FLASHCARD 91 ‚Äî √Ä conna√Ætre 24 : Z√©ros isol√©s des solutions d'EDL

### RECTO
**Z√©ros isol√©s des solutions d'une EDL d'ordre $n$**

Soit $y$ une solution non identiquement nulle de l'EDL homog√®ne $y^{(n)} + a_{n-1}(t) y^{(n-1)} + \dots + a_0(t) y = 0$ sur un intervalle $I$, avec $a_k$ continues.

**Question :** Que peut-on dire des z√©ros de $y$ ?

### VERSO
**Hypoth√®ses :**
*   $I$ intervalle de $\mathbb{R}$
*   $a_0, \dots, a_{n-1} : I \to \mathbb{K}$ continues
*   $y : I \to \mathbb{K}$ solution de l'EDL homog√®ne, $y \not\equiv 0$

**Conclusion :**
Les z√©ros de $y$ sont isol√©s : pour tout $t_0 \in I$ tel que $y(t_0) = 0$, il existe $\varepsilon > 0$ tel que $y$ ne s'annule pas sur $]t_0 - \varepsilon, t_0 + \varepsilon[ \setminus \{t_0\}$.

En particulier, $y$ n'a qu'un nombre fini de z√©ros sur tout segment $[a, b] \subset I$.

**D√©monstration (esquisse) :**
Si $y(t_0) = 0$, poser $Y(t_0) = (y(t_0), y'(t_0), \dots, y^{(n-1)}(t_0))$.
Comme $y \not\equiv 0$, par unicit√© de Cauchy-Lipschitz, $Y(t_0) \neq 0$, donc il existe $k \in \{0, \dots, n-1\}$ tel que $y^{(k)}(t_0) \neq 0$.
Soit $k_0$ le plus petit tel indice. Si $k_0 = 0$, $y(t_0) \neq 0$, contradiction. Sinon $y(t_0) = y'(t_0) = \dots = y^{(k_0-1)}(t_0) = 0$ et $y^{(k_0)}(t_0) \neq 0$.
Par Taylor (ou par continuit√© de $y^{(k_0)}$), $y(t) \sim \frac{y^{(k_0)}(t_0)}{k_0!} (t-t_0)^{k_0}$ au voisinage de $t_0$, donc $y$ ne s'annule pas au voisinage de $t_0$ (sauf en $t_0$ lui-m√™me).
Nombre fini sur un segment : l'ensemble des z√©ros est ferm√© et discret dans $I$, donc fini sur tout compact.

### 
**Subtilit√©s :**
*   Le r√©sultat est faux pour des fonctions quelconques : $t \mapsto t^2 \sin(1/t)$ a des z√©ros non isol√©s.
*   C'est aussi faux pour les EDL √† coefficients discontinus.
*   Pour $\mathbb{K} = \mathbb{C}$, les z√©ros sont encore isol√©s, mais on ne peut pas parler de ¬´ signe ¬ª.

**Extensions :**
*   Pour les EDL d'ordre 2 √† coefficients r√©els, on peut dire beaucoup plus : les z√©ros de deux solutions lin√©airement ind√©pendantes s'entrelacent (th√©or√®me de Sturm).

**Pi√®ges classiques :**
*   √âcrire ¬´ les z√©ros sont en nombre fini sur $I$ ¬ª sans pr√©ciser ¬´ sur tout segment ¬ª : sur $I = \mathbb{R}$, $\sin(t)$ (solution de $y''+y=0$) a une infinit√© de z√©ros, mais ils sont isol√©s.
*   Confondre ¬´ isol√©s ¬ª et ¬´ en nombre fini ¬ª.

---

## FLASHCARD 92 ‚Äî √Ä conna√Ætre 25 : Th√©or√®me de Sturm-Liouville (th√©or√®me de comparaison de Sturm)

### RECTO
**Th√©or√®me de comparaison de Sturm**

Soient $q_1, q_2 : [a, b] \to \mathbb{R}$ continues avec $q_1 \le q_2$ sur $[a, b]$. Soit $y_1$ (resp. $y_2$) une solution non triviale de $y'' + q_1(t)y = 0$ (resp. $y'' + q_2(t)y = 0$).

**Question :** √ânoncer le th√©or√®me de comparaison de Sturm reliant les z√©ros de $y_1$ et $y_2$.

### VERSO
**Hypoth√®ses :**
*   $[a, b]$ segment de $\mathbb{R}$
*   $q_1, q_2 : [a, b] \to \mathbb{R}$ continues, $q_1(t) \le q_2(t)$ pour tout $t \in [a, b]$
*   $y_1$ solution non triviale de $y_1'' + q_1(t) y_1 = 0$
*   $y_2$ solution non triviale de $y_2'' + q_2(t) y_2 = 0$

**Conclusion :**
Entre deux z√©ros cons√©cutifs de $y_1$, il y a au moins un z√©ro de $y_2$ (√† condition que $q_1 \not\equiv q_2$ sur cet intervalle, sinon $y_2$ peut ne pas s'annuler).

Plus pr√©cis√©ment : si $\alpha < \beta$ sont deux z√©ros cons√©cutifs de $y_1$ et $q_1 \le q_2$ avec $q_1 \not\equiv q_2$, alors $y_2$ s'annule au moins une fois dans $]\alpha, \beta[$.

**D√©monstration (esquisse) :**
On peut supposer $y_1 > 0$ sur $]\alpha, \beta[$ (quitte √† changer de signe).
On suppose par l'absurde que $y_2 > 0$ sur $]\alpha, \beta[$.
On consid√®re l'identit√© de Picone ou on calcule $\frac{d}{dt}[y_1 y_2' - y_1' y_2]$ :
$$ \frac{d}{dt}(y_1 y_2' - y_1' y_2) = (q_1 - q_2) y_1 y_2 $$
On int√®gre sur $[\alpha, \beta]$ : le membre de gauche se calcule aux bornes ($y_1(\alpha) = y_1(\beta) = 0$), le membre de droite est $\le 0$ (car $q_1 \le q_2$ et $y_1, y_2 > 0$), ce qui m√®ne √† une contradiction si $q_1 \not\equiv q_2$.

### 
**Subtilit√©s :**
*   Le th√©or√®me est sp√©cifique √† l'ordre 2 et aux coefficients r√©els.
*   Si $q_1 = q_2$, on retrouve l'entrelacement des z√©ros de deux solutions lin√©airement ind√©pendantes d'une m√™me EDL d'ordre 2 (th√©or√®me de Sturm).
*   L'hypoth√®se est $q_1 \le q_2$ : plus le ¬´ potentiel ¬ª $q$ est grand, plus les solutions oscillent rapidement.

**Applications classiques :**
*   Comparer les z√©ros de $y'' + t y = 0$ (Airy) √† ceux de $\sin$ ou $\cos$ (solutions de $y'' + y = 0$).
*   Montrer qu'une solution a une infinit√© de z√©ros si $q(t) \to +\infty$.

**Pi√®ges classiques :**
*   Appliquer Sturm √† des √©quations qui ne sont pas sous forme $y'' + q(t) y = 0$ : il faut d'abord se ramener √† cette forme (ou adapter l'√©nonc√© si le coefficient de $y'$ n'est pas nul).
*   Oublier la condition $q_1 \not\equiv q_2$.

---

## FLASHCARD 93 ‚Äî Th√©or√®me 42 : Condition n√©cessaire d'extremum local en un point int√©rieur (calcul diff√©rentiel)

### RECTO
**Condition n√©cessaire d'extremum local en un point int√©rieur (fonctions de plusieurs variables)**

Soit $U$ un ouvert de $\mathbb{R}^n$, $f : U \to \mathbb{R}$ diff√©rentiable en $a \in U$.

**Question :** √ânoncer la condition n√©cessaire d'extremum local de $f$ en $a$.

### VERSO
**Hypoth√®ses :**
*   $U$ ouvert de $\mathbb{R}^n$
*   $f : U \to \mathbb{R}$
*   $f$ diff√©rentiable en $a \in U$
*   $f$ admet un extremum local en $a$

**Conclusion :**
$$ df(a) = 0 \quad \text{i.e.} \quad \forall h \in \mathbb{R}^n, df(a) \cdot h = 0 $$
Autrement dit, $\nabla f(a) = 0$ (toutes les d√©riv√©es partielles s'annulent en $a$) :
$$ \frac{\partial f}{\partial x_i}(a) = 0 \quad \forall i \in \{1, \dots, n\} $$

**D√©monstration (esquisse) :**
Pour tout $h \in \mathbb{R}^n$, la fonction $\varphi : t \mapsto f(a + th)$ est d√©finie au voisinage de $0$, diff√©rentiable en $0$, et admet un extremum local en $0$. Par le cas r√©el unidimensionnel : $\varphi'(0) = df(a) \cdot h = 0$.

### 
**Subtilit√©s :**
*   Le point $a$ doit √™tre int√©rieur au domaine. Si $a$ est sur le bord, la condition n'est plus n√©cessaire (cf. optimisation sous contrainte).
*   La condition est n√©cessaire mais pas suffisante : $f(x, y) = x^3$ en $(0, 0)$ a $df(0) = 0$ mais pas d'extremum.
*   $f$ doit √™tre √† valeurs r√©elles. Pour $f : U \to \mathbb{R}^p$ avec $p \ge 2$, la notion d'extremum n'a pas de sens (pas d'ordre sur $\mathbb{R}^p$).

**Pi√®ges classiques :**
*   Confondre ¬´ $f$ admet toutes ses d√©riv√©es partielles nulles en $a$ ¬ª (condition plus faible si $f$ n'est pas diff√©rentiable) et ¬´ $df(a) = 0$ ¬ª.
*   Oublier de v√©rifier la diff√©rentiabilit√© (l'existence des d√©riv√©es partielles ne suffit pas).

---

## FLASHCARD 94 ‚Äî Proposition 25 : R√®gle de la cha√Æne

### RECTO
**R√®gle de la cha√Æne (chain rule)**

Soient $U \subset \mathbb{R}^n$ ouvert, $V \subset \mathbb{R}^p$ ouvert, $f : U \to V$ et $g : V \to \mathbb{R}^q$.

**Question :** Sous quelles hypoth√®ses $g \circ f$ est-elle diff√©rentiable en $a \in U$, et quelle est sa diff√©rentielle ?

### VERSO
**Hypoth√®ses :**
*   $U$ ouvert de $\mathbb{R}^n$, $V$ ouvert de $\mathbb{R}^p$
*   $f : U \to \mathbb{R}^p$ diff√©rentiable en $a \in U$, avec $f(U) \subset V$
*   $g : V \to \mathbb{R}^q$ diff√©rentiable en $b = f(a) \in V$

**Conclusion :**
$g \circ f$ est diff√©rentiable en $a$ et :
$$ d(g \circ f)(a) = dg(f(a)) \circ df(a) $$

En termes de matrices jacobiennes :
$$ J_{g \circ f}(a) = J_g(f(a)) \cdot J_f(a) $$

**D√©monstration (esquisse) :**
*   √âcrire $f(a+h) = f(a) + df(a) \cdot h + o(\|h\|)$.
*   √âcrire $g(f(a)+k) = g(f(a)) + dg(f(a)) \cdot k + o(\|k\|)$ avec $k = df(a) \cdot h + o(\|h\|)$.
*   Composer : $g(f(a+h)) = g(f(a)) + dg(f(a)) \cdot df(a) \cdot h + o(\|h\|)$.
*   V√©rifier que les restes sont bien des $o(\|h\|)$ en utilisant que $\|k\| = O(\|h\|)$.

### 
**Subtilit√©s :**
*   La r√®gle de la cha√Æne donne la composition des applications lin√©aires (et non leur somme ou produit terme √† terme).
*   En coordonn√©es : $\frac{\partial (g \circ f)}{\partial x_j}(a) = \sum_{i=1}^p \frac{\partial g}{\partial y_i}(f(a)) \frac{\partial f_i}{\partial x_j}(a)$.
*   L'hypoth√®se ¬´ $f(U) \subset V$ ¬ª est parfois oubli√©e mais n√©cessaire pour que $g \circ f$ ait un sens.

**Extensions :**
*   Valable en dimension infinie entre espaces de Banach (m√™me d√©monstration).
*   Si $f$ est $C^1$ et $g$ est $C^1$, alors $g \circ f$ est $C^1$ (et la formule est valable en tout point).

**Pi√®ges classiques :**
*   Inverser l'ordre dans la composition : $dg(f(a)) \circ df(a)$ et non $df(a) \circ dg(f(a))$.
*   √âvaluer $dg$ en $a$ au lieu de $f(a)$.
*   Oublier que la diff√©rentiabilit√© de $f$ en $a$ implique la continuit√© de $f$ en $a$ (n√©cessaire pour que $f(a+h)$ reste dans $V$).

---

## FLASHCARD 95 ‚Äî Proposition 26 : Int√©gration le long d'un arc (chemin)

### RECTO
**Int√©gration le long d'un chemin**

Soit $U$ un ouvert de $\mathbb{R}^n$, $f : U \to \mathbb{R}$ de classe $C^1$, et $\gamma : [a, b] \to U$ un chemin de classe $C^1$.

**Question :** Exprimer $f(\gamma(b)) - f(\gamma(a))$ √† l'aide d'une int√©grale.

### VERSO
**Hypoth√®ses :**
*   $U$ ouvert de $\mathbb{R}^n$
*   $f : U \to \mathbb{R}$ de classe $C^1$
*   $\gamma : [a, b] \to U$ de classe $C^1$ (ou $C^1$ par morceaux)

**Conclusion :**
$$ f(\gamma(b)) - f(\gamma(a)) = \int_a^b df(\gamma(t)) \cdot \gamma'(t) dt = \int_a^b \langle \nabla f(\gamma(t)), \gamma'(t) \rangle dt $$

En coordonn√©es : si $\gamma(t) = (\gamma_1(t), \dots, \gamma_n(t))$ :
$$ f(\gamma(b)) - f(\gamma(a)) = \int_a^b \sum_{i=1}^n \frac{\partial f}{\partial x_i}(\gamma(t)) \gamma_i'(t) dt $$

**D√©monstration :**
Poser $\varphi(t) = f(\gamma(t))$. Par la r√®gle de la cha√Æne, $\varphi'(t) = df(\gamma(t)) \cdot \gamma'(t)$. Puis $\varphi(b) - \varphi(a) = \int_a^b \varphi'(t) dt$.

### 
**Subtilit√©s :**
*   C'est essentiellement le th√©or√®me fondamental de l'analyse appliqu√© √† $\varphi = f \circ \gamma$.
*   Cela fournit une version de l'in√©galit√© des accroissements finis en dimension $n$ : en prenant $\gamma(t) = a + t(b-a)$ et en majorant la norme de $\nabla f$.

**Extensions :**
*   C'est le point de d√©part de la th√©orie des formes diff√©rentielles et des int√©grales curvilignes.

**Pi√®ges classiques :**
*   La formule n√©cessite que l'image de $\gamma$ soit dans $U$ (important si $U$ n'est pas convexe : le segment $[a, b]$ dans $\mathbb{R}^n$ peut sortir de $U$).
*   Oublier le produit scalaire : c'est $\nabla f \cdot \gamma'$ et non $\nabla f \cdot \gamma$.

---

## FLASHCARD 96 ‚Äî √Ä conna√Ætre 26 : In√©galit√© des accroissements finis en dimension quelconque

### RECTO
**In√©galit√© des accroissements finis (fonctions de plusieurs variables, ou √† valeurs vectorielles)**

Soit $U$ un ouvert convexe de $\mathbb{R}^n$, $f : U \to \mathbb{R}^p$ de classe $C^1$.

**Question :** √ânoncer l'in√©galit√© des accroissements finis pour $f$ entre deux points $a, b \in U$.

### VERSO
**Hypoth√®ses :**
*   $U$ ouvert convexe de $\mathbb{R}^n$ (ou plus g√©n√©ralement : le segment $[a, b] \subset U$)
*   $f : U \to \mathbb{R}^p$ de classe $C^1$
*   $a, b \in U$

**Conclusion :**
$$ \|f(b) - f(a)\| \le \sup_{t \in [0, 1]} \|df(a + t(b-a))\|_{\mathcal{L}(\mathbb{R}^n, \mathbb{R}^p)} \cdot \|b-a\| $$

Si $M = \sup_{x \in [a, b]} \|\|df(x)\|\|$ (norme d'op√©rateur de la diff√©rentielle) :
$$ \|f(b) - f(a)\| \le M \|b-a\| $$

**Cas $p=1$ (r√©el) :** On a en fait l'√©galit√© de la moyenne $f(b) - f(a) = df(c) \cdot (b-a)$ pour un certain $c$ sur le segment $[a, b]$ (seulement pour $f$ √† valeurs r√©elles et $n=1$).

**D√©monstration (esquisse) :**
Poser $\varphi(t) = f(a + t(b-a))$. Alors $\varphi'(t) = df(a + t(b-a)) \cdot (b-a)$.
$f(b) - f(a) = \varphi(1) - \varphi(0) = \int_0^1 \varphi'(t) dt$.
Majorer en norme : $\|f(b) - f(a)\| \le \int_0^1 \|\varphi'(t)\| dt \le \sup_t \|df(\dots)\| \cdot \|b-a\|$.

### 
**Subtilit√©s :**
*   La convexit√© de $U$ (ou l'inclusion du segment $[a, b]$ dans $U$) est cruciale. Sur un ouvert non convexe, le chemin rectiligne peut sortir du domaine.
*   L'√©galit√© des accroissements finis ($\exists c, f(b) - f(a) = f'(c)(b-a)$) est fausse pour $f$ √† valeurs vectorielles : consid√©rer $f(t) = e^{it}$ sur $[0, 2\pi]$.
*   En revanche, l'in√©galit√© reste vraie pour $f : U \subset \mathbb{R}^n \to E$ avec $E$ evn quelconque (m√™me de dimension infinie).

**Pi√®ges classiques :**
*   Appliquer le TAF (√©galit√©) √† une fonction √† valeurs vectorielles.
*   Oublier que la norme de la diff√©rentielle est une norme d'op√©rateur.

---

## FLASHCARD 97 ‚Äî Proposition 27 : Caract√©risation des fonctions constantes

### RECTO
**Caract√©risation des fonctions constantes sur un connexe**

Soit $U$ un ouvert connexe de $\mathbb{R}^n$ et $f : U \to \mathbb{R}^p$ de classe $C^1$.

**Question :** √ânoncer la caract√©risation de la constance de $f$ par sa diff√©rentielle.

### VERSO
**Hypoth√®ses :**
*   $U$ ouvert connexe de $\mathbb{R}^n$ (connexe par arcs revient au m√™me pour un ouvert)
*   $f : U \to \mathbb{R}^p$ de classe $C^1$

**Conclusion :**
$$ f \text{ est constante sur } U \iff \forall x \in U, df(x) = 0 $$
(i.e. toutes les d√©riv√©es partielles de toutes les composantes sont nulles sur $U$)

**D√©monstration (esquisse) :**
*   $(\Rightarrow)$ : trivial.
*   $(\Leftarrow)$ : Soit $a \in U$ fix√©. L'ensemble $\{x \in U : f(x) = f(a)\}$ est ferm√© (par continuit√©) et ouvert (car si $df=0$, par l'IAF, $f$ est localement constante). Comme $U$ est connexe et cet ensemble est non vide (contient $a$), il est √©gal √† $U$.
*   Alternative (sur un ouvert convexe) : on utilise directement l'IAF avec $M=0$.

### 
**Subtilit√©s :**
*   La connexit√© est essentielle : sur $U = ]-2, -1[ \cup ]1, 2[$, la fonction valant $0$ sur la premi√®re composante et $1$ sur la seconde a $df=0$ mais n'est pas constante.
*   Pour un ouvert de $\mathbb{R}^n$, connexe $\iff$ connexe par arcs.

**Extensions :**
*   Deux fonctions $C^1$ ayant la m√™me diff√©rentielle sur un ouvert connexe diff√®rent d'une constante.

**Pi√®ges classiques :**
*   Oublier l'hypoth√®se de connexit√©.
*   Confondre ¬´ toutes les d√©riv√©es partielles nulles ¬ª et ¬´ la diff√©rentielle nulle ¬ª : c'est la m√™me chose si $f$ est diff√©rentiable, mais l'existence des d√©riv√©es partielles seule ne suffit pas.

---

## FLASHCARD 98 ‚Äî Proposition 28 : Diff√©omorphisme et inverse local

### RECTO
**Diff√©rentielle d'un diff√©omorphisme et condition n√©cessaire**

Soit $U, V$ ouverts de $\mathbb{R}^n$, et $f : U \to V$ un diff√©omorphisme de classe $C^1$.

**Question :** Que peut-on dire de $df(a)$ pour tout $a \in U$ ? Donner la formule de la diff√©rentielle de $f^{-1}$.

### VERSO
**Hypoth√®ses :**
*   $U, V$ ouverts de $\mathbb{R}^n$
*   $f : U \to V$ bijection de classe $C^1$, $f^{-1} : V \to U$ de classe $C^1$ (i.e. $f$ est un $C^1$-diff√©omorphisme)

**Conclusion :**
Pour tout $a \in U$, $df(a) \in \mathcal{L}(\mathbb{R}^n)$ est un isomorphisme (i.e. $\det J_f(a) \neq 0$), et :
$$ d(f^{-1})(f(a)) = [df(a)]^{-1} $$

En termes de matrices jacobiennes :
$$ J_{f^{-1}}(f(a)) = [J_f(a)]^{-1} $$

**D√©monstration :**
Appliquer la r√®gle de la cha√Æne √† $f^{-1} \circ f = Id_U$ :
$$ d(f^{-1})(f(a)) \circ df(a) = Id_{\mathbb{R}^n} $$
De m√™me avec $f \circ f^{-1} = Id_V$. Donc $df(a)$ est inversible.

### 
**Subtilit√©s :**
*   C'est une condition n√©cessaire. La r√©ciproque (th√©or√®me d'inversion locale) affirme que si $f$ est $C^1$ et $df(a)$ est inversible, alors $f$ est un $C^1$-diff√©omorphisme local au voisinage de $a$. (Ce th√©or√®me est selon les programmes hors programme en MP, mais l'√©nonc√© est √† conna√Ætre.)
*   Si $f$ est $C^k$, alors $f^{-1}$ est aussi $C^k$.

**Pi√®ges classiques :**
*   Croire que $df(a)$ inversible implique que $f$ est un diff√©omorphisme global : c'est faux ($\exp : \mathbb{R} \to \mathbb{R}_+^*$ est un diff√©omorphisme global, mais $t \mapsto e^{it}$ de $\mathbb{R}$ dans $S^1$ ne l'est pas).
*   Oublier que le th√©or√®me d'inversion locale ne donne qu'un r√©sultat local.

---

## FLASHCARD 99 ‚Äî Th√©or√®me 43 : Optimisation sous contrainte (multiplicateurs de Lagrange)

### RECTO
**Th√©or√®me des multiplicateurs de Lagrange**

Soit $U$ un ouvert de $\mathbb{R}^n$, $f : U \to \mathbb{R}$ et $g_1, \dots, g_p : U \to \mathbb{R}$ de classe $C^1$, avec $p < n$.

**Question :** √ânoncer la condition n√©cessaire d'extremum local de $f$ sous les contraintes $g_1 = \dots = g_p = 0$.

### VERSO
**Hypoth√®ses :**
*   $U$ ouvert de $\mathbb{R}^n$, $\mathbb{K} = \mathbb{R}$
*   $f, g_1, \dots, g_p : U \to \mathbb{R}$ de classe $C^1$, avec $p < n$
*   $a \in U$ tel que $g_1(a) = \dots = g_p(a) = 0$
*   **Condition de qualification :** les formes lin√©aires $dg_1(a), \dots, dg_p(a)$ sont lin√©airement ind√©pendantes (i.e. la matrice jacobienne $(\nabla g_1(a) \mid \dots \mid \nabla g_p(a))$ est de rang $p$)
*   $f$ admet un extremum local en $a$ sur l'ensemble $\Gamma = \{x \in U : g_1(x) = \dots = g_p(x) = 0\}$

**Conclusion :**
Il existe des scalaires $\lambda_1, \dots, \lambda_p \in \mathbb{R}$ (les multiplicateurs de Lagrange) tels que :
$$ df(a) = \lambda_1 dg_1(a) + \dots + \lambda_p dg_p(a) $$
Autrement dit :
$$ \nabla f(a) = \lambda_1 \nabla g_1(a) + \dots + \lambda_p \nabla g_p(a) $$

On a donc $n+p$ √©quations (les $n$ composantes de la relation ci-dessus, plus les $p$ contraintes $g_k(a) = 0$) pour $n+p$ inconnues ($a_1, \dots, a_n, \lambda_1, \dots, \lambda_p$).

**D√©monstration (esquisse) :**
Par le th√©or√®me des fonctions implicites (ou un argument de rang), la contrainte $\Gamma$ est localement une sous-vari√©t√© de dimension $n-p$, et le noyau $\ker(dg_1(a), \dots, dg_p(a))$ est l'espace tangent √† $\Gamma$ en $a$.
Pour tout vecteur $h$ tangent √† $\Gamma$ en $a$, on a $df(a) \cdot h = 0$ (condition n√©cessaire d'extremum sur $\Gamma$).
Donc $df(a)$ s'annule sur $\ker(dg_1(a), \dots, dg_p(a))$, ce qui signifie que $df(a) \in \text{Vect}(dg_1(a), \dots, dg_p(a))$.

### 
**Subtilit√©s :**
*   La condition de qualification (ind√©pendance des $dg_k(a)$) est indispensable. Sans elle, la conclusion peut √™tre fausse.
*   Le th√©or√®me donne une condition n√©cessaire, pas suffisante. Un point v√©rifiant les conditions de Lagrange est un point critique mais pas n√©cessairement un extremum.
*   Les multiplicateurs $\lambda_k$ sont uniques (gr√¢ce √† l'ind√©pendance des $dg_k(a)$).

**Extensions :**
*   On peut ajouter des contraintes d'in√©galit√© : conditions de Karush-Kuhn-Tucker (hors programme MP).
*   Pour une seule contrainte ($p=1$), la condition se r√©duit √† $\nabla f(a) = \lambda \nabla g(a)$, c'est-√†-dire que les lignes de niveau de $f$ et $g$ sont tangentes en $a$.

**Pi√®ges classiques :**
*   Oublier la condition de qualification et perdre tous les points.
*   Oublier de v√©rifier que le point trouv√© est bien un extremum (et pas un col).
*   Se tromper dans le comptage : $p$ contraintes, $p$ multiplicateurs, et il faut $p < n$.
*   Confondre ¬´ les gradients sont colin√©aires ¬ª (cas $p=1$) et ¬´ les gradients sont √©gaux ¬ª.

---

## FLASHCARD 100 ‚Äî Th√©or√®me 44 : Th√©or√®me de Schwarz

### RECTO
**Th√©or√®me de Schwarz**

Soit $U$ un ouvert de $\mathbb{R}^n$ et $f : U \to \mathbb{R}$.

**Question :** Sous quelles hypoth√®ses les d√©riv√©es partielles crois√©es de $f$ commutent-elles ? √ânoncer le th√©or√®me.

### VERSO
**Hypoth√®ses :**
*   $U$ ouvert de $\mathbb{R}^n$
*   $f : U \to \mathbb{R}$ (ou plus g√©n√©ralement $f : U \to \mathbb{R}^p$, composante par composante)
*   $f$ est de classe $C^2$ sur $U$ (il suffit que les d√©riv√©es partielles secondes $\frac{\partial^2 f}{\partial x_i \partial x_j}$ et $\frac{\partial^2 f}{\partial x_j \partial x_i}$ existent et soient continues sur $U$)

**Conclusion :**
$$ \forall a \in U, \forall (i, j) \in \{1, \dots, n\}^2, \quad \frac{\partial^2 f}{\partial x_i \partial x_j}(a) = \frac{\partial^2 f}{\partial x_j \partial x_i}(a) $$

Plus g√©n√©ralement, si $f$ est $C^k$, les d√©riv√©es partielles d'ordre $\le k$ ne d√©pendent pas de l'ordre de d√©rivation.

**D√©monstration (esquisse, cas $n=2$) :**
Consid√©rer $\Delta(s, t) = f(a_1+s, a_2+t) - f(a_1+s, a_2) - f(a_1, a_2+t) + f(a_1, a_2)$.
Appliquer le TAF en $s$ puis en $t$ (ou inversement) : on obtient $\Delta(s, t) = st \frac{\partial^2 f}{\partial x_1 \partial x_2}(c_1)$ d'un c√¥t√©, et $\Delta(s, t) = st \frac{\partial^2 f}{\partial x_2 \partial x_1}(c_2)$ de l'autre.
Passer √† la limite $(s, t) \to (0, 0)$ en utilisant la continuit√© des d√©riv√©es secondes.

### 
**Subtilit√©s :**
*   L'hypoth√®se minimale classique est : les deux d√©riv√©es partielles secondes crois√©es existent au voisinage de $a$ et l'une d'elles est continue en $a$. Alors elles sont √©gales en $a$. En pratique, en MP, on travaille avec des fonctions $C^2$, ce qui est plus confortable.
*   Le th√©or√®me est faux sans hypoth√®se de continuit√© des d√©riv√©es secondes : il existe un contre-exemple classique.
*   **Contre-exemple :** $f(x, y) = \frac{xy(x^2-y^2)}{x^2+y^2}$ si $(x, y) \neq (0, 0)$ et $0$ sinon. On a $\frac{\partial^2 f}{\partial x \partial y}(0, 0) = 1 \neq -1 = \frac{\partial^2 f}{\partial y \partial x}(0, 0)$.

**Pi√®ges classiques :**
*   Appliquer Schwarz sans v√©rifier la r√©gularit√© $C^2$.
*   En concours, Schwarz est souvent utilis√© implicitement : attention √† bien le mentionner.

---

## FLASHCARD 101 ‚Äî Proposition 29 : Formule de Taylor-Young √† l'ordre 2 (plusieurs variables)

### RECTO
**Formule de Taylor-Young √† l'ordre 2 (fonctions de plusieurs variables)**

Soit $U$ un ouvert de $\mathbb{R}^n$, $f : U \to \mathbb{R}$ de classe $C^2$, $a \in U$.

**Question :** √ânoncer le d√©veloppement de Taylor-Young de $f$ √† l'ordre 2 en $a$.

### VERSO
**Hypoth√®ses :**
*   $U$ ouvert de $\mathbb{R}^n$
*   $f : U \to \mathbb{R}$ de classe $C^2$
*   $a \in U$, $h = (h_1, \dots, h_n) \in \mathbb{R}^n$

**Conclusion :**
$$ f(a+h) = f(a) + \sum_{i=1}^n \frac{\partial f}{\partial x_i}(a) h_i + \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \frac{\partial^2 f}{\partial x_i \partial x_j}(a) h_i h_j + o(\|h\|^2) $$

Soit, en notation compacte :
$$ f(a+h) = f(a) + df(a) \cdot h + \frac{1}{2} d^2f(a) \cdot (h, h) + o(\|h\|^2) $$

o√π $d^2f(a)$ est la forme bilin√©aire sym√©trique (par Schwarz) de matrice la hessienne :
$$ H_f(a) = \left( \frac{\partial^2 f}{\partial x_i \partial x_j}(a) \right)_{1 \le i, j \le n} $$

**D√©monstration (esquisse) :**
Appliquer Taylor-Young en une variable √† $\varphi(t) = f(a+th)$, qui est $C^2$ au voisinage de $0$ :
$\varphi(1) = \varphi(0) + \varphi'(0) + \frac{1}{2} \varphi''(0) + o(1)$
puis exprimer $\varphi'(0)$ et $\varphi''(0)$ en termes des d√©riv√©es partielles de $f$ (r√®gle de la cha√Æne).

### 
**Subtilit√©s :**
*   La hessienne est sym√©trique par le th√©or√®me de Schwarz.
*   Le terme quadratique $\frac{1}{2} d^2f(a) \cdot (h, h) = \frac{1}{2} {}^t h H_f(a) h$ est la forme quadratique associ√©e √† la hessienne.
*   La formule est un DL √† l'ordre 2, avec un reste en $o(\|h\|^2)$, quelle que soit la norme choisie.

**Pi√®ges classiques :**
*   Oublier le facteur $1/2$ devant le terme quadratique.
*   Confondre $d^2f(a) \cdot (h, h)$ (forme bilin√©aire √©valu√©e en $(h, h)$) avec $d^2f(a) \cdot h$ (qui n'a pas de sens : $d^2f(a)$ est bilin√©aire, pas lin√©aire).
*   √âcrire le d√©veloppement sans pr√©ciser que $h \to 0$ dans $\mathbb{R}^n$.

---

## FLASHCARD 102 ‚Äî Th√©or√®me 45 : Condition d'extremum local d'ordre 2

### RECTO
**Condition suffisante d'extremum local d'ordre 2 (fonctions de plusieurs variables)**

Soit $U$ ouvert de $\mathbb{R}^n$, $f : U \to \mathbb{R}$ de classe $C^2$, $a \in U$ un point critique ($df(a) = 0$).

**Question :** √ânoncer les conditions suffisantes de minimum local, maximum local, et la condition de point selle, en termes de la hessienne $H_f(a)$.

### VERSO
**Hypoth√®ses :**
*   $U$ ouvert de $\mathbb{R}^n$, $f : U \to \mathbb{R}$ de classe $C^2$
*   $a \in U$, $df(a) = 0$ (point critique)
*   $H_f(a) = (\frac{\partial^2 f}{\partial x_i \partial x_j}(a))$ la matrice hessienne

**Conclusions :**
*   Si $H_f(a)$ est **d√©finie positive** ($\forall h \neq 0, {}^t h H_f(a) h > 0$) : $f$ admet un **minimum local strict** en $a$.
*   Si $H_f(a)$ est **d√©finie n√©gative** : $f$ admet un **maximum local strict** en $a$.
*   Si $H_f(a)$ est **non d√©g√©n√©r√©e et ind√©finie** (a des valeurs propres de signes diff√©rents) : $a$ est un **point selle** (pas d'extremum local).
*   Si $H_f(a)$ est semi-d√©finie (positive ou n√©gative) mais pas d√©finie : on ne peut pas conclure (le terme d'ordre 2 ne suffit pas).

**D√©monstration (esquisse) :**
Par Taylor-Young : $f(a+h) - f(a) = \frac{1}{2} {}^t h H_f(a) h + o(\|h\|^2)$.
Si $H_f(a) \succ 0$ : par compacit√© de la sph√®re unit√©, $\min_{\|h\|=1} {}^t h H_f(a) h = \alpha > 0$, donc ${}^t h H_f(a) h \ge \alpha \|h\|^2$, et pour $\|h\|$ assez petit, $f(a+h) - f(a) \ge \frac{\alpha}{4} \|h\|^2 > 0$.

### 
**Subtilit√©s :**
*   En dimension $n=2$, $H_f(a) = \begin{pmatrix} r & s \\ s & t \end{pmatrix}$ : d√©finie positive $\iff r > 0$ et $rt - s^2 > 0$. Point selle $\iff rt - s^2 < 0$.
*   Le cas $rt - s^2 = 0$ est d√©g√©n√©r√© : il faut aller √† l'ordre sup√©rieur.
*   Le crit√®re utilise que la hessienne est sym√©trique (par Schwarz), donc elle est diagonalisable √† valeurs propres r√©elles.

**Pi√®ges classiques :**
*   Oublier de v√©rifier $df(a) = 0$ avant d'utiliser le crit√®re d'ordre 2.
*   Confondre ¬´ semi-d√©finie positive ¬ª (on ne conclut pas) et ¬´ d√©finie positive ¬ª (minimum local).
*   En dimension $n=2$, ne v√©rifier que $rt - s^2 > 0$ sans v√©rifier le signe de $r$ (ou $t$).
*   Croire que $H_f(a) \succ 0$ implique un minimum global : c'est faux (seulement local).

---

# CHAPITRE 10 ‚Äî Arithm√©tique

## FLASHCARD 103 ‚Äî √Ä conna√Ætre 27 : Arithm√©tique dans $\mathbb{Z}$ (division euclidienne, PGCD, B√©zout)

### RECTO
**Arithm√©tique fondamentale dans $\mathbb{Z}$**

**Question :** Rappeler la division euclidienne dans $\mathbb{Z}$, la notion de PGCD, et le th√©or√®me de B√©zout dans $\mathbb{Z}$.

### VERSO
**Division euclidienne dans $\mathbb{Z}$ :**
$\forall (a, b) \in \mathbb{Z} \times \mathbb{Z}^*, \exists! (q, r) \in \mathbb{Z}^2$ tel que :
$$ a = bq + r, \quad 0 \le r < |b| $$

**PGCD :**
Pour $a, b \in \mathbb{Z}$ non tous deux nuls, $\text{pgcd}(a, b)$ est le plus grand diviseur commun (positif) de $a$ et $b$. On le calcule par l'algorithme d'Euclide.
On a : $\text{pgcd}(a, b) = \text{pgcd}(b, a \pmod b)$.

**Th√©or√®me de B√©zout :**
$$ \text{pgcd}(a, b) = d \iff \exists (u, v) \in \mathbb{Z}^2, au + bv = d $$
En particulier, $a$ et $b$ sont premiers entre eux ($\text{pgcd}(a, b) = 1$) si et seulement si $\exists (u, v) \in \mathbb{Z}^2, au + bv = 1$.

**Lemme de Gauss :**
Si $a \mid bc$ et $\text{pgcd}(a, b) = 1$, alors $a \mid c$.

### 
**Subtilit√©s :**
*   Le PGCD est d√©fini comme un entier $\ge 0$ par convention.
*   B√©zout donne des coefficients $u, v$ qui ne sont pas uniques.
*   L'algorithme d'Euclide √©tendu fournit explicitement les coefficients de B√©zout.

**Pi√®ges classiques :**
*   Confondre ¬´ $a \mid b$ et $a \mid c$ ¬ª avec ¬´ $a \mid bc$ ¬ª (la seconde est plus faible).
*   Oublier la condition ¬´ non tous deux nuls ¬ª pour le PGCD.

---

## FLASHCARD 104 ‚Äî Th√©or√®me 46 : Petit th√©or√®me de Fermat

### RECTO
**Petit th√©or√®me de Fermat**

Soit $p$ un nombre premier et $a \in \mathbb{Z}$.

**Question :** √ânoncer le petit th√©or√®me de Fermat (deux versions).

### VERSO
**Hypoth√®ses :**
*   $p$ premier
*   $a \in \mathbb{Z}$

**Version 1 :**
$$ a^p \equiv a \pmod p $$

**Version 2 (si $p \nmid a$) :**
$$ a^{p-1} \equiv 1 \pmod p $$

**D√©monstration (esquisse) :**
$\mathbb{Z}/p\mathbb{Z}$ est un corps (car $p$ premier), donc $(\mathbb{Z}/p\mathbb{Z})^* = \mathbb{Z}/p\mathbb{Z} \setminus \{0\}$ est un groupe de cardinal $p-1$.
Par le th√©or√®me de Lagrange (pour les groupes finis) : l'ordre de tout √©l√©ment divise $p-1$, donc $\bar{a}^{p-1} = \bar{1}$ pour $\bar{a} \neq \bar{0}$.
Alternative : Par r√©currence sur $a$ en utilisant $(a+1)^p \equiv a^p + 1 \pmod p$ (les coefficients binomiaux $\binom{p}{k}$ sont divisibles par $p$ pour $1 \le k \le p-1$).

### 
**Subtilit√©s :**
*   La version 1 est valable m√™me si $p \mid a$ (les deux c√¥t√©s sont congrus √† 0).
*   La r√©ciproque est fausse : il existe des nombres compos√©s $n$ tels que $a^n \equiv a \pmod n$ pour tout $a$ (nombres de Carmichael).
*   Fermat permet de calculer des inverses dans $\mathbb{Z}/p\mathbb{Z}$ : $a^{-1} \equiv a^{p-2} \pmod p$.

**Pi√®ges classiques :**
*   Appliquer Fermat avec un exposant $p$ alors que le module n'est pas premier.
*   Oublier l'hypoth√®se $p \nmid a$ dans la version 2.

---

## FLASHCARD 105 ‚Äî Th√©or√®me 47 : Isomorphisme chinois (th√©or√®me des restes chinois)

### RECTO
**Th√©or√®me des restes chinois (isomorphisme chinois)**

Soient $n_1, \dots, n_k \in \mathbb{N}^*$ deux √† deux premiers entre eux, et $N = n_1 \dots n_k$.

**Question :** √ânoncer l'isomorphisme chinois dans $\mathbb{Z}/N\mathbb{Z}$.

### VERSO
**Hypoth√®ses :**
*   $n_1, \dots, n_k \in \mathbb{N}_{\ge 2}$, deux √† deux premiers entre eux ($\forall i \neq j, \text{pgcd}(n_i, n_j) = 1$)
*   $N = n_1 n_2 \dots n_k$

**Conclusion :**
L'application :
$$ \varphi : \mathbb{Z}/N\mathbb{Z} \to \mathbb{Z}/n_1\mathbb{Z} \times \dots \times \mathbb{Z}/n_k\mathbb{Z} $$
$$ \bar{x} \mapsto (\bar{x}_1, \dots, \bar{x}_k) \quad (\text{r√©ductions modulo } n_i) $$
est un isomorphisme d'anneaux.

**Cons√©quences :**
*   Pour tout $(a_1, \dots, a_k) \in \mathbb{Z}^k$, le syst√®me $x \equiv a_i \pmod{n_i}$ pour $i=1, \dots, k$ admet une solution, unique modulo $N$.
*   Isomorphisme de groupes multiplicatifs : $(\mathbb{Z}/N\mathbb{Z})^* \cong (\mathbb{Z}/n_1\mathbb{Z})^* \times \dots \times (\mathbb{Z}/n_k\mathbb{Z})^*$.
*   En particulier : $\varphi(N) = \varphi(n_1) \dots \varphi(n_k)$ (multiplicativit√© de l'indicatrice d'Euler).

**D√©monstration (esquisse) :**
*   $\varphi$ est un morphisme d'anneaux (√©vident).
*   $\ker \varphi = \{x \in \mathbb{Z}/N\mathbb{Z} : n_i \mid x \ \forall i\} = \{0\}$ car les $n_i$ sont premiers entre eux deux √† deux, donc $N \mid x$.
*   $|\mathbb{Z}/N\mathbb{Z}| = N = n_1 \dots n_k = |\prod \mathbb{Z}/n_i\mathbb{Z}|$, donc $\varphi$ est bijectif.

### 
**Subtilit√©s :**
*   L'hypoth√®se ¬´ deux √† deux premiers entre eux ¬ª est strictement plus forte que ¬´ de PGCD global 1 ¬ª. Exemple : 6, 10, 15 ont $\text{pgcd}(6, 10, 15)=1$ mais ne sont pas deux √† deux premiers entre eux.
*   Le CRT s'applique aussi dans des anneaux principaux (ex : $K[X]$) : si $P_1, \dots, P_k$ sont deux √† deux premiers entre eux, $K[X]/(P_1 \dots P_k) \cong \prod K[X]/(P_i)$.

**Pi√®ges classiques :**
*   Oublier la condition ¬´ deux √† deux premiers entre eux ¬ª.
*   Confondre isomorphisme d'anneaux et isomorphisme de groupes.
*   Oublier que l'isomorphisme donne aussi la multiplicativit√© de $\varphi$ d'Euler.

---

## FLASHCARD 106 ‚Äî Proposition 30 : Indicatrice d'Euler

### RECTO
**Indicatrice d'Euler**

**Question :** D√©finir l'indicatrice d'Euler $\varphi(n)$. Donner sa formule en fonction de la d√©composition en facteurs premiers. √ânoncer sa propri√©t√© de multiplicativit√©.

### VERSO
**D√©finition :**
Pour $n \ge 1$ :
$$ \varphi(n) = \#\{k \in \{1, \dots, n\} : \text{pgcd}(k, n) = 1\} = |(\mathbb{Z}/n\mathbb{Z})^*| $$

**Formule :**
Si $n = p_1^{\alpha_1} \dots p_r^{\alpha_r}$ est la d√©composition en facteurs premiers :
$$ \varphi(n) = n \prod_{i=1}^r \left( 1 - \frac{1}{p_i} \right) = \prod_{i=1}^r p_i^{\alpha_i - 1} (p_i - 1) $$

**Multiplicit√© :**
Si $\text{pgcd}(m, n) = 1$, alors $\varphi(mn) = \varphi(m) \varphi(n)$.
(C'est une cons√©quence directe du CRT.)

**Formule de sommation :**
$$ \sum_{d \mid n} \varphi(d) = n $$

**Cas particuliers :**
$\varphi(1) = 1$, $\varphi(p) = p-1$, $\varphi(p^k) = p^{k-1}(p-1)$ pour $p$ premier.

### 
**Subtilit√©s :**
*   La multiplicativit√© de $\varphi$ n'est valable que pour des entiers premiers entre eux. $\varphi$ n'est pas compl√®tement multiplicative.
*   La formule $\sum_{d \mid n} \varphi(d) = n$ se d√©montre en partitionnant $\{1, \dots, n\}$ selon $\text{pgcd}(k, n)$.

**Pi√®ges classiques :**
*   √âcrire $\varphi(mn) = \varphi(m)\varphi(n)$ sans v√©rifier $\text{pgcd}(m, n) = 1$.
*   Confondre $\varphi(p^k) = p^{k-1}(p-1)$ avec $p^k-1$.

---

## FLASHCARD 107 ‚Äî Th√©or√®me 48 : Th√©or√®me d'Euler

### RECTO
**Th√©or√®me d'Euler**

Soit $n \ge 2$ un entier et $a \in \mathbb{Z}$ tel que $\text{pgcd}(a, n) = 1$.

**Question :** √ânoncer le th√©or√®me d'Euler.

### VERSO
**Hypoth√®ses :**
*   $n \ge 2$ entier
*   $a \in \mathbb{Z}$, $\text{pgcd}(a, n) = 1$

**Conclusion :**
$$ a^{\varphi(n)} \equiv 1 \pmod n $$

**D√©monstration :**
$(\mathbb{Z}/n\mathbb{Z})^*$ est un groupe multiplicatif de cardinal $\varphi(n)$. Par le th√©or√®me de Lagrange, l'ordre de $\bar{a}$ divise $\varphi(n)$, donc $\bar{a}^{\varphi(n)} = \bar{1}$.

### 
**Subtilit√©s :**
*   Le petit th√©or√®me de Fermat est le cas particulier $n=p$ premier (et $\varphi(p) = p-1$).
*   L'exposant $\varphi(n)$ n'est en g√©n√©ral pas le plus petit exposant universel. Le plus petit $\lambda$ tel que $a^\lambda \equiv 1 \pmod n$ pour tout $a$ premier √† $n$ est la fonction de Carmichael $\lambda(n)$, qui divise $\varphi(n)$.

**Pi√®ges classiques :**
*   Appliquer le th√©or√®me d'Euler sans v√©rifier $\text{pgcd}(a, n) = 1$.
*   Confondre l'ordre d'un √©l√©ment avec $\varphi(n)$ : $\varphi(n)$ est un multiple de l'ordre, pas n√©cessairement l'ordre lui-m√™me.

---

## FLASHCARD 108 ‚Äî √Ä conna√Ætre 28 : Existence et nombre de racines primitives

### RECTO
**Racines primitives modulo $n$**

**Question :** Pour quels entiers $n \ge 2$ le groupe $(\mathbb{Z}/n\mathbb{Z})^*$ est-il cyclique ? Qu'appelle-t-on alors une racine primitive ?

### VERSO
**D√©finition :**
Un √©l√©ment $g \in (\mathbb{Z}/n\mathbb{Z})^*$ est une racine primitive modulo $n$ si $g$ engendre $(\mathbb{Z}/n\mathbb{Z})^*$, i.e. $\text{ord}(g) = \varphi(n)$.

**Th√©or√®me :**
$(\mathbb{Z}/n\mathbb{Z})^*$ est cyclique si et seulement si $n \in \{1, 2, 4, p^k, 2p^k\}$ o√π $p$ est un premier impair et $k \ge 1$.

**Nombre de racines primitives :**
Quand $(\mathbb{Z}/n\mathbb{Z})^*$ est cyclique, il y a exactement $\varphi(\varphi(n))$ racines primitives modulo $n$.

### 
**Subtilit√©s :**
*   $(\mathbb{Z}/8\mathbb{Z})^* \cong \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z}$ n'est pas cyclique.
*   $(\mathbb{Z}/p\mathbb{Z})^*$ est toujours cyclique pour $p$ premier : c'est le cas le plus important en MP.
*   La preuve que $(\mathbb{Z}/p\mathbb{Z})^*$ est cyclique repose sur le fait que dans un corps, un polyn√¥me de degr√© $d$ a au plus $d$ racines, et on compte les √©l√©ments d'ordre $d$ pour chaque $d \mid p-1$.

**Pi√®ges classiques :**
*   Croire que $(\mathbb{Z}/n\mathbb{Z})^*$ est toujours cyclique.
*   Confondre ¬´ il existe un √©l√©ment d'ordre $\varphi(n)$ ¬ª (racine primitive) avec ¬´ tout √©l√©ment est d'ordre $\varphi(n)$ ¬ª.

---

## FLASHCARD 109 ‚Äî √Ä conna√Ætre 29 : Formule de Legendre

### RECTO
**Formule de Legendre (valuation $p$-adique de $n!$)**

Soit $p$ un nombre premier et $n \in \mathbb{N}^*$.

**Question :** Donner la formule de Legendre pour $v_p(n!)$ (la valuation $p$-adique de $n!$).

### VERSO
**Formule :**
$$ v_p(n!) = \sum_{k=1}^{+\infty} \left\lfloor \frac{n}{p^k} \right\rfloor $$
La somme est finie (les termes sont nuls d√®s que $p^k > n$).

**Formule alternative :**
$$ v_p(n!) = \frac{n - s_p(n)}{p-1} $$
o√π $s_p(n)$ est la somme des chiffres de $n$ en base $p$.

**D√©monstration (esquisse) :**
$v_p(n!) = \sum_{j=1}^n v_p(j)$. Pour chaque $k \ge 1$, le nombre d'entiers $j \in \{1, \dots, n\}$ divisibles par $p^k$ est $\lfloor n/p^k \rfloor$. En √©changeant les sommations, on obtient la formule.

### 
**Subtilit√©s :**
*   La formule alternative avec $s_p(n)$ est parfois plus pratique pour des estimations asymptotiques.
*   Utile pour d√©terminer si $\binom{n}{k}$ est divisible par $p$ : $v_p(\binom{n}{k}) = \frac{s_p(k) + s_p(n-k) - s_p(n)}{p-1}$ (th√©or√®me de Kummer).

**Applications classiques :**
*   Montrer que $\binom{2n}{n}$ est pair pour $n \ge 1$.
*   Calculer la puissance exacte de $p$ divisant $\binom{n}{k}$.

**Pi√®ges classiques :**
*   Oublier que la somme est finie.
*   Confondre $\lfloor n/p^k \rfloor$ avec $n/p^k$ (oublier la partie enti√®re).

---

## FLASHCARD 110 ‚Äî Proposition 31 : Groupes monog√®nes / cycliques

### RECTO
**Classification des groupes monog√®nes**

**Question :** Rappeler la classification des groupes monog√®nes (engendr√©s par un seul √©l√©ment). Distinguer le cas fini et le cas infini.

### VERSO
**D√©finition :**
Un groupe $G$ est monog√®ne s'il existe $g \in G$ tel que $G = \langle g \rangle = \{g^n : n \in \mathbb{Z}\}$ (notation multiplicative). Si $G$ est monog√®ne et fini, on dit que $G$ est cyclique.

**Classification :**
*   Si $G$ est monog√®ne infini : $G \cong (\mathbb{Z}, +)$.
*   Si $G$ est monog√®ne fini de cardinal $n$ : $G \cong (\mathbb{Z}/n\mathbb{Z}, +)$.

**Propri√©t√©s des groupes cycliques $\mathbb{Z}/n\mathbb{Z}$ :**
*   Les sous-groupes de $\mathbb{Z}/n\mathbb{Z}$ sont les $\langle \bar{d} \rangle$ pour $d \mid n$, isomorphes √† $\mathbb{Z}/(n/d)\mathbb{Z}$. Il y a exactement un sous-groupe d'ordre $d$ pour chaque diviseur $d$ de $n$.
*   Les g√©n√©rateurs de $\mathbb{Z}/n\mathbb{Z}$ sont les $\bar{k}$ avec $\text{pgcd}(k, n) = 1$, au nombre de $\varphi(n)$.

### 
**Subtilit√©s :**
*   Un sous-groupe d'un groupe cyclique est cyclique.
*   Un quotient d'un groupe cyclique est cyclique.
*   Tout groupe d'ordre premier est cyclique (par Lagrange).

**Pi√®ges classiques :**
*   Confondre ¬´ monog√®ne ¬ª et ¬´ cyclique ¬ª (le second est le cas fini du premier, selon la convention la plus courante en France).
*   Oublier l'unicit√© du sous-groupe d'ordre $d$ pour $d \mid n$.

---

## FLASHCARD 111 ‚Äî √Ä conna√Ætre 30 : Structure des groupes ab√©liens finis (programme MP ‚Äî version simplifi√©e)

### RECTO
**Structure des groupes ab√©liens finis ‚Äî cas au programme**

**Question :** √ânoncer le r√©sultat de d√©composition d'un groupe ab√©lien fini en produit de groupes cycliques d'ordres premiers entre eux (cons√©quence du CRT). Rappeler la condition pour qu'un produit de cycliques soit cyclique.

### VERSO
**R√©sultat :**
Soit $G$ un groupe ab√©lien fini d'ordre $n = p_1^{\alpha_1} \dots p_r^{\alpha_r}$. Alors :
$$ G \cong G_{p_1} \times \dots \times G_{p_r} $$
o√π $G_{p_i}$ est le $p_i$-Sylow de $G$ (sous-groupe des √©l√©ments d'ordre une puissance de $p_i$), et $|G_{p_i}| = p_i^{\alpha_i}$.

**Condition pour qu'un produit soit cyclique :**
$$ \mathbb{Z}/m\mathbb{Z} \times \mathbb{Z}/n\mathbb{Z} \cong \mathbb{Z}/mn\mathbb{Z} \iff \text{pgcd}(m, n) = 1. $$

### 
**Pi√®ges classiques :**
*   Croire que tout groupe ab√©lien fini est cyclique : $\mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z}$ est ab√©lien d'ordre 4 mais non cyclique.
*   Le th√©or√®me complet de classification (facteurs invariants / d√©composition primaire) est hors programme MP mais peut √™tre utile conceptuellement.

---

## FLASHCARD 112 ‚Äî Proposition 32 : Ordre d'un √©l√©ment dans un groupe fini

### RECTO
**Ordre d'un √©l√©ment dans un groupe fini**

Soit $G$ un groupe fini et $g \in G$.

**Question :** D√©finir l'ordre de $g$. √ânoncer les propri√©t√©s fondamentales de l'ordre.

### VERSO
**D√©finition :**
L'ordre de $g$, not√© $\text{ord}(g)$ ou $|g|$, est le plus petit entier $n \ge 1$ tel que $g^n = e$ (neutre).

**Propri√©t√©s :**
*   $g^k = e \iff \text{ord}(g) \mid k$.
*   $\text{ord}(g)$ divise $|G|$ (th√©or√®me de Lagrange).
*   $\text{ord}(g^k) = \frac{\text{ord}(g)}{\text{pgcd}(k, \text{ord}(g))}$.
*   Si $g$ et $h$ commutent et $\text{pgcd}(\text{ord}(g), \text{ord}(h)) = 1$, alors $\text{ord}(gh) = \text{ord}(g) \cdot \text{ord}(h)$.

### 
**Subtilit√©s :**
*   La propri√©t√© 4 n√©cessite la commutativit√© et la coprimalit√©. Sans coprimalit√©, on a seulement $\text{ord}(gh) \mid \text{ppcm}(\text{ord}(g), \text{ord}(h))$.
*   En lien avec la r√©duction : si $A \in M_n(\mathbb{K})$ et $A^m = I_n$, alors le polyn√¥me minimal de $A$ divise $X^m - 1$.

**Pi√®ges classiques :**
*   Oublier la condition de commutativit√© dans la propri√©t√© 4.
*   Confondre ¬´ $g^k = e$ ¬ª avec ¬´ $\text{ord}(g) = k$ ¬ª : le premier dit seulement que $\text{ord}(g) \mid k$.

---

## FLASHCARD 113 ‚Äî √Ä conna√Ætre 31 : Th√©or√®me de Lagrange

### RECTO
**Th√©or√®me de Lagrange (pour les groupes finis)**

Soit $G$ un groupe fini et $H$ un sous-groupe de $G$.

**Question :** √ânoncer le th√©or√®me de Lagrange.

### VERSO
**Hypoth√®ses :**
*   $G$ groupe fini
*   $H$ sous-groupe de $G$

**Conclusion :**
$$ |H| \text{ divise } |G| $$
Plus pr√©cis√©ment, l'indice $[G : H] = |G|/|H|$ est le nombre de classes √† gauche (ou √† droite) de $H$ dans $G$.

**D√©monstration (esquisse) :**
Les classes √† gauche $gH$ forment une partition de $G$, et chaque classe a le m√™me cardinal $|H|$ (par bijectivit√© de $x \mapsto gx$). Donc $|G| = [G : H] \cdot |H|$.

**Corollaires :**
*   L'ordre de tout √©l√©ment de $G$ divise $|G|$.
*   $\forall g \in G, g^{|G|} = e$.
*   Tout groupe d'ordre premier est cyclique.

### 
**Subtilit√©s :**
*   La r√©ciproque est fausse : si $d \mid |G|$, il n'existe pas n√©cessairement de sous-groupe d'ordre $d$ (contre-exemple : $\mathfrak{A}_4$ d'ordre 12 n'a pas de sous-groupe d'ordre 6). (La r√©ciproque est vraie si $d$ est premier : th√©or√®me de Cauchy, hors programme strict MP mais bon √† savoir.)

**Pi√®ges classiques :**
*   Croire que Lagrange donne l'existence de sous-groupes de tout ordre divisant $|G|$.
*   Confondre ¬´ $|H|$ divise $|G|$ ¬ª avec ¬´ $H$ est distingu√© dans $G$ ¬ª (pas de lien).

---

## FLASHCARD 114 ‚Äî Proposition 33 : Morphismes de groupes ‚Äî propri√©t√©s fondamentales

### RECTO
**Morphismes de groupes**

Soit $\phi : G \to H$ un morphisme de groupes.

**Question :** Rappeler les propri√©t√©s fondamentales (image du neutre, image des inverses, image et noyau).

### VERSO
**Propri√©t√©s :**
*   $\phi(e_G) = e_H$.
*   $\forall g \in G, \phi(g^{-1}) = \phi(g)^{-1}$.
*   $\ker \phi = \{g \in G : \phi(g) = e_H\}$ est un sous-groupe distingu√© de $G$.
*   $\text{Im}(\phi) = \phi(G)$ est un sous-groupe de $H$.
*   $\phi$ est injectif $\iff \ker \phi = \{e_G\}$.
*   Si $G$ est fini : $|G| = |\ker \phi| \cdot |\text{Im}(\phi)|$ (formule analogue au th√©or√®me du rang).

**Premier th√©or√®me d'isomorphisme :**
$$ G/\ker \phi \cong \text{Im}(\phi) $$

### 
**Subtilit√©s :**
*   Le noyau est distingu√© (invariant par conjugaison). L'image n'est en g√©n√©ral pas distingu√©e dans $H$.
*   Le premier th√©or√®me d'isomorphisme est l'analogue du th√©or√®me du rang en alg√®bre lin√©aire.

**Pi√®ges classiques :**
*   √âcrire ¬´ $\phi$ bijectif $\iff \ker \phi = \{e\}$ et $\text{Im}\phi = H$ ¬ª : c'est vrai, mais en pratique on oublie souvent la surjectivit√©.
*   Pour les groupes non ab√©liens, $\ker \phi$ est distingu√© mais tout sous-groupe distingu√© n'est pas n√©cessairement un noyau... (en fait si, par la projection canonique).

---

## FLASHCARD 115 ‚Äî Lemme 3 : Lemme de Gauss (arithm√©tique)

### RECTO
**Lemme de Gauss**

Soient $a, b, c \in \mathbb{Z}$.

**Question :** √ânoncer le lemme de Gauss.

### VERSO
**Hypoth√®ses :**
*   $a, b, c \in \mathbb{Z}$
*   $a \mid bc$
*   $\text{pgcd}(a, b) = 1$

**Conclusion :**
$$ a \mid c $$

**D√©monstration :**
Par B√©zout, $\exists u, v \in \mathbb{Z}, au + bv = 1$. Multiplier par $c$ : $acu + bcv = c$. Comme $a \mid acu$ et $a \mid bcv$ (car $a \mid bc$), on obtient $a \mid c$.

### 
**Subtilit√©s :**
*   Le lemme de Gauss se g√©n√©ralise aux anneaux principaux (polyn√¥mes, entiers de Gauss...).
*   L'hypoth√®se $\text{pgcd}(a, b) = 1$ est essentielle : $6 \mid 4 \times 3$ mais $6 \nmid 4$ et $6 \nmid 3$.

**Applications :**
*   Preuve de l'unicit√© de la d√©composition en facteurs premiers.
*   Crit√®re d'irr√©ductibilit√©.

**Pi√®ges classiques :**
*   Oublier de v√©rifier la coprimalit√©.

---

## FLASHCARD 116 ‚Äî Proposition 34 : Identit√© de B√©zout dans $\mathbb{Z}$

### RECTO
**Th√©or√®me de B√©zout (dans $\mathbb{Z}$)**

Soient $a, b \in \mathbb{Z}$ non tous deux nuls.

**Question :** √ânoncer le th√©or√®me de B√©zout (caract√©risation du PGCD via combinaisons lin√©aires).

### VERSO
**Hypoth√®ses :**
*   $a, b \in \mathbb{Z}, (a, b) \neq (0, 0)$
*   $d = \text{pgcd}(a, b)$

**Conclusion :**
$$ \exists (u, v) \in \mathbb{Z}^2, \quad au + bv = d $$

**Corollaire (B√©zout pour la coprimalit√©) :**
$$ \text{pgcd}(a, b) = 1 \iff \exists (u, v) \in \mathbb{Z}^2, au + bv = 1 $$

**D√©monstration :**
L'id√©al $a\mathbb{Z} + b\mathbb{Z} = \{au + bv : (u, v) \in \mathbb{Z}^2\}$ est un id√©al de $\mathbb{Z}$, donc principal : $a\mathbb{Z} + b\mathbb{Z} = d\mathbb{Z}$, o√π $d$ est le plus petit √©l√©ment strictement positif.

### 
**Subtilit√©s :**
*   Les coefficients de B√©zout $(u, v)$ ne sont pas uniques.
*   Le th√©or√®me est constructif via l'algorithme d'Euclide √©tendu.

**Pi√®ges classiques :**
*   Confondre ¬´ $d \mid a$ et $d \mid b$ ¬ª (d√©finition de diviseur commun) avec ¬´ $d = au + bv$ ¬ª (B√©zout) : le PGCD v√©rifie les deux.

---

## FLASHCARD 117 ‚Äî Proposition 35 : B√©zout dans $K[X]$

### RECTO
**Th√©or√®me de B√©zout dans $K[X]$**

Soient $A, B \in K[X]$, non tous deux nuls.

**Question :** √ânoncer le th√©or√®me de B√©zout dans $K[X]$.

### VERSO
**Hypoth√®ses :**
*   $K$ corps
*   $A, B \in K[X], (A, B) \neq (0, 0)$
*   $D = \text{pgcd}(A, B)$ (unitaire, par convention)

**Conclusion :**
$$ \exists (U, V) \in K[X]^2, \quad AU + BV = D $$

**Corollaire :**
$A$ et $B$ sont premiers entre eux si et seulement si $\exists (U, V) \in K[X]^2, AU + BV = 1$.

On peut de plus imposer $\deg U < \deg B$ et $\deg V < \deg A$ (unicit√© dans ce cas).

**D√©monstration :**
$K[X]$ est un anneau principal (euclidien), donc l'id√©al $(A) + (B)$ est principal, engendr√© par $D$.

### 
**Subtilit√©s :**
*   $K[X]$ est euclidien (pour le degr√©), donc principal, donc B√©zout y est valable.
*   Attention : $\mathbb{Z}[X]$ n'est pas principal, et B√©zout sous cette forme n'y est pas valable.

**Pi√®ges classiques :**
*   Oublier que le PGCD est d√©fini √† une constante multiplicative pr√®s, et que par convention on le prend unitaire.
*   Confondre les corps : sur $\mathbb{Q}[X]$, $\mathbb{R}[X]$, $\mathbb{C}[X]$, les PGCD peuvent diff√©rer si l'on change de corps.

---

## FLASHCARD 118 ‚Äî Th√©or√®me 49 : Division euclidienne dans $K[X]$

### RECTO
**Division euclidienne dans $K[X]$**

Soient $A, B \in K[X]$ avec $B \neq 0$.

**Question :** √ânoncer le th√©or√®me de division euclidienne.

### VERSO
**Hypoth√®ses :**
*   $K$ corps
*   $A \in K[X], B \in K[X] \setminus \{0\}$

**Conclusion :**
$$ \exists! (Q, R) \in K[X]^2, \quad A = BQ + R, \quad \deg R < \deg B $$
(avec la convention $\deg 0 = -\infty$)

**D√©monstration (esquisse) :**
Par r√©currence (forte) sur $\deg A$ :
*   Si $\deg A < \deg B$ : $Q=0, R=A$.
*   Sinon : poser $A_1 = A - \frac{a_n}{b_m} X^{n-m} B$ (le terme dominant de $A_1$ est de degr√© $< n$), puis appliquer l'hypoth√®se de r√©currence √† $A_1$.

### 
**Subtilit√©s :**
*   L'existence et l'unicit√© requi√®rent que $K$ soit un corps (ou au moins que le coefficient dominant de $B$ soit inversible). Sur $\mathbb{Z}[X]$, la division euclidienne n'est pas toujours possible.
*   La division euclidienne fait de $K[X]$ un anneau euclidien pour le stathme $\deg$.

**Pi√®ges classiques :**
*   Oublier la condition $\deg R < \deg B$ (et non $\le$).
*   Sur $\mathbb{Z}[X]$ : tenter de diviser alors que le coefficient dominant de $B$ n'est pas inversible.

---

## FLASHCARD 119 ‚Äî √Ä conna√Ætre 32 : Racines et factorisation

### RECTO
**Racines et factorisation dans $K[X]$**

Soit $P \in K[X]$ de degr√© $n \ge 1$.

**Question :** Rappeler le lien entre racines et divisibilit√©. Combien de racines $P$ peut-il avoir au maximum ?

### VERSO
**Propri√©t√© fondamentale :**
$\alpha \in K$ est racine de $P$ si et seulement si $(X - \alpha) \mid P$ dans $K[X]$.

**Nombre de racines :**
$P$ a au plus $\deg P$ racines dans $K$ (compt√©es avec multiplicit√©).

**Multiplicit√© :**
$\alpha$ est racine de multiplicit√© $m$ si $(X - \alpha)^m \mid P$ et $(X - \alpha)^{m+1} \nmid P$.

Si $P$ est scind√© sur $K$ :
$$ P = a \prod_{i=1}^r (X - \alpha_i)^{m_i}, \quad \sum m_i = \deg P $$

**Formules de Vi√®te :**
Les fonctions sym√©triques √©l√©mentaires des racines s'expriment en termes des coefficients de $P$.

### 
**Subtilit√©s :**
*   Le r√©sultat ¬´ au plus $\deg P$ racines ¬ª est valable sur un corps. Sur un anneau non int√®gre (ex : $\mathbb{Z}/6\mathbb{Z}$), c'est faux : $X^2 - 1$ a 4 racines dans $\mathbb{Z}/8\mathbb{Z}$.
*   En corollaire : si $P, Q \in K[X]$, $\deg P, \deg Q \le n$, et $P$ et $Q$ co√Øncident en $n+1$ points, alors $P=Q$.

**Pi√®ges classiques :**
*   Appliquer le r√©sultat sur un anneau non int√®gre.
*   Oublier le ¬´ compt√©es avec multiplicit√© ¬ª.

---

## FLASHCARD 120 ‚Äî √Ä conna√Ætre 33 : Irr√©ductibles de $\mathbb{R}[X]$ et $\mathbb{C}[X]$

### RECTO
**Polyn√¥mes irr√©ductibles de $\mathbb{R}[X]$ et $\mathbb{C}[X]$**

**Question :** D√©crire les polyn√¥mes irr√©ductibles sur $\mathbb{C}$ puis sur $\mathbb{R}$.

### VERSO
**Sur $\mathbb{C}[X]$ :**
Les irr√©ductibles sont exactement les polyn√¥mes de degr√© 1 : $aX + b$ avec $a \neq 0$.
(Cons√©quence du th√©or√®me de d'Alembert-Gauss.)

**Sur $\mathbb{R}[X]$ :**
Les irr√©ductibles sont :
*   Les polyn√¥mes de degr√© 1 : $aX + b, a \neq 0$.
*   Les polyn√¥mes de degr√© 2 √† discriminant strictement n√©gatif : $aX^2 + bX + c$ avec $a \neq 0$ et $b^2 - 4ac < 0$.

**Factorisation dans $\mathbb{R}[X]$ :**
Tout $P \in \mathbb{R}[X]$ de degr√© $\ge 1$ s'√©crit de mani√®re unique (√† l'ordre et aux constantes pr√®s) comme produit de polyn√¥mes de degr√© 1 et de polyn√¥mes de degr√© 2 √† discriminant n√©gatif.

### 
**Subtilit√©s :**
*   Les racines complexes non r√©elles de $P \in \mathbb{R}[X]$ viennent par paires conjugu√©es : si $\alpha$ est racine, $\bar{\alpha}$ aussi, avec la m√™me multiplicit√©. Le produit $(X-\alpha)(X-\bar{\alpha}) = X^2 - 2\text{Re}(\alpha)X + |\alpha|^2$ est le facteur irr√©ductible de degr√© 2.

**Pi√®ges classiques :**
*   Oublier qu'il n'y a pas d'irr√©ductible de degr√© $\ge 3$ sur $\mathbb{R}$ : tout polyn√¥me de degr√© impair $\ge 3$ a une racine r√©elle.
*   Confondre ¬´ irr√©ductible sur $\mathbb{R}$ ¬ª et ¬´ irr√©ductible sur $\mathbb{Q}$ ¬ª.

---

## FLASHCARD 121 ‚Äî Th√©or√®me 50 : Th√©or√®me de d'Alembert-Gauss

### RECTO
**Th√©or√®me de d'Alembert-Gauss (th√©or√®me fondamental de l'alg√®bre)**

**Question :** √ânoncer le th√©or√®me de d'Alembert-Gauss.

### VERSO
**√ânonc√© :**
Tout polyn√¥me $P \in \mathbb{C}[X]$ de degr√© $n \ge 1$ poss√®de exactement $n$ racines dans $\mathbb{C}$ (compt√©es avec multiplicit√©).

De mani√®re √©quivalente : $\mathbb{C}$ est alg√©briquement clos, i.e. tout polyn√¥me non constant √† coefficients complexes admet au moins une racine dans $\mathbb{C}$.

De mani√®re encore √©quivalente : tout $P \in \mathbb{C}[X]$ de degr√© $n \ge 1$ se factorise :
$$ P = a_n \prod_{i=1}^n (X - z_i), \quad z_i \in \mathbb{C} $$

**D√©monstration :** Admise en MP. (Les preuves connues utilisent l'analyse : topologie de $\mathbb{C}$, th√©orie de Liouville, ou l'argument du minimum du module.)

### 
**Subtilit√©s :**
*   $\mathbb{R}$ n'est pas alg√©briquement clos ($X^2 + 1$ n'a pas de racine r√©elle).
*   $\mathbb{Q}$ n'est pas alg√©briquement clos ($X^2 - 2$ n'a pas de racine rationnelle).
*   Le th√©or√®me ne donne pas de m√©thode pour calculer les racines (pas de formule g√©n√©rale en degr√© $\ge 5$, par Abel-Ruffini).

**Applications en alg√®bre lin√©aire :**
*   Tout endomorphisme d'un $\mathbb{C}$-espace vectoriel de dimension finie admet au moins une valeur propre.
*   Tout endomorphisme sur $\mathbb{C}$ est trigonalisable (car son polyn√¥me caract√©ristique est scind√©).

**Pi√®ges classiques :**
*   Oublier ¬´ compt√©es avec multiplicit√© ¬ª.
*   Croire que le th√©or√®me donne un algorithme de calcul.

---

## FLASHCARD 122 ‚Äî Proposition 36 : Caract√©risation de la multiplicit√© d'une racine

### RECTO
**Caract√©risation de la multiplicit√© d'une racine par les d√©riv√©es**

Soit $P \in K[X]$ et $\alpha \in K$.

**Question :** Caract√©riser la multiplicit√© de $\alpha$ comme racine de $P$ en termes des d√©riv√©es successives de $P$.

### VERSO
**Hypoth√®ses :**
*   $K$ corps de caract√©ristique z√©ro (en pratique $\mathbb{Q}, \mathbb{R}$ ou $\mathbb{C}$)
*   $P \in K[X], \alpha \in K, m \ge 1$

**Conclusion :**
$\alpha$ est racine de multiplicit√© au moins $m$ de $P$ si et seulement si :
$$ P(\alpha) = P'(\alpha) = P''(\alpha) = \dots = P^{(m-1)}(\alpha) = 0 $$

$\alpha$ est racine de multiplicit√© exactement $m$ si de plus $P^{(m)}(\alpha) \neq 0$.

**D√©monstration (esquisse) :**
√âcrire $P(X) = (X - \alpha)^k Q(X)$ avec $Q(\alpha) \neq 0$. Par la formule de Leibniz :
$$ P^{(j)}(\alpha) = j! \binom{k}{j} Q(\alpha) \cdot [\text{si } j < k, \text{ alors } 0; \text{ si } j=k, \text{ alors } k! Q(\alpha)] $$
Plus rigoureusement, par la formule de Taylor pour les polyn√¥mes : $P(X) = \sum_{j=0}^n \frac{P^{(j)}(\alpha)}{j!} (X - \alpha)^j$.

### 
**Subtilit√©s :**
*   L'hypoth√®se de caract√©ristique z√©ro est cruciale. En caract√©ristique $p$, $P(X) = X^p$ a $0$ comme racine de multiplicit√© $p$ mais $P'(X) = 0$ identiquement.
*   La formule de Taylor pour les polyn√¥mes est purement alg√©brique (pas de convergence √† v√©rifier) et valide en toute caract√©ristique, mais la division par $j!$ requiert la caract√©ristique z√©ro.

**Pi√®ges classiques :**
*   Oublier de v√©rifier la caract√©ristique du corps (peu probable en MP, mais important conceptuellement).
*   Confondre ¬´ $P^{(m)}(\alpha) = 0$ ¬ª avec ¬´ $\alpha$ est racine de $P^{(m)}$ de multiplicit√© $\ge 1$ ¬ª.

---

## FLASHCARD 123 ‚Äî √Ä conna√Ætre 34 : Crit√®re de divisibilit√© (Eisenstein, ou autres)

### RECTO
**Crit√®re d'irr√©ductibilit√© d'Eisenstein**

Soit $P = a_n X^n + \dots + a_1 X + a_0 \in \mathbb{Z}[X]$.

**Question :** √ânoncer le crit√®re d'Eisenstein. Quand permet-il de conclure √† l'irr√©ductibilit√© sur $\mathbb{Q}$ ?

### VERSO
**Hypoth√®ses :**
*   $P = a_n X^n + a_{n-1} X^{n-1} + \dots + a_0 \in \mathbb{Z}[X], n \ge 1$
*   Il existe un nombre premier $p$ tel que :
    *   $p \nmid a_n$ (le coefficient dominant n'est pas divisible par $p$)
    *   $p \mid a_i$ pour tout $i \in \{0, 1, \dots, n-1\}$
    *   $p^2 \nmid a_0$

**Conclusion :**
$P$ est irr√©ductible dans $\mathbb{Q}[X]$ (et donc dans $\mathbb{Z}[X]$ par le lemme de Gauss sur le contenu).

**D√©monstration (esquisse) :**
Supposer $P = QR$ dans $\mathbb{Z}[X]$ avec $\deg Q, \deg R \ge 1$. R√©duire modulo $p$ : $\bar{P} = \bar{a}_n X^n$ dans $\mathbb{F}_p[X]$, donc $\bar{Q} = \bar{b}_s X^s$ et $\bar{R} = \bar{c}_r X^r$ (car $\mathbb{F}_p[X]$ est int√®gre). Cela force $p \mid q_0$ et $p \mid r_0$, donc $p^2 \mid a_0 = q_0 r_0$, contradiction avec l'hypoth√®se 3.

### 
**Subtilit√©s :**
*   Eisenstein ne s'applique pas directement √† tout polyn√¥me. Parfois un changement de variable $X \leftarrow X+a$ rend le crit√®re applicable (exemple classique : les polyn√¥mes cyclotomiques $\Phi_p(X) = \frac{X^p-1}{X-1}$, irr√©ductibles via le changement $X \leftarrow X+1$).
*   Le lemme de Gauss (contenu) assure qu'un polyn√¥me primitif de $\mathbb{Z}[X]$ irr√©ductible dans $\mathbb{Z}[X]$ l'est dans $\mathbb{Q}[X]$.

**Applications classiques :**
*   $X^n - p$ est irr√©ductible sur $\mathbb{Q}$ (Eisenstein avec $p$).
*   Polyn√¥mes cyclotomiques $\Phi_p$.

**Pi√®ges classiques :**
*   V√©rifier les trois conditions. Oublier $p^2 \nmid a_0$ est l'erreur la plus fr√©quente.
*   Eisenstein donne l'irr√©ductibilit√© sur $\mathbb{Q}$, pas n√©cessairement sur $\mathbb{R}$ ou $\mathbb{C}$.

---

## FLASHCARD 124 ‚Äî √Ä conna√Ætre 35 : Relations coefficients-racines (Vi√®te)

### RECTO
**Formules de Vi√®te (relations coefficients-racines)**

Soit $P = a_n X^n + a_{n-1} X^{n-1} + \dots + a_0 \in K[X]$ scind√© sur $K$, de racines $\alpha_1, \dots, \alpha_n$ (compt√©es avec multiplicit√©).

**Question :** Exprimer les fonctions sym√©triques √©l√©mentaires des racines en fonction des coefficients.

### VERSO
**Hypoth√®ses :**
*   $P = a_n (X - \alpha_1)(X - \alpha_2) \dots (X - \alpha_n)$

**Formules de Vi√®te :**
$$ \sigma_k := \sum_{1 \le i_1 < \dots < i_k \le n} \alpha_{i_1} \dots \alpha_{i_k} = (-1)^k \frac{a_{n-k}}{a_n} $$

En particulier :
*   $\alpha_1 + \dots + \alpha_n = -\frac{a_{n-1}}{a_n}$
*   $\sum_{i < j} \alpha_i \alpha_j = \frac{a_{n-2}}{a_n}$
*   $\alpha_1 \dots \alpha_n = (-1)^n \frac{a_0}{a_n}$

### 
**Subtilit√©s :**
*   Les formules de Vi√®te ne n√©cessitent pas de conna√Ætre les racines individuellement.
*   Les formules de Newton relient les sommes de puissances $p_k = \sum \alpha_i^k$ aux $\sigma_k$.
*   Vi√®te est valable sur tout corps (pas besoin de caract√©ristique z√©ro).

**Pi√®ges classiques :**
*   Oublier le facteur $(-1)^k$ ou la normalisation par $a_n$.
*   Appliquer Vi√®te √† un polyn√¥me non scind√© (les racines n'existent pas toutes dans $K$).

---

## FLASHCARD 125 ‚Äî Proposition 37 : Polyn√¥me d√©riv√© et racines multiples

### RECTO
**Polyn√¥me d√©riv√© et racines multiples ‚Äî polyn√¥me sans racine multiple**

Soit $P \in K[X]$, $K$ de caract√©ristique z√©ro.

**Question :** Caract√©riser le fait que $P$ n'a que des racines simples (dans une cl√¥ture alg√©brique) en termes de $\text{pgcd}(P, P')$.

### VERSO
**Hypoth√®ses :**
*   $K$ corps de caract√©ristique z√©ro
*   $P \in K[X], \deg P \ge 1$

**Conclusion :**
$P$ n'a que des racines simples (dans $\bar{K}$) si et seulement si :
$$ \text{pgcd}(P, P') = 1 $$

Plus g√©n√©ralement : les racines multiples de $P$ sont exactement les racines communes √† $P$ et $P'$.

Si $P = \prod (X - \alpha_i)^{m_i}$, alors $\text{pgcd}(P, P') = \prod (X - \alpha_i)^{m_i - 1}$ (√† une constante pr√®s).

Le polyn√¥me s√©parable associ√© $P/\text{pgcd}(P, P')$ a les m√™mes racines que $P$, toutes simples.

### 
**Subtilit√©s :**
*   En caract√©ristique $p$, $P' = 0$ n'implique pas $P$ constant (ex : $P = X^p$). La caract√©risation par le PGCD reste valable mais le calcul de $P'$ change.
*   Le calcul de $\text{pgcd}(P, P')$ se fait par l'algorithme d'Euclide, sans avoir besoin de factoriser $P$.

**Pi√®ges classiques :**
*   √âcrire $P' = 0 \implies P$ constant (faux en caract√©ristique $p > 0$, vrai en caract√©ristique z√©ro).
*   Oublier que le PGCD est d√©fini √† une constante multiplicative pr√®s.

---

## FLASHCARD 126 ‚Äî Proposition 38 : Interpolation de Lagrange

### RECTO
**Interpolation de Lagrange**

Soient $x_0, \dots, x_n \in K$ deux √† deux distincts, et $y_0, \dots, y_n \in K$.

**Question :** √ânoncer le th√©or√®me d'interpolation de Lagrange (existence, unicit√©, formule explicite).

### VERSO
**Hypoth√®ses :**
*   $K$ corps
*   $x_0, \dots, x_n \in K$ deux √† deux distincts
*   $y_0, \dots, y_n \in K$

**Conclusion :**
Il existe un unique polyn√¥me $P \in K_n[X]$ (de degr√© $\le n$) tel que :
$$ \forall i \in \{0, \dots, n\}, \quad P(x_i) = y_i $$

**Formule explicite :**
$$ P(X) = \sum_{i=0}^n y_i \prod_{j \neq i} \frac{X - x_j}{x_i - x_j} $$

Les polyn√¥mes de base de Lagrange sont :
$$ L_i(X) = \prod_{j \neq i} \frac{X - x_j}{x_i - x_j}, \quad L_i(x_j) = \delta_{ij} $$

**D√©monstration :**
*   **Unicit√© :** si $P$ et $Q$ conviennent, $P-Q$ est de degr√© $\le n$ et s'annule en $n+1$ points, donc $P-Q=0$.
*   **Existence :** la formule de Lagrange donne explicitement un $P$ de degr√© $\le n$ v√©rifiant les conditions.

**Interpr√©tation lin√©aire :**
L'application ¬´ √©valuation ¬ª $ev : K_n[X] \to K^{n+1}, P \mapsto (P(x_0), \dots, P(x_n))$ est un isomorphisme (les deux espaces sont de dimension $n+1$, et $ev$ est injective par l'argument d'unicit√©).

### 
**Subtilit√©s :**
*   Les $L_i$ forment une base de $K_n[X]$, appel√©e base de Lagrange associ√©e aux n≈ìuds $x_0, \dots, x_n$.
*   La formule est valable sur tout corps, et m√™me sur tout anneau int√®gre (avec $n+1$ √©l√©ments distincts).
*   La matrice de Vandermonde $V = (x_i^j)_{0 \le i, j \le n}$ est inversible $\iff$ les $x_j$ sont distincts, et l'interpolation revient √† inverser ce syst√®me.

**Pi√®ges classiques :**
*   Confondre degr√© $\le n$ et degr√© $= n$ : le polyn√¥me interpolateur peut √™tre de degr√© strictement inf√©rieur √† $n$.
*   Oublier la condition ¬´ deux √† deux distincts ¬ª.

---

## FLASHCARD 127 ‚Äî √Ä conna√Ætre 36 : Polyn√¥mes de Tchebychev

### RECTO
**Polyn√¥mes de Tchebychev**

**Question :** D√©finir les polyn√¥mes de Tchebychev de premi√®re esp√®ce $T_n$. Donner leurs propri√©t√©s fondamentales (relation de r√©currence, racines, propri√©t√© de minimax).

### VERSO
**D√©finition :**
Le polyn√¥me de Tchebychev de premi√®re esp√®ce $T_n$ est l'unique polyn√¥me de degr√© $n$ tel que :
$$ \forall \theta \in \mathbb{R}, \quad T_n(\cos \theta) = \cos(n\theta) $$

**Relation de r√©currence :**
$$ T_0(X) = 1, \quad T_1(X) = X, \quad T_{n+1}(X) = 2X T_n(X) - T_{n-1}(X) $$

**Propri√©t√©s :**
*   $T_n$ est de degr√© $n$, de coefficient dominant $2^{n-1}$ (pour $n \ge 1$).
*   **Racines :** $T_n$ a $n$ racines r√©elles simples dans $[-1, 1]$ :
    $$ x_k = \cos \left( \frac{(2k-1)\pi}{2n} \right), \quad k=1, \dots, n $$
*   $|T_n(x)| \le 1$ pour tout $x \in [-1, 1]$.
*   **Propri√©t√© de minimax :** Parmi tous les polyn√¥mes unitaires de degr√© $n$, $\frac{T_n}{2^{n-1}}$ est celui dont la norme $\|\cdot\|_\infty$ sur $[-1, 1]$ est minimale, et ce minimum vaut $\frac{1}{2^{n-1}}$.

**Orthogonalit√© :**
Les $T_n$ sont orthogonaux pour le produit scalaire :
$$ \langle f, g \rangle = \int_{-1}^1 \frac{f(x)g(x)}{\sqrt{1-x^2}} dx $$

### 
**Subtilit√©s :**
*   La propri√©t√© de minimax est fondamentale en approximation num√©rique (choix optimal des n≈ìuds d'interpolation pour minimiser l'erreur : n≈ìuds de Tchebychev).
*   Les polyn√¥mes de Tchebychev de seconde esp√®ce $U_n$ v√©rifient $U_n(\cos \theta) = \frac{\sin((n+1)\theta)}{\sin \theta}$.

**Pi√®ges classiques :**
*   Confondre $T_n$ et $U_n$.
*   Oublier le coefficient dominant $2^{n-1}$ : $T_n$ n'est pas unitaire pour $n \ge 2$.

---

# CHAPITRE 11 ‚Äî Alg√®bre lin√©aire

## FLASHCARD 128 ‚Äî √Ä conna√Ætre 37 : Lemme de Gauss (alg√®bre lin√©aire ‚Äî pivot de Gauss)

### RECTO
**Algorithme du pivot de Gauss**

**Question :** √ânoncer le principe de l'√©limination de Gauss. Quels probl√®mes r√©sout-il ?

### VERSO
**Principe :**
Toute matrice $A \in M_{n, p}(K)$ peut √™tre r√©duite par op√©rations √©l√©mentaires sur les lignes (et/ou les colonnes) √† une forme √©chelonn√©e en lignes (ou √©chelonn√©e r√©duite, sous forme de Gauss-Jordan).

**Op√©rations √©l√©mentaires sur les lignes :**
*   $L_i \leftrightarrow L_j$ (√©change de deux lignes)
*   $L_i \leftarrow \lambda L_i$, $\lambda \neq 0$ (multiplication d'une ligne par un scalaire non nul)
*   $L_i \leftarrow L_i + \mu L_j$, $i \neq j$ (transvection : ajouter un multiple d'une ligne √† une autre)

**Applications :**
*   Calcul du rang d'une matrice
*   R√©solution de syst√®mes lin√©aires $AX = B$
*   Calcul de l'inverse d'une matrice (m√©thode $[A \mid I_n] \to [I_n \mid A^{-1}]$)
*   Calcul du d√©terminant

**Complexit√© :** $O(n^3)$ op√©rations pour une matrice $n \times n$.

### 
**Subtilit√©s :**
*   Les op√©rations sur les lignes correspondent √† la multiplication √† gauche par des matrices inversibles (transvections, dilatations, permutations).
*   Les op√©rations sur les colonnes correspondent √† la multiplication √† droite.
*   La forme √©chelonn√©e r√©duite (Gauss-Jordan) est unique ; la forme √©chelonn√©e non r√©duite ne l'est pas.

**Pi√®ges classiques :**
*   M√©langer op√©rations sur les lignes et sur les colonnes dans un m√™me calcul (sauf si on cherche des matrices $P, Q$ telles que $PAQ$ soit sous forme canonique).
*   Oublier qu'une multiplication par $\lambda = 0$ n'est pas une op√©ration √©l√©mentaire valide.

---

## FLASHCARD 129 ‚Äî √Ä conna√Ætre 38 : Caract√©risation des homoth√©ties

### RECTO
**Caract√©risation des homoth√©ties**

Soit $E$ un $K$-espace vectoriel et $u \in \mathcal{L}(E)$.

**Question :** Caract√©riser les endomorphismes qui commutent avec tous les endomorphismes de $E$ (ou qui stabilisent tout sous-espace vectoriel).

### VERSO
**Th√©or√®me :**
Soit $E$ un $K$-espace vectoriel de dimension $n \ge 1$.

Les assertions suivantes sont √©quivalentes :
1.  $u$ est une homoth√©tie : $\exists \lambda \in K, u = \lambda Id_E$.
2.  $u$ commute avec tout endomorphisme de $E$ : $\forall v \in \mathcal{L}(E), u \circ v = v \circ u$.
3.  Tout sous-espace vectoriel de $E$ est stable par $u$.

**En termes matriciels :**
$M \in M_n(K)$ commute avec toute matrice si et seulement si $M = \lambda I_n$.

**D√©monstration (esquisse de 2 $\Rightarrow$ 1) :**
Pour $v$ un projecteur sur une droite $Ke_i$, $u \circ v = v \circ u$ implique que $u(e_i) \in Ke_i$, donc les vecteurs de la base sont des vecteurs propres de $u$. En prenant $v$ une transvection, on montre que les valeurs propres sont toutes √©gales.

### 
**Subtilit√©s :**
*   En dimension infinie, 2 $\Rightarrow$ 1 reste vrai, mais 3 $\Rightarrow$ 1 peut √™tre plus d√©licat √† √©tablir.
*   La condition ¬´ commute avec tout endomorphisme ¬ª peut √™tre remplac√©e par ¬´ commute avec tout √©l√©ment d'un sous-ensemble engendrant $\mathcal{L}(E)$ comme alg√®bre ¬ª.

**Pi√®ges classiques :**
*   Confondre ¬´ commute avec une matrice particuli√®re ¬ª et ¬´ commute avec toute matrice ¬ª. Le commutant d'une matrice quelconque peut √™tre bien plus grand que les homoth√©ties.

---

## FLASHCARD 130 ‚Äî Th√©or√®me 51 : Th√©or√®me de la base incompl√®te

### RECTO
**Th√©or√®me de la base incompl√®te**

Soit $E$ un $K$-espace vectoriel de dimension finie $n$.

**Question :** √ânoncer le th√©or√®me de la base incompl√®te (deux versions : compl√©ter une famille libre, extraire d'une famille g√©n√©ratrice).

### VERSO
**Version 1 (compl√©ter une famille libre) :**
*   Soit $(e_1, \dots, e_p)$ une famille libre de $E$ avec $p \le n$.
*   Alors on peut trouver $e_{p+1}, \dots, e_n \in E$ tels que $(e_1, \dots, e_n)$ soit une base de $E$.
*   De plus, si $(f_1, \dots, f_m)$ est une famille g√©n√©ratrice de $E$, on peut choisir les $e_{p+1}, \dots, e_n$ parmi les $f_j$.

**Version 2 (extraire d'une famille g√©n√©ratrice) :**
*   Soit $(f_1, \dots, f_m)$ une famille g√©n√©ratrice de $E$ avec $m \ge n$.
*   Alors on peut en extraire une base de $E$ (sous-famille de $n$ √©l√©ments).

**D√©monstration (esquisse) :**
Algorithme glouton : on ajoute des vecteurs un par un en v√©rifiant qu'ils restent en dehors du sous-espace engendr√© par les pr√©c√©dents.

### 
**Subtilit√©s :**
*   Le th√©or√®me est faux en dimension infinie en g√©n√©ral (il faut l'axiome du choix / le lemme de Zorn pour l'existence de bases, via le th√©or√®me de la base de Zorn).
*   La version ¬´ on peut choisir les compl√©mentaires parmi une famille g√©n√©ratrice donn√©e ¬ª est plus forte et tr√®s utile.

**Pi√®ges classiques :**
*   Croire que le compl√©ment est unique : il ne l'est pas.
*   En dimension infinie, ne pas invoquer aveugl√©ment le th√©or√®me de la base incompl√®te.

---

## FLASHCARD 131 ‚Äî Proposition 39 : Formule de Grassmann

### RECTO
**Formule de Grassmann (dimension de la somme de deux sous-espaces)**

Soient $F$ et $G$ deux sous-espaces vectoriels d'un espace $E$ de dimension finie.

**Question :** √ânoncer la formule de Grassmann.

### VERSO
**Hypoth√®ses :**
*   $E$ espace vectoriel de dimension finie sur $K$
*   $F, G$ sous-espaces de $E$

**Formule :**
$$ \dim(F+G) = \dim F + \dim G - \dim(F \cap G) $$

**D√©monstration (esquisse) :**
Choisir une base de $F \cap G$, la compl√©ter en une base de $F$ et une base de $G$ (th√©or√®me de la base incompl√®te). Les r√©unions forment une famille g√©n√©ratrice de $F+G$, et on v√©rifie qu'elle est libre.

**Corollaire (somme directe) :**
$F+G$ est directe ($F \oplus G$) si et seulement si $F \cap G = \{0\}$, et dans ce cas $\dim(F \oplus G) = \dim F + \dim G$.

$F$ et $G$ sont suppl√©mentaires dans $E$ si $E = F \oplus G$, i.e. $F \cap G = \{0\}$ et $\dim F + \dim G = \dim E$.

### 
**Subtilit√©s :**
*   La formule est l'analogue vectoriel de la formule $|A \cup B| = |A| + |B| - |A \cap B|$ pour les ensembles finis.
*   Elle se g√©n√©ralise √† $k$ sous-espaces via la formule du crible, mais c'est rarement utilis√© (les intersections deviennent compliqu√©es).

**Pi√®ges classiques :**
*   Appliquer la formule en oubliant l'intersection : √©crire $\dim(F+G) = \dim F + \dim G$ sans v√©rifier que $F \cap G = \{0\}$.
*   Confondre $F+G$ (somme de sous-espaces) et $F \cup G$ (qui n'est en g√©n√©ral pas un sous-espace).

---

## FLASHCARD 132 ‚Äî Proposition 40 : Existence de suppl√©mentaires

### RECTO
**Existence de suppl√©mentaires**

Soit $E$ un $K$-espace vectoriel de dimension finie et $F$ un sous-espace de $E$.

**Question :** √ânoncer le th√©or√®me d'existence d'un suppl√©mentaire.

### VERSO
**Hypoth√®ses :**
*   $E$ espace vectoriel de dimension finie $n$ sur $K$
*   $F$ sous-espace de $E$

**Conclusion :**
Il existe un sous-espace $G$ de $E$ tel que $E = F \oplus G$.

On a alors $\dim G = \dim E - \dim F$.

**D√©monstration :**
Choisir une base $(e_1, \dots, e_p)$ de $F$, la compl√©ter en une base $(e_1, \dots, e_n)$ de $E$. Poser $G = \text{Vect}(e_{p+1}, \dots, e_n)$.

### 
**Subtilit√©s :**
*   Le suppl√©mentaire n'est pas unique (sauf si $F=\{0\}$ ou $F=E$).
*   En dimension infinie, un sous-espace ferm√© d'un espace de Hilbert admet un suppl√©mentaire orthogonal (unique). Mais un sous-espace quelconque d'un evn de dimension infinie n'admet pas toujours de suppl√©mentaire topologique.

**Pi√®ges classiques :**
*   Croire que le suppl√©mentaire est canonique ou unique.
*   Confondre suppl√©mentaire alg√©brique et suppl√©mentaire topologique en dimension infinie.

---

## FLASHCARD 133 ‚Äî Th√©or√®me 52 : Th√©or√®me du rang

### RECTO
**Th√©or√®me du rang**

Soit $f : E \to F$ une application lin√©aire entre espaces vectoriels de dimension finie.

**Question :** √ânoncer le th√©or√®me du rang.

### VERSO
**Hypoth√®ses :**
*   $E, F$ espaces vectoriels sur $K$, $\dim E = n$ finie
*   $f \in \mathcal{L}(E, F)$

**Conclusion :**
$$ \dim E = \dim \ker f + \dim \text{Im} f = \dim \ker f + \text{rg } f $$

Autrement dit : $n = \dim \ker f + \text{rg } f$.

**D√©monstration (esquisse) :**
Choisir une base $(e_1, \dots, e_p)$ de $\ker f$, la compl√©ter en une base $(e_1, \dots, e_n)$ de $E$. Montrer que $(f(e_{p+1}), \dots, f(e_n))$ est une base de $\text{Im} f$. Donc $\text{rg } f = n - p$.

### 
**Subtilit√©s :**
*   Le th√©or√®me n√©cessite que $\dim E$ soit finie. $\dim F$ peut √™tre quelconque.
*   En termes matriciels : pour $A \in M_{m, n}(K)$, $\text{rg } A + \dim \ker A = n$ (nombre de colonnes).

**Corollaires :**
*   $f$ injective $\iff \ker f = \{0\} \iff \text{rg } f = \dim E$.
*   Si $\dim E = \dim F$ (dimension finie), alors : $f$ injective $\iff f$ surjective $\iff f$ bijective.
*   Existence de bases dans lesquelles la matrice de $f$ est $\begin{pmatrix} I_r & 0 \\ 0 & 0 \end{pmatrix}$ avec $r = \text{rg } f$.

**Pi√®ges classiques :**
*   Appliquer le th√©or√®me du rang en prenant la dimension de $F$ au lieu de celle de $E$.
*   Oublier que le th√©or√®me du rang donne le lien entre noyau et image, pas entre noyau et conoyau.

---

## FLASHCARD 134 ‚Äî √Ä conna√Ætre 39 : Rang d'une compos√©e

### RECTO
**Rang d'une compos√©e**

Soient $f : E \to F$ et $g : F \to G$ lin√©aires, avec $E, F, G$ de dimension finie.

**Question :** Donner les in√©galit√©s reliant $\text{rg}(g \circ f)$, $\text{rg } f$ et $\text{rg } g$.

### VERSO
**In√©galit√©s :**

$$ \text{rg}(g \circ f) \le \min(\text{rg } f, \text{rg } g) $$

**In√©galit√© de Sylvester (pour les endomorphismes ou les matrices) :**
Si $A \in M_{m, n}(K)$ et $B \in M_{n, p}(K)$ :
$$ \text{rg}(AB) \ge \text{rg } A + \text{rg } B - n $$

En particulier pour $f : E \to F$ et $g : F \to G$ :
$$ \text{rg}(g \circ f) \ge \text{rg } f + \text{rg } g - \dim F $$

*   Si $g$ est surjective : $\text{rg}(g \circ f) = \text{rg } f - \dim(\ker g \cap \text{Im } f)$.
*   Si $f$ est injective : $\text{rg}(g \circ f) = \text{rg}(g|_{\text{Im } f})$.

**D√©monstration de 1 :**
$\text{Im}(g \circ f) = g(\text{Im } f) \subset \text{Im } g$, donc $\text{rg}(g \circ f) \le \text{rg } g$.
$\text{Im}(g \circ f) = g(f(E))$ et $g|_{\text{Im } f}$ est une application lin√©aire de $\text{Im } f$ dans $G$, donc par le th√©or√®me du rang, $\dim g(\text{Im } f) \le \dim \text{Im } f = \text{rg } f$.

### 
**Subtilit√©s :**
*   L'in√©galit√© de Sylvester est souvent utilis√©e sous la forme : si $A, B \in M_n(K)$, $\text{rg}(AB) \ge \text{rg } A + \text{rg } B - n$. Si le membre de droite est $\ge n$, alors $AB$ est inversible.
*   Cas d'√©galit√© dans l'in√©galit√© sup√©rieure : $\text{rg}(g \circ f) = \text{rg } f$ ssi $\ker g \cap \text{Im } f = \{0\}$.

**Pi√®ges classiques :**
*   √âcrire $\text{rg}(AB) = \text{rg } A \cdot \text{rg } B$ (faux !).
*   Oublier la dimension de l'espace interm√©diaire $F$ dans l'in√©galit√© de Sylvester.

---

## FLASHCARD 135 ‚Äî Proposition 41 : Rang d'une matrice

### RECTO
**Rang d'une matrice**

Soit $A \in M_{m, n}(K)$.

**Question :** Donner les diff√©rentes caract√©risations du rang de $A$.

### VERSO
**D√©finition :**
$\text{rg}(A) = \text{rg}(f_A)$ o√π $f_A : K^n \to K^m, X \mapsto AX$.

**Caract√©risations √©quivalentes :**
*   $\text{rg}(A) = \dim \text{Im}(f_A) = $ dimension de l'espace vectoriel engendr√© par les colonnes de $A$.
*   $\text{rg}(A) = $ dimension de l'espace vectoriel engendr√© par les lignes de $A$ (rang ligne = rang colonne).
*   $\text{rg}(A) = $ taille du plus grand mineur non nul de $A$ (sous-matrice carr√©e de d√©terminant non nul).
*   $\text{rg}(A) = n - \dim \ker(f_A)$ (th√©or√®me du rang).
*   $\text{rg}(A) = r$ ssi il existe $P \in GL_m(K), Q \in GL_n(K)$ tels que $PAQ = \begin{pmatrix} I_r & 0 \\ 0 & 0 \end{pmatrix}$.

**Invariance par op√©rations √©l√©mentaires :**
$\text{rg}(PAQ) = \text{rg}(A)$ pour $P, Q$ inversibles. Le rang est invariant par pivot de Gauss (sur les lignes ou les colonnes).

### 
**Subtilit√©s :**
*   $\text{rg}(A) = \text{rg}({}^t A)$ (rang ligne = rang colonne). C'est un r√©sultat non trivial.
*   $\text{rg}(A) = \text{rg}({}^t A A)$ (utile avec les matrices de Gram).

**Pi√®ges classiques :**
*   Confondre rang de $A$ et rang de $A^2$ (ils peuvent diff√©rer).
*   Croire que le pivot de Gauss modifie le rang.

---

## FLASHCARD 136 ‚Äî √Ä conna√Ætre 40 : Matrice √† diagonale strictement dominante (Hadamard)

### RECTO
**Lemme d'Hadamard (matrices √† diagonale strictement dominante)**

Soit $A = (a_{ij}) \in M_n(K)$.

**Question :** Sous quelle condition de dominance diagonale la matrice $A$ est-elle inversible ?

### VERSO
**Hypoth√®ses :**
$A = (a_{ij}) \in M_n(\mathbb{C})$ (ou $\mathbb{R}$) est √† diagonale strictement dominante (par lignes) :
$$ \forall i \in \{1, \dots, n\}, \quad |a_{ii}| > \sum_{j \neq i} |a_{ij}| $$

**Conclusion :**
$A$ est inversible.

**D√©monstration (esquisse) :**
Supposer $AX = 0$ avec $X \neq 0$. Soit $i_0$ l'indice tel que $|x_{i_0}| = \max_i |x_i| > 0$.
De la ligne $i_0$ : $a_{i_0 i_0} x_{i_0} = - \sum_{j \neq i_0} a_{i_0 j} x_j$.
En module : $|a_{i_0 i_0}| \cdot |x_{i_0}| \le \sum_{j \neq i_0} |a_{i_0 j}| \cdot |x_j| \le |x_{i_0}| \sum_{j \neq i_0} |a_{i_0 j}|$.
D'o√π $|a_{i_0 i_0}| \le \sum_{j \neq i_0} |a_{i_0 j}|$, contradiction.

### 
**Subtilit√©s :**
*   On peut aussi d√©finir la dominance diagonale par colonnes : $|a_{jj}| > \sum_{i \neq j} |a_{ij}|$. Le r√©sultat reste vrai (appliquer le th√©or√®me √† ${}^t A$).
*   Plus g√©n√©ralement, les valeurs propres de $A$ sont localis√©es dans les **disques de Gershgorin** : $\lambda \in \bigcup_{i=1}^n D(a_{ii}, R_i)$ avec $R_i = \sum_{j \neq i} |a_{ij}|$. La dominance diagonale assure que $0$ n'est dans aucun disque.

**Pi√®ges classiques :**
*   Oublier le ¬´ strictement ¬ª : la dominance diagonale large ne suffit pas en g√©n√©ral (il faut l'irr√©ductibilit√© en plus).
*   Appliquer le crit√®re en oubliant les valeurs absolues.

---

## FLASHCARD 137 ‚Äî Proposition 42 : Matrice de Vandermonde

### RECTO
**D√©terminant de Vandermonde**

Soient $x_0, \dots, x_{n-1} \in K$.

**Question :** Calculer le d√©terminant de la matrice de Vandermonde $V = (x_i^j)_{0 \le i, j \le n-1}$.

### VERSO
**Matrice de Vandermonde :**
$$ V = \begin{pmatrix} 1 & x_0 & x_0^2 & \dots & x_0^{n-1} \\ 1 & x_1 & x_1^2 & \dots & x_1^{n-1} \\ \vdots & \vdots & \vdots & & \vdots \\ 1 & x_{n-1} & x_{n-1}^2 & \dots & x_{n-1}^{n-1} \end{pmatrix} $$

**Formule :**
$$ \det V = \prod_{0 \le i < j \le n-1} (x_j - x_i) $$

**Corollaire :**
$V$ est inversible si et seulement si les $x_i$ sont deux √† deux distincts.

**D√©monstration (esquisse) :**
*   Voir $\det V$ comme un polyn√¥me en $x_{n-1}$ (de degr√© $n-1$) : ses racines sont $x_0, \dots, x_{n-2}$.
*   Donc $\det V = c \prod_{j=0}^{n-2} (x_{n-1} - x_j)$, o√π $c$ est le cofacteur (qui est le Vandermonde d'ordre $n-1$).
*   Conclure par r√©currence.

### 
**Subtilit√©s :**
*   La formule est valable sur tout anneau commutatif (et a fortiori sur tout corps).
*   Le lien avec l'interpolation de Lagrange : la matrice de Vandermonde est la matrice de passage de la base canonique $(1, X, \dots, X^{n-1})$ √† la base d'√©valuation $(e_0, \dots, e_{n-1})$ (fonctionnelles d'√©valuation aux points $x_i$).

**Pi√®ges classiques :**
*   Se tromper dans l'ordre des indices : $x_j - x_i$ avec $i < j$ (et non $x_i - x_j$).
*   Il y a $\binom{n}{2}$ facteurs dans le produit.
*   Confondre la transpos√©e de la matrice de Vandermonde (les deux conventions existent).

---

## FLASHCARD 138 ‚Äî √Ä conna√Ætre 41 : Transvections

### RECTO
**√Ä conna√Ætre 41 : Transvections**

Soit $E$ un $K$-espace vectoriel de dimension finie $n$, et $B$ une base de $E$.

**Question :** D√©finir une transvection, donner sa matrice dans une base, et √©noncer ses propri√©t√©s fondamentales (d√©terminant, inversibilit√©, lien avec les op√©rations √©l√©mentaires).

### VERSO
**Hypoth√®ses / Contexte**
*   $K$ un corps (en pratique $\mathbb{R}$ ou $\mathbb{C}$)
*   $E$ un $K$-ev de dimension $n \ge 1$
*   $B = (e_1, \dots, e_n)$ base de $E$
*   $i \neq j \in [[1, n]], \lambda \in K$

**D√©finition formelle**
La transvection $T_{ij}(\lambda)$ est l'endomorphisme de $E$ d√©fini par :
$$ T_{ij}(\lambda)(e_k) = \begin{cases} e_k + \lambda e_i & \text{si } k=j \\ e_k & \text{si } k \neq j \end{cases} $$

Sa matrice dans $B$ est $I_n + \lambda E_{ij}$, o√π $E_{ij}$ est la matrice √©l√©mentaire avec un $1$ en position $(i, j)$ et des $0$ ailleurs :
$$ \text{Mat}_B(T_{ij}(\lambda)) = \begin{pmatrix} 1 & & \lambda & \\ & 1 & & \\ & & 1 & \\ & & & 1 \end{pmatrix} $$
(la colonne $j$ voit appara√Ætre $\lambda$ en ligne $i$, tout le reste est l'identit√©)

**Propri√©t√©s fondamentales**
*   **D√©terminant :** $\det(T_{ij}(\lambda)) = 1$
*   **Inversibilit√© :** $T_{ij}(\lambda)$ est toujours inversible, d'inverse $T_{ij}(-\lambda)$
*   **Valeurs propres :** $1$ est l'unique valeur propre (multiplicit√© $n$)
*   **Nilpotence :** $T_{ij}(\lambda) - I_n = \lambda E_{ij}$ est nilpotente d'indice 2
*   **Op√©ration √©l√©mentaire :** Correspond √† $L_i \leftarrow L_i + \lambda L_j$ (ou $C_j \leftarrow C_j + \lambda C_i$)

**Th√©or√®me de g√©n√©ration**
Tout √©l√©ment de $GL_n(K)$ (ou de $SL_n(K)$) est un produit fini de transvections.
En particulier, $SL_n(K)$ est engendr√© par les transvections.

**Id√©e de d√©monstration**
L'algorithme du pivot de Gauss d√©compose toute matrice inversible en produit d'op√©rations √©l√©mentaires (transvections + dilatations).
Une dilatation $D_i(\mu)$ ($\mu \neq 0$) se d√©compose en transvections et $\det = \mu$ ; pour rester dans $SL_n$, on absorbe le d√©terminant.
R√©currence sur $n$ par blocs.

### 
**Subtilit√©s**
*   $i \neq j$ est imp√©ratif : si $i=j$, on obtiendrait $I + \lambda E_{ii}$ qui est une dilatation, pas une transvection.
*   La transvection n'est pas une sym√©trie : elle n'est pas involutive ($T_{ij}(\lambda)^2 \neq I$ en g√©n√©ral si $\lambda \neq 0$).
*   Le d√©terminant vaut exactement 1 : les transvections sont dans $SL_n(K)$, ce qui est crucial pour le calcul de d√©terminants par pivot.
*   **Attention √† la convention :** $T_{ij}(\lambda)$ agit sur la colonne $j$ (ajoute $\lambda$ fois la ligne/colonne $i$). La confusion ligne/colonne est une source d'erreur fr√©quente selon que l'on travaille sur les lignes ou les colonnes.

**Pi√®ges classiques**
*   Confondre $E_{ij}$ et $E_{ji}$ : $I_n + \lambda E_{ij}$ ajoute $\lambda$ fois la colonne $i$ √† la colonne $j$ quand on multiplie √† droite, mais ajoute $\lambda$ fois la ligne $j$ √† la ligne $i$ quand on multiplie √† gauche. Il faut savoir quel c√¥t√© on multiplie.
*   Oublier que $\lambda = 0$ donne l'identit√© : $T_{ij}(0) = I_n$, ce qui est licite mais trivial.
*   **En r√©duction :** une matrice triangulaire avec des 1 sur la diagonale est un produit de transvections ‚Äî c'est le lien avec les matrices unipotentes.
*   **Calcul de d√©terminant :** $\det(I_n + \lambda E_{ij}) = 1$ (d√©velopper selon la colonne $j$, ou utiliser le fait que les valeurs propres sont toutes √©gales √† 1).

**Extension / Programme MP**
*   Au programme MP : les transvections apparaissent dans la r√©duction des matrices et dans le pivot de Gauss.
*   Le r√©sultat "tout √©l√©ment de $GL_n$ est produit de transvections et d'une dilatation" est la justification th√©orique de la m√©thode de Gauss-Jordan.
*   Lien avec la d√©composition LU : la matrice $L$ dans $PA=LU$ est un produit de transvections inf√©rieures.

---

## FLASHCARD 139 ‚Äî √Ä conna√Ætre 42

### RECTO
**√Ä conna√Ætre 42 : Formes des matrices selon leurs propri√©t√©s ‚Äî Matrices √©quivalentes, semblables, rang**

Soit $K$ un corps, $A \in M_{n, p}(K)$.

**Question :** √ânoncer le th√©or√®me de classification des matrices √† √©quivalence pr√®s (forme canonique), rappeler la d√©finition de matrices semblables, et les invariants associ√©s.

### VERSO
**D√©finitions**
*   **Matrices √©quivalentes :** Deux matrices $A, B \in M_{n, p}(K)$ sont √©quivalentes s'il existe $P \in GL_n(K)$ et $Q \in GL_p(K)$ tels que :
    $$ B = PAQ $$
*   **Matrices semblables :** Deux matrices $A, B \in M_n(K)$ (carr√©es, m√™me taille) sont semblables s'il existe $P \in GL_n(K)$ tel que :
    $$ B = P^{-1}AP $$

**Th√©or√®me : Forme canonique d'√©quivalence**
Toute matrice $A \in M_{n, p}(K)$ de rang $r$ est √©quivalente √† la matrice :
$$ J_r = \begin{pmatrix} I_r & 0 \\ 0 & 0 \end{pmatrix} \in M_{n, p}(K) $$

**Corollaire :** Deux matrices $A, B \in M_{n, p}(K)$ sont √©quivalentes $\iff$ elles ont le m√™me rang.

**Invariants**
*   **√âquivalence :** Rang
*   **Similitude :** Valeurs propres (avec multiplicit√©s), polyn√¥me caract√©ristique, polyn√¥me minimal, trace, d√©terminant

**D√©monstration de la forme canonique**
Par le pivot de Gauss, on peut op√©rer des op√©rations √©l√©mentaires sur les lignes (multiplication √† gauche par des transvections/dilatations) et sur les colonnes (multiplication √† droite) pour mettre $A$ sous la forme $J_r$.
Ces op√©rations correspondent exactement √† la multiplication par des matrices inversibles $P$ et $Q$.
Le rang est pr√©serv√© car $P$ et $Q$ sont inversibles.

### 
**Subtilit√©s**
*   √âquivalence $\not\Rightarrow$ similitude : deux matrices √©quivalentes ont le m√™me rang, mais pas n√©cessairement le m√™me spectre. Exemple : $I_2$ et $\begin{pmatrix} 1 & 1 \\ 0 & 1 \end{pmatrix}$ sont semblables √† elles-m√™mes, mais $I_2$ et $2I_2$ sont non semblables (spectre diff√©rent) mais ont m√™me rang.
*   La similitude est plus fine que l'√©quivalence : si $A \sim B$ (semblables), alors $A \equiv B$ (√©quivalentes), mais la r√©ciproque est fausse.
*   **Invariants de similitude :** trace et d√©terminant sont n√©cessaires mais non suffisants pour conclure √† la similitude. Le polyn√¥me minimal est un invariant plus fin.

**Pi√®ges classiques**
*   Confondre "m√™me polyn√¥me caract√©ristique" et "semblables" : faux en g√©n√©ral. Contre-exemple : $\begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}$ et $\begin{pmatrix} 0 & 0 \\ 0 & 0 \end{pmatrix}$ ont des polyn√¥mes caract√©ristiques diff√©rents, mais... En fait l'exemple standard est deux matrices de Jordan de m√™me polyn√¥me caract√©ristique mais de polyn√¥mes minimaux diff√©rents.
*   **Taille diff√©rente :** l'√©quivalence est d√©finie pour des matrices $n \times p$ avec $n \neq p$ possible ; la similitude est uniquement pour les matrices carr√©es de m√™me taille.
*   V√©rifier que $P$ est bien inversible avant d'affirmer la similitude.

**Application au programme MP**
*   Ces notions sont au c≈ìur du chapitre R√©duction : diagonaliser/trigonaliser $\iff$ trouver une matrice semblable diagonale/triangulaire.
*   La forme canonique d'√©quivalence justifie que le rang est le seul invariant pour l'√©quivalence ‚Äî utile pour les applications lin√©aires.

---

## FLASHCARD 140 ‚Äî Proposition 43

### RECTO
**Proposition 43 : Valeurs propres et sous-espaces propres**

Soit $E$ un $K$-espace vectoriel de dimension finie $n \ge 1$, et $f \in \mathcal{L}(E)$.

**Question :** D√©finir valeur propre, vecteur propre, sous-espace propre. √ânoncer les propri√©t√©s de base : lien avec le polyn√¥me caract√©ristique, caract√©risation de la diagonalisabilit√© en termes de somme directe des sous-espaces propres.

### VERSO
**D√©finitions**
*   $\lambda \in K$ est valeur propre de $f$ s'il existe $x \neq 0$ tel que $f(x) = \lambda x$.
*   Un tel $x$ est appel√© vecteur propre associ√© √† $\lambda$.
*   Le sous-espace propre associ√© √† $\lambda$ est :
    $$ E_\lambda(f) = \ker(f - \lambda id_E) $$
    C'est un sous-espace vectoriel de $E$, non r√©duit √† $\{0\}$ si et seulement si $\lambda$ est valeur propre.

**Polyn√¥me caract√©ristique**
$$ \chi_f(X) = \det(X \cdot id_E - f) \in K[X] $$
C'est un polyn√¥me de degr√© $n$, de coefficient dominant 1.

**Propri√©t√© fondamentale :** $\lambda$ est valeur propre de $f \iff \chi_f(\lambda) = 0$.

**Multiplicit√©s**
Pour $\lambda$ valeur propre :
*   **Multiplicit√© alg√©brique $m_a(\lambda)$ :** ordre de $\lambda$ comme racine de $\chi_f$.
*   **Multiplicit√© g√©om√©trique $m_g(\lambda) = \dim E_\lambda(f)$.**
*   **In√©galit√© fondamentale :**
    $$ 1 \le m_g(\lambda) \le m_a(\lambda) $$

**Ind√©pendance des sous-espaces propres**
**Proposition :** Les sous-espaces propres associ√©s √† des valeurs propres distinctes sont en somme directe :
$$ \lambda_1, \dots, \lambda_k \text{ distincts} \implies E_{\lambda_1} + \dots + E_{\lambda_k} \text{ est directe} $$

**D√©monstration :** Par r√©currence sur $k$. Si $x_1 + \dots + x_k = 0$ avec $x_i \in E_{\lambda_i}$, appliquer $(f - \lambda_k id)$ et utiliser $\lambda_i \neq \lambda_k$.

**Caract√©risation de la diagonalisabilit√©**
$f$ est diagonalisable
$\iff E = \bigoplus_{\lambda \in Sp(f)} E_\lambda(f)$
$\iff \sum_{\lambda \in Sp(f)} \dim E_\lambda(f) = n$
$\iff \forall \lambda \in Sp(f), m_g(\lambda) = m_a(\lambda)$

### 
**Subtilit√©s**
*   $K$ doit contenir les valeurs propres : sur $\mathbb{R}$, une matrice peut ne pas avoir de valeurs propres r√©elles (ex : rotation d'angle $\pi/2$ en dimension 2). Sur $\mathbb{C}$, le polyn√¥me caract√©ristique est scind√© (d'Alembert-Gauss).
*   L'in√©galit√© $m_g \le m_a$ est stricte en g√©n√©ral : c'est le cas des blocs de Jordan non triviaux.
*   **Vecteur propre $\neq 0$ par d√©finition :** ne jamais oublier cette condition dans les d√©monstrations.

**Pi√®ges classiques**
*   Confondre multiplicit√© alg√©brique et g√©om√©trique : l'√©galit√© $m_g = m_a$ pour toutes les valeurs propres est la condition de diagonalisabilit√©.
*   Calculer $\chi_f(\lambda) = \det(\lambda I - f)$ ou $\det(f - \lambda I)$ : les deux diff√®rent d'un signe $(-1)^n$, donc les racines sont les m√™mes, mais le coefficient dominant change. Convention √† fixer.
*   Oublier de v√©rifier que le polyn√¥me caract√©ristique est scind√© sur $K$ avant de parler de diagonalisabilit√© sur $K$.

---

## FLASHCARD 141 ‚Äî √Ä conna√Ætre 43

### RECTO
**√Ä conna√Ætre 43 : Polyn√¥me minimal**

Soit $E$ un $K$-ev de dimension $n$, $f \in \mathcal{L}(E)$.

**Question :** D√©finir le polyn√¥me minimal de $f$. √ânoncer ses propri√©t√©s (existence, unicit√©, lien avec le polyn√¥me caract√©ristique, lien avec la diagonalisabilit√© et la trigonalisabilit√©).

### VERSO
**D√©finition**
L'ensemble $\{P \in K[X] \mid P(f) = 0\}$ est un id√©al de $K[X]$ (anneau principal), donc de la forme $(m_f)$ o√π $m_f$ est l'unique polyn√¥me unitaire de plus petit degr√© annulant $f$.

Le polyn√¥me minimal $m_f$ de $f$ est le g√©n√©rateur unitaire de l'id√©al $\text{Ann}(f) = \{P \in K[X] \mid P(f) = 0_{\mathcal{L}(E)}\}$.

**Propri√©t√©s fondamentales**
*   **Divisibilit√© :** $P(f) = 0 \iff m_f \mid P$
*   **Lien avec $\chi_f$ (Cayley-Hamilton) :** $m_f \mid \chi_f$ (et $\chi_f \mid m_f^n$ dans un sens plus pr√©cis : m√™mes racines)
*   **M√™mes racines :** $\lambda$ est valeur propre de $f \iff m_f(\lambda) = 0$
*   **Degr√© :** $1 \le \deg(m_f) \le n$

**Caract√©risations**
*   $f$ diagonalisable sur $K \iff m_f$ est scind√© √† racines simples sur $K$
*   $f$ trigonalisable sur $K \iff m_f$ est scind√© sur $K$
*   $f = \lambda id \iff m_f = X - \lambda$

**Calcul pratique**
*   Pour une matrice $A$ donn√©e, chercher le plus petit degr√© $d$ tel qu'il existe un polyn√¥me unitaire de degr√© $d$ annulant $A$.
*   Si $\chi_f$ est scind√© √† racines simples $\Rightarrow m_f = \chi_f$.
*   Pour une matrice diagonale $\text{diag}(\lambda_1, \dots, \lambda_n)$ : $m_f = \prod_{\lambda \in Sp(f)} (X - \lambda)$ (produit sur les valeurs propres distinctes).

**D√©monstration de l'existence**
$K[X]$ est un anneau principal. La famille $(f^0, f^1, \dots, f^{n^2})$ dans $\mathcal{L}(E) \simeq M_n(K)$ (dimension $n^2$) est li√©e, donc il existe une relation non triviale $\sum a_k f^k = 0$, i.e., un polyn√¥me non nul annulant $f$. L'annulateur est donc non r√©duit √† $\{0\}$, et son g√©n√©rateur unitaire est $m_f$.

### 
**Subtilit√©s**
*   $m_f$ et $\chi_f$ ont les m√™mes racines (dans $\bar{K}$) mais pas forc√©ment les m√™mes multiplicit√©s. C'est le pont entre polyn√¥me minimal et spectre.
*   Le fait que $m_f \mid \chi_f$ est une cons√©quence de Cayley-Hamilton ($\chi_f(f)=0$), mais la r√©ciproque $\chi_f \mid m_f$ est fausse en g√©n√©ral.
*   En dimension infinie, le polyn√¥me minimal peut ne pas exister (plus d'annulateur de degr√© fini en g√©n√©ral).

**Pi√®ges classiques**
*   Confondre "$m_f$ scind√© √† racines simples" (diagonalisabilit√©) et "$m_f$ scind√©" (trigonalisabilit√©).
*   Penser que $m_f = \chi_f$ toujours : faux. Pour $f = id$ : $\chi_f = (X-1)^n$ mais $m_f = X-1$.
*   Pour un endomorphisme d'un espace de dimension $n$ : $\deg(m_f) \le n$, pas $\le n^2$ (borne triviale). La borne $n$ vient de Cayley-Hamilton.

---

## FLASHCARD 142 ‚Äî Th√©or√®me 53 : Condition suffisante de diagonalisabilit√©

### RECTO
**Th√©or√®me 53 : Condition suffisante de diagonalisabilit√©**

Soit $E$ un $K$-espace vectoriel de dimension $n \ge 1$, $f \in \mathcal{L}(E)$.

**Question :** √ânoncer une condition suffisante simple de diagonalisabilit√© de $f$ faisant intervenir le nombre de valeurs propres distinctes. √ânoncer √©galement la condition suffisante via le polyn√¥me minimal.

### VERSO
**Th√©or√®me (condition suffisante par le nombre de valeurs propres)**
Si $f$ admet $n$ valeurs propres distinctes dans $K$, alors $f$ est diagonalisable sur $K$.

**D√©monstration :** Si $\lambda_1, \dots, \lambda_n$ sont $n$ valeurs propres distinctes, les sous-espaces propres $E_{\lambda_i}$ sont en somme directe (Prop. 43), chacun de dimension $\ge 1$. Donc $\sum \dim E_{\lambda_i} \ge n$. Comme $\dim E = n$, on a √©galit√© et $E = \bigoplus_{i=1}^n E_{\lambda_i}$.

**Attention :** La r√©ciproque est fausse : $f$ peut √™tre diagonalisable avec des valeurs propres multiples (ex : $f=id$).

**Th√©or√®me (condition suffisante via le polyn√¥me minimal)**
$f$ est diagonalisable sur $K \iff m_f$ est scind√© √† racines simples sur $K$.

C'est-√†-dire : il existe $\lambda_1, \dots, \lambda_k \in K$ distincts tels que :
$$ m_f = (X - \lambda_1)(X - \lambda_2) \dots (X - \lambda_k) $$

**Condition n√©cessaire et suffisante compl√®te (rappel)**
$f$ diagonalisable $\iff \forall \lambda \in Sp(f), m_g(\lambda) = m_a(\lambda) \iff \chi_f$ scind√© et $m_g = m_a$ partout

**Strat√©gie pratique de diagonalisation**
1.  Calculer $\chi_f(X) = \det(X \cdot I - A)$.
2.  V√©rifier que $\chi_f$ est scind√© sur $K$.
3.  Pour chaque valeur propre $\lambda_i$ de multiplicit√© $m_a(\lambda_i)$, calculer $\dim \ker(f - \lambda_i id) = m_g(\lambda_i)$.
4.  V√©rifier $m_g(\lambda_i) = m_a(\lambda_i)$ pour tout $i$.
5.  Construire une base de vecteurs propres.

### 
**Subtilit√©s**
*   "$n$ valeurs propres distinctes" implique que $\chi_f$ est scind√© √† racines simples, donc $m_f = \chi_f$ dans ce cas.
*   Sur $\mathbb{C}$, $\chi_f$ est toujours scind√© (d'Alembert), mais cela ne suffit pas pour la diagonalisabilit√© sur $\mathbb{C}$.
*   Condition n√©cessaire seule ne suffit pas : $\chi_f$ scind√© $\not\Rightarrow$ diagonalisable. Il faut en plus $m_g = m_a$.

**Pi√®ges classiques**
*   Croire que "polyn√¥me caract√©ristique scind√© $\implies$ diagonalisable" : faux. $\begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}$ a $\chi = X^2$ scind√© mais n'est pas diagonalisable.
*   En dimension infinie, les notions de multiplicit√© alg√©brique/g√©om√©trique ne s'appliquent plus directement.
*   Ne pas v√©rifier que les valeurs propres sont dans $K$ (et non seulement dans $\bar{K}$) : une matrice r√©elle peut √™tre diagonalisable sur $\mathbb{C}$ mais pas sur $\mathbb{R}$.

---

## FLASHCARD 143 ‚Äî √Ä conna√Ætre 44

### RECTO
**√Ä conna√Ætre 44 : Polyn√¥me d'endomorphisme, calcul fonctionnel**

Soit $E$ un $K$-ev de dimension $n$, $f \in \mathcal{L}(E)$, et $P = \sum_{k=0}^d a_k X^k \in K[X]$.

**Question :** D√©finir $P(f)$. √ânoncer les propri√©t√©s alg√©briques fondamentales (morphisme d'alg√®bre). √ânoncer le th√©or√®me de Cayley-Hamilton.

### VERSO
**D√©finition**
$$ P(f) = \sum_{k=0}^d a_k f^k \in \mathcal{L}(E) $$
avec la convention $f^0 = id_E$.

**Morphisme d'alg√®bre**
L'application $\varphi : K[X] \to \mathcal{L}(E), P \mapsto P(f)$ est un morphisme d'alg√®bres, i.e. :
$$ \forall P, Q \in K[X] : (P+Q)(f) = P(f) + Q(f), \quad (PQ)(f) = P(f) \circ Q(f) $$

En particulier, $P(f)$ et $Q(f)$ commutent : $P(f) \circ Q(f) = Q(f) \circ P(f)$.

**Cons√©quence importante :** Si $P = \prod_i (X - \lambda_i)^{n_i}$, alors $P(f) = \prod_i (f - \lambda_i id)^{n_i}$.

**Th√©or√®me de Cayley-Hamilton**
**Th√©or√®me :** $\chi_f(f) = 0_{\mathcal{L}(E)}$

i.e., tout endomorphisme est racine de son propre polyn√¥me caract√©ristique.

**Cons√©quence :** $m_f \mid \chi_f$.

**D√©monstration (esquisse)**
M√©thode matricielle : En base $B$, $A = \text{Mat}_B(f)$. On calcule $\text{com}(XI_n - A)$ (matrice des cofacteurs transpos√©e), et on utilise l'identit√© $(XI_n - A) \cdot \text{adj}(XI_n - A) = \det(XI_n - A) \cdot I_n = \chi_A(X) I_n$. En d√©veloppant et en substituant $X=A$, on obtient $\chi_A(A) = 0$.

**Application : calcul de puissances et d'inverses**
*   Si $\chi_f = X^n + a_{n-1} X^{n-1} + \dots + a_0$, alors $f^n = -a_{n-1} f^{n-1} - \dots - a_0 id$.
*   Si $a_0 \neq 0$ : $f^{-1} = -\frac{1}{a_0}(f^{n-1} + \dots + a_1 id)$ (car $f$ est inversible ssi $a_0 = \chi_f(0) = (-1)^n \det(f) \neq 0$).

### 
**Subtilit√©s**
*   La commutativit√© $P(f) \circ Q(f) = Q(f) \circ P(f)$ est sp√©cifique aux polyn√¥mes en un m√™me endomorphisme $f$. Elle est fausse en g√©n√©ral pour $P(f) \circ Q(g)$ avec $f \neq g$.
*   Cayley-Hamilton dit $\chi_f(f) = 0$, pas $\chi_f(A) = 0$ pour n'importe quelle matrice $A$ : c'est sp√©cifique √† $f$.
*   L'erreur classique : "substituer $\lambda$ √† $X$ dans $\chi_A(X) = \det(XI - A)$ et obtenir $\det(\lambda I - A) = 0$" ne prouve pas Cayley-Hamilton. Il faut substituer $A$ (une matrice), pas $\lambda$ (un scalaire).

**Pi√®ges classiques**
*   Cayley-Hamilton $\not\Rightarrow m_f = \chi_f$ : on a seulement $m_f \mid \chi_f$.
*   En exam, on demande souvent d'utiliser Cayley-Hamilton pour calculer $A^{-1}$ ou des puissances √©lev√©es de $A$. La m√©thode : exprimer $A^n$ en fonction de $A^{n-1}, \dots, I$ gr√¢ce √† $\chi_A(A)=0$.
*   Ne pas confondre $\chi_f(X) = \det(XI - f)$ et $\det(f - XI)$ : diff√©rence de signe $(-1)^n$.

---

## FLASHCARD 144 ‚Äî Th√©or√®me 54

### RECTO
**Th√©or√®me 54 : Crit√®re de diagonalisabilit√© par le polyn√¥me minimal ‚Äî version compl√®te**

Soit $E$ un $K$-ev de dimension finie $n$, $f \in \mathcal{L}(E)$.

**Question :** √ânoncer les √©quivalences compl√®tes caract√©risant la diagonalisabilit√© de $f$, en faisant intervenir le polyn√¥me minimal, le polyn√¥me caract√©ristique, et les multiplicit√©s.

### VERSO
**Th√©or√®me (√©quivalences pour la diagonalisabilit√©)**
Les assertions suivantes sont √©quivalentes :

(i) $f$ est diagonalisable sur $K$ (il existe une base de $E$ form√©e de vecteurs propres de $f$).

(ii) $\chi_f$ est scind√© sur $K$ et $\forall \lambda \in Sp(f), m_g(\lambda) = m_a(\lambda)$.

(iii) $m_f$ est scind√© √† racines simples sur $K$ : $m_f = \prod_{\lambda \in Sp(f)} (X - \lambda)$.

(iv) $E = \bigoplus_{\lambda \in Sp(f)} \ker(f - \lambda \cdot id_E)$.

(v) Il existe $P \in K[X]$ scind√© √† racines simples tel que $P(f) = 0$.

**Implications et logique**
(i) $\iff$ (ii) $\iff$ (iii) $\iff$ (iv) $\iff$ (v)

Pour (v) $\Rightarrow$ (iii) : $m_f \mid P$, et si $P$ est scind√© √† racines simples, alors $m_f$ l'est aussi.

**Condition suffisante rapide (pour les concours)**
*   Si $f$ v√©rifie $f^2 = f$ (projecteur) : $m_f \mid X(X-1)$, scind√© √† racines simples $\Rightarrow$ diagonalisable.
*   Si $f$ v√©rifie $f^k = id$ avec $\text{car}(K) \nmid k$ et $K$ contient les racines $k$-i√®mes de l'unit√© : diagonalisable.

### 
**Subtilit√©s**
*   La condition (iii) est souvent la plus rapide √† v√©rifier en pratique : il suffit de trouver un polyn√¥me annulateur scind√© √† racines simples.
*   En caract√©ristique nulle (sur $\mathbb{R}$ ou $\mathbb{C}$), les projecteurs ($f^2=f$) et les sym√©tries ($f^2=id$) sont toujours diagonalisables.
*   La condition (v) donne une m√©thode : si on peut trouver $P$ annulateur scind√© √† racines simples sans calculer $m_f$, c'est suffisant.

**Pi√®ges classiques**
*   $\chi_f$ scind√© n'est pas suffisant ‚Äî c'est l'erreur la plus fr√©quente en concours.
*   Sur $\mathbb{R}$ : une matrice peut avoir $\chi_f$ non scind√© sur $\mathbb{R}$ (racines complexes non r√©elles), donc non diagonalisable sur $\mathbb{R}$ mais diagonalisable sur $\mathbb{C}$.
*   Confondre "polyn√¥me annulateur" et "polyn√¥me minimal" : tout polyn√¥me annulateur est multiple du minimal, mais pas n√©cessairement √©gal.

---

## FLASHCARD 145 ‚Äî Th√©or√®me 55 : Condition n√©cessaire et suffisante de trigonalisabilit√©

### RECTO
**Th√©or√®me 55 : Condition n√©cessaire et suffisante de trigonalisabilit√©**

Soit $E$ un $K$-espace vectoriel de dimension $n \ge 1$, $f \in \mathcal{L}(E)$.

**Question :** √ânoncer le th√©or√®me caract√©risant la trigonalisabilit√© de $f$, avec hypoth√®ses exactes et conclusion. Pr√©ciser le cas $K = \mathbb{C}$.

### VERSO
**Th√©or√®me**
$f$ est trigonalisable sur $K$ (il existe une base de $E$ dans laquelle la matrice de $f$ est triangulaire sup√©rieure) si et seulement si $\chi_f$ est scind√© sur $K$.

i.e., $\exists \lambda_1, \dots, \lambda_n \in K$ (non n√©cessairement distincts) tels que :
$$ \chi_f(X) = \prod_{i=1}^n (X - \lambda_i) $$

**Corollaire imm√©diat**
Tout endomorphisme d'un $\mathbb{C}$-espace vectoriel de dimension finie est trigonalisable (sur $\mathbb{C}$).
(Car $\mathbb{C}$ est alg√©briquement clos, donc $\chi_f$ est scind√© sur $\mathbb{C}$ ‚Äî th√©or√®me de d'Alembert-Gauss.)

**Forme de la matrice trigonalis√©e**
Si $f$ est trigonalisable de valeurs propres $\lambda_1, \dots, \lambda_k$ (distinctes, de multiplicit√©s $n_1, \dots, n_k$), il existe une base dans laquelle la matrice de $f$ est :
$$ T = \begin{pmatrix} \lambda_1 & \ast & \cdots & \ast \\ 0 & \lambda_2 & \cdots & \ast \\ \vdots & \ddots & \ddots & \vdots \\ 0 & 0 & \cdots & \lambda_n \end{pmatrix} $$
Les valeurs propres apparaissent sur la diagonale (avec multiplicit√©s).

**D√©monstration (esquisse)**
Par r√©currence sur $n = \dim E$ :
*   $n=1$ : trivial.
*   Si $\chi_f$ est scind√©, il admet une racine $\lambda_1 \in K$. Prendre $e_1$ vecteur propre associ√©.
*   Poser $F = E/\text{Vect}(e_1)$ (ou utiliser un suppl√©mentaire), l'endomorphisme induit sur le quotient a un polyn√¥me caract√©ristique qui est $\chi_f/(X-\lambda_1)$, encore scind√©.
*   Appliquer l'hypoth√®se de r√©currence.

### 
**Subtilit√©s**
*   "Trigonalisable sur $K$" d√©pend du corps. Sur $\mathbb{R}$, une rotation d'angle $\pi/2$ en dimension 2 n'est pas trigonalisable (pas de valeur propre r√©elle). Sur $\mathbb{C}$, elle l'est.
*   La trigonalisabilit√© est strictement plus faible que la diagonalisabilit√© : $\chi_f$ scind√© est n√©cessaire et suffisant pour trigonaliser, mais il faut en plus $m_f$ scind√© √† racines simples pour diagonaliser.
*   Un endomorphisme nilpotent (toutes les valeurs propres nulles) est trigonalisable, avec des 0 sur la diagonale, mais rarement diagonalisable (sauf si $f=0$).

**Pi√®ges classiques**
*   Confondre trigonalisabilit√© et diagonalisabilit√© : $\chi_f$ scind√© $\implies$ trigonalisable mais pas forc√©ment diagonalisable.
*   Sur $\mathbb{R}$, $\chi_f$ est de degr√© $n$ et √† coefficients r√©els. Il peut avoir des racines complexes non r√©elles, auquel cas $f$ n'est pas trigonalisable sur $\mathbb{R}$.
*   La d√©monstration par r√©currence utilise souvent des quotients ou des suppl√©mentaires ‚Äî bien ma√Ætriser la technique.

---

## FLASHCARD 146 ‚Äî Corollaire 2

### RECTO
**Corollaire 2 : Trace et d√©terminant en termes des valeurs propres**

Soit $A \in M_n(K)$, et supposons $\chi_A$ scind√© sur $K$ avec valeurs propres $\lambda_1, \dots, \lambda_n$ (compt√©es avec multiplicit√©s).

**Question :** Exprimer $\text{tr}(A)$ et $\det(A)$ en termes des valeurs propres.

### VERSO
**Formules**
Si $\chi_A(X) = (X - \lambda_1)(X - \lambda_2) \dots (X - \lambda_n)$, alors :

$$ \text{tr}(A) = \sum_{i=1}^n \lambda_i $$

$$ \det(A) = \prod_{i=1}^n \lambda_i $$

**D√©monstration**
En d√©veloppant $\chi_A(X) = X^n - \text{tr}(A)X^{n-1} + \dots + (-1)^n \det(A)$, et en identifiant avec $\prod_{i=1}^n (X - \lambda_i) = X^n - (\sum \lambda_i) X^{n-1} + \dots + (-1)^n \prod \lambda_i$.

Plus pr√©cis√©ment :
*   Coefficient de $X^{n-1}$ : $-\sum \lambda_i = -\text{tr}(A)$ donc $\text{tr}(A) = \sum \lambda_i$.
*   Terme constant : $(-1)^n \prod \lambda_i = (-1)^n \det(A)$ donc $\det(A) = \prod \lambda_i$.

**G√©n√©ralisation (fonctions sym√©triques)**
Les coefficients de $\chi_A$ s'expriment par les polyn√¥mes sym√©triques √©l√©mentaires des valeurs propres :
$$ \chi_A(X) = \sum_{k=0}^n (-1)^k e_k(\lambda_1, \dots, \lambda_n) X^{n-k} $$
avec $e_k(\lambda_1, \dots, \lambda_n) = \sum_{i_1 < \dots < i_k} \lambda_{i_1} \dots \lambda_{i_k}$.

### 
**Subtilit√©s**
*   Ces formules sont valables m√™me si $\chi_A$ n'est pas scind√© sur $K$, √† condition de travailler sur $\bar{K}$ (cl√¥ture alg√©brique). La trace et le d√©terminant sont d√©finis ind√©pendamment.
*   En particulier : $\text{tr}(A)$ est le coefficient de $(-X^{n-1})$ dans $\chi_A$, et $\det(A) = (-1)^n \chi_A(0) = \chi_A(0) \cdot (-1)^n$.
*   **Matrice semblable :** trace et d√©terminant sont des invariants de similitude (ils ne d√©pendent que des valeurs propres).

**Pi√®ges classiques**
*   **Signe de $\chi_A$ :** $\chi_A(X) = \det(XI - A)$, donc $\chi_A(0) = \det(-A) = (-1)^n \det(A)$. Attention au signe.
*   Sur $\mathbb{R}$, les valeurs propres complexes viennent par paires conjugu√©es, donc $\text{tr}(A) \in \mathbb{R}$ et $\det(A) \in \mathbb{R}$ ‚Äî ce qui est coh√©rent.
*   Trace nulle $\not\Leftrightarrow$ d√©terminant nul (et vice-versa).

---

## FLASHCARD 147 ‚Äî Corollaire 3 : Induit d'un trigonalisable

### RECTO
**Corollaire 3 : Induit d'un endomorphisme trigonalisable sur un sous-espace stable**

Soit $E$ un $K$-ev de dimension finie $n$, $f \in \mathcal{L}(E)$ trigonalisable sur $K$, et $F$ un sous-espace vectoriel de $E$ stable par $f$.

**Question :** Montrer que l'endomorphisme induit $f|_F$ est aussi trigonalisable sur $K$. Quelle propri√©t√© du spectre en d√©coule ?

### VERSO
**Th√©or√®me**
Soit $F$ un sous-espace de $E$ stable par $f$ (i.e., $f(F) \subset F$). Si $f$ est trigonalisable sur $K$, alors $f|_F : F \to F$ est aussi trigonalisable sur $K$.

**D√©monstration**
$f$ trigonalisable $\implies \chi_f$ scind√© sur $K$. Il suffit de montrer que $\chi_{f|_F}$ divise $\chi_f$ et est donc aussi scind√©.

**M√©thode :** Compl√©ter une base $(e_1, \dots, e_p)$ de $F$ en une base $(e_1, \dots, e_p, e_{p+1}, \dots, e_n)$ de $E$. Dans cette base, la matrice de $f$ est :
$$ \begin{pmatrix} A & B \\ 0 & C \end{pmatrix} $$
o√π $A = \text{Mat}(f|_F)$ et le bloc nul traduit la stabilit√© de $F$. Alors :
$$ \chi_f(X) = \det \begin{pmatrix} XI_p - A & -B \\ 0 & XI_{n-p} - C \end{pmatrix} = \chi_{f|_F}(X) \cdot \det(XI_{n-p} - C) $$
Donc $\chi_{f|_F} \mid \chi_f$, et comme $\chi_f$ est scind√©, $\chi_{f|_F}$ l'est aussi.

**Corollaire sur le spectre**
$$ Sp(f|_F) \subset Sp(f) $$

### 
**Subtilit√©s**
*   La stabilit√© de $F$ est essentielle : sans elle, $f$ ne d√©finit pas d'endomorphisme de $F$.
*   La relation $\chi_{f|_F} \mid \chi_f$ est plus forte que la simple inclusion des spectres : elle donne une information sur les multiplicit√©s.
*   En particulier, si $f$ est diagonalisable, $f|_F$ l'est aussi (m√™me raisonnement avec $m_{f|_F} \mid m_f$, et $m_f$ scind√© √† racines simples).

**Pi√®ges classiques**
*   Ne pas oublier que le sous-espace $F$ doit √™tre stable : un sous-espace quelconque ne donne pas d'endomorphisme induit bien d√©fini.
*   La relation en blocs $\begin{pmatrix} A & B \\ 0 & C \end{pmatrix}$ est le calcul √† ma√Ætriser parfaitement.

---

## FLASHCARD 148 ‚Äî √Ä conna√Ætre 45

### RECTO
**√Ä conna√Ætre 45 : Endomorphismes qui commutent ‚Äî propri√©t√©s**

Soit $E$ un $K$-ev de dimension finie, $f, g \in \mathcal{L}(E)$ tels que $f \circ g = g \circ f$.

**Question :** √ânoncer les propri√©t√©s de stabilit√© des sous-espaces propres de $f$ par $g$. Quelle cons√©quence pour la codiagonalisabilit√© ?

### VERSO
**Propri√©t√© fondamentale**
Si $f \circ g = g \circ f$ et $\lambda$ est valeur propre de $f$, alors le sous-espace propre $E_\lambda(f) = \ker(f - \lambda id)$ est stable par $g$.

**D√©monstration :** Soit $x \in E_\lambda(f)$, i.e., $f(x) = \lambda x$. Alors :
$$ f(g(x)) = g(f(x)) = g(\lambda x) = \lambda g(x) $$
Donc $g(x) \in E_\lambda(f)$. $\square$

**Plus g√©n√©ralement**
Les sous-espaces $\ker(f - \lambda id)^k$ (espaces caract√©ristiques) sont stables par $g$ si $f$ et $g$ commutent.

**Corollaire pour la codiagonalisabilit√©**
Si $f$ et $g$ commutent et sont tous deux diagonalisables, alors ils sont simultan√©ment diagonalisables (il existe une base de $E$ dans laquelle les matrices de $f$ et de $g$ sont toutes deux diagonales).

**D√©monstration :** Sur chaque $E_\lambda(f)$ (stable par $g$), l'endomorphisme $g|_{E_\lambda(f)}$ est diagonalisable (induit d'un diagonalisable sur un sous-espace stable). Diagonaliser $g$ sur chaque $E_\lambda(f)$ donne une base de vecteurs propres communs.

**R√©ciproque**
Si $f$ et $g$ sont simultan√©ment diagonalisables, alors $f \circ g = g \circ f$.

### 
**Subtilit√©s**
*   La condition "tous deux diagonalisables" est indispensable pour la codiagonalisabilit√©. Si l'un est seulement trigonalisable, on peut avoir cotrigonalisabilit√©, pas codiagonalisabilit√©.
*   La stabilit√© s'√©tend aux polyn√¥mes en $f$ et $g$ : si $f$ et $g$ commutent, alors $P(f)$ commute avec $Q(g)$ pour tous polyn√¥mes $P, Q$.

**Pi√®ges classiques**
*   Le r√©sultat de stabilit√© $E_\lambda(f)$ stable par $g$ est valable pour n'importe quels $f, g$ qui commutent, sans hypoth√®se de diagonalisabilit√©.
*   En exam, la strat√©gie standard est : identifier les sous-espaces stables communs, puis diagonaliser sur chacun.

---

## FLASHCARD 149 ‚Äî Proposition 44 : Nilpotents

### RECTO
**Proposition 44 : Endomorphismes nilpotents**

Soit $E$ un $K$-ev de dimension $n \ge 1$, $f \in \mathcal{L}(E)$.

**Question :** D√©finir un endomorphisme nilpotent. √ânoncer les √©quivalences caract√©risant la nilpotence. Donner les propri√©t√©s fondamentales (spectre, polyn√¥me caract√©ristique, polynomial minimal).

### VERSO
**D√©finition**
$f$ est nilpotent s'il existe $k \in \mathbb{N}^*$ tel que $f^k = 0$.
Le plus petit tel $k$ est l'indice de nilpotence de $f$ (not√© $\nu(f)$).

**√âquivalences**
Les assertions suivantes sont √©quivalentes :
(i) $f$ est nilpotent.
(ii) $\chi_f(X) = X^n$.
(iii) $Sp(f) = \{0\}$ (la seule valeur propre est $0$, si $K$ est alg√©briquement clos, ou $\chi_f = X^n$).
(iv) $m_f = X^\nu$ pour un certain $\nu \in \llbracket 1, n \rrbracket$.
(v) $f$ est trigonalisable avec $0$ sur toute la diagonale.

**Propri√©t√©s**
*   $\text{tr}(f) = 0$ (somme des valeurs propres toutes nulles)
*   $\det(f) = 0$ (produit des valeurs propres toutes nulles), donc $f$ n'est pas inversible (sauf si $E=\{0\}$)
*   $\nu(f) \le n$ (car $m_f \mid \chi_f = X^n$ et $\deg m_f \le n$)
*   Si $f^{n-1} \neq 0$ et $f^n = 0$ : $\nu(f) = n$, et $f$ est semblable √† la matrice de Jordan nilpotente $J_n(0)$.

**Exemples canoniques**
*   Matrice $N = \begin{pmatrix} 0 & 1 & 0 \\ 0 & 0 & 1 \\ 0 & 0 & 0 \end{pmatrix}$ : nilpotente d'indice 3.
*   Toute matrice strictement triangulaire sup√©rieure est nilpotente.

### 
**Subtilit√©s**
*   L'√©quivalence (ii) $\iff$ (i) utilise Cayley-Hamilton : $f^n = 0$ si $\chi_f = X^n$ (car Cayley-Hamilton donne $\chi_f(f) = f^n = 0$).
*   La r√©ciproque : si $f$ nilpotent, toutes les valeurs propres sont $0$, donc $\chi_f = X^n$ (si $\chi_f$ est scind√©, ce qui est le cas sur $\mathbb{C}$ ou si l'endomorphisme est nilpotent il est trigonalisable avec des $0$).
*   Trace nulle $\not\Rightarrow$ nilpotent : contre-exemple $\begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}$.

**Pi√®ges classiques**
*   Confondre "nilpotent" et "a $0$ comme valeur propre" : si $0$ est valeur propre mais pas la seule, $f$ n'est pas nilpotent. Ex : $\begin{pmatrix} 0 & 0 \\ 0 & 1 \end{pmatrix}$.
*   L'indice de nilpotence satisfait $\nu \le n$ mais peut √™tre strictement plus petit que $n$. Ex : $\begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}$ dans $M_2$ a $\nu = 2 = n$.

---

## FLASHCARD 150 ‚Äî Lemme 4

### RECTO
**Lemme 4 : Noyaux it√©r√©s d'un endomorphisme nilpotent**

Soit $E$ un $K$-ev de dimension finie $n$, $f \in \mathcal{L}(E)$ nilpotent d'indice $\nu$.

**Question :** √ânoncer les propri√©t√©s des noyaux it√©r√©s $\ker(f^k)$ pour $k \ge 0$. Donner la suite des dimensions et sa stabilisation.

### VERSO
**Suite des noyaux it√©r√©s**
Posons $N_k = \ker(f^k)$ pour $k \ge 0$.

**Propri√©t√©s :**
*   $N_0 = \{0\} \subset N_1 \subset N_2 \subset \dots \subset N_\nu = E$
*   La suite $(\dim N_k)_{k \ge 0}$ est strictement croissante jusqu'√† $k=\nu$, puis constante √©gale √† $n$.
    $$ 0 = \dim N_0 < \dim N_1 < \dim N_2 < \dots < \dim N_\nu = n $$
*   Stabilisation : $N_k = N_{k+1} \iff f|_{N_{k+1}} = 0 \dots$ En fait : si $N_k = N_{k+1}$ alors $N_k = N_j$ pour tout $j \ge k$.

**Lemme des noyaux (propri√©t√© cl√©)**
*   Si $f^k = 0$ (i.e., $\nu \le k$), alors $N_k = E$.
*   Si $f^{k+1} = 0$ et $f^k \neq 0$, alors $\dim N_{k+1} > \dim N_k$.

**Cons√©quence sur l'indice**
$$ \nu(f) = \min \{k \ge 0 : f^k = 0\} \le n $$
Et $\nu(f) = n$ si et seulement si il existe $x \in E$ tel que $(x, f(x), \dots, f^{n-1}(x))$ est une base de $E$ (base cyclique ou de Jordan).

### 
**Subtilit√©s**
*   La stricte croissance jusqu'√† $\nu$ garantit que $\nu \le n$ : en effet, $n+1$ termes strictement croissants dans $\{0, 1, \dots, n\}$ est impossible.
*   La suite des sauts $d_k = \dim N_k - \dim N_{k-1}$ est d√©croissante : $d_1 \ge d_2 \ge \dots \ge d_\nu \ge 1$. C'est li√© √† la structure des blocs de Jordan.

**Pi√®ges classiques**
*   Ne pas confondre "noyaux it√©r√©s de $f$" avec "noyaux it√©r√©s de $f - \lambda id$" (espaces caract√©ristiques), qui sont le bon outil pour la d√©composition de Dunford.
*   La d√©croissance des sauts n'est pas √† d√©montrer en concours mais est utile pour d√©terminer la forme de Jordan.

---

## FLASHCARD 151 ‚Äî √Ä conna√Ætre 46 : Codiagonalisation, cotrigonalisation

### RECTO
**√Ä conna√Ætre 46 : Codiagonalisation et cotrigonalisation**

Soit $E$ un $K$-ev de dimension finie, et $f_1, \dots, f_p \in \mathcal{L}(E)$.

**Question :** √ânoncer le th√©or√®me de codiagonalisation simultan√©e, et le th√©or√®me de cotrigonalisation. Donner les conditions n√©cessaires et suffisantes.

### VERSO
**Codiagonalisation simultan√©e**
**Th√©or√®me :** Les endomorphismes $f_1, \dots, f_p$ sont simultan√©ment diagonalisables (il existe une base de $E$ dans laquelle toutes les matrices de $f_i$ sont diagonales) si et seulement si :
1.  Chaque $f_i$ est diagonalisable (sur $K$),
2.  Les $f_i$ commutent deux √† deux : $\forall i \neq j, f_i \circ f_j = f_j \circ f_i$.

**Id√©e de preuve :** Par r√©currence sur $p$ et sur $\dim E$, en utilisant la stabilit√© des sous-espaces propres de $f_1$ par les $f_j$ (qui commutent), puis en diagonalisant simultan√©ment les induits.

**Cotrigonalisation simultan√©e**
**Th√©or√®me :** Les endomorphismes $f_1, \dots, f_p$ sont simultan√©ment trigonalisables si et seulement si :
1.  Chaque $f_i$ est trigonalisable (sur $K$),
2.  Les $f_i$ commutent deux √† deux.

**Application pratique**
Pour deux endomorphismes $f, g$ :
*   $f, g$ diagonalisables et $fg = gf \implies$ base commune de diagonalisation.
*   **En pratique :** diagonaliser $f$ d'abord, puis diagonaliser $g$ restreint √† chaque sous-espace propre de $f$.

### 
**Subtilit√©s**
*   La commutativit√© seule ne suffit pas (sans diagonalisabilit√©).
*   La diagonalisabilit√© seule ne suffit pas (sans commutativit√©) : deux rotations dans $\mathbb{R}^2$ (d'angles diff√©rents de $\pi$) ne commutent pas en g√©n√©ral.
*   Sur $\mathbb{C}$ : tout endomorphisme est trigonalisable, donc pour la cotrigonalisation il suffit de la commutativit√©.

**Pi√®ges classiques**
*   Oublier de v√©rifier la commutativit√© deux √† deux (et pas seulement globale).
*   En dimension infinie, ces th√©or√®mes ne s'appliquent plus directement.

---

## FLASHCARD 152 ‚Äî √Ä conna√Ætre 47 : Caract√©risation des nilpotents par la trace

### RECTO
**√Ä conna√Ætre 47 : Caract√©risation des nilpotents par les traces des puissances**

Soit $K$ un corps de caract√©ristique $0$ (e.g., $K = \mathbb{R}$ ou $\mathbb{C}$), $E$ un $K$-ev de dimension finie $n$, $f \in \mathcal{L}(E)$.

**Question :** √ânoncer la caract√©risation des endomorphismes nilpotents en termes des traces de puissances.

### VERSO
**Th√©or√®me**
Supposons $\text{car}(K) = 0$. Alors :
$$ f \text{ nilpotent} \iff \forall k \in \{1, 2, \dots, n\}, \text{tr}(f^k) = 0 $$

**D√©monstration**
*   $(\Rightarrow)$ : Si $f$ nilpotent, les valeurs propres sont toutes nulles (Prop. 44), donc $\text{tr}(f^k) = \sum_i \lambda_i^k = 0$.
*   $(\Leftarrow)$ : Notons $s_k = \text{tr}(f^k)$ et $\lambda_1, \dots, \lambda_n$ les valeurs propres (dans $\bar{K}$). Les relations de Newton relient les $s_k$ aux fonctions sym√©triques √©l√©mentaires $e_k$ des valeurs propres :
    $$ s_k - e_1 s_{k-1} + e_2 s_{k-2} - \dots + (-1)^{k-1} e_{k-1} s_1 + (-1)^k k e_k = 0 $$
    Si $s_1 = s_2 = \dots = s_n = 0$ et $\text{car}(K) = 0$ (donc $k \neq 0$ dans $K$), on d√©duit par r√©currence $e_1 = e_2 = \dots = e_n = 0$, donc $\chi_f = X^n$, donc $f$ nilpotent.

**Remarque sur la caract√©ristique**
En caract√©ristique $p > 0$, le r√©sultat est faux : par exemple sur $\mathbb{F}_p$, $\text{tr}(f^k) = 0$ pour tout $k$ ne garantit pas la nilpotence.

### 
**Subtilit√©s**
*   La condition $\text{car}(K) = 0$ est essentielle : elle intervient dans les relations de Newton via les facteurs $k$.
*   Il suffit de v√©rifier les puissances $k = 1, \dots, n$ (pas toutes les puissances).
*   Ce r√©sultat est utile pour prouver la nilpotence sans calculer explicitement les puissances de $f$.

**Pi√®ges classiques**
*   Croire que $\text{tr}(f) = 0$ suffit pour conclure √† la nilpotence : faux. Il faut $\text{tr}(f^k) = 0$ pour $k = 1, \dots, n$.
*   En caract√©ristique $p$, les relations de Newton d√©g√©n√®rent pour $k=p$.

---

## FLASHCARD 153 ‚Äî Lemme 5

### RECTO
**Lemme 5 : Lemme de d√©composition (pr√©liminaire √† la d√©composition de Dunford)**

Soit $E$ un $K$-ev de dimension finie $n$, $f \in \mathcal{L}(E)$, et $P, Q \in K[X]$ tels que $P$ et $Q$ sont premiers entre eux (i.e., $\text{pgcd}(P, Q) = 1$).

**Question :** Si $PQ(f) = 0$, que peut-on dire de $\ker(P(f))$ et $\ker(Q(f))$ ?

### VERSO
**Lemme**
Soient $P, Q \in K[X]$ avec $\text{pgcd}(P, Q) = 1$, et $f \in \mathcal{L}(E)$ tel que $PQ(f) = (PQ)(f) = 0$. Alors :
$$ E = \ker(P(f)) \oplus \ker(Q(f)) $$

**D√©monstration**
Par B√©zout : $\exists U, V \in K[X], UP + VQ = 1$. En √©valuant en $f$ :
$$ U(f) \circ P(f) + V(f) \circ Q(f) = id_E $$
*   **Somme :** Tout $x \in E$ s'√©crit $x = U(f)(P(f)(x)) + V(f)(Q(f)(x))$.
    Posons $y = V(f)(Q(f)(x))$. Alors $P(f)(y) = P(f) \circ V(f) \circ Q(f)(x) = V(f) \circ (PQ)(f)(x) = 0$, donc $y \in \ker(P(f))$.
    De m√™me $U(f)(P(f)(x)) \in \ker(Q(f))$.
    Donc $E = \ker(P(f)) + \ker(Q(f))$.
*   **Directe :** Si $x \in \ker(P(f)) \cap \ker(Q(f))$, alors $x = U(f)(P(f)(x)) + V(f)(Q(f)(x)) = 0$.

**G√©n√©ralisation : th√©or√®me de d√©composition des noyaux**
Si $m_f = P_1^{n_1} \dots P_k^{n_k}$ (factorisation en irr√©ductibles deux √† deux premiers entre eux sur $K$), alors :
$$ E = \bigoplus_{i=1}^k \ker(P_i^{n_i}(f)) $$

### 
**Subtilit√©s**
*   Le lemme s'applique sous la seule condition $PQ(f) = 0$ (pas n√©cessairement $m_f = PQ$) et $\text{pgcd}(P, Q) = 1$.
*   Les sous-espaces $\ker(P(f))$ et $\ker(Q(f))$ sont stables par $f$.
*   C'est le lemme fondamental pour la d√©composition de Dunford et la r√©duction de Jordan.

**Pi√®ges classiques**
*   Oublier la condition $\text{pgcd}(P, Q) = 1$ : sans cela, la somme n'est pas directe.
*   Appliquer le lemme avec $P = (X - \lambda)$ et $Q = \chi_f / (X - \lambda)^{m_a(\lambda)}$ pour isoler l'espace caract√©ristique.

---

## FLASHCARD 154 ‚Äî Lemme 6 : Racines du polyn√¥me minimal

### RECTO
**Lemme 6 : Racines du polyn√¥me minimal**

Soit $E$ un $K$-ev de dimension finie $n$, $f \in \mathcal{L}(E)$.

**Question :** Montrer que $\lambda \in K$ est valeur propre de $f$ si et seulement si $\lambda$ est racine de $m_f$. Autrement dit : $Sp(f)$ est exactement l'ensemble des racines de $m_f$ dans $K$.

### VERSO
**√ânonc√©**
$$ \lambda \in Sp(f) \iff m_f(\lambda) = 0 $$
i.e., les racines de $m_f$ dans $K$ sont exactement les valeurs propres de $f$.

**D√©monstration**
*   $(\Rightarrow)$ : Soit $\lambda$ valeur propre, $x \neq 0$ vecteur propre : $f(x) = \lambda x$. Alors $m_f(f)(x) = m_f(\lambda) x$ (car $f^k(x) = \lambda^k x$). Comme $m_f(f) = 0$ et $x \neq 0$, on a $m_f(\lambda) = 0$.
*   $(\Leftarrow)$ : Soit $\lambda$ racine de $m_f$. √âcrivons $m_f(X) = (X - \lambda) Q(X)$ avec $Q \in K[X]$.
    Comme $m_f$ est le minimal, $Q(f) \neq 0$. Donc $\exists x \neq 0 : Q(f)(x) \neq 0$.
    Posons $y = Q(f)(x) \neq 0$. Alors :
    $$ (f - \lambda id)(y) = (f - \lambda id) \circ Q(f)(x) = m_f(f)(x) = 0 $$
    Donc $f(y) = \lambda y$ et $y \neq 0$ : $\lambda$ est valeur propre. $\square$

**Corollaire**
$m_f$ et $\chi_f$ ont les m√™mes racines dans $K$ (les valeurs propres de $f$).

### 
**Subtilit√©s**
*   Ce lemme est fondamental : il justifie pourquoi $m_f$ contient exactement les m√™me facteurs lin√©aires que $\chi_f$, juste avec des multiplicit√©s potentiellement plus petites.
*   La d√©monstration de $(\Leftarrow)$ utilise la minimalit√© de $m_f$ : si $(X - \lambda) \mid m_f$ mais $Q = m_f / (X - \lambda)$ n'annule pas $f$, c'est qu'on peut "fabriquer" un vecteur propre.

**Pi√®ges classiques**
*   Ne pas confondre "racine de $m_f$" et "racine de $\chi_f$" : elles co√Øncident, mais les multiplicit√©s diff√®rent.
*   Ce lemme ne parle que des racines dans $K$, pas dans $\bar{K}$.

---

Voici la suite et fin de la r√©√©criture de votre fichier, en reprenant √† la **Flashcard 155**.

---

## FLASHCARD 155 ‚Äî √Ä conna√Ætre 48 : Matrice compagnon

### RECTO
**√Ä conna√Ætre 48 : Matrice compagnon**

Soit $P(X) = X^n + a_{n-1} X^{n-1} + \dots + a_1 X + a_0 \in K[X]$ un polyn√¥me unitaire de degr√© $n$.

**Question :** D√©finir la matrice compagnon de $P$. Quel est son polyn√¥me caract√©ristique ? Son polyn√¥me minimal ?

### VERSO
**D√©finition**
La matrice compagnon de $P$ est :
$$ C(P) = \begin{pmatrix} 0 & 0 & \dots & 0 & -a_0 \\ 1 & 0 & \dots & 0 & -a_1 \\ 0 & 1 & \dots & 0 & -a_2 \\ \vdots & \ddots & \ddots & \vdots & \vdots \\ 0 & 0 & \dots & 1 & -a_{n-1} \end{pmatrix} \in M_n(K) $$
(La derni√®re colonne contient les coefficients de $-P$ √† partir du degr√© $0$.)

**Propri√©t√©s fondamentales**
**Th√©or√®me :** $\chi_{C(P)} = P$ et $m_{C(P)} = P$.

i.e., la matrice compagnon est un exemple canonique o√π polyn√¥me minimal = polyn√¥me caract√©ristique.

**D√©monstration :**
*   $\chi_{C(P)} = P$ : par d√©veloppement direct du d√©terminant $\det(XI_n - C(P))$ le long de la derni√®re colonne (r√©currence).
*   $m_{C(P)} = P$ : puisque $\deg m_{C(P)} \le n = \deg \chi_{C(P)} = \deg P$ et $m_{C(P)} \mid \chi_{C(P)} = P$. De plus, si on note $(e_1, \dots, e_n)$ la base canonique, on a $C(P)e_k = e_{k+1}$ pour $k < n$. Ainsi la famille $(e_1, C(P)e_1, \dots, C(P)^{n-1}e_1)$ est libre (c'est la base canonique). Aucun polyn√¥me de degr√© $< n$ ne peut annuler $C(P)$ (sinon il annulerait $e_1$ de fa√ßon non triviale). Donc $\deg m_{C(P)} = n$, d'o√π $m_{C(P)} = P$.

**Application**
Tout polyn√¥me unitaire de degr√© $n$ est le polyn√¥me minimal (et caract√©ristique) d'une matrice $n \times n$ : il suffit de prendre sa matrice compagnon.

### 
**Subtilit√©s**
*   La matrice compagnon r√©alise l'isomorphisme $K[X]/(P) \simeq K^n$ comme $K[X]$-modules, o√π $X$ agit par $C(P)$.
*   Elle est utilis√©e dans la preuve du th√©or√®me de Cayley-Hamilton et dans la r√©duction des matrices.
*   $m_{C(P)} = \chi_{C(P)} = P$ : c'est l'un des rares cas o√π polyn√¥me minimal et caract√©ristique co√Øncident de fa√ßon garantie.

**Pi√®ges classiques**
*   La convention peut varier (lignes/colonnes) : bien pr√©ciser la convention utilis√©e.
*   Ne pas confondre "matrice compagnon de $P$" et "matrice d'un endomorphisme dont $P$ est un annulateur quelconque" : la matrice compagnon a $P$ comme polyn√¥me minimal.

---

## FLASHCARD 156 ‚Äî Th√©or√®me 56 : Cayley-Hamilton

### RECTO
**Th√©or√®me 56 : Th√©or√®me de Cayley-Hamilton**

Soit $K$ un corps, $E$ un $K$-espace vectoriel de dimension finie $n \ge 1$, $f \in \mathcal{L}(E)$ et $A = \text{Mat}_B(f)$ sa matrice dans une base $B$.

**Question :** √ânoncer le th√©or√®me de Cayley-Hamilton avec hypoth√®ses exactes et conclusion. Donner une esquisse de preuve rigoureuse.

### VERSO
**Hypoth√®ses**
*   $K$ corps quelconque
*   $A \in M_n(K)$
*   $\chi_A(X) = \det(XI_n - A)$ le polyn√¥me caract√©ristique de $A$

**√ânonc√© formel**
**Th√©or√®me de Cayley-Hamilton :**
$$ \chi_A(A) = 0_{M_n(K)} $$

i.e., toute matrice carr√©e est annul√©e par son propre polyn√¥me caract√©ristique.

En termes d'endomorphismes : $\chi_f(f) = 0_{\mathcal{L}(E)}$.

**Corollaires imm√©diats**
*   $m_f \mid \chi_f$ (le polyn√¥me minimal divise le polyn√¥me caract√©ristique).
*   $\deg(m_f) \le n$.
*   $f^n$ est combinaison lin√©aire de $id, f, \dots, f^{n-1}$ (expression de Cayley-Hamilton pour le calcul de puissances).

**D√©monstration rigoureuse (m√©thode de la matrice adjointe)**
Soit $B(X) = XI_n - A \in M_n(K[X])$. Consid√©rons la matrice adjointe (transpos√©e de la comatrice) :
$$ \text{adj}(B(X)) \in M_n(K[X]) $$

Par d√©finition de l'adjointe : $B(X) \cdot \text{adj}(B(X)) = \det(B(X)) \cdot I_n = \chi_A(X) I_n$.

Les coefficients de $\text{adj}(B(X))$ sont des polyn√¥mes en $X$ de degr√© $\le n-1$ :
$$ \text{adj}(B(X)) = C_{n-1} X^{n-1} + C_{n-2} X^{n-2} + \dots + C_0 $$
avec $C_k \in M_n(K)$. En d√©veloppant :
$$ (XI_n - A)(C_{n-1}X^{n-1} + \dots + C_0) = \chi_A(X) I_n $$

En identifiant les coefficients de $X^k$ des deux membres, on obtient $n+1$ relations matricielles. En multipliant la relation de $X^k$ par $A^k$ et en sommant, tout se t√©lescope et donne $\chi_A(A) = 0$. $\square$

**Mise en garde :** La substitution na√Øve "$X=A$ dans $\det(XI - A) = 0$" est fausse : on substitue une matrice √† une variable scalaire dans un d√©terminant scalaire, ce qui n'a pas de sens direct. La preuve ci-dessus est la seule correcte.

### 
**Subtilit√©s**
*   L'erreur classique : "Puisque $\det(\lambda I - A) = \chi_A(\lambda) = 0$ pour $\lambda$ valeur propre, en mettant $A$ √† la place de $\lambda$, on obtient $\chi_A(A) = 0$." Ce raisonnement est faux.
*   La preuve correcte travaille dans $M_n(K[X])$ (matrices √† coefficients polynomiaux) et utilise l'identit√© de l'adjointe avant de sp√©cialiser.
*   Sur un corps quelconque (m√™me de caract√©ristique $p$), le th√©or√®me reste vrai.

**Pi√®ges classiques**
*   Confondre $\chi_A(A) = 0$ (Cayley-Hamilton, vrai) avec $\chi_A(\lambda) = 0 \implies \lambda$ v.p. (d√©finition des valeurs propres, diff√©rent).
*   Utiliser Cayley-Hamilton pour calculer $A^{-1}$ : si $\chi_A = X^n + a_{n-1}X^{n-1} + \dots + a_0$ avec $a_0 \neq 0$, alors $A^{-1} = -\frac{1}{a_0}(A^{n-1} + a_{n-1}A^{n-2} + \dots + a_1 I_n)$.
*   En dimension infinie, Cayley-Hamilton n'a pas d'analogue direct.

---

## FLASHCARD 157 ‚Äî Lemme 7 : D√©composition des noyaux

### RECTO
**Lemme 7 (de d√©composition des noyaux)**

Soit $E$ un $K$-ev de dimension finie, $f \in \mathcal{L}(E)$.

Soit $P_1, \dots, P_k \in K[X]$ des polyn√¥mes deux √† deux premiers entre eux, et $P = P_1 \dots P_k$.

**Question :** √ânoncer le lemme de d√©composition des noyaux (th√©or√®me chinois des endomorphismes).

### VERSO
**√ânonc√© formel**
Si $P(f) = 0$ et $P = P_1 \dots P_k$ avec $\text{pgcd}(P_i, P_j) = 1$ pour $i \neq j$, alors :
$$ E = \bigoplus_{i=1}^k \ker(P_i(f)) $$

**Propri√©t√©s suppl√©mentaires**
*   Chaque $F_i = \ker(P_i(f))$ est stable par $f$.
*   $f|_{F_i}$ a pour polyn√¥me minimal $P_i^{n_i}$ o√π $P_i^{n_i} \mid P$ (√† pr√©ciser selon le contexte).
*   La projection sur $F_i$ parall√®lement √† $\bigoplus_{j \neq i} F_j$ est un polyn√¥me en $f$.

**D√©monstration (r√©currence sur $k$)**
Cas $k=2$ : B√©zout donne $UP_1 + VP_2 = 1$ (avec $P_1P_2(f) = 0$). Alors $id = U(f)P_1(f) + V(f)P_2(f)$, ce qui donne la d√©composition $E = \ker P_1(f) \oplus \ker P_2(f)$ (Lemme 5).

R√©currence : $P_1$ et $P_2 \dots P_k$ sont premiers entre eux (par Gauss), donc on d√©compose d'abord $E = \ker P_1(f) \oplus \ker(P_2 \dots P_k)(f)$, puis on applique l'hypoth√®se de r√©currence √† $\ker(P_2 \dots P_k)(f)$.

**Application : D√©composition de Dunford (esquisse)**
Si $\chi_f = \prod_{i=1}^k (X - \lambda_i)^{n_i}$ (scind√© sur $K$), les polyn√¥mes $(X - \lambda_i)^{n_i}$ sont deux √† deux premiers entre eux, d'o√π :
$$ E = \bigoplus_{i=1}^k \ker(f - \lambda_i id)^{n_i} $$
Ce sont les espaces caract√©ristiques de $f$.

### 
**Subtilit√©s**
*   Il suffit que $P(f) = 0$ (pas n√©cessairement $P = m_f$) : n'importe quel annulateur scind√© en facteurs premiers entre eux convient.
*   Les projections $\pi_i$ sur $\ker P_i(f)$ sont des polyn√¥mes en $f$ : $\pi_i = Q_i(f)$ o√π $Q_i$ est construit par B√©zout.
*   Le lemme est la clef de la d√©composition de Dunford et de la r√©duction de Jordan.

**Pi√®ges classiques**
*   Oublier que les $P_i$ doivent √™tre deux √† deux premiers entre eux, pas seulement sans facteur commun global.
*   Si $P = m_f$, les $\ker P_i(f)$ sont exactement les espaces caract√©ristiques et leur d√©composition est intrins√®que.

---

## FLASHCARD 158 ‚Äî Proposition 45

### RECTO
**Proposition 45 : Sous-espaces caract√©ristiques ‚Äî propri√©t√©s**

Soit $E$ un $K$-ev de dimension finie $n$, $f \in \mathcal{L}(E)$, $\chi_f$ scind√© sur $K$ avec valeurs propres $\lambda_1, \dots, \lambda_k$ de multiplicit√©s $n_1, \dots, n_k$.

**Question :** D√©finir les sous-espaces caract√©ristiques de $f$ et en √©noncer les propri√©t√©s (dimension, lien avec $\chi_f$, lien avec les espaces propres).

### VERSO
**D√©finition**
Le sous-espace caract√©ristique associ√© √† $\lambda_i$ est :
$$ C_{\lambda_i}(f) = \ker(f - \lambda_i id)^{n_i} = \ker(f - \lambda_i id)^n $$
(les deux d√©finitions co√Øncident, et il suffit de prendre une puissance $\ge n_i$).

**Propri√©t√©s**
**Proposition :**
*   $\dim C_{\lambda_i}(f) = n_i$ (la multiplicit√© alg√©brique).
*   $C_{\lambda_i}(f)$ est stable par $f$.
*   $E_{\lambda_i}(f) = \ker(f - \lambda_i id) \subset C_{\lambda_i}(f)$ (l'espace propre est inclus dans le caract√©ristique).
*   $E = \bigoplus_{i=1}^k C_{\lambda_i}(f)$ (d√©composition de Dunford des noyaux).
*   L'endomorphisme induit $(f - \lambda_i id)|_{C_{\lambda_i}(f)}$ est nilpotent d'indice $\le n_i$.

**D√©composition de Dunford**
**Cons√©quence :** Sur chaque $C_{\lambda_i}(f)$, on peut √©crire $f = \lambda_i id + (f - \lambda_i id)$ comme somme d'un scalaire et d'un nilpotent. Globalement :
$$ f = D + N $$
o√π $D$ est diagonalisable, $N$ nilpotent, $D \circ N = N \circ D$ (d√©composition de Dunford).

### 
**Subtilit√©s**
*   $\dim C_{\lambda_i}(f) = n_i$ (multiplicit√© alg√©brique), tandis que $\dim E_{\lambda_i}(f) = m_g(\lambda_i) \le n_i$.
*   La d√©composition $E = \bigoplus C_{\lambda_i}$ n'est possible que si $\chi_f$ est scind√© sur $K$.
*   L'indice de nilpotence de $(f - \lambda_i id)|_{C_{\lambda_i}(f)}$ est li√© √† la taille des blocs de Jordan associ√©s √† $\lambda_i$.

**Pi√®ges classiques**
*   Confondre espace propre ($\ker(f - \lambda id)$) et espace caract√©ristique ($\ker(f - \lambda id)^{n_i}$).
*   La d√©composition $f = D + N$ de Dunford est unique sous les conditions de commutativit√© et de nilpotence/diagonalisabilit√©.

---

## FLASHCARD 159 ‚Äî Th√©or√®me 57 : Th√©or√®me de Jordan (d√©composition de Jordan)

### RECTO
**Th√©or√®me 57 : D√©composition de Jordan**

Soit $K$ un corps alg√©briquement clos (e.g., $K = \mathbb{C}$), $E$ un $K$-ev de dimension finie $n$, $f \in \mathcal{L}(E)$.

**Question :** √ânoncer le th√©or√®me de r√©duction de Jordan : existence d'une base de Jordan, forme de la matrice de Jordan, unicit√©.

### VERSO
**Th√©or√®me**
Soit $K$ alg√©briquement clos. Tout endomorphisme $f \in \mathcal{L}(E)$ admet une base de Jordan, i.e., une base dans laquelle sa matrice est de la forme :
$$ J = \text{diag}(J_{n_1}(\lambda_1), J_{n_2}(\lambda_2), \dots, J_{n_r}(\lambda_r)) $$
o√π chaque bloc de Jordan est :
$$ J_k(\lambda) = \begin{pmatrix} \lambda & 1 & 0 & \cdots & 0 \\ 0 & \lambda & 1 & \cdots & 0 \\ \vdots & \ddots & \ddots & \ddots & \vdots \\ 0 & 0 & \cdots & \lambda & 1 \\ 0 & 0 & \cdots & 0 & \lambda \end{pmatrix} \in M_k(K) $$

**Unicit√©**
La forme de Jordan est unique √† permutation des blocs pr√®s : les blocs $J_{n_i}(\lambda_i)$ sont d√©termin√©s uniquement (leurs tailles et valeurs propres).

**Lien avec les invariants**
*   Les valeurs propres $\lambda_i$ sont les racines de $\chi_f$ (avec multiplicit√©s).
*   Le nombre de blocs de Jordan associ√©s √† $\lambda = \dim \ker(f - \lambda id) = m_g(\lambda)$.
*   La taille du plus grand bloc de Jordan associ√© √† $\lambda =$ indice de nilpotence de $(f - \lambda id)|_{C_\lambda}$.
*   $f$ diagonalisable $\iff$ tous les blocs sont de taille 1.

**Structure des blocs**
Sur chaque bloc $J_k(\lambda)$ : la restriction de $f$ √† l'espace correspondant v√©rifie $(f - \lambda id)^k = 0$ mais $(f - \lambda id)^{k-1} \neq 0$.

### 
**Subtilit√©s**
*   $K$ alg√©briquement clos est n√©cessaire pour que $\chi_f$ soit scind√©. Sur $\mathbb{R}$, la forme de Jordan n'existe pas toujours (mais il existe une forme r√©elle de Jordan avec des blocs $2 \times 2$ pour les valeurs propres complexes conjugu√©es).
*   L'unicit√© est un th√©or√®me non trivial. Elle se d√©duit des invariants : nombre de blocs de chaque taille pour chaque valeur propre.
*   La forme de Jordan est la "forme canonique" pour la similitude sur un corps alg√©briquement clos.

**Programme MP**
En MP, la forme de Jordan est au programme sur $\mathbb{C}$ (ou plus g√©n√©ralement sur un corps alg√©briquement clos). La d√©monstration compl√®te de l'unicit√© est hors programme strict, mais l'√©nonc√© et l'utilisation sont exigibles.
Utilisation pratique : calculer des puissances de matrices, r√©soudre des √©quations diff√©rentielles, √©tudier $e^{tA}$.

**Pi√®ges classiques**
*   $f$ trigonalisable $\not\Rightarrow$ r√©ductible en Jordan sur $\mathbb{R}$ (manque de valeurs propres r√©elles).
*   Confondre "nombre de blocs" ($= m_g$) et "taille des blocs" ($=$ ordre de nilpotence).
*   La forme de Jordan d√©pend de $K$ : sur $\mathbb{C}$ elle existe toujours, sur $\mathbb{R}$ pas forc√©ment.

---

## FLASHCARD 160 ‚Äî Proposition 46 : Induit d'un endomorphisme diagonalisable

### RECTO
**Proposition 46 : Induit d'un endomorphisme diagonalisable sur un sous-espace stable**

Soit $E$ un $K$-ev de dimension finie, $f \in \mathcal{L}(E)$ diagonalisable, et $F$ un sous-espace de $E$ stable par $f$.

**Question :** Montrer que l'endomorphisme induit $f|_F$ est diagonalisable.

### VERSO
**√ânonc√©**
Si $f$ est diagonalisable et $F$ est un sous-espace stable par $f$, alors $f|_F : F \to F$ est diagonalisable.

**D√©monstration**
**M√©thode 1 (via le polyn√¥me minimal) :**
$f$ diagonalisable $\implies m_f$ est scind√© √† racines simples : $m_f = \prod_{i=1}^k (X - \lambda_i)$.
Comme $m_f(f) = 0$ et $F$ est stable par $f$ : $m_f(f|_F) = (m_f(f))|_F = 0$.
Donc $m_{f|_F} \mid m_f$, et comme $m_f$ est scind√© √† racines simples, $m_{f|_F}$ l'est aussi.
Donc $f|_F$ est diagonalisable. $\square$

**M√©thode 2 (via les bases) :**
$f$ diagonalisable $\implies E = \bigoplus_\lambda E_\lambda(f)$. Chaque $E_\lambda(f)$ est stable par $f$ (car $f$ agit comme $\lambda \cdot id$ dessus). Donc $F = \bigoplus_\lambda (F \cap E_\lambda(f))$ (somme directe car $F$ est stable), et $F \cap E_\lambda(f) = E_\lambda(f|_F)$. Donc $F$ est somme directe de sous-espaces propres de $f|_F$.

### 
**Subtilit√©s**
*   La m√©thode 1 est la plus √©l√©gante et g√©n√©rale : elle utilise que le polyn√¥me minimal de l'induit divise celui de l'endomorphisme.
*   La m√©thode 2 donne plus d'informations : $Sp(f|_F) \subset Sp(f)$. En particulier, les valeurs propres de $f|_F$ sont parmi celles de $f$.

**Pi√®ges classiques**
*   La r√©ciproque est fausse : si $f|_F$ est diagonalisable pour tout sous-espace stable $F$, il n'en d√©coule pas forc√©ment que $f$ est diagonalisable.
*   Bien v√©rifier la stabilit√© de $F$ avant d'appliquer la proposition.

---

## FLASHCARD 161 ‚Äî Proposition 47

### RECTO
**Proposition 47 : Caract√©risation matricielle de la diagonalisabilit√©**

Soit $A \in M_n(K)$.

**Question :** Donner des conditions √©quivalentes pour que $A$ soit diagonalisable sur $K$. En particulier, √©noncer la condition en termes de similitude et de matrice diagonale.

### VERSO
**√âquivalences**
Les assertions suivantes sont √©quivalentes :

(i) $A$ est diagonalisable sur $K$ : $\exists P \in GL_n(K), P^{-1}AP = D$ diagonale.

(ii) Il existe une base de $K^n$ form√©e de vecteurs propres de $A$.

(iii) $\chi_A$ est scind√© sur $K$ et $\forall \lambda \in Sp(A), m_g(\lambda) = m_a(\lambda)$.

(iv) $m_A$ est scind√© √† racines simples sur $K$.

**Proc√©d√© de diagonalisation**
1.  Calculer $\chi_A(X)$ et le factoriser sur $K$.
2.  Pour chaque valeur propre $\lambda_i$ : calculer une base de $\ker(A - \lambda_i I_n)$.
3.  V√©rifier que $\sum \dim \ker(A - \lambda_i I) = n$.
4.  La matrice de passage $P$ a pour colonnes les vecteurs propres.
5.  $P^{-1}AP = \text{diag}(\lambda_1, \dots, \lambda_n)$ (avec r√©p√©titions selon les multiplicit√©s).

**R√©sultats sur les puissances**
Si $A = P D P^{-1}$ avec $D = \text{diag}(d_1, \dots, d_n)$, alors :
$$ A^k = P D^k P^{-1}, \quad D^k = \text{diag}(d_1^k, \dots, d_n^k) $$

### 
**Subtilit√©s**
*   La diagonalisation d√©pend du corps $K$ : une matrice r√©elle peut √™tre diagonalisable sur $\mathbb{C}$ mais pas sur $\mathbb{R}$.
*   La matrice de passage $P$ n'est pas unique : elle d√©pend du choix des vecteurs propres (normalisation, ordre).

**Pi√®ges classiques**
*   Confondre $P^{-1}AP = D$ et $PAP^{-1} = D$ : les deux d√©finitions coexistent selon les auteurs.
*   Oublier de v√©rifier que les colonnes de $P$ forment bien une base (i.e., $P$ inversible).
*   En calcul : ne pas oublier de calculer $P^{-1}$ pour obtenir la d√©composition compl√®te.

---

## FLASHCARD 162 ‚Äî √Ä conna√Ætre 49 : Diagonalisation √† $\varepsilon$-pr√®s

### RECTO
**√Ä conna√Ætre 49 : Diagonalisation √† $\varepsilon$-pr√®s (densit√© des matrices diagonalisables)**

Soit $K = \mathbb{C}$ (ou tout corps infini), $n \ge 1$.

**Question :** √ânoncer le th√©or√®me de densit√© des matrices diagonalisables dans $M_n(\mathbb{C})$, et en donner une cons√©quence pratique (approximation).

### VERSO
**Th√©or√®me**
L'ensemble des matrices diagonalisables sur $\mathbb{C}$ est dense dans $M_n(\mathbb{C})$ (pour toute norme).

Autrement dit : pour toute $A \in M_n(\mathbb{C})$ et tout $\varepsilon > 0$, il existe $A_\varepsilon \in M_n(\mathbb{C})$ diagonalisable telle que $\|A - A_\varepsilon\| < \varepsilon$.

**Id√©e de construction**
Si $A$ est trigonalisable (ce qui est toujours le cas sur $\mathbb{C}$), on √©crit $A = PTP^{-1}$ avec $T$ triangulaire sup√©rieure. On perturbe l√©g√®rement les entr√©es diagonales de $T$ pour les rendre distinctes : $T_\varepsilon = T + \varepsilon' D$ avec $D$ choisie pour rendre les valeurs propres distinctes. Alors $A_\varepsilon = P T_\varepsilon P^{-1}$ est diagonalisable (valeurs propres distinctes) et $\|A - A_\varepsilon\| \to 0$.

**Cons√©quences pratiques**
*   **Identit√©s polynomiales :** Si une identit√© $P(A) = 0$ est v√©rifi√©e pour toutes les matrices diagonalisables, elle est vraie pour toutes les matrices (par densit√© et continuit√©).
*   **det et tr :** Des formules prouv√©es sur les matrices diagonalisables s'√©tendent par densit√©/continuit√©.
*   **Commutant :** L'√©tude du commutant d'une matrice peut se ramener au cas diagonalisable par densit√©.

**Sur $\mathbb{R}$**
Sur $\mathbb{R}$, les matrices diagonalisables (sur $\mathbb{R}$) ne sont pas denses dans $M_n(\mathbb{R})$ en g√©n√©ral (les matrices sans valeurs propres r√©elles forment un ouvert non vide pour $n \ge 2$). Mais les matrices diagonalisables sur $\mathbb{C}$ (= trigonalisables sur $\mathbb{C}$) restent denses.

### 
**Subtilit√©s**
*   Ce r√©sultat est utilis√© pour transf√©rer des propri√©t√©s du cas diagonalisable au cas g√©n√©ral, par un argument de densit√©/continuit√©.
*   La densit√© est relative √† la topologie de $M_n(\mathbb{C}) \simeq \mathbb{C}^{n^2}$ (toutes les normes sont √©quivalentes en dimension finie).
*   Sur $\mathbb{R}$, il faut √™tre plus prudent : les matrices √† spectre r√©el simple (diagonalisables sur $\mathbb{R}$) forment un sous-ensemble ouvert mais pas dense.

**Pi√®ges classiques**
*   Ne pas confondre "dense sur $\mathbb{C}$" et "dense sur $\mathbb{R}$".
*   La perturbation doit √™tre faite de fa√ßon √† pr√©server la trigonalisabilit√© (sur $\mathbb{C}$, c'est automatique).
*   En utilisant la densit√© pour prouver une identit√©, v√©rifier que l'identit√© est continue en les coefficients de la matrice.

---

## FLASHCARD 163 ‚Äî √Ä conna√Ætre 50 : D√©composition de Dunford

### RECTO
**√Ä conna√Ætre 50 : D√©composition de Dunford**

Soit $K$ un corps, $E$ un $K$-ev de dimension finie $n$, $f \in \mathcal{L}(E)$. On suppose $\chi_f$ scind√© sur $K$.

**Question :** √ânoncer le th√©or√®me de d√©composition de Dunford de $f = D + N$. Pr√©ciser les propri√©t√©s de $D$ et $N$, leur commutativit√©, et leur expression en termes de polyn√¥mes en $f$.

### VERSO
**Th√©or√®me de Dunford**
Sous l'hypoth√®se que $\chi_f$ est scind√© sur $K$, il existe un unique couple $(D, N)$ d'endomorphismes de $E$ tel que :

1.  $f = D + N$
2.  $D$ est diagonalisable (sur $K$)
3.  $N$ est nilpotent
4.  $D$ et $N$ commutent : $D \circ N = N \circ D$

De plus, $D$ et $N$ sont des polyn√¥mes en $f$ (i.e., $D = P(f)$ et $N = Q(f)$ pour certains $P, Q \in K[X]$).

**Construction**
Soit $\chi_f = \prod_{i=1}^k (X - \lambda_i)^{n_i}$ (valeurs propres distinctes $\lambda_1, \dots, \lambda_k$).

Par le lemme de d√©composition des noyaux : $E = \bigoplus_{i=1}^k C_{\lambda_i}$ o√π $C_{\lambda_i} = \ker(f - \lambda_i id)^{n_i}$.

Notons $\pi_i$ la projection sur $C_{\lambda_i}$ parall√®lement aux autres (polyn√¥me en $f$). Alors :
$$ D = \sum_{i=1}^k \lambda_i \pi_i, \quad N = f - D = \sum_{i=1}^k (f - \lambda_i id) \circ \pi_i $$

$D$ est diagonalisable (agit comme $\lambda_i$ sur $C_{\lambda_i}$), $N$ est nilpotent (agit comme $(f - \lambda_i id)|_{C_{\lambda_i}}$ qui est nilpotent).

**Unicit√©**
Si $f = D' + N'$ avec $D'$ diagonalisable, $N'$ nilpotent, $D'N' = N'D'$ : alors $D' = D$ et $N' = N$.

### 
**Subtilit√©s**
*   **Hypoth√®se cl√© :** $\chi_f$ scind√© sur $K$ est indispensable. Sur $\mathbb{R}$, si $f$ a des valeurs propres complexes non r√©elles, la d√©composition de Dunford n'existe pas sur $\mathbb{R}$.
*   $D$ et $N$ sont des polyn√¥mes en $f$ : cela implique qu'ils commutent avec tout endomorphisme qui commute avec $f$.
*   La d√©composition de Dunford g√©n√©ralise la diagonalisation : si $f$ est d√©j√† diagonalisable, $N=0$.

**Application**
*   Calcul de $f^k$ : $f^k = (D+N)^k = \sum_{j=0}^{\nu-1} \binom{k}{j} D^{k-j} N^j$ (car $D$ et $N$ commutent, et $N^\nu = 0$).
*   Exponentielle : $e^{tA} = e^{tD} e^{tN}$ o√π $e^{tN} = \sum_{j=0}^{\nu-1} \frac{t^j}{j!} N^j$ (s√©rie finie).

**Pi√®ges classiques**
*   Confondre d√©composition de Dunford (sur $K$ si $\chi_f$ scind√©) et forme de Jordan (sur corps alg√©briquement clos, donne plus d'informations).
*   Oublier l'unicit√© : il n'y a qu'une seule d√©composition de Dunford.
*   En exam : utiliser la d√©composition de Dunford pour calculer des puissances ou des exponentielles de matrices.

---

## FLASHCARD 164 ‚Äî Th√©or√®me 58 : Repr√©sentation des formes lin√©aires (espace euclidien)

### RECTO
**Th√©or√®me 58 : Th√©or√®me de repr√©sentation des formes lin√©aires (Riesz en dimension finie)**

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace euclidien (resp. hermitien) de dimension finie $n \ge 1$.

**Question :** √ânoncer le th√©or√®me de repr√©sentation des formes lin√©aires continues sur $E$ par un produit scalaire. Pr√©ciser les hypoth√®ses et la conclusion.

### VERSO
**Hypoth√®ses**
*   $(E, \langle \cdot, \cdot \rangle)$ espace euclidien ($\mathbb{R}$-ev de dimension finie muni d'un produit scalaire) ou hermitien ($\mathbb{C}$-ev de dimension finie muni d'un produit hermitien)
*   $\varphi : E \to \mathbb{K}$ forme lin√©aire (resp. semi-lin√©aire dans le cas hermitien)

**√ânonc√© formel**
**Th√©or√®me :** Il existe un unique vecteur $a \in E$ tel que :
$$ \forall x \in E, \quad \varphi(x) = \langle x, a \rangle $$

**D√©monstration**
*   **Existence :** Soit $B = (e_1, \dots, e_n)$ une base orthonorm√©e de $E$. Pour tout $x = \sum x_i e_i$ :
    $$ \varphi(x) = \sum_{i=1}^n x_i \varphi(e_i) $$
    Posons $a = \sum_{i=1}^n \overline{\varphi(e_i)} e_i$ (dans le cas hermitien, $\varphi(e_i)$ dans le cas r√©el). Alors $\langle x, a \rangle = \sum x_i \overline{\langle e_i, a \rangle}$... [calcul direct montre $\varphi(x) = \langle x, a \rangle$].
*   **Unicit√© :** Si $\langle x, a \rangle = \langle x, a' \rangle$ pour tout $x$, alors $\langle x, a - a' \rangle = 0$ pour tout $x$, donc $a = a'$.

**Isomorphisme**
L'application $\Phi : E \to E^*, a \mapsto (x \mapsto \langle x, a \rangle)$ est un isomorphisme ($\mathbb{R}$-lin√©aire dans le cas r√©el, $\mathbb{R}$-lin√©aire ou anti-lin√©aire dans le cas hermitien).

### 
**Subtilit√©s**
*   En dimension finie, toutes les formes lin√©aires sont automatiquement continues, donc la continuit√© n'est pas une hypoth√®se suppl√©mentaire.
*   **Dans le cas hermitien :** $\varphi(x) = \langle x, a \rangle$ est $\mathbb{C}$-lin√©aire en $x$ (si le produit hermitien est lin√©aire √† gauche) ou $\mathbb{C}$-antilin√©aire selon la convention. Bien pr√©ciser la convention.
*   Le th√©or√®me de Riesz en dimension infinie (espaces de Hilbert) est beaucoup plus profond et n√©cessite la compl√©tude.

**Pi√®ges classiques**
*   En dimension infinie : le th√©or√®me de Riesz pour les espaces de Hilbert n√©cessite l'hypoth√®se que $\varphi$ est continue (i.e., born√©e). En dimension finie, c'est automatique.
*   Confusion dans le cas hermitien : $\varphi(x) = \langle x, a \rangle$ ou $\langle a, x \rangle$ selon la convention du produit hermitien (lin√©aire √† gauche ou √† droite).

---

## FLASHCARD 165 ‚Äî Proposition 48 : Gram-Schmidt

### RECTO
**Proposition 48 : Proc√©d√© d'orthonormalisation de Gram-Schmidt**

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace euclidien (ou hermitien) de dimension finie, et $(e_1, \dots, e_p)$ une famille libre de $E$.

**Question :** √ânoncer le proc√©d√© de Gram-Schmidt. Donner les formules explicites et la propri√©t√© fondamentale.

### VERSO
**√ânonc√©**
Il existe une famille orthonorm√©e $(f_1, \dots, f_p)$ telle que :
$$ \forall k \in \llbracket 1, p \rrbracket, \quad \text{Vect}(f_1, \dots, f_k) = \text{Vect}(e_1, \dots, e_k) $$

**Algorithme de Gram-Schmidt**
*   **Initialisation :** $u_1 = e_1$, $f_1 = \frac{u_1}{\|u_1\|}$.
*   **R√©currence :** Pour $k = 2, \dots, p$ :
    $$ u_k = e_k - \sum_{j=1}^{k-1} \langle e_k, f_j \rangle f_j $$
    $$ f_k = \frac{u_k}{\|u_k\|} $$
    (On soustrait la projection de $e_k$ sur $\text{Vect}(f_1, \dots, f_{k-1})$.)

**Justification que $u_k \neq 0$ :** Puisque $(e_1, \dots, e_k)$ est libre, $e_k \notin \text{Vect}(e_1, \dots, e_{k-1}) = \text{Vect}(f_1, \dots, f_{k-1})$, donc $u_k \neq 0$.

**Propri√©t√©s**
*   $(f_1, \dots, f_p)$ est orthonorm√©e : $\langle f_i, f_j \rangle = \delta_{ij}$.
*   $\text{Vect}(f_1, \dots, f_k) = \text{Vect}(e_1, \dots, e_k)$ pour tout $k$.
*   La matrice de passage de $(e_i)$ √† $(f_i)$ est triangulaire sup√©rieure √† diagonale strictement positive.

### 
**Subtilit√©s**
*   Gram-Schmidt est constructif et donne une preuve de l'existence de bases orthonorm√©es dans tout espace euclidien de dimension finie.
*   La matrice de passage triangulaire sup√©rieure donne la d√©composition QR : $A = QR$ o√π $Q$ est orthogonale et $R$ triangulaire sup√©rieure.
*   Dans le cas hermitien, les formules sont identiques avec le produit hermitien.

**Pi√®ges classiques**
*   Ne pas oublier de normaliser : $f_k = u_k / \|u_k\|$, ne pas arr√™ter √† $u_k$.
*   V√©rifier que $u_k \neq 0$ √† chaque √©tape (condition de libert√©).
*   L'ordre des vecteurs compte : deux ordres diff√©rents donnent des familles orthonorm√©es diff√©rentes.

---

## FLASHCARD 166 ‚Äî Proposition 49 : Projection orthogonale sur un sous-espace de dimension finie

### RECTO
**Proposition 49 : Projection orthogonale sur un sous-espace de dimension finie**

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace euclidien (ou hermitien) de dimension finie, $F$ un sous-espace vectoriel de $E$.

**Question :** D√©finir la projection orthogonale sur $F$. Donner la d√©composition $E = F \oplus F^\perp$, la formule de la projection, et ses propri√©t√©s.

### VERSO
**D√©finition et d√©composition**
**Th√©or√®me :** $E = F \oplus F^\perp$ o√π $F^\perp = \{x \in E \mid \forall y \in F, \langle x, y \rangle = 0\}$.

En particulier : $\dim F + \dim F^\perp = \dim E$, et $(F^\perp)^\perp = F$.

**Projection orthogonale**
La projection orthogonale sur $F$ est le projecteur $p_F : E \to E$ tel que :
*   $p_F(x) \in F$ pour tout $x$
*   $x - p_F(x) \in F^\perp$ pour tout $x$

**Formule explicite (via une base orthonorm√©e de $F$)**
Si $(e_1, \dots, e_k)$ est une base orthonorm√©e de $F$ :
$$ p_F(x) = \sum_{i=1}^k \langle x, e_i \rangle e_i $$

**Propri√©t√©s fondamentales**
*   $p_F$ est lin√©aire, $p_F^2 = p_F$ (projecteur), $p_F = p_F^*$ (autoadjoint).
*   $\text{Im}(p_F) = F$, $\ker(p_F) = F^\perp$.
*   $\|p_F(x)\| \le \|x\|$ pour tout $x$ (projecteur de norme $\le 1$).
*   **Meilleure approximation :** $p_F(x)$ est l'√©l√©ment de $F$ le plus proche de $x$ :
    $$ \forall y \in F, \quad \|x - p_F(x)\| \le \|x - y\| $$

### 
**Subtilit√©s**
*   La d√©composition $E = F \oplus F^\perp$ est propre √† la g√©om√©trie euclidienne : elle n√©cessite un produit scalaire (pas seulement une structure d'ev).
*   En dimension infinie (espaces de Hilbert) : la d√©composition $H = F \oplus F^\perp$ reste vraie si $F$ est ferm√©, mais pas pour n'importe quel sous-espace (un sous-espace dense non ferm√© a $F^\perp = \{0\}$).
*   La propri√©t√© de meilleure approximation caract√©rise $p_F(x)$ sans utiliser de base.

**Pi√®ges classiques**
*   La formule $\sum \langle x, e_i \rangle e_i$ n'est valable que si $(e_i)$ est orthonorm√©e (pas juste orthogonale).
*   En dimension finie, $F^{\perp\perp} = F$ toujours. En dimension infinie, $F^{\perp\perp} = \bar{F}$.
*   Ne pas confondre "projecteur orthogonal" (autoadjoint) et "projecteur" (idempotent non n√©cessairement autoadjoint).

---

## FLASHCARD 167 ‚Äî Proposition 50

### RECTO
**Proposition 50 : Propri√©t√©s du compl√©ment orthogonal**

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace euclidien de dimension finie, $F, G$ des sous-espaces de $E$.

**Question :** √ânoncer les propri√©t√©s fondamentales du compl√©ment orthogonal : $\dim F^\perp$, $(F^\perp)^\perp$, $(F+G)^\perp$, $(F \cap G)^\perp$.

### VERSO
**Propri√©t√©s**
1.  $\dim F^\perp = \dim E - \dim F$
2.  $(F^\perp)^\perp = F$
3.  $(F + G)^\perp = F^\perp \cap G^\perp$
4.  $(F \cap G)^\perp = F^\perp + G^\perp$
5.  $F \subset G \implies G^\perp \subset F^\perp$

**D√©monstrations**
*   1 et 2 : D√©coulent de $E = F \oplus F^\perp$ et $\dim E = \dim F + \dim F^\perp$. Puis $(F^\perp)^\perp \supset F$ (par d√©finition), et $\dim (F^\perp)^\perp = \dim E - \dim F^\perp = \dim F$, donc $(F^\perp)^\perp = F$.
*   3 : $x \in (F+G)^\perp \iff \langle x, y+z \rangle = 0 \ \forall y \in F, z \in G \iff x \in F^\perp \cap G^\perp$.
*   4 : $(F \cap G)^\perp = ((F^\perp)^\perp \cap (G^\perp)^\perp)^\perp$... Utiliser $F \cap G = (F^\perp + G^\perp)^\perp$ (d√©duit de 3 par orthogonalisation) et prendre le perp.

### 
**Subtilit√©s**
*   En dimension finie, ces formules sont toutes exactes. En dimension infinie, (4) devient $(F \cap G)^\perp = \overline{F^\perp + G^\perp}$ (la somme n'est pas n√©cessairement ferm√©e).
*   La propri√©t√© (2) $(F^\perp)^\perp = F$ est sp√©cifique √† la dimension finie (ou aux sous-espaces ferm√©s en Hilbert).

**Pi√®ges classiques**
*   En dimension infinie, $F^\perp + G^\perp$ peut ne pas √™tre ferm√©, donc $(F \cap G)^\perp \neq F^\perp + G^\perp$ en g√©n√©ral.
*   V√©rifier (3) et (4) : les deux identit√©s sont duales l'une de l'autre (De Morgan orthogonal).

---

## FLASHCARD 168 ‚Äî Th√©or√®me 59 : Distance √† un sous-espace

### RECTO
**Th√©or√®me 59 : Distance √† un sous-espace et projection orthogonale**

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace euclidien de dimension finie, $F$ un sous-espace de $E$, $x \in E$.

**Question :** D√©finir $d(x, F)$ et montrer que cette distance est atteinte en un unique point, donner ce point explicitement.

### VERSO
**D√©finition**
$$ d(x, F) = \inf_{y \in F} \|x - y\| $$

**Th√©or√®me**
La distance $d(x, F)$ est atteinte en un unique point : la projection orthogonale $p_F(x)$.

$$ d(x, F) = \|x - p_F(x)\| $$

et
$$ \forall y \in F, \quad y \neq p_F(x) \implies \|x - y\| > \|x - p_F(x)\| $$

**D√©monstration**
Pour $y \in F$ quelconque :
$$ \|x - y\|^2 = \|(x - p_F(x)) + (p_F(x) - y)\|^2 = \|x - p_F(x)\|^2 + 2\langle x - p_F(x), p_F(x) - y \rangle + \|p_F(x) - y\|^2 $$
Or $x - p_F(x) \in F^\perp$ et $p_F(x) - y \in F$, donc $\langle x - p_F(x), p_F(x) - y \rangle = 0$.
Donc $\|x - y\|^2 = \|x - p_F(x)\|^2 + \|p_F(x) - y\|^2 \ge \|x - p_F(x)\|^2$, avec √©galit√© ssi $y = p_F(x)$. $\square$

**Formule explicite**
Si $(e_1, \dots, e_k)$ est une base orthonorm√©e de $F$ :
$$ d(x, F)^2 = \|x\|^2 - \sum_{i=1}^k |\langle x, e_i \rangle|^2 $$

### 
**Subtilit√©s**
*   Le caract√®re euclidien (produit scalaire) est essentiel : dans un espace norm√© quelconque, la distance √† un sous-espace peut ne pas √™tre atteinte ou ne pas √™tre unique.
*   La formule $d(x, F)^2 = \|x\|^2 - \|p_F(x)\|^2$ est la relation de Pythagore : $\|x\|^2 = \|p_F(x)\|^2 + \|x - p_F(x)\|^2$.

**Pi√®ges classiques**
*   Oublier l'unicit√© : dans un espace euclidien, le point le plus proche est toujours unique (contrairement aux espaces norm√©s g√©n√©raux).
*   La distance est exprim√©e par $\|x - p_F(x)\|$, pas $\|p_F(x)\|$.

---

## FLASHCARD 169 ‚Äî √Ä conna√Ætre 51 : Caract√©risations des projecteurs orthogonaux

### RECTO
**√Ä conna√Ætre 51 : Caract√©risations des projecteurs orthogonaux**

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace euclidien de dimension finie, $p \in \mathcal{L}(E)$.

**Question :** Donner des conditions √©quivalentes pour que $p$ soit un projecteur orthogonal.

### VERSO
**√âquivalences**
Les assertions suivantes sont √©quivalentes :

(i) $p$ est la projection orthogonale sur $F = \text{Im}(p)$ (i.e., $p = p_F$ pour un certain sous-espace $F$).

(ii) $p$ est un projecteur ($p^2 = p$) et autoadjoint ($p^* = p$, i.e., $\langle p(x), y \rangle = \langle x, p(y) \rangle$ pour tout $x, y$).

(iii) $p$ est un projecteur et $\ker(p) = \text{Im}(p)^\perp$.

(iv) $p$ est un projecteur et $\|p\| \le 1$ (norme op√©rateur).

(v) $p$ est un projecteur et $\|p(x)\| \le \|x\|$ pour tout $x \in E$.

**Matrice d'un projecteur orthogonal**
Dans une base orthonorm√©e, la matrice de $p_F$ est sym√©trique ($\mathbb{R}$) ou hermitienne ($\mathbb{C}$), idempotente, et ses valeurs propres sont dans $\{0, 1\}$.

**D√©composition spectrale**
$p_F$ a pour valeurs propres $1$ (sur $F$) et $0$ (sur $F^\perp$), donc est diagonalisable avec spectre $\{0, 1\}$.

### 
**Subtilit√©s**
*   L'autoadjonction ($p = p^*$) est la condition qui distingue un projecteur orthogonal d'un projecteur oblique.
*   Dans une base non orthonorm√©e, la matrice d'un projecteur orthogonal n'est pas n√©cessairement sym√©trique.
*   En dimension infinie, les conditions (iv) et (v) ne suffisent plus sans hypoth√®se de fermeture sur $\text{Im}(p)$.

**Pi√®ges classiques**
*   Un projecteur ($p^2 = p$) n'est pas n√©cessairement orthogonal : il faut en plus $p = p^*$ (ou une condition √©quivalente).
*   Confondre "projecteur de norme 1" et "projecteur orthogonal" : tout projecteur orthogonal non nul a norme op√©rateur √©gale √† 1, mais la r√©ciproque n'est pas √©vidente.

---

## FLASHCARD 170 ‚Äî √Ä conna√Ætre 52 : In√©galit√© d'Hadamard

### RECTO
**√Ä conna√Ætre 52 : In√©galit√© d'Hadamard**

Soit $A \in M_n(\mathbb{R})$ (ou $M_n(\mathbb{C})$), de colonnes $C_1, \dots, C_n \in \mathbb{R}^n$ (ou $\mathbb{C}^n$).

**Question :** √ânoncer l'in√©galit√© d'Hadamard sur le d√©terminant. Donner les conditions d'√©galit√©.

### VERSO
**√ânonc√© formel**
**In√©galit√© d'Hadamard :**
$$ |\det(A)| \le \prod_{j=1}^n \|C_j\| $$
o√π $\|C_j\| = \sqrt{\sum_{i=1}^n |a_{ij}|^2}$ est la norme euclidienne de la $j$-i√®me colonne.

**Condition d'√©galit√©**
$|\det(A)| = \prod_{j=1}^n \|C_j\|$ si et seulement si les colonnes $C_1, \dots, C_n$ sont orthogonales deux √† deux (ou si l'une d'elles est nulle, auquel cas les deux membres sont nuls).

**D√©monstration (esquisse)**
Appliquer Gram-Schmidt aux colonnes de $A$ : $A = QR$ o√π $Q$ est orthogonale et $R$ triangulaire sup√©rieure. Alors $|\det A| = |\det R| = \prod |R_{ii}|$.
Par Gram-Schmidt, $R_{ii} = \|C_i - \text{proj sur prec.}\| \le \|C_i\|$.
Donc $|\det A| \le \prod \|C_i\|$. L'√©galit√© a lieu si et seulement si chaque $C_i$ est orthogonal aux $C_1, \dots, C_{i-1}$.

**Autre d√©monstration :** Utiliser l'in√©galit√© de Cauchy-Schwarz dans le d√©veloppement de $\det$ par multilin√©arit√©.

**Interpr√©tation g√©om√©trique**
$|\det(A)|$ est le volume du parall√©l√©pip√®de engendr√© par les colonnes. Il est major√© par le produit des normes (volume du parall√©l√©pip√®de rectangle).

### 
**Subtilit√©s**
*   L'in√©galit√© est valable pour les colonnes ou les lignes (par transposition et $|\det A| = |\det A^T|$).
*   La condition d'√©galit√© correspond exactement au cas o√π la matrice $A$ est √† colonnes orthogonales (matrice orthogonale √† une normalisation pr√®s).

**Pi√®ges classiques**
*   Ne pas oublier que $\|C_j\|$ est la norme euclidienne, pas la norme infinie ou d'autres normes.
*   L'in√©galit√© donne une borne sup√©rieure sur $|\det A|$ ‚Äî utile pour les estimations.

---

## FLASHCARD 171 ‚Äî √Ä conna√Ætre 53

### RECTO
**√Ä conna√Ætre 53 : Adjoint d'un endomorphisme**

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace euclidien (ou hermitien) de dimension finie, $f \in \mathcal{L}(E)$.

**Question :** D√©finir l'adjoint $f^*$ de $f$. Donner son existence, son unicit√©, sa matrice dans une base orthonorm√©e, et ses propri√©t√©s alg√©briques.

### VERSO
**D√©finition et existence**
**Th√©or√®me :** Il existe un unique endomorphisme $f^* \in \mathcal{L}(E)$, appel√© adjoint de $f$, tel que :
$$ \forall x, y \in E, \quad \langle f(x), y \rangle = \langle x, f^*(y) \rangle $$

**Existence :** Pour tout $y \in E$, l'application $x \mapsto \langle f(x), y \rangle$ est une forme lin√©aire sur $E$. Par le th√©or√®me de repr√©sentation de Riesz (dim. finie), il existe un unique $f^*(y)$ tel que $\langle f(x), y \rangle = \langle x, f^*(y) \rangle$.

**Matrice dans une base orthonorm√©e**
Si $B$ est une base orthonorm√©e de $E$ :
$$ \text{Mat}_B(f^*) = \overline{\text{Mat}_B(f)}^T = {}^t \bar{A} $$
(transpos√©e conjugu√©e de la matrice de $f$). Dans le cas r√©el : $\text{Mat}(f^*) = {}^t A$.

**Propri√©t√©s alg√©briques**
*   **Involutivit√© :** $(f^*)^* = f$
*   **Lin√©arit√© :** $(\lambda f + \mu g)^* = \bar{\lambda} f^* + \bar{\mu} g^*$
*   **Composition :** $(f \circ g)^* = g^* \circ f^*$
*   **D√©terminant :** $\det(f^*) = \overline{\det(f)}$
*   **Spectre :** $Sp(f^*) = \overline{Sp(f)}$

**Endomorphismes remarquables**
*   $f^* = f$ : Autoadjoint (sym√©trique si r√©el, hermitien si complexe)
*   $f^* = -f$ : Antisym√©trique (antisym√©trique/antihermitien)
*   $f^* \circ f = f \circ f^* = id$ : Orthogonal (isom√©trie si r√©el, unitaire si complexe)
*   $f^* \circ f = f \circ f^*$ : Normal

### 
**Subtilit√©s**
*   La matrice de $f^*$ dans une base non orthonorm√©e n'est pas simplement ${}^t A$ : il faut tenir compte de la matrice de Gram du produit scalaire.
*   Dans le cas hermitien : $(\lambda f)^* = \bar{\lambda} f^*$ (anti-lin√©arit√© en $\lambda$), pas $\lambda f^*$.
*   L'adjoint est d√©fini par la structure euclidienne/hermitienne ‚Äî sans produit scalaire, il n'y a pas d'adjoint canonique.

**Pi√®ges classiques**
*   Dans une base non orthonorm√©e : si $G$ est la matrice de Gram de $\langle \cdot, \cdot \rangle$, alors $\text{Mat}(f^*) = G^{-1} {}^t \bar{A} G$.
*   Confondre $f^*$ (adjoint) et $f^{-1}$ (inverse) : pour les isom√©tries, $f^* = f^{-1}$, mais en g√©n√©ral ce sont des objets distincts.
*   Ne pas oublier la conjugaison dans le cas hermitien.

---

## FLASHCARD 172 ‚Äî √Ä conna√Ætre 54 : Projection sur un convexe ferm√©

### RECTO
**√Ä conna√Ætre 54 : Projection sur un convexe ferm√© (espace de Hilbert / espace euclidien)**

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace de Hilbert r√©el (en particulier, un espace euclidien de dimension finie), $C \subset E$ un ensemble convexe ferm√© non vide.

**Question :** √ânoncer le th√©or√®me d'existence et d'unicit√© de la projection sur $C$, et la caract√©risation variationnelle.

### VERSO
**Th√©or√®me**
Soit $C$ un sous-ensemble convexe, ferm√©, non vide d'un espace de Hilbert r√©el $H$. Pour tout $x \in H$, il existe un unique $p_C(x) \in C$ tel que :
$$ \|x - p_C(x)\| = d(x, C) = \inf_{y \in C} \|x - y\| $$

**Caract√©risation variationnelle**
$p = p_C(x)$ est l'unique √©l√©ment de $C$ tel que :
$$ \forall y \in C, \quad \langle x - p, y - p \rangle \le 0 $$
(En dimension finie : le vecteur $x - p$ fait un angle obtus avec tout vecteur $y - p$ pour $y \in C$.)

**Cas particulier : $C = F$ sous-espace ferm√©**
Si $C = F$ est un sous-espace vectoriel ferm√©, la condition $\langle x - p_F(x), y \rangle \le 0$ pour tout $y \in F$ et $-y \in F$ donne $\langle x - p_F(x), y \rangle = 0$ pour tout $y \in F$, ce qui redonne la projection orthogonale.

**Application en dimension finie**
En dimension finie (espace euclidien), tout convexe ferm√© est automatiquement complet (ferm√© = compact si born√©), et le th√©or√®me s'applique. L'unique point le plus proche de $x$ dans $C$ est $p_C(x)$.

### 
**Subtilit√©s**
*   En dimension infinie, la compl√©tude (Hilbert) est indispensable : dans un espace pr√©-hilbertien non complet, la projection peut ne pas exister.
*   La convexit√© est indispensable pour l'unicit√© : sans convexit√©, la distance peut √™tre atteinte en plusieurs points.
*   La fermeture est indispensable pour l'existence : sans fermeture, la distance peut ne pas √™tre atteinte.

**Pi√®ges classiques**
*   Confondre "convexe ferm√©" (projection existe et est unique) et "sous-espace ferm√©" (projection orthogonale, cas lin√©aire).
*   La caract√©risation $\langle x - p, y - p \rangle \le 0$ est une in√©galit√© (pas une √©galit√©) : c'est la diff√©rence fondamentale avec le cas lin√©aire.

---

## FLASHCARD 173 ‚Äî √Ä conna√Ætre 55 : In√©galit√© de Bessel, famille orthonorm√©e totale

### RECTO
**√Ä conna√Ætre 55 : In√©galit√© de Bessel et famille orthonorm√©e totale**

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace euclidien (ou de Hilbert), $(e_i)_{i \in I}$ une famille orthonorm√©e (finie ou d√©nombrable) de $E$.

**Question :** √ânoncer l'in√©galit√© de Bessel. D√©finir une famille totale (base hilbertienne). √ânoncer la relation de Parseval.

### VERSO
**In√©galit√© de Bessel**
Pour tout $x \in E$ et toute famille orthonorm√©e $(e_1, \dots, e_n)$ :
$$ \sum_{i=1}^n |\langle x, e_i \rangle|^2 \le \|x\|^2 $$

**D√©monstration :** $0 \le \|x - p_F(x)\|^2 = \|x\|^2 - \|p_F(x)\|^2 = \|x\|^2 - \sum |\langle x, e_i \rangle|^2$.

**Famille orthonorm√©e totale (base hilbertienne)**
Une famille orthonorm√©e $(e_i)$ est dite totale (ou base orthonorm√©e) si :
$$ \forall x \in E, \quad x = \sum_i \langle x, e_i \rangle e_i $$
(en dimension finie, cela signifie que la famille est une base orthonorm√©e de $E$).

**Relation de Parseval**
Si $(e_i)$ est une famille orthonorm√©e totale :
$$ \forall x \in E, \quad \|x\|^2 = \sum_i |\langle x, e_i \rangle|^2 $$
C'est l'√©galit√© dans l'in√©galit√© de Bessel.

**√âquivalences (totale $\iff$...)**
$(e_i)$ est totale
$\iff \forall x \in E, \|x\|^2 = \sum |\langle x, e_i \rangle|^2$
$\iff \forall x, \langle x, e_i \rangle = 0 \ \forall i \Rightarrow x = 0$
$\iff \text{Vect}(e_i)$ est dense dans $E$.

### 
**Subtilit√©s**
*   En dimension finie, "famille orthonorm√©e de cardinal $n = \dim E$" $\iff$ "totale" $\iff$ "base orthonorm√©e".
*   En dimension infinie, une famille orthonorm√©e peut √™tre totale sans √™tre une base au sens alg√©brique (combinaisons finies) : la convergence est au sens de la norme.
*   L'in√©galit√© de Bessel est valable pour toute famille orthonorm√©e, m√™me non totale.

**Pi√®ges classiques**
*   Oublier que Parseval est l'√©galit√© de Bessel, valable uniquement pour les familles totales.
*   Confondre "base orthonorm√©e" (totale) et "famille orthonorm√©e" (Bessel mais pas n√©cessairement Parseval).

---

## FLASHCARD 174 ‚Äî Proposition 51

### RECTO
**Proposition 51 : Matrice d'une isom√©trie dans une base orthonorm√©e**

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace euclidien de dimension finie $n$, $f \in \mathcal{L}(E)$, $B$ une base orthonorm√©e de $E$, $A = \text{Mat}_B(f)$.

**Question :** Caract√©riser matriciellement les isom√©tries (endomorphismes orthogonaux) et donner leurs propri√©t√©s fondamentales.

### VERSO
**D√©finition**
$f$ est une isom√©trie (endomorphisme orthogonal) si $\forall x \in E, \|f(x)\| = \|x\|$, ou de fa√ßon √©quivalente :
$$ \forall x, y \in E, \quad \langle f(x), f(y) \rangle = \langle x, y \rangle $$

**Caract√©risation matricielle**
Dans une base orthonorm√©e $B$ : $f$ est une isom√©trie $\iff A = \text{Mat}_B(f)$ est orthogonale, i.e., ${}^t A A = I_n$ (√©quivalent : $A {}^t A = I_n$, √©quivalent : $A^{-1} = {}^t A$).

On note $O_n(\mathbb{R}) = \{A \in M_n(\mathbb{R}) \mid {}^t A A = I_n\}$ le groupe orthogonal.

**Propri√©t√©s des matrices orthogonales**
*   $\det(A) = \pm 1$
*   Les colonnes de $A$ forment une base orthonorm√©e de $\mathbb{R}^n$.
*   Les lignes de $A$ forment une base orthonorm√©e de $\mathbb{R}^n$.
*   Les valeurs propres (r√©elles ou complexes) sont de module $1$.
*   $SO_n(\mathbb{R}) = \{A \in O_n \mid \det A = 1\}$ est le groupe sp√©cial orthogonal (rotations).

### 
**Subtilit√©s**
*   La caract√©risation ${}^t A A = I_n$ d√©pend de la base choisie : elle est valable en base orthonorm√©e uniquement.
*   Dans le cas hermitien : les isom√©tries unitaires v√©rifient $A^* A = I_n$ ($A^* = {}^t \bar{A}$).
*   En dimension infinie : les isom√©tries peuvent ne pas √™tre surjectives (isom√©tries partielles).

**Pi√®ges classiques**
*   ${}^t A A = I_n \not\Rightarrow A {}^t A = I_n$ en g√©n√©ral... si $A$ est carr√©e, les deux sont √©quivalents. Mais en dimension infinie ou pour des matrices rectangulaires, il faut pr√©ciser.
*   V√©rifier que la base est orthonorm√©e avant d'√©crire ${}^t A A = I_n$.
*   Ne pas confondre $O_n$ (groupe orthogonal, $\det = \pm 1$) et $SO_n$ (rotations, $\det = 1$).

---

## FLASHCARD 175 ‚Äî Lemme 8 : Lemme de stabilit√©

### RECTO
**Lemme 8 (Lemme de stabilit√©) : Stabilit√© du compl√©ment orthogonal par une isom√©trie**

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace euclidien de dimension finie, $f \in \mathcal{L}(E)$ une isom√©trie, et $F$ un sous-espace de $E$ stable par $f$.

**Question :** Montrer que $F^\perp$ est aussi stable par $f$.

### VERSO
**√ânonc√©**
Si $f$ est une isom√©trie et $F$ est un sous-espace stable par $f$ (i.e., $f(F) \subset F$), alors $F^\perp$ est stable par $f$ (i.e., $f(F^\perp) \subset F^\perp$).

**D√©monstration**
Soit $x \in F^\perp$ et $y \in F$. On veut montrer $\langle f(x), y \rangle = 0$.

Comme $f$ est une isom√©trie, $f$ est bijective. En particulier, $f(F) = F$ (car $f(F) \subset F$ et $f$ est injective, donc $\dim f(F) = \dim F$, et $f(F) \subset F$ implique $f(F) = F$).

Donc $y \in F$ implique $y = f(z)$ pour un certain $z \in F$.

$$ \langle f(x), y \rangle = \langle f(x), f(z) \rangle = \langle x, z \rangle = 0 $$

(car $f$ est une isom√©trie : $\langle f(x), f(z) \rangle = \langle x, z \rangle$, et $x \in F^\perp, z \in F$). $\square$

**Corollaire**
Si $f$ est une isom√©trie et $F$ est stable par $f$, alors l'endomorphisme induit $f|_F$ est une isom√©trie de $F$, et $f|_{F^\perp}$ est une isom√©trie de $F^\perp$.

### 
**Subtilit√©s**
*   La bijectivit√© de $f$ (qui d√©coule de l'isom√©trie en dimension finie) est essentielle pour avoir $f(F) = F$.
*   En dimension infinie, une isom√©trie peut √™tre non surjective (d√©calage unilat√©ral), et le lemme peut tomber en d√©faut.
*   Ce lemme est la cl√© de la r√©duction des isom√©tries (Prop. 52) : on peut orthogonaliser les sous-espaces stables.

**Pi√®ges classiques**
*   Oublier que "$f(F) \subset F$ et $f$ injective" donne $f(F) = F$ (en dimension finie) ‚Äî c'est n√©cessaire pour la d√©monstration.
*   Ne pas confondre "stable par $f$" ($f(F) \subset F$) et "stable par $f$ et $f^{-1}$" ($f(F) = F$) : en dimension finie, les deux sont √©quivalents pour $f$ inversible.

---

## FLASHCARD 176 ‚Äî Proposition 52 : R√©duction des isom√©tries

### RECTO
**Proposition 52 : R√©duction des isom√©tries en dimension finie**

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace euclidien r√©el de dimension finie $n$, $f \in \mathcal{L}(E)$ une isom√©trie.

**Question :** √ânoncer le th√©or√®me de r√©duction des isom√©tries : d√©composition de $E$ en sous-espaces stables de dimension 1 ou 2, forme canonique de la matrice dans une base orthonorm√©e adapt√©e.

### VERSO
**Th√©or√®me**
Toute isom√©trie $f$ de $E$ (r√©el, dimension finie) admet une base orthonorm√©e dans laquelle sa matrice est bloc-diagonale de la forme :
$$ \begin{pmatrix} \pm 1 & & & & & \\ & \ddots & & & & \\ & & \pm 1 & & & \\ & & & R_{\theta_1} & & \\ & & & & \ddots & \\ & & & & & R_{\theta_k} \end{pmatrix} $$
o√π $R_\theta = \begin{pmatrix} \cos \theta & -\sin \theta \\ \sin \theta & \cos \theta \end{pmatrix}$ est une matrice de rotation d'angle $\theta \in (0, \pi)$.

**Description des blocs**
*   **Blocs $1 \times 1$ :** $+1$ (vecteurs propres pour $\lambda = 1$) ou $-1$ (vecteurs propres pour $\lambda = -1$).
*   **Blocs $2 \times 2$ :** rotations d'angle $\theta \in (0, \pi)$ (correspondant aux valeurs propres complexes $e^{\pm i \theta}$).

**Cons√©quence**
*   $f$ est une rotation ($\det f = 1$) $\iff$ le nombre de blocs $(-1)$ est pair.
*   $f$ est un retournement ($\det f = -1$) $\iff$ le nombre de blocs $(-1)$ est impair.

**Id√©e de d√©monstration**
Par r√©currence sur $n$ :
1.  Chercher un sous-espace stable de dimension 1 ou 2 en √©tudiant les valeurs propres r√©elles ou les valeurs propres complexes par paires.
2.  Utiliser le Lemme 8 : $F^\perp$ est aussi stable, puis appliquer l'hypoth√®se de r√©currence √† $f|_{F^\perp}$.

### 
**Subtilit√©s**
*   Cette r√©duction est sp√©cifique aux espaces r√©els : sur $\mathbb{C}$, les isom√©tries unitaires sont diagonalisables (valeurs propres sur le cercle unit√©).
*   Les angles $\theta \in (0, \pi)$ (pas $\{0, \pi\}$ qui donnent des blocs $1 \times 1$).
*   La forme bloc-diagonale est obtenue dans une base orthonorm√©e : dans une base quelconque, la matrice n'a pas cette forme simple.

**Pi√®ges classiques**
*   Sur $\mathbb{R}$ : une isom√©trie peut ne pas avoir de valeurs propres r√©elles (rotation en dimension 2 d'angle $\neq 0, \pi$). Donc "trigonalisable sur $\mathbb{R}$" ne s'applique pas en g√©n√©ral.
*   Ne pas oublier les blocs $(-1)$ : une r√©flexion en dimension impaire est une isom√©trie avec un bloc $(-1)$.
*   En dimension 2 : les isom√©tries directes sont des rotations, les isom√©tries indirectes sont des r√©flexions ‚Äî √† conna√Ætre parfaitement.

---

## FLASHCARD 177 ‚Äî √Ä conna√Ætre 56

### RECTO
**√Ä conna√Ætre 56 : Endomorphismes normaux**

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace hermitien de dimension finie, $f \in \mathcal{L}(E)$.

**Question :** D√©finir un endomorphisme normal. √ânoncer le th√©or√®me spectral pour les endomorphismes normaux en dimension finie sur $\mathbb{C}$.

### VERSO
**D√©finition**
$f$ est normal si $f \circ f^* = f^* \circ f$.

**Exemples d'endomorphismes normaux**
*   $f^* = f$ (Hermitien) : Oui
*   $f^* = -f$ (Antihermitien) : Oui
*   $f^* f = f f^* = id$ (Unitaire) : Oui
*   $f$ quelconque : Pas n√©cessairement

**Th√©or√®me spectral (cas normal, $\mathbb{C}$)**
**Th√©or√®me :** $f$ est normal (sur un espace hermitien de dimension finie sur $\mathbb{C}$) si et seulement si $f$ est unitairement diagonalisable : il existe une base orthonorm√©e de $E$ form√©e de vecteurs propres de $f$.

**Propri√©t√©s des endomorphismes normaux**
*   $\ker(f) = \ker(f^*)$
*   $\|f(x)\| = \|f^*(x)\|$ pour tout $x$
*   Les espaces propres de $f$ associ√©s √† des valeurs propres distinctes sont orthogonaux.
*   $f$ est normal $\iff m_f$ est scind√© √† racines simples sur $\mathbb{C}$ (dans ce cas diagonalisable).

### 
**Subtilit√©s**
*   Le th√©or√®me spectral pour les endomorphismes normaux est le r√©sultat de diagonalisabilit√© le plus g√©n√©ral en dimension finie sur $\mathbb{C}$ : tout normal est unitairement diagonalisable.
*   La base de diagonalisation est orthonorm√©e, ce qui est plus fort que simplement "diagonalisable".
*   Sur $\mathbb{R}$ : les endomorphismes normaux (sym√©triques) sont diagonalisables orthogonalement (Th√©or√®me 60 spectral r√©el).

**Pi√®ges classiques**
*   Confondre "diagonalisable" et "unitairement diagonalisable" : la diff√©rence est que la base doit √™tre orthonorm√©e pour le second.
*   Un endomorphisme hermitien est normal, mais un endomorphisme normal n'est pas n√©cessairement hermitien.

---

## FLASHCARD 178 ‚Äî Th√©or√®me 60 : Th√©or√®me Spectral (r√©el)

### RECTO
**Th√©or√®me 60 ‚Äî Th√©or√®me Spectral (r√©el)**

Soit $E$ un espace euclidien (de dimension finie $n$), et soit $u \in \mathcal{L}(E)$.

**Question :** √ânoncer le th√©or√®me spectral pour les endomorphismes sym√©triques en dimension finie r√©elle, avec ses hypoth√®ses exactes et sa conclusion compl√®te.

### VERSO
**Hypoth√®ses compl√®tes**
*   $E$ est un espace euclidien : $\mathbb{R}$-espace vectoriel de dimension finie $n \ge 1$, muni d'un produit scalaire $\langle \cdot, \cdot \rangle$
*   $u \in \mathcal{L}(E)$ est un endomorphisme sym√©trique : $\forall x, y \in E, \langle u(x), y \rangle = \langle x, u(y) \rangle$

**√ânonc√© formel**
$$ u \text{ sym√©trique} \implies \exists B \text{ base orthonorm√©e de } E \text{ form√©e de vecteurs propres de } u $$

Plus pr√©cis√©ment :
$$ \exists \lambda_1, \dots, \lambda_n \in \mathbb{R}, \exists (e_1, \dots, e_n) \text{ BON de } E \text{ tels que } \forall i \in \llbracket 1, n \rrbracket, u(e_i) = \lambda_i e_i $$

Autrement dit, la matrice de $u$ dans $B = (e_1, \dots, e_n)$ est :
$$ \text{Mat}_B(u) = \text{diag}(\lambda_1, \dots, \lambda_n) \in M_n(\mathbb{R}) $$

**Traduction matricielle :** Toute matrice sym√©trique r√©elle $A \in S_n(\mathbb{R})$ est orthogonalement diagonalisable :
$$ \exists P \in O_n(\mathbb{R}), \exists D \in D_n(\mathbb{R}) \text{ telles que } A = P D P^{-1} = P D P^\top $$

**Propri√©t√©s spectrales garanties**
1.  Toutes les valeurs propres sont r√©elles : $Sp(u) \subset \mathbb{R}$
2.  Les sous-espaces propres sont deux √† deux orthogonaux : $\lambda \neq \mu \implies E_\lambda(u) \perp E_\mu(u)$
3.  La somme des sous-espaces propres est directe et √©gale √† $E$ : $E = \bigoplus_{\lambda \in Sp(u)} E_\lambda(u)$ (orthogonale)
4.  Le polyn√¥me caract√©ristique est scind√© √† racines r√©elles sur $\mathbb{R}$

**D√©monstration (Esquisse ‚Äî 4 id√©es cl√©s)**
1.  **R√©alit√© des valeurs propres :** Si $\chi_u$ admet une racine complexe $\lambda = a+ib$, on travaille dans $\mathbb{C}^n$ par complexification et on montre via $\langle u(x), x \rangle = \langle x, u(x) \rangle$ que $\lambda \in \mathbb{R}$ (le produit scalaire hermitien r√©v√®le $b=0$).
2.  **Scindage du polyn√¥me caract√©ristique :** Par r√©currence sur $n$. Existence d'une valeur propre r√©elle (via le th√©or√®me de d'Alembert-Gauss appliqu√© √† $\chi_u \in \mathbb{R}[X]$ et r√©alit√© des racines complexes par conjugaison + sym√©trie).
3.  **Stabilit√© de l'orthogonal :** Si $F$ est stable par $u$ (sym√©trique), alors $F^\perp$ est aussi stable par $u$.
4.  **R√©currence :** On prend $e_1$ vecteur propre unitaire, $F = \text{Vect}(e_1)^\perp$ est stable par $u$, et on applique l'hypoth√®se de r√©currence √† $u|_{F^\perp}$ qui est encore sym√©trique.

### 
**Subtilit√©s**
*   **Dimension finie absolument n√©cessaire :** En dimension infinie (espace de Hilbert), un op√©rateur sym√©trique born√© n'est pas n√©cessairement diagonalisable au sens classique ‚Äî on dispose d'un th√©or√®me spectral mais avec une mesure spectrale, hors programme MP.
*   **$\mathbb{R}$ vs $\mathbb{C}$ :** Sur $\mathbb{C}$, le th√©or√®me analogue concerne les endomorphismes hermitiens ($u^* = u$) et les matrices hermitiennes $A^* = A$. Les matrices normales ($AA^* = A^*A$) sont unitairement diagonalisables sur $\mathbb{C}$ ‚Äî mais ce r√©sultat est hors programme MP strict.
*   **Orthogonal $\neq$ diagonalisable :** Une matrice orthogonale $P \in O_n(\mathbb{R})$ n'est pas n√©cessairement diagonalisable sur $\mathbb{R}$ (ex : rotation de $\pi/2$ en dim 2). Le th√©or√®me spectral ne s'applique pas aux matrices orthogonales en g√©n√©ral.
*   **Les $\lambda_i$ ne sont pas n√©cessairement distincts :** Si $\lambda$ est valeur propre de multiplicit√© $k$, alors $\dim E_\lambda = k$ (le th√©or√®me garantit que la multiplicit√© g√©om√©trique = multiplicit√© alg√©brique pour les sym√©triques).
*   **La d√©composition est orthogonale :** $E = E_{\lambda_1} \oplus^\perp \dots \oplus^\perp E_{\lambda_r}$.

**Extensions**
*   **Formes bilin√©aires sym√©triques :** Le th√©or√®me spectral implique que toute forme quadratique sur un espace euclidien peut √™tre diagonalis√©e dans une BON ‚Äî lien direct avec la r√©duction des formes quadratiques.
*   **Endomorphismes sym√©triques positifs :** $u$ sym√©trique et $\forall x, \langle u(x), x \rangle \ge 0 \iff$ toutes les valeurs propres sont $\ge 0$ (voir Proposition 53).
*   **D√©composition spectrale (projecteurs) :** $u = \sum_{\lambda \in Sp(u)} \lambda \cdot p_\lambda$ o√π $p_\lambda$ est le projecteur orthogonal sur $E_\lambda(u)$.
*   **Fonctions de matrices :** Gr√¢ce au th√©or√®me spectral, on peut d√©finir $f(u)$ pour toute fonction $f : Sp(u) \to \mathbb{R}$ par $f(u) = \sum \lambda f(\lambda) p_\lambda$, en particulier $\sqrt{u}$ pour $u$ sym√©trique positif.

**Pi√®ges classiques**
*   **Confusion sym√©trique/orthogonal :** Appliquer le th. spectral √† une matrice orthogonale. Seules les matrices sym√©triques $A^\top = A$ sont orthogonalement diagonalisables.
*   **Oublier l'orthogonalit√© de $P$ :** √âcrire $A = PDP^{-1}$ sans pr√©ciser $P \in O_n(\mathbb{R})$. Il faut $P^\top P = I_n$, ce qui est la force du th√©or√®me.
*   **Multiplicit√© :** Croire que les valeurs propres sont toujours simples. Elles peuvent √™tre multiples, mais $\dim E_\lambda =$ multiplicit√© alg√©brique.
*   **Corps de base :** Oublier que le th√©or√®me est faux pour $S_n(\mathbb{Q})$ ou en dimension infinie. Le th√©or√®me requiert $\mathbb{R}$ et dimension finie.
*   **R√©ciproque :** Croire que orthogonalement diagonalisable $\implies$ sym√©trique. C'est vrai ! La r√©ciproque est vraie : $A = P D P^\top \implies A^\top = A$.

---

## FLASHCARD 179 ‚Äî √Ä conna√Ætre 57 : Endomorphismes sym√©triques ‚Äî Caract√©risation via la base

### RECTO
**√Ä conna√Ætre 57 ‚Äî Caract√©risation matricielle des endomorphismes sym√©triques**

Soit $E$ un espace euclidien de dimension $n$, $B$ une base orthonorm√©e de $E$, et $u \in \mathcal{L}(E)$.

**Question :** Quelle est la caract√©risation matricielle de la sym√©trie de $u$ dans une BON ? Et comment varie la matrice si on change de BON ?

### VERSO
**Hypoth√®ses compl√®tes**
*   $E$ euclidien de dimension finie $n$
*   $B = (e_1, \dots, e_n)$ base orthonorm√©e de $E$
*   $u \in \mathcal{L}(E)$, $A = \text{Mat}_B(u)$

**√ânonc√© formel**
$$ u \text{ sym√©trique} \iff A^\top = A \iff A \in S_n(\mathbb{R}) $$

**Attention :** Cette √©quivalence est valable uniquement si $B$ est orthonorm√©e. Dans une base quelconque $C$, la matrice de $u$ n'est pas n√©cessairement sym√©trique m√™me si $u$ l'est.

**Changement de BON :** Si $B'$ est une autre BON et $P$ la matrice de passage ($P \in O_n(\mathbb{R})$), alors :
$$ \text{Mat}_{B'}(u) = P^\top A P $$
qui est encore sym√©trique ($P^\top A P \in S_n(\mathbb{R})$).

**D√©monstration (Esquisse)**
$\langle u(e_i), e_j \rangle = A_{ji}$ et $\langle e_i, u(e_j) \rangle = A_{ij}$. Donc $u$ sym√©trique $\iff A_{ij} = A_{ji} \ \forall i, j \iff A^\top = A$.

### 
**Subtilit√©s**
*   **D√©pendance √† la base :** Dans une base non orthonorm√©e $C$, $u$ sym√©trique $\iff \text{Mat}_C(u)$ est sym√©trique par rapport √† la matrice de Gram $G = (\langle e_i, e_j \rangle)$, i.e. $G A = A^\top G$. Hors programme MP mais utile pour comprendre.
*   $S_n(\mathbb{R})$ est un sous-espace vectoriel de $M_n(\mathbb{R})$ de dimension $\frac{n(n+1)}{2}$.

**Pi√®ges classiques**
*   √âcrire $u$ sym√©trique $\iff$ sa matrice dans une base quelconque est sym√©trique : FAUX. Il faut une BON.
*   Confondre matrice sym√©trique et endomorphisme sym√©trique sans pr√©ciser la base.

---

## FLASHCARD 180 ‚Äî √Ä conna√Ætre 58 : Valeurs propres d'un sym√©trique ‚Äî Extrema du quotient de Rayleigh

### RECTO
**√Ä conna√Ætre 58 ‚Äî Quotient de Rayleigh et valeurs propres extr√©males**

Soit $E$ un espace euclidien de dimension $n$, $u \in \mathcal{L}(E)$ sym√©trique, de valeurs propres $\lambda_1 \le \lambda_2 \le \dots \le \lambda_n$ (compt√©es avec multiplicit√©).

**Question :** Exprimer $\lambda_1$ et $\lambda_n$ comme extrema du quotient de Rayleigh, et donner les caract√©risations variationnelles associ√©es.

### VERSO
**Hypoth√®ses compl√®tes**
*   $E$ euclidien de dimension $n \ge 1$
*   $u \in \mathcal{L}(E)$ sym√©trique
*   $\lambda_1 \le \dots \le \lambda_n$ valeurs propres r√©elles de $u$ (le th√©or√®me spectral garantit leur existence)
*   **Quotient de Rayleigh :** $R(x) = \frac{\langle u(x), x \rangle}{\langle x, x \rangle}$ pour $x \neq 0$

**√ânonc√© formel**
$$ \lambda_1 = \min_{x \neq 0} \frac{\langle u(x), x \rangle}{\|x\|^2} = \min_{\|x\|=1} \langle u(x), x \rangle $$

$$ \lambda_n = \max_{x \neq 0} \frac{\langle u(x), x \rangle}{\|x\|^2} = \max_{\|x\|=1} \langle u(x), x \rangle $$

Et plus g√©n√©ralement :
$$ \forall x \in E, \quad \lambda_1 \|x\|^2 \le \langle u(x), x \rangle \le \lambda_n \|x\|^2 $$

Les extrema sont atteints en les vecteurs propres associ√©s √† $\lambda_1$ et $\lambda_n$ respectivement.

**D√©monstration (Esquisse)**
Dans la BON propre $(e_1, \dots, e_n)$, si $x = \sum \alpha_i e_i$ avec $\|x\|^2 = \sum \alpha_i^2 = 1$ :
$\langle u(x), x \rangle = \sum \lambda_i \alpha_i^2 \ge \lambda_1 \sum \alpha_i^2 = \lambda_1$.
√âgalit√© si et seulement si $x \in E_{\lambda_1}(u)$.

### 
**Subtilit√©s**
*   Le min est atteint (compacit√© de la sph√®re unit√© en dimension finie, $x \mapsto \langle u(x), x \rangle$ continue).
*   **Caract√©risation sans calcul matriciel :** Les valeurs propres extr√©males caract√©risent la "taille" de l'endomorphisme dans un sens pr√©cis.
*   **Lien avec les normes :** $\|u\|_{op} = \max(|\lambda_1|, |\lambda_n|)$ pour $u$ sym√©trique (la norme d'op√©rateur est le rayon spectral).

**Extensions**
*   Le principe du minimax de Courant-Fischer (√Ä conna√Ætre 59) g√©n√©ralise cette id√©e √† toutes les valeurs propres interm√©diaires $\lambda_k$.

**Pi√®ges classiques**
*   Oublier que les extrema sont bien atteints (compacit√© de la sph√®re en dim finie).
*   Appliquer la formule sans v√©rifier que $u$ est sym√©trique.
*   Confondre $\|u\|_{op}$ avec $\lambda_n$ : si $\lambda_1 < 0$, alors $\|u\|_{op} = |\lambda_1|$ peut √™tre plus grand que $\lambda_n$.

---

## FLASHCARD 181 ‚Äî √Ä conna√Ætre 59 : Principe du Minimax de Courant-Fischer

### RECTO
**√Ä conna√Ætre 59 ‚Äî Principe du Minimax de Courant-Fischer**

Soit $E$ un espace euclidien de dimension $n$, $u \in \mathcal{L}(E)$ sym√©trique, $\lambda_1 \le \dots \le \lambda_n$ ses valeurs propres.

**Question :** √ânoncer le principe du minimax de Courant-Fischer donnant une caract√©risation variationnelle de chaque valeur propre $\lambda_k$.

### VERSO
**Hypoth√®ses compl√®tes**
*   $E$ euclidien de dimension $n \ge 1$
*   $u \in \mathcal{L}(E)$ sym√©trique
*   $\lambda_1 \le \lambda_2 \le \dots \le \lambda_n \in \mathbb{R}$ valeurs propres (avec multiplicit√©)
*   $G_k(E)$ d√©signe l'ensemble des sous-espaces vectoriels de $E$ de dimension $k$

**√ânonc√© formel**
$$ \forall k \in \llbracket 1, n \rrbracket : \lambda_k = \min_{\substack{F \subset E \\ \dim F = k}} \max_{\substack{x \in F \\ x \neq 0}} \frac{\langle u(x), x \rangle}{\|x\|^2} $$

**Formulation √©quivalente (maximin) :**

$$ \lambda_k = \max_{\substack{F \subset E \\ \dim F = n-k+1}} \min_{\substack{x \in F \\ x \neq 0}} \frac{\langle u(x), x \rangle}{\|x\|^2} $$

**Cas particuliers :** $k=1$ donne $\lambda_1 = \min \frac{\langle u(x), x \rangle}{\|x\|^2}$, $k=n$ donne $\lambda_n = \max \frac{\langle u(x), x \rangle}{\|x\|^2}$.

**D√©monstration (Esquisse)**
Dans la BON propre $(e_1, \dots, e_n)$ : pour $F = \text{Vect}(e_1, \dots, e_k)$, le max sur $F$ vaut $\lambda_k$. On montre ensuite que pour tout sous-espace $G$ de dimension $k$, $G \cap \text{Vect}(e_k, \dots, e_n) \neq \{0\}$ (par comptage de dimension : $k + (n-k+1) = n+1 > n$), ce qui fournit un vecteur sur lequel le quotient de Rayleigh est $\ge \lambda_k$.

### 
**Subtilit√©s**
*   **Application directe :** Permet de comparer les valeurs propres de $u$ et $v$ (deux sym√©triques) si $u \le v$ au sens des formes quadratiques ($\langle u(x), x \rangle \le \langle v(x), x \rangle \ \forall x$) : alors $\lambda_k(u) \le \lambda_k(v)$.
*   **Monotonie par restriction :** Si $F$ est un sous-espace stable par $u$, les valeurs propres de $u|_F$ s'intercalent entre celles de $u$ (th√©or√®me d'entrelacement).

**Pi√®ges classiques**
*   Confondre le min et le max dans la formule (m√©moriser : on minimise sur les sous-espaces de dim $k$ le max du quotient de Rayleigh).
*   Croire que le th√©or√®me est au programme MP : il est au programme MP* ‚Äî √† ma√Ætriser pour l'oral mais √† utiliser avec pr√©caution.

---

## FLASHCARD 182 ‚Äî Proposition 53 : Endomorphismes sym√©triques positifs et d√©finis positifs

### RECTO
**Proposition 53 ‚Äî Endomorphismes sym√©triques positifs et d√©finis positifs**

Soit $E$ un espace euclidien de dimension finie $n$, et $u \in \mathcal{L}(E)$ un endomorphisme sym√©trique.

**Question :** Donner les caract√©risations √©quivalentes de "$u$ est sym√©trique positif" et "$u$ est sym√©trique d√©fini positif", en termes de valeurs propres, de forme quadratique, et de d√©composition.

### VERSO
**D√©finitions**
*   $u$ est **sym√©trique positif** (not√© $u \succeq 0$) si : $u$ est sym√©trique et $\forall x \in E, \langle u(x), x \rangle \ge 0$.
*   $u$ est **sym√©trique d√©fini positif** (not√© $u \succ 0$) si : $u$ est sym√©trique et $\forall x \in E \setminus \{0\}, \langle u(x), x \rangle > 0$.

**Caract√©risations √©quivalentes**
$u$ sym√©trique positif $\iff$ :
(a) $\forall x \in E, \langle u(x), x \rangle \ge 0$
$\iff$ (b) $Sp(u) \subset [0, +\infty[$
$\iff$ (c) $\exists v \in \mathcal{L}(E)$ sym√©trique, $u = v^2$

$u$ sym√©trique d√©fini positif $\iff$ :
(a') $\forall x \neq 0, \langle u(x), x \rangle > 0$
$\iff$ (b') $Sp(u) \subset ]0, +\infty[$
$\iff$ (c') $u$ inversible et positif

**Traduction matricielle**
$A \in S_n(\mathbb{R})$ est d√©finie positive $\iff$ toutes ses valeurs propres sont $>0$ $\iff$ tous ses mineurs principaux sont $>0$ (crit√®re de Sylvester, hors programme MP mais utile).

**Ordre sur les sym√©triques**
On d√©finit $u \preceq v \iff v - u \succeq 0$. C'est un ordre partiel sur les endomorphismes sym√©triques.

**D√©monstration (Esquisse)**
Par le th√©or√®me spectral : dans la BON propre, $\langle u(x), x \rangle = \sum \lambda_i \alpha_i^2$. Ceci est $\ge 0$ pour tout $x \iff$ tous les $\lambda_i \ge 0$.
Pour (c) : si tous $\lambda_i \ge 0$, poser $v = \sum \sqrt{\lambda_i} p_i$ (racine carr√©e de $u$).

### 
**Subtilit√©s**
*   $u \succeq 0$ n'implique pas $u$ inversible : Si $0 \in Sp(u)$, $u$ est positif mais non d√©fini positif. Exemple : le projecteur orthogonal (valeurs propres 0 et 1).
*   **Produit scalaire induit :** Si $u \succ 0$, alors $(x, y) \mapsto \langle u(x), y \rangle$ est un nouveau produit scalaire sur $E$.
*   **Somme de sym√©triques positifs :** $u \succeq 0$ et $v \succeq 0 \implies u+v \succeq 0$. Si de plus $u \succ 0$, alors $u+v \succ 0$.
*   **Composition :** $u \succeq 0$ et $v \succeq 0$ n'implique pas $uv \succeq 0$ (sauf si $uv=vu$).

**Extensions**
*   **Racine carr√©e :** Si $u \succeq 0$, il existe un unique $v \succeq 0$ tel que $v^2 = u$ (voir √Ä conna√Ætre 61). C'est la racine carr√©e de $u$, not√©e $\sqrt{u}$ ou $u^{1/2}$.
*   **D√©composition polaire (√Ä conna√Ætre 62) :** tout endomorphisme $f$ s'√©crit $f = s \circ r$ avec $r$ isom√©trie et $s$ sym√©trique positif.

**Pi√®ges classiques**
*   Croire qu'une matrice √† coefficients positifs est d√©finie positive : FAUX.
*   Confondre $\langle u(x), x \rangle \ge 0$ et $u^2 \succeq 0$ : tout carr√© $u^2$ d'un sym√©trique est toujours $\succeq 0$ (valeurs propres $\lambda_i^2 \ge 0$).
*   Oublier que la caract√©risation (b) requiert que $u$ soit sym√©trique d'abord (les valeurs propres d'un endomorphisme non sym√©trique peuvent ne pas √™tre r√©elles).

---

## FLASHCARD 183 ‚Äî √Ä conna√Ætre 60 : Matrice de Gram

### RECTO
**√Ä conna√Ætre 60 ‚Äî Matrice de Gram**

Soit $E$ un espace euclidien et $(x_1, \dots, x_p) \in E^p$ une famille de $p$ vecteurs.

**Question :** D√©finir la matrice de Gram, exprimer son lien avec la libert√© de la famille, et donner sa relation avec le d√©terminant (volume).

### VERSO
**D√©finition**
La matrice de Gram de la famille $(x_1, \dots, x_p)$ est :
$$ G = G(x_1, \dots, x_p) = (\langle x_i, x_j \rangle)_{1 \le i, j \le p} \in M_p(\mathbb{R}) $$

**Propri√©t√©s fondamentales**
1.  **Sym√©trie et positivit√© :**
    $G \in S_p(\mathbb{R})$ et $G \succeq 0$ (i.e. $G$ est sym√©trique positive).
    Preuve : $\forall \alpha \in \mathbb{R}^p, \alpha^\top G \alpha = \langle \sum_i \alpha_i x_i, \sum_j \alpha_j x_j \rangle = \|\sum_i \alpha_i x_i\|^2 \ge 0$.

2.  **Caract√©risation de la libert√© :**
    *   $\det G(x_1, \dots, x_p) > 0 \iff (x_1, \dots, x_p)$ est libre
    *   $\det G(x_1, \dots, x_p) = 0 \iff (x_1, \dots, x_p)$ est li√©e

3.  **Interpr√©tation g√©om√©trique :** Si $p=n=\dim E$ et $A = \text{Mat}_B(x_1, \dots, x_n)$ dans une BON $B$ :
    $$ \det G = (\det A)^2 $$
    Et $\sqrt{\det G}$ est le volume du parall√©l√©pip√®de engendr√© par $(x_1, \dots, x_p)$.

**Formule explicite en dimension 2**
$G(x, y) = \begin{pmatrix} \|x\|^2 & \langle x, y \rangle \\ \langle x, y \rangle & \|y\|^2 \end{pmatrix}, \quad \det G = \|x\|^2 \|y\|^2 - \langle x, y \rangle^2$.
C'est exactement l'in√©galit√© de Cauchy-Schwarz : $\det G \ge 0$ avec √©galit√© ssi $(x, y)$ li√©e.

### 
**Subtilit√©s**
*   $G \succ 0 \iff$ famille libre : La matrice de Gram est d√©finie positive si et seulement si la famille est libre.
*   **Lien avec le produit scalaire :** Si $(e_1, \dots, e_n)$ est une base (non n√©cessairement orthonorm√©e), la matrice de Gram est exactement la matrice du produit scalaire dans cette base.
*   Dans une BON : $G(e_1, \dots, e_n) = I_n$ (matrice identit√©).

**Extensions**
*   **Rang de $G$ :** $\text{rang}(G) = \text{rang}(x_1, \dots, x_p)$ (le rang de la famille). En particulier, $G$ est inversible $\iff$ famille libre.
*   **Formule de la distance :** $d(x, \text{Vect}(x_1, \dots, x_p))^2 = \frac{\det G(x_1, \dots, x_p, x)}{\det G(x_1, \dots, x_p)}$ (formule de la distance via Gram, utile pour les calculs de distance √† un sous-espace).

**Pi√®ges classiques**
*   Confondre $G \succeq 0$ (toujours vrai) et $G \succ 0$ (uniquement si famille libre).
*   Oublier que $\det G = (\det A)^2$ n√©cessite une BON pour √©crire les colonnes.

---

## FLASHCARD 184 ‚Äî √Ä conna√Ætre 61 : Racine carr√©e d'un endomorphisme sym√©trique positif

### RECTO
**√Ä conna√Ætre 61 ‚Äî Racine carr√©e d'un endomorphisme sym√©trique positif**

Soit $E$ un espace euclidien de dimension finie $n$, et $u \in \mathcal{L}(E)$ un endomorphisme sym√©trique positif ($u \succeq 0$).

**Question :** √ânoncer l'existence et l'unicit√© de la racine carr√©e de $u$, et pr√©ciser ses propri√©t√©s.

### VERSO
**√ânonc√© formel**
$$ \exists ! v \in \mathcal{L}(E) \text{ tel que } \begin{cases} v \text{ est sym√©trique positif} \\ v^2 = u \end{cases} $$

Cet unique $v$ est appel√© la racine carr√©e de $u$ et not√© $\sqrt{u}$ ou $u^{1/2}$.

**Construction explicite**
Par le th√©or√®me spectral : $u = \sum_{i=1}^n \lambda_i \langle \cdot, e_i \rangle e_i$ dans une BON propre $(e_1, \dots, e_n)$ avec $\lambda_i \ge 0$. On pose :
$$ \sqrt{u} = \sum_{i=1}^n \sqrt{\lambda_i} \langle \cdot, e_i \rangle e_i $$
c'est-√†-dire $\sqrt{u}$ a les m√™mes vecteurs propres que $u$, avec valeurs propres $\sqrt{\lambda_i} \ge 0$.

**Propri√©t√©s**
*   $\sqrt{u}$ est sym√©trique positive : $Sp(\sqrt{u}) = \{\sqrt{\lambda} : \lambda \in Sp(u)\} \subset [0, +\infty[$
*   $(\sqrt{u})^2 = u$
*   $\sqrt{u}$ commute avec tout endomorphisme qui commute avec $u$
*   $u \succ 0 \implies \sqrt{u} \succ 0$ et $\sqrt{u}$ est inversible
*   $\|\sqrt{u}\|_{op} = \sqrt{\|u\|_{op}}$

### 
**Subtilit√©s**
*   **Unicit√© dans la classe "sym√©trique positif" :** Sans la contrainte de positivit√©, il peut exister plusieurs $v$ tels que $v^2 = u$ (par exemple $-\sqrt{u}$ v√©rifie aussi $(-\sqrt{u})^2 = u$ mais n'est pas positif si $u \neq 0$).
*   La racine carr√©e ne commute pas forc√©ment avec les autres endomorphismes, sauf si ceux-ci commutent avec $u$.
*   $\sqrt{u \circ v} \neq \sqrt{u} \circ \sqrt{v}$ en g√©n√©ral (si $u$ et $v$ ne commutent pas).

**Extensions**
*   **Puissances fractionnaires :** De m√™me, on peut d√©finir $u^\alpha$ pour tout $\alpha > 0$ par $u^\alpha = \sum \lambda_i^\alpha \langle \cdot, e_i \rangle e_i$.
*   **Application √† la d√©composition polaire (√Ä conna√Ætre 62) :** pour tout $f \in \mathcal{L}(E)$, $f^* \circ f \succeq 0$ et on pose $s = \sqrt{f^* \circ f}$.

**Pi√®ges classiques**
*   Croire que $\sqrt{u \circ v} = \sqrt{u} \circ \sqrt{v}$ : FAUX en g√©n√©ral.
*   Oublier la condition $u \succeq 0$ pour l'existence (si $u$ a une valeur propre n√©gative, $\sqrt{u}$ n'existe pas dans $\mathcal{L}(E)$ r√©el).

---

## FLASHCARD 185 ‚Äî √Ä conna√Ætre 62 : D√©composition polaire

### RECTO
**√Ä conna√Ætre 62 ‚Äî D√©composition polaire**

Soit $E$ un espace euclidien de dimension finie $n$, et $f \in \mathcal{L}(E)$.

**Question :** √ânoncer le th√©or√®me de d√©composition polaire de $f$, pr√©ciser l'unicit√©, et donner l'analogue matriciel.

### VERSO
**Hypoth√®ses**
*   $E$ euclidien de dimension finie $n$
*   $f \in \mathcal{L}(E)$ quelconque (pas n√©cessairement inversible)

**√ânonc√© formel**
$$ \exists s \in \mathcal{L}(E) \text{ sym√©trique positive}, \exists r \in O(E) \text{ isom√©trie, tels que } f = s \circ r $$

**Unicit√© si $f$ est inversible :**
$f$ inversible $\implies \exists ! (s, r)$ avec $s \succ 0$ et $r \in O(E)$ tels que $f = s \circ r$

Construction : $s = \sqrt{f \circ f^*}$ (racine carr√©e de $f \circ f^* \succeq 0$), puis $r = s^{-1} \circ f$ (si $f$ inversible).

**D√©composition droite :** De m√™me, $\exists r' \in O(E), \exists s' \succeq 0$ sym√©triques tels que $f = r' \circ s'$ (avec $s' = \sqrt{f^* \circ f}$).

**Traduction matricielle**
Toute matrice $A \in M_n(\mathbb{R})$ s'√©crit :
$$ A = S \cdot R \quad \text{avec } S \in S_n^+(\mathbb{R}), R \in O_n(\mathbb{R}) $$
Si $A$ est inversible : d√©composition unique avec $S \in S_n^{++}(\mathbb{R})$.

### 
**Subtilit√©s**
*   **Analogie avec $\mathbb{C}$ :** En dimension 1, tout $z \in \mathbb{C}^*$ s'√©crit $z = |z| \cdot e^{i\theta}$ (module $\times$ argument). La d√©composition polaire en est la g√©n√©ralisation matricielle : $f = \underbrace{s}_{\text{"module"}} \circ \underbrace{r}_{\text{"rotation"}}$.
*   **$f$ non inversible :** La d√©composition existe mais $s$ est seulement positive (pas d√©finie positive) et $r$ n'est pas unique.
*   La d√©composition gauche et droite donnent des $r$ diff√©rents en g√©n√©ral ($r \neq r'$), mais $s$ et $s'$ ont les m√™mes valeurs propres (valeurs singuli√®res de $f$).

**Extensions**
*   **Valeurs singuli√®res :** $Sp(s) = Sp(s') = \{\sigma_1 \ge \dots \ge \sigma_n \ge 0\}$ sont les valeurs singuli√®res de $f$. Elles caract√©risent $f$ √† isom√©trie pr√®s.
*   **SVD (Singular Value Decomposition) :** $\exists$ BON $(e_1, \dots, e_n)$ et $(f_1, \dots, f_n)$ et $\sigma_1 \ge \dots \ge \sigma_n \ge 0$ tels que $f(e_i) = \sigma_i f_i$. Hors programme MP mais fondamental en pratique.

**Pi√®ges classiques**
*   Confondre $s = \sqrt{f \circ f^*}$ et $s' = \sqrt{f^* \circ f}$ : ce sont deux sym√©triques positives diff√©rentes (isospectres mais de vecteurs propres diff√©rents).
*   Croire que la d√©composition polaire implique $f$ normale ($f \circ f^* = f^* \circ f$) : non, la d√©composition existe pour tout $f$.

---

## FLASHCARD 186 ‚Äî √Ä conna√Ætre 63 : Endomorphismes normaux (compl√©ment)

### RECTO
**√Ä conna√Ætre 63 ‚Äî Endomorphismes normaux en dimension finie r√©elle**

Soit $E$ un espace euclidien de dimension $n$, et $u \in \mathcal{L}(E)$.

**Question :** D√©finir un endomorphisme normal, donner des exemples importants, et √©noncer la propri√©t√© de r√©duction des endomorphismes normaux sur $\mathbb{R}$.

### VERSO
**D√©finition**
$u$ est normal si $u$ commute avec son adjoint :
$$ u \circ u^* = u^* \circ u $$
o√π $u^*$ est l'adjoint de $u$ d√©fini par $\forall x, y \in E : \langle u(x), y \rangle = \langle x, u^*(y) \rangle$.

**Exemples fondamentaux**
*   **Sym√©trique :** $u^* = u$ (Oui, $u \circ u = u \circ u$)
*   **Antisym√©trique :** $u^* = -u$ (Oui, $(-u) \circ u = u \circ (-u)$)
*   **Isom√©trie :** $u^* = u^{-1}$ (Oui, $u^{-1} u = u u^{-1} = id$)
*   **Projecteur orthogonal :** $u^* = u, u^2 = u$ (Oui)

**Propri√©t√© de r√©duction (sur $\mathbb{R}$)**
Sur $\mathbb{R}$, $u$ normal ne se diagonalise pas forc√©ment dans une BON (contrairement √† $\mathbb{C}$). Mais :
$$ u \text{ normal} \implies E = \bigoplus_k F_k \quad (\text{somme orthogonale}) $$
o√π chaque $F_k$ est de dimension 1 (si $\lambda_k \in \mathbb{R}$) ou de dimension 2 (si $\lambda_k, \bar{\lambda}_k \in \mathbb{C} \setminus \mathbb{R}$), et $u|_{F_k}$ est une homoth√©tie ou une similitude directe (rotation-homoth√©tie).

**Traduction matricielle :** $u$ normal $\iff \exists P \in O_n(\mathbb{R})$ telle que $P^\top A P$ est bloc-diagonale avec blocs de taille 1 (r√©els) ou 2 (complexes conjugu√©s).

### 
**Subtilit√©s**
*   **Sur $\mathbb{C}$ :** Tout endomorphisme normal d'un espace hermitien est unitairement diagonalisable ‚Äî c'est le th√©or√®me spectral complexe. Sur $\mathbb{R}$, on doit se contenter de blocs $1 \times 1$ et $2 \times 2$.
*   **Isom√©tries :** Le r√©sultat de la Proposition 52 (r√©duction des isom√©tries) est un cas particulier de la r√©duction des normaux : les blocs de taille 2 correspondent √† des rotations.
*   La normalit√© se teste via : $\|u(x)\| = \|u^*(x)\| \ \forall x$ (car $\langle u^*u(x), x \rangle = \langle uu^*(x), x \rangle$).

**Pi√®ges classiques**
*   Croire que normal $\implies$ sym√©trique : FAUX (les isom√©tries sont normales mais non sym√©triques en g√©n√©ral).
*   Sur $\mathbb{R}$, croire qu'un endomorphisme normal est toujours orthogonalement diagonalisable : FAUX (une rotation d'angle $\neq 0, \pi$ en $\mathbb{R}^2$ est normale mais n'a pas de valeur propre r√©elle).

---

# CHAPITRE 12 ‚Äî Probabilit√©s

## FLASHCARD 187 ‚Äî Proposition 54 : Continuit√© croissante et d√©croissante d'une probabilit√©

### RECTO
**Proposition 54 ‚Äî Continuit√© croissante et d√©croissante d'une mesure de probabilit√©**

Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√©.

**Question :** √ânoncer les propri√©t√©s de continuit√© croissante et d√©croissante de $P$, avec les hypoth√®ses exactes sur les suites d'√©v√©nements.

### VERSO
**Hypoth√®ses compl√®tes**
*   $(\Omega, \mathcal{A}, P)$ espace probabilis√©
*   $(A_n)_{n \ge 0}$ suite d'√©v√©nements ($A_n \in \mathcal{A} \ \forall n$)

**√ânonc√© formel**
**Continuit√© croissante :**
$$ A_0 \subset A_1 \subset \dots \subset A_n \subset \dots \implies P\left(\bigcup_{n=0}^{+\infty} A_n\right) = \lim_{n \to +\infty} P(A_n) $$

**Continuit√© d√©croissante :**
$$ A_0 \supset A_1 \supset \dots \supset A_n \supset \dots \implies P\left(\bigcap_{n=0}^{+\infty} A_n\right) = \lim_{n \to +\infty} P(A_n) $$

**D√©monstration (Esquisse)**
*   **Continuit√© croissante :** Poser $B_0 = A_0$ et $B_n = A_n \setminus A_{n-1}$ pour $n \ge 1$. Les $B_n$ sont deux √† deux disjoints, $\bigcup_{k=0}^n B_k = A_n$, et $\bigcup_{n \ge 0} B_n = \bigcup_{n \ge 0} A_n$. Par $\sigma$-additivit√© :
    $$ P\left(\bigcup_n A_n\right) = \sum_{n=0}^{+\infty} P(B_n) = \lim_{N \to \infty} \sum_{n=0}^N P(B_n) = \lim_{N \to \infty} P(A_N) $$
*   **Continuit√© d√©croissante :** Par compl√©mentarit√© : $B_n = A_n^c$ est croissante, appliquer la continuit√© croissante √† $(B_n)$.

### 
**Subtilit√©s**
*   **La $\sigma$-additivit√© est la cl√© :** Ces propri√©t√©s sont √©quivalentes √† la $\sigma$-additivit√© (avec la finitude de $P(\Omega)=1$). Une mesure additive (non $\sigma$-additive) ne v√©rifie pas forc√©ment ces continuit√©s.
*   **Continuit√© d√©croissante sans hypoth√®se de finitude :** En th√©orie de la mesure g√©n√©rale, la continuit√© d√©croissante requiert que $P(A_0) < +\infty$. Ici, puisque $P(A_0) \le 1 < +\infty$, c'est automatique.
*   Ces r√©sultats s'appliquent √† toute mesure finie, pas seulement aux probabilit√©s.

**Pi√®ges classiques**
*   Oublier la condition de monotonie : sans $A_n \subset A_{n+1}$ (resp. $\supset$), le r√©sultat est faux en g√©n√©ral.
*   Confondre $\liminf A_n$, $\limsup A_n$, $\cup A_n$, $\cap A_n$ : la continuit√© concerne les suites monotones.
*   Contre-exemple pour la d√©croissante sans finitude : Sur $(\mathbb{N}, \mathcal{P}(\mathbb{N}), \#)$ (mesure de comptage), $A_n = \{k \ge n\}$ est d√©croissante, $\cap A_n = \emptyset$ mais $\#(A_n) = +\infty \ \forall n$.

---

## FLASHCARD 188 ‚Äî √Ä conna√Ætre 64 : Formule du crible (inclusion-exclusion)

### RECTO
**√Ä conna√Ætre 64 ‚Äî Formule du crible (Poincar√©)**

Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√© et $A_1, \dots, A_n \in \mathcal{A}$.

**Question :** √ânoncer la formule du crible pour $P(A_1 \cup \dots \cup A_n)$.

### VERSO
**√ânonc√© formel**
$$ P\left(\bigcup_{i=1}^n A_i\right) = \sum_{k=1}^n (-1)^{k-1} \sum_{1 \le i_1 < \dots < i_k \le n} P(A_{i_1} \cap \dots \cap A_{i_k}) $$

**D√©velopp√© pour $n=3$ :**
$P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B \cap C) + P(A \cap B \cap C)$

**Formule compl√©mentaire (√©v√©nement contraire) :**
$$ P\left(\bigcap_{i=1}^n A_i^c\right) = 1 - P\left(\bigcup_{i=1}^n A_i\right) = \sum_{k=0}^n (-1)^k \sum_{|I|=k} P\left(\bigcap_{i \in I} A_i\right) $$

**D√©monstration (Esquisse)**
Par r√©currence sur $n$ : initialisation triviale. H√©r√©dit√© via $P(A \cup B) = P(A) + P(B) - P(A \cap B)$ (additivit√© + compl√©mentarit√©). Alternativement, via l'indicatrice : $1_{\cup A_i} = 1 - \prod_i (1 - 1_{A_i})$, d√©velopper et prendre l'esp√©rance.

### 
**Subtilit√©s**
*   **Formule du crible in√©gale (Bonferroni) :** Les troncatures donnent des in√©galit√©s altern√©es :
    $P(\cup A_i) \le \sum P(A_i)$ (union bound)
    $P(\cup A_i) \ge \sum P(A_i) - \sum_{i<j} P(A_i \cap A_j)$
*   **Nombre de termes :** La somme contient $2^n - 1$ termes au total.

**Pi√®ges classiques**
*   Oublier les signes altern√©s : le terme d'ordre $k$ est de signe $(-1)^{k-1}$.
*   Erreur de comptage dans la somme sur les $\binom{n}{k}$ intersections.
*   Confondre avec la formule d'inclusion-exclusion ensembliste (m√™me structure, mais avec des cardinaux).

---

## FLASHCARD 189 ‚Äî √Ä conna√Ætre 65 : Premier lemme de Borel-Cantelli

### RECTO
**√Ä conna√Ætre 65 ‚Äî Premier lemme de Borel-Cantelli**

Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√© et $(A_n)_{n \ge 1}$ une suite d'√©v√©nements.

**Question :** √ânoncer le premier lemme de Borel-Cantelli, pr√©ciser la condition et la conclusion sur $P(\limsup A_n)$.

### VERSO
**Notation pr√©liminaire**
$$ \limsup_{n \to +\infty} A_n = \bigcap_{n=1}^{+\infty} \bigcup_{k=n}^{+\infty} A_k = \{A_n \text{ i.o.}\} = \{\omega : \omega \in A_n \text{ pour une infinit√© de } n\} $$
("i.o." = infinitely often = infiniment souvent)

**Hypoth√®se**
$$ \sum_{n=1}^{+\infty} P(A_n) < +\infty $$

**Conclusion**
$$ P(\limsup_{n \to +\infty} A_n) = 0 $$

**D√©monstration**
$$ P\left(\bigcap_{n=1}^\infty \bigcup_{k=n}^\infty A_k\right) \le P\left(\bigcup_{k=n}^\infty A_k\right) \le \sum_{k=n}^{+\infty} P(A_k) \xrightarrow[n \to +\infty]{} 0 $$
car $\sum P(A_n) < +\infty$ (reste d'une s√©rie convergente). Par continuit√© d√©croissante :
$$ P\left(\bigcap_{n \ge 1} \bigcup_{k \ge n} A_k\right) = \lim_{n \to +\infty} P\left(\bigcup_{k \ge n} A_k\right) = 0 $$

### 
**Subtilit√©s**
*   **Aucune hypoth√®se d'ind√©pendance !** Le premier lemme vaut pour des √©v√©nements quelconques (pas besoin d'ind√©pendance).
*   **La r√©ciproque est fausse :** $\sum P(A_n) = +\infty$ n'implique pas $P(\limsup A_n) > 0$ en g√©n√©ral (sans ind√©pendance). Exemple : $A_n = A$ pour tout $n$, $P(A) > 0$, $\sum P(A_n) = +\infty$, mais $\limsup A_n = A$ et $P(A)$ peut √™tre < 1.
*   **La r√©ciproque avec ind√©pendance :** C'est le second lemme de Borel-Cantelli (√Ä conna√Ætre 66).

**Pi√®ges classiques**
*   Croire qu'il faut l'ind√©pendance pour le premier lemme : non, il est g√©n√©ral.
*   Mal interpr√©ter $\limsup A_n$ : c'est l'√©v√©nement "infiniment souvent $A_n$", pas la limite de $A_n$.
*   Utiliser $\sigma$-sous-additivit√© ($P(\cup A_k) \le \sum P(A_k)$) sans la mentionner.

---

## FLASHCARD 190 ‚Äî √Ä conna√Ætre 66 : Second lemme de Borel-Cantelli

### RECTO
**√Ä conna√Ætre 66 ‚Äî Second lemme de Borel-Cantelli**

Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√© et $(A_n)_{n \ge 1}$ une suite d'√©v√©nements mutuellement ind√©pendants.

**Question :** √ânoncer le second lemme de Borel-Cantelli et sa conclusion sur $P(\limsup A_n)$.

### VERSO
**Hypoth√®ses**
*   $(A_n)_{n \ge 1}$ suite d'√©v√©nements mutuellement ind√©pendants :
    $$ \forall k \ge 1, \forall 1 \le n_1 < \dots < n_k, \quad P(A_{n_1} \cap \dots \cap A_{n_k}) = \prod_{i=1}^k P(A_{n_i}) $$
*   $\sum_{n=1}^{+\infty} P(A_n) = +\infty$

**Conclusion**
$$ P(\limsup_{n \to +\infty} A_n) = 1 $$

**D√©monstration (Esquisse)**
Il suffit de montrer $P(\liminf A_n^c) = 0$, i.e. $P(\bigcup_n \bigcap_{k \ge n} A_k^c) = 0$.

Pour $n \le k \le N$, par ind√©pendance :
$$ P\left(\bigcap_{k=n}^N A_k^c\right) = \prod_{k=n}^N (1 - P(A_k)) \le \prod_{k=n}^N e^{-P(A_k)} = \exp\left(-\sum_{k=n}^N P(A_k)\right) \xrightarrow[N \to +\infty]{} 0 $$
car $\sum P(A_k) = +\infty$. Par continuit√© d√©croissante, $P(\bigcap_{k \ge n} A_k^c) = 0 \ \forall n$, donc $P(\bigcup_n \bigcap_{k \ge n} A_k^c) = 0$.

### 
**Subtilit√©s**
*   **L'ind√©pendance mutuelle est cruciale :** L'ind√©pendance deux √† deux ne suffit pas.
*   $\sum P(A_n) = +\infty$ + ind√©pendance $\implies P(\limsup A_n) = 1$ : La loi du 0-1 de Kolmogorov affirme que $P(\limsup A_n) \in \{0, 1\}$ pour des √©v√©nements ind√©pendants (c'est un √©v√©nement asymptotique "terminal").
*   L'in√©galit√© $1-x \le e^{-x}$ est la cl√© de la preuve.

**Pi√®ges classiques**
*   Confondre les deux lemmes de Borel-Cantelli : premier = convergence de la s√©rie $\implies$ proba nulle (sans ind√©pendance) ; second = divergence + ind√©pendance $\implies$ proba 1.
*   Oublier que l'ind√©pendance deux √† deux ne suffit pas pour le second lemme.

---

## FLASHCARD 191 ‚Äî Proposition 55 : Formule des probabilit√©s totales

### RECTO
**Proposition 55 ‚Äî Formule des probabilit√©s totales**

Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√©.

**Question :** √ânoncer la formule des probabilit√©s totales dans le cadre d'un syst√®me complet d'√©v√©nements, avec les hypoth√®ses exactes.

### VERSO
**D√©finition pr√©liminaire**
$(B_i)_{i \in I}$ (avec $I$ fini ou d√©nombrable) est un syst√®me complet d'√©v√©nements (SCE) si :
*   Les $B_i$ sont deux √† deux incompatibles : $\forall i \neq j, B_i \cap B_j = \emptyset$
*   Ils recouvrent $\Omega$ : $\bigsqcup_{i \in I} B_i = \Omega$
*   $\forall i \in I, P(B_i) > 0$ (hypoth√®se parfois requise pour conditionner)

**√ânonc√© formel**
Soit $(B_i)_{i \in I}$ un SCE avec $P(B_i) > 0 \ \forall i$, et $A \in \mathcal{A}$ :

$$ P(A) = \sum_{i \in I} P(A \mid B_i) P(B_i) $$

Version sans conditionnement (si certains $P(B_i) = 0$) :
$$ P(A) = \sum_{i \in I} P(A \cap B_i) $$
(toujours valide par $\sigma$-additivit√© car $A = \bigsqcup_i (A \cap B_i)$).

**D√©monstration**
$A = A \cap \Omega = A \cap \bigsqcup_i B_i = \bigsqcup_i (A \cap B_i)$, disjoints. Par $\sigma$-additivit√© :
$$ P(A) = \sum_i P(A \cap B_i) = \sum_i P(A \mid B_i) P(B_i) $$

### 
**Subtilit√©s**
*   **$I$ peut √™tre infini d√©nombrable :** La formule reste valide par $\sigma$-additivit√©, √† condition que $(B_i)$ soit bien un SCE d√©nombrable.
*   $P(B_i) > 0$ n√©cessaire pour √©crire $P(A \mid B_i)$ : Si $P(B_i) = 0$, le terme $P(A \cap B_i) = 0$ donc on peut ignorer $B_i$ ou utiliser la version sans conditionnement.
*   Le cas $I = \{B, B^c\}$ : $P(A) = P(A \mid B)P(B) + P(A \mid B^c)P(B^c)$ (version la plus classique).

**Pi√®ges classiques**
*   Oublier que les $B_i$ doivent partitionner tout $\Omega$, pas juste un sous-ensemble.
*   Appliquer la formule avec un $B_i$ de probabilit√© nulle sans pr√©caution.
*   Confondre $P(A \mid B_i)P(B_i)$ avec $P(B_i \mid A)P(A)$ ‚Äî c'est la formule de Bayes.

---

## FLASHCARD 192 ‚Äî Proposition 56 : Formule de Bayes

### RECTO
**Proposition 56 ‚Äî Formule de Bayes**

Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√©, $(B_i)_{i \in I}$ un syst√®me complet d'√©v√©nements avec $P(B_i) > 0$, et $A \in \mathcal{A}$ avec $P(A) > 0$.

**Question :** √ânoncer la formule de Bayes permettant de calculer $P(B_j \mid A)$.

### VERSO
**√ânonc√© formel**
$$ \forall j \in I : \quad P(B_j \mid A) = \frac{P(A \mid B_j) P(B_j)}{\sum_{i \in I} P(A \mid B_i) P(B_i)} $$

**D√©monstration**
Par d√©finition de la probabilit√© conditionnelle et la formule des probabilit√©s totales :
$$ P(B_j \mid A) = \frac{P(A \cap B_j)}{P(A)} = \frac{P(A \mid B_j) P(B_j)}{P(A)} = \frac{P(A \mid B_j) P(B_j)}{\sum_i P(A \mid B_i) P(B_i)} $$

**Terminologie probabiliste**
*   $P(B_j)$ : probabilit√© a priori (prior) de $B_j$
*   $P(A \mid B_j)$ : vraisemblance de $A$ sachant $B_j$
*   $P(B_j \mid A)$ : probabilit√© a posteriori (posterior) de $B_j$ sachant $A$

### 
**Subtilit√©s**
*   $P(A) > 0$ est indispensable pour que $P(B_j \mid A)$ soit d√©fini.
*   Bayes est une cons√©quence directe de la d√©finition de la probabilit√© conditionnelle + formule des probabilit√©s totales : ce n'est pas un axiome.
*   **Application classique :** Tests m√©dicaux (sensibilit√©/sp√©cificit√©), paradoxe de Monty Hall, etc.

**Pi√®ges classiques**
*   **Inverser $P(A \mid B_j)$ et $P(B_j \mid A)$ :** c'est l'erreur de la transposition du conditionnel (fallacy of the transposed conditional), tr√®s fr√©quente.
*   Oublier de normaliser (le d√©nominateur est $P(A)$, pas 1).

---

## FLASHCARD 193 ‚Äî Proposition 57 : In√©galit√© de Cauchy-Schwarz (probabiliste)

### RECTO
**Proposition 57 ‚Äî In√©galit√© de Cauchy-Schwarz probabiliste**

Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√©, et $X, Y$ deux variables al√©atoires de carr√© int√©grable ($X, Y \in L^2(\Omega)$).

**Question :** √ânoncer l'in√©galit√© de Cauchy-Schwarz dans ce cadre, avec la condition d'√©galit√©.

### VERSO
**Hypoth√®ses**
*   $X, Y : \Omega \to \mathbb{R}$ variables al√©atoires
*   $E[X^2] < +\infty$ et $E[Y^2] < +\infty$ (i.e. $X, Y \in L^2$)

**√ânonc√© formel**
$$ |E[XY]|^2 \le E[X^2] E[Y^2] $$

**Condition d'√©galit√© :**
$$ E[XY]^2 = E[X^2] E[Y^2] \iff \exists (\alpha, \beta) \neq (0, 0), \alpha X + \beta Y = 0 \text{ p.s.} $$
i.e. $X$ et $Y$ sont presque s√ªrement proportionnels.

**Corollaire (covariance)**
$$ |\text{Cov}(X, Y)|^2 \le \text{Var}(X) \text{Var}(Y) $$
$$ |\rho(X, Y)| \le 1 \quad \text{o√π } \rho(X, Y) = \frac{\text{Cov}(X, Y)}{\sqrt{\text{Var}(X)} \sqrt{\text{Var}(Y)}} $$

**D√©monstration (Esquisse)**
$(X, Y) \mapsto E[XY]$ est un produit scalaire sur $L^2$. Appliquer Cauchy-Schwarz dans cet espace de Hilbert : $\|XY\|_1 = |E[XY]| \le \|X\|_2 \|Y\|_2$. Formellement, discriminant de $t \mapsto E[(tX+Y)^2] = E[X^2]t^2 + 2E[XY]t + E[Y^2] \ge 0$.

### 
**Subtilit√©s**
*   $L^2$ est requis : $E[XY]$ peut ne pas exister si $X \notin L^2$ ou $Y \notin L^2$ (l'in√©galit√© de H√∂lder g√©n√©ralise).
*   **Corr√©lation :** $|\rho| = 1 \iff X$ et $Y$ affines p.s. ($Y = aX+b$ p.s.). La corr√©lation mesure la d√©pendance lin√©aire, non la d√©pendance tout court.

**Pi√®ges classiques**
*   Confondre $E[XY]^2 \le E[X^2] E[Y^2]$ avec $(E[XY])^2 \le E[X^2] E[Y^2]$ : ce sont la m√™me chose ($|E[XY]|^2$).
*   Croire que $\rho(X, Y) = 0$ implique l'ind√©pendance : FAUX (corr√©lation nulle $\not\Rightarrow$ ind√©pendance).

---

## FLASHCARD 194 ‚Äî Proposition 58 : Variance d'une somme

### RECTO
**Proposition 58 ‚Äî Variance d'une somme de variables al√©atoires**

Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√© et $X_1, \dots, X_n \in L^2(\Omega)$.

**Question :** Donner la formule de la variance d'une somme $S_n = X_1 + \dots + X_n$, en faisant appara√Ætre les covariances. Donner le cas des variables deux √† deux non corr√©l√©es.

### VERSO
**√ânonc√© formel ‚Äî Formule g√©n√©rale**
$$ \text{Var}(X_1 + \dots + X_n) = \sum_{i=1}^n \text{Var}(X_i) + 2 \sum_{1 \le i < j \le n} \text{Cov}(X_i, X_j) $$

Ou de fa√ßon compacte :
$$ \text{Var}\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \sum_{j=1}^n \text{Cov}(X_i, X_j) $$
(en notant $\text{Cov}(X_i, X_i) = \text{Var}(X_i)$).

**Cas particuliers**
**Variables deux √† deux non corr√©l√©es** ($\text{Cov}(X_i, X_j) = 0 \ \forall i \neq j$) :
$$ \text{Var}\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \text{Var}(X_i) $$

En particulier pour des v.a. ind√©pendantes de $L^2$ : (ind√©pendance $\implies$ non corr√©l√©es) :
$$ X_1, \dots, X_n \text{ ind√©pendantes} \implies \text{Var}\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \text{Var}(X_i) $$

**Rappels**
*   $\text{Var}(X) = E[X^2] - (E[X])^2 = E[(X - E[X])^2]$
*   $\text{Cov}(X, Y) = E[XY] - E[X]E[Y]$
*   $\text{Var}(aX+b) = a^2 \text{Var}(X)$

### 
**Subtilit√©s**
*   **Non corr√©l√© $\not\Rightarrow$ ind√©pendant :** Il existe des variables non corr√©l√©es mais d√©pendantes. La formule de la variance s'additionne pour les non corr√©l√©es, ce qui est plus faible que l'ind√©pendance.
*   **Ind√©pendant $\implies$ non corr√©l√© :** Si $X, Y$ ind√©pendantes et $\in L^2$, alors $E[XY] = E[X]E[Y]$ donc $\text{Cov}(X, Y) = 0$.
*   $n^2$ termes dans la double somme, dont $n$ termes diagonaux (variances) et $n(n-1)$ termes crois√©s (covariances, par paires = $n(n-1)/2$ termes distincts).

**Pi√®ges classiques**
*   Oublier le facteur 2 devant $\sum_{i < j} \text{Cov}(X_i, X_j)$.
*   Confondre non corr√©l√©es et ind√©pendantes.
*   Appliquer la formule $\text{Var}(\sum X_i) = \sum \text{Var}(X_i)$ sans v√©rifier la non-corr√©lation.

---

## FLASHCARD 195 ‚Äî Proposition 59 : Variables al√©atoires ind√©pendantes

### RECTO
**Proposition 59 ‚Äî Propri√©t√©s des variables al√©atoires ind√©pendantes**

Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√© et $X_1, \dots, X_n$ des variables al√©atoires mutuellement ind√©pendantes.

**Question :** √ânoncer les principales propri√©t√©s des variables al√©atoires ind√©pendantes : esp√©rance du produit, fonctions, loi jointe.

### VERSO
**D√©finition (rappel)**
$X_1, \dots, X_n$ sont mutuellement ind√©pendantes si :
$$ \forall B_1, \dots, B_n \in \mathcal{B}(\mathbb{R}) : P(X_1 \in B_1, \dots, X_n \in B_n) = \prod_{i=1}^n P(X_i \in B_i) $$

**Propri√©t√©s fondamentales**
1.  **Loi jointe = produit des lois marginales :**
    $$ P_{(X_1, \dots, X_n)} = P_{X_1} \otimes \dots \otimes P_{X_n} $$

2.  **Esp√©rance du produit (si $X_i \in L^1$) :**
    $$ E\left[\prod_{i=1}^n X_i\right] = \prod_{i=1}^n E[X_i] $$

3.  **Stabilit√© par fonctions mesurables :** Si $f_1, \dots, f_n : \mathbb{R} \to \mathbb{R}$ sont mesurables, alors $f_1(X_1), \dots, f_n(X_n)$ sont mutuellement ind√©pendantes.

4.  **Stabilit√© par regroupement :** Si $(I_1, \dots, I_k)$ est une partition de $\llbracket 1, n \rrbracket$ et $g_j$ mesurable, alors $g_1((X_i)_{i \in I_1}), \dots, g_k((X_i)_{i \in I_k})$ sont ind√©pendantes.

5.  **Non corr√©lation :** $X_i, X_j \in L^2 \implies \text{Cov}(X_i, X_j) = 0$.

### 
**Subtilit√©s**
*   **Ind√©pendance mutuelle $\neq$ ind√©pendance deux √† deux :** Il existe des familles deux √† deux ind√©pendantes mais pas mutuellement ind√©pendantes (contre-exemple classique : pile ou face avec 3 variables).
*   La r√©ciproque de (2) est fausse : $E[XY] = E[X]E[Y]$ (non corr√©l√©es) n'implique pas l'ind√©pendance.
*   Propri√©t√© (3) est extr√™mement utile : Elle permet par exemple de d√©duire que $X^2$ et $Y^2$ sont ind√©pendantes si $X$ et $Y$ le sont.

**Pi√®ges classiques**
*   Confondre ind√©pendance deux √† deux et mutuelle : bien pr√©ciser dans les √©nonc√©s.
*   Oublier l'int√©grabilit√© pour (2) : $X_i$ doivent √™tre dans $L^1$ pour que $E[\prod X_i] = \prod E[X_i]$.

---

## FLASHCARD 196 ‚Äî Proposition 60 : Esp√©rance conditionnelle (cas discret)

### RECTO
**Proposition 60 ‚Äî Esp√©rance conditionnelle (cadre discret)**

Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√©, $X$ une variable al√©atoire r√©elle et $Y$ une variable al√©atoire discr√®te (√† valeurs dans un ensemble d√©nombrable $D$).

**Question :** D√©finir $E[X \mid Y]$ dans le cas discret, et √©noncer ses propri√©t√©s fondamentales.

### VERSO
**D√©finition**
Si $X \in L^1(\Omega)$ et $Y$ discr√®te √† valeurs dans $D$ :

$$ E[X \mid Y] : \omega \mapsto \sum_{y \in D} E[X \mid Y=y] \, 1_{Y(\omega)=y} $$

o√π $E[X \mid Y=y] = \frac{E[X \cdot 1_{Y=y}]}{P(Y=y)}$ si $P(Y=y) > 0$.

C'est une variable al√©atoire (mesurable par rapport √† $\sigma(Y)$).

**Propri√©t√©s fondamentales**
1.  **Lin√©arit√© :** $E[\alpha X + \beta Z \mid Y] = \alpha E[X \mid Y] + \beta E[Z \mid Y]$ p.s.
2.  **Esp√©rance totale (tour de la tour ‚Äî cas simple) :**
    $$ E[E[X \mid Y]] = E[X] $$
3.  **Extraction des facteurs mesurables :**
    $$ E[f(Y) \cdot X \mid Y] = f(Y) \cdot E[X \mid Y] \quad \text{p.s.} $$
4.  **Ind√©pendance :**
    $$ X \perp Y \implies E[X \mid Y] = E[X] \quad \text{p.s.} $$
5.  **Positivit√© :** $X \ge 0$ p.s. $\implies E[X \mid Y] \ge 0$ p.s.

### 
**Subtilit√©s**
*   $E[X \mid Y]$ est une variable al√©atoire, pas un nombre : elle d√©pend de $\omega$ √† travers $Y(\omega)$.
*   La formule des probabilit√©s totales est le cas $X = 1_A$ : $P(A) = E[1_A] = E[E[1_A \mid Y]] = \sum_y P(A \mid Y=y)P(Y=y)$.
*   **En programme MP :** L'esp√©rance conditionnelle compl√®te (d√©finie par le th√©or√®me de Radon-Nikodym) est hors programme ; on se limite au cas discret.

**Pi√®ges classiques**
*   Confondre $E[X \mid Y=y]$ (un r√©el) et $E[X \mid Y]$ (une v.a.).
*   Oublier que $E[X \mid Y]$ est $\sigma(Y)$-mesurable, donc est une fonction de $Y$.

---

## FLASHCARD 197 ‚Äî Lemme 9 : Lemme des coalitions

### RECTO
**Lemme 9 ‚Äî Lemme des coalitions**

Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√© et $(X_i)_{i \in I}$ une famille de variables al√©atoires mutuellement ind√©pendantes.

**Question :** √ânoncer le lemme des coalitions, pr√©cisant comment on peut regrouper des variables ind√©pendantes.

### VERSO
**√ânonc√© formel**
Soit $(X_1, \dots, X_n)$ des variables al√©atoires mutuellement ind√©pendantes. Soit $(I_1, \dots, I_k)$ une partition de $\llbracket 1, n \rrbracket$ (i.e. $I_1 \sqcup \dots \sqcup I_k = \llbracket 1, n \rrbracket$).

Soit pour chaque $j \in \llbracket 1, k \rrbracket$, $f_j : \mathbb{R}^{|I_j|} \to \mathbb{R}$ une fonction mesurable (bor√©lienne).

Alors les variables al√©atoires :
$$ Y_j = f_j((X_i)_{i \in I_j}), \quad j = 1, \dots, k $$
sont mutuellement ind√©pendantes.

**Cas particulier important**
$$ X_1, \dots, X_n \text{ i.i.d.} \implies (X_1, \dots, X_p) \perp (X_{p+1}, \dots, X_n) $$

Et donc $f(X_1, \dots, X_p) \perp g(X_{p+1}, \dots, X_n)$ pour toutes fonctions mesurables $f, g$.

**D√©monstration (Id√©e)**
Les $\sigma$-alg√®bres $\sigma(X_i, i \in I_j)$ pour $j = 1, \dots, k$ sont mutuellement ind√©pendantes (par ind√©pendance mutuelle des $X_i$). Comme $Y_j$ est mesurable par rapport √† $\sigma(X_i, i \in I_j)$, les $Y_j$ sont ind√©pendantes.

### 
**Subtilit√©s**
*   Partition = recouvrement disjoint complet : Les groupes $I_j$ ne se chevauchent pas.
*   **Mesurabilit√© des $f_j$ indispensable :** Sans mesurabilit√©, $Y_j$ n'est pas une variable al√©atoire.
*   Application typique : $S_p = X_1 + \dots + X_p$ et $T = X_{p+1} + \dots + X_n$ sont ind√©pendantes si $(X_i)$ i.i.d.

**Pi√®ges classiques**
*   Croire que ce lemme s'applique √† des variables seulement deux √† deux ind√©pendantes : il faut l'ind√©pendance mutuelle.
*   Confondre "les $X_i$ sont ind√©pendants" avec "les $Y_j$ sont ind√©pendants" sans pr√©ciser la partition.

---

## FLASHCARD 198 ‚Äî Proposition 61 : Esp√©rance d'un produit de variables ind√©pendantes

### RECTO
**Proposition 61 ‚Äî Esp√©rance d'un produit de variables al√©atoires ind√©pendantes**

Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√©, et $X_1, \dots, X_n$ des variables al√©atoires mutuellement ind√©pendantes et int√©grables ($X_i \in L^1$).

**Question :** Montrer que $X_1 \dots X_n \in L^1$ et que $E[X_1 \dots X_n] = \prod_{i=1}^n E[X_i]$.

### VERSO
**Hypoth√®ses**
*   $X_1, \dots, X_n$ mutuellement ind√©pendantes
*   $\forall i, X_i \in L^1(\Omega)$ (i.e. $E[|X_i|] < +\infty$)

**√ânonc√© formel**
$$ X_1 \dots X_n \in L^1(\Omega) \quad \text{et} \quad E\left[\prod_{i=1}^n X_i\right] = \prod_{i=1}^n E[X_i] $$

**D√©monstration (Esquisse)**
Cas $n=2$ : Par la formule de transfert et l'ind√©pendance (loi jointe = produit des marginales) :
$$ E[XY] = \int_{\mathbb{R}^2} xy d(P_X \otimes P_Y)(x, y) = \int_\mathbb{R} x dP_X(x) \cdot \int_\mathbb{R} y dP_Y(y) = E[X] E[Y] $$
L'int√©grabilit√© de $XY$ vient du th√©or√®me de Fubini : $E[|XY|] = E[|X|]E[|Y|] < +\infty$.

Cas g√©n√©ral : Par r√©currence et le lemme des coalitions.

### 
**Subtilit√©s**
*   L'int√©grabilit√© du produit n'est pas automatique pour des variables non ind√©pendantes : $X$ et $Y$ int√©grables n'implique pas $XY$ int√©grable. Ici, l'ind√©pendance + $L^1$ donne $E[|XY|] = E[|X|]E[|Y|] < +\infty$.
*   La r√©ciproque est fausse : $E[XY] = E[X]E[Y]$ n'implique pas l'ind√©pendance (seulement la non-corr√©lation si $X, Y \in L^2$).
*   Pour $X \in L^2$ : $E[XY] = E[X]E[Y]$ √©quivaut √† $\text{Cov}(X, Y) = 0$.

**Pi√®ges classiques**
*   Appliquer la formule $E[\prod X_i] = \prod E[X_i]$ √† des variables corr√©l√©es.
*   Oublier de v√©rifier l'int√©grabilit√© du produit avant d'invoquer la formule.

---

## FLASHCARD 199 ‚Äî Proposition 62 : Formule de transfert

### RECTO
**Proposition 62 ‚Äî Formule de transfert**

Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√©, $X : \Omega \to E$ une variable al√©atoire √† valeurs dans un espace mesurable $(E, \mathcal{E})$, et $f : E \to \mathbb{R}$ une fonction mesurable.

**Question :** √ânoncer la formule de transfert, donnant $E[f(X)]$ en fonction de la loi $P_X$ de $X$.

### VERSO
**√ânonc√© formel**
Si $f \ge 0$ ou $f(X) \in L^1(\Omega)$ :

$$ E[f(X)] = \int_E f(x) dP_X(x) $$

o√π $P_X = X^* P$ est la loi image (pushforward) de $P$ par $X$.

**Cas discret ($X$ √† valeurs dans $D$ d√©nombrable)**
$$ E[f(X)] = \sum_{x \in D} f(x) P(X=x) $$

**Cas √† densit√© ($X$ admet une densit√© $p_X$ par rapport √† la mesure de Lebesgue)**
$$ E[f(X)] = \int_\mathbb{R} f(x) p_X(x) dx $$

**D√©monstration (Id√©e)**
Par d√©finition de l'int√©grale par rapport √† la mesure image : $\int_E f d(X^* P) = \int_\Omega f \circ X dP = E[f(X)]$.

### 
**Subtilit√©s**
*   La formule de transfert est fondamentale : Elle permet de calculer $E[f(X)]$ √† partir de la seule loi de $X$, sans revenir √† $\Omega$.
*   **Condition d'applicabilit√© :** $f(X) \in L^1(\Omega) \iff \int_E |f| dP_X < +\infty$. V√©rifier cela en pratique (via la densit√© ou la loi discr√®te).
*   **G√©n√©ralisation :** Pour $(X_1, \dots, X_n)$ de loi jointe $P_{(X_1, \dots, X_n)}$ :
    $$ E[f(X_1, \dots, X_n)] = \int_{\mathbb{R}^n} f(x_1, \dots, x_n) dP_{(X_1, \dots, X_n)}(x_1, \dots, x_n) $$

**Pi√®ges classiques**
*   Confondre la mesure de probabilit√© $P_X$ (d√©finie sur $\mathbb{R}$) avec la densit√© $p_X$ (fonction). $P_X = p_X \cdot \lambda$ seulement si $X$ a une densit√©.
*   Oublier de v√©rifier l'int√©grabilit√© de $f$ avant d'appliquer la formule.

---

## FLASHCARD 200 ‚Äî Proposition 63 : Fonctions g√©n√©ratrices

### RECTO
**Proposition 63 ‚Äî Fonctions g√©n√©ratrices des probabilit√©s et des moments**

Soit $X$ une variable al√©atoire √† valeurs dans $\mathbb{N}$ (variable al√©atoire discr√®te sur $\mathbb{N}$).

**Question :** D√©finir la fonction g√©n√©ratrice de $X$, son rayon de convergence minimal, et √©noncer les propri√©t√©s permettant de retrouver la loi et les moments.

### VERSO
**D√©finition**
La fonction g√©n√©ratrice (des probabilit√©s) de $X$ est :

$$ G_X : t \mapsto E[t^X] = \sum_{k=0}^{+\infty} P(X=k) t^k $$

**Domaine :** $G_X$ est d√©finie et la s√©rie converge absolument au moins pour $t \in [-1, 1]$ (car $\sum P(X=k)|t|^k \le \sum P(X=k) = 1$ pour $|t| \le 1$).

**Propri√©t√©s fondamentales**
1.  **D√©termination de la loi :**
    $$ P(X=k) = \frac{G_X^{(k)}(0)}{k!} \quad \forall k \in \mathbb{N} $$

2.  **Moments :**
    $$ E[X] = G_X'(1^-), \quad E[X(X-1)] = G_X''(1^-), \dots $$
    $$ E[X(X-1)\dots(X-k+1)] = G_X^{(k)}(1^-) $$

3.  **Ind√©pendance :**
    $$ X \perp Y \implies G_{X+Y}(t) = G_X(t) \cdot G_Y(t) $$

4.  La suite $(G_X(t))_t$ caract√©rise la loi de $X$ (unicit√© de la d√©composition en s√©rie enti√®re).

**Fonctions g√©n√©ratrices classiques**
*   **$B(n, p)$ :** $(1-p+pt)^n$
*   **$P(\lambda)$ :** $e^{\lambda(t-1)}$
*   **$G(p)$ :** $\frac{p}{1-(1-p)t}$
*   **$B(1, p)$ :** $1-p+pt$

### 
**Subtilit√©s**
*   $G_X(1) = 1$ toujours (conservation de la masse totale).
*   Rayon de convergence $\ge 1$ : $G_X$ est une s√©rie enti√®re de rayon $R \ge 1$. Elle peut diverger pour $|t| > 1$.
*   D√©riv√©es en $t=1$ : Les formules de moments utilisent les d√©riv√©es en $1^-$ (limite √† gauche) car $G_X$ peut ne pas √™tre d√©finie pour $t > 1$.
*   Diff√©rence avec la fonction g√©n√©ratrice des moments : $M_X(t) = E[e^{tX}]$ (ne converge pas toujours), diff√©rente de $G_X$.

**Pi√®ges classiques**
*   Confondre fonction g√©n√©ratrice (pour $\mathbb{N}$-valu√©es) et fonction caract√©ristique $\varphi_X(t) = E[e^{itX}]$ (toujours d√©finie, pour toute v.a. r√©elle).
*   Oublier que $G_X$ ne s'applique qu'aux v.a. √† valeurs dans $\mathbb{N}$.
*   Erreur dans la formule des moments : $E[X] = G_X'(1)$, pas $G_X'(0)$.

---

## FLASHCARD 201 ‚Äî √Ä conna√Ætre 67 : Fonction caract√©ristique

### RECTO
**√Ä conna√Ætre 67 ‚Äî Fonction caract√©ristique d'une variable al√©atoire**

Soit $X$ une variable al√©atoire r√©elle sur $(\Omega, \mathcal{A}, P)$.

**Question :** D√©finir la fonction caract√©ristique de $X$, donner ses propri√©t√©s fondamentales et les exemples classiques.

### VERSO
**D√©finition**
$$ \varphi_X : \mathbb{R} \to \mathbb{C}, \quad \varphi_X(t) = E[e^{itX}] = \int_\mathbb{R} e^{itx} dP_X(x) $$

**Remarque :** $|\varphi_X(t)| \le E[|e^{itX}|] = 1$, donc $\varphi_X$ est toujours d√©finie et born√©e.

**Propri√©t√©s fondamentales**
1.  **Valeur en 0 :** $\varphi_X(0) = 1$
2.  **Conjugaison :** $\varphi_X(-t) = \overline{\varphi_X(t)}$
3.  **Continuit√© :** $\varphi_X$ est continue sur $\mathbb{R}$
4.  **Caract√©risation de la loi :** $\varphi_X = \varphi_Y \iff P_X = P_Y$ (injectivit√©)
5.  **Ind√©pendance :** $X \perp Y \implies \varphi_{X+Y}(t) = \varphi_X(t) \cdot \varphi_Y(t)$
6.  **Lien avec les moments :** Si $E[|X|^k] < +\infty$, alors $\varphi_X$ est $k$ fois d√©rivable et :
    $$ \varphi_X^{(k)}(0) = i^k E[X^k] $$

**Fonctions caract√©ristiques classiques**
*   **$N(0, 1)$ :** $e^{-t^2/2}$
*   **$N(\mu, \sigma^2)$ :** $e^{i\mu t - \sigma^2 t^2/2}$
*   **$P(\lambda)$ :** $e^{\lambda(e^{it}-1)}$
*   **$U([a, b])$ :** $\frac{e^{ibt}-e^{iat}}{i(b-a)t}$
*   **$B(n, p)$ :** $(1-p+pe^{it})^n$

### 
**Subtilit√©s**
*   Toujours d√©finie, contrairement √† la fonction g√©n√©ratrice des moments $M_X(t) = E[e^{tX}]$ qui peut diverger.
*   **Th√©or√®me de Paul L√©vy :** $\varphi_{X_n} \to \varphi_X$ ponctuellement $\implies X_n \xrightarrow{\mathcal{L}} X$ (convergence en loi). C'est la base de la preuve du TCL via les fonctions caract√©ristiques.
*   **Formule d'inversion :** Si $\varphi_X \in L^1(\mathbb{R})$, alors $X$ a une densit√© $p_X(x) = \frac{1}{2\pi} \int_\mathbb{R} e^{-itx} \varphi_X(t) dt$.

**Pi√®ges classiques**
*   Confondre $\varphi_X(t) = E[e^{itX}]$ (fonction caract√©ristique, $t$ r√©el) avec la transform√©e de Laplace $E[e^{tX}]$ ($t$ r√©el mais peut diverger) ou la transform√©e de Fourier.
*   Oublier le $i$ dans $e^{itX}$ : sans $i$, $E[e^{tX}]$ est la fonction g√©n√©ratrice des moments, qui peut ne pas exister.

---

## FLASHCARD 202 ‚Äî Proposition 64 : Lois classiques

### RECTO
**Proposition 64 ‚Äî Lois classiques et leurs caract√©ristiques**

**Question :** Donner le tableau des lois de probabilit√© classiques du programme MP, avec pour chacune : param√®tres, support, esp√©rance et variance.

### VERSO
**Lois discr√®tes**
*   **Bernoulli $B(p)$** : $p \in [0, 1]$, support $\{0, 1\}$, $E[X]=p$, $Var(X)=p(1-p)$.
*   **Binomiale $B(n, p)$** : $n \in \mathbb{N}^*, p \in [0, 1]$, support $\llbracket 0, n \rrbracket$, $E[X]=np$, $Var(X)=np(1-p)$.
*   **Poisson $P(\lambda)$** : $\lambda > 0$, support $\mathbb{N}$, $E[X]=\lambda$, $Var(X)=\lambda$.
*   **G√©om√©trique $G(p)$** : $p \in ]0, 1]$, support $\mathbb{N}^*$, $E[X]=1/p$, $Var(X)=(1-p)/p^2$.
*   **Uniforme discr√®te $U(\llbracket a, b \rrbracket)$** : $a \le b \in \mathbb{Z}$, support $\llbracket a, b \rrbracket$, $E[X]=\frac{a+b}{2}$, $Var(X)=\frac{(b-a)(b-a+2)}{12}$.

**Lois continues (√† densit√©)**
*   **Uniforme $U([a, b])$** : $a < b$, densit√© $\frac{1}{b-a} 1_{[a, b]}$, $E[X]=\frac{a+b}{2}$, $Var(X)=\frac{(b-a)^2}{12}$.
*   **Exponentielle $E(\lambda)$** : $\lambda > 0$, densit√© $\lambda e^{-\lambda x} 1_{x \ge 0}$, $E[X]=1/\lambda$, $Var(X)=1/\lambda^2$.
*   **Normale $N(\mu, \sigma^2)$** : $\mu \in \mathbb{R}, \sigma > 0$, densit√© $\frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$, $E[X]=\mu$, $Var(X)=\sigma^2$.
*   **Gamma $\Gamma(a, \lambda)$** : $a, \lambda > 0$, densit√© $\frac{\lambda^a}{\Gamma(a)} x^{a-1} e^{-\lambda x} 1_{x>0}$, $E[X]=a/\lambda$, $Var(X)=a/\lambda^2$.
*   **Beta $B(a, b)$** : $a, b > 0$, densit√© $\frac{x^{a-1}(1-x)^{b-1}}{B(a, b)} 1_{(0, 1)}$, $E[X]=\frac{a}{a+b}$, $Var(X)=\frac{ab}{(a+b)^2(a+b+1)}$.

### 
**Subtilit√©s et propri√©t√©s importantes**
*   **Stabilit√© de la loi normale :** Si $X \sim N(\mu_1, \sigma_1^2)$ et $Y \sim N(\mu_2, \sigma_2^2)$ ind√©pendantes, $X+Y \sim N(\mu_1+\mu_2, \sigma_1^2+\sigma_2^2)$.
*   **Loi de Poisson comme limite de binomiales :** $B(n, \lambda/n) \xrightarrow{\mathcal{L}} P(\lambda)$ quand $n \to \infty$.
*   **Sans m√©moire :** $G(p)$ et $E(\lambda)$ sont les seules lois sans m√©moire (discr√®te et continue resp.).
*   $\chi^2(n) = \Gamma(n/2, 1/2)$ : Loi du chi-deux (hors programme mais utile √† conna√Ætre).

**Pi√®ges classiques**
*   Confondre $G(p)$ √† support $\mathbb{N}^*$ (nombre d'essais avant le premier succ√®s) et $G(p)$ √† support $\mathbb{N}$ (nombre d'√©checs avant le succ√®s) ‚Äî conventions diff√©rentes selon les ouvrages.
*   Pour $N(\mu, \sigma^2)$ : la variance est $\sigma^2$, l'√©cart-type est $\sigma$. Ne pas confondre.
*   $Var(U([a, b])) = \frac{(b-a)^2}{12}$ (ne pas confondre avec la variance discr√®te).

---

## FLASHCARD 203 ‚Äî Proposition 65 : In√©galit√© de Markov

### RECTO
**Proposition 65 ‚Äî In√©galit√© de Markov**

**Contexte :** Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√© et $X$ une variable al√©atoire positive ($X \ge 0$ p.s.) et int√©grable ($X \in L^1$).

**Question :** √ânoncer l'in√©galit√© de Markov avec les hypoth√®ses exactes.

### VERSO
**Hypoth√®ses**
*   $X \ge 0$ p.s.
*   $E[X] < +\infty$

**√ânonc√© formel**
$$ \forall t > 0 : \quad P(X \ge t) \le \frac{E[X]}{t} $$

**Formulation √©quivalente :** Pour $f : \mathbb{R}_+ \to \mathbb{R}_+$ croissante avec $f(t) > 0$ :
$$ P(X \ge t) = P(f(X) \ge f(t)) \le \frac{E[f(X)]}{f(t)} $$

**D√©monstration**
$E[X] = E[X 1_{X \ge t}] + E[X 1_{X < t}] \ge E[X 1_{X \ge t}] \ge t \cdot E[1_{X \ge t}] = t \cdot P(X \ge t)$
D'o√π $P(X \ge t) \le \frac{E[X]}{t}$.

### 
**Subtilit√©s**
*   **$X \ge 0$ p.s. est n√©cessaire :** Pour $X$ quelconque, appliquer Markov √† $|X|$ : $P(|X| \ge t) \le \frac{E[|X|]}{t}$.
*   **L'in√©galit√© est optimale :** Pour $X = t \cdot 1_A$ avec $P(A) = p$, $E[X] = tp$ et $P(X \ge t) = p = \frac{E[X]}{t}$ : √©galit√©.
*   **G√©n√©ralisation :** $P(|X|^p \ge t^p) \le \frac{E[|X|^p]}{t^p}$ pour $p > 0$ (Markov appliqu√© √† $|X|^p$).

**Pi√®ges classiques**
*   Oublier la condition $X \ge 0$ p.s. et appliquer Markov directement √† une v.a. sign√©e.
*   Confondre Markov ($P(X \ge t) \le E[X]/t$) et Bienaym√©-Tchebychev (qui utilise la variance).

---

## FLASHCARD 204 ‚Äî Proposition 66 : In√©galit√© de Bienaym√©-Tchebychev

### RECTO
**Proposition 66 ‚Äî In√©galit√© de Bienaym√©-Tchebychev**

Soit $X \in L^2(\Omega, \mathcal{A}, P)$ une variable al√©atoire de carr√© int√©grable.

**Question :** √ânoncer l'in√©galit√© de Bienaym√©-Tchebychev, la relier √† Markov, et donner l'application √† la loi des grands nombres.

### VERSO
**Hypoth√®ses**
*   $X \in L^2(\Omega)$ : $E[X^2] < +\infty$
*   $E[X] = \mu$, $\text{Var}(X) = \sigma^2 < +\infty$

**√ânonc√© formel**
$$ \forall \varepsilon > 0 : \quad P(|X - \mu| \ge \varepsilon) \le \frac{\sigma^2}{\varepsilon^2} = \frac{\text{Var}(X)}{\varepsilon^2} $$

**D√©monstration**
Appliquer l'in√©galit√© de Markov √† la variable positive $(X - \mu)^2 \in L^1$ et au seuil $\varepsilon^2 > 0$ :
$$ P((X - \mu)^2 \ge \varepsilon^2) \le \frac{E[(X - \mu)^2]}{\varepsilon^2} = \frac{\text{Var}(X)}{\varepsilon^2} $$
Or $\{(X - \mu)^2 \ge \varepsilon^2\} = \{|X - \mu| \ge \varepsilon\}$.

**Application : Loi faible des grands nombres (version $L^2$)**
Soit $(X_n)$ i.i.d. de $L^2$, $\mu = E[X_1]$, $\sigma^2 = \text{Var}(X_1)$. Soit $\bar{X}_n = \frac{1}{n} \sum_{k=1}^n X_k$.

$$ P(|\bar{X}_n - \mu| \ge \varepsilon) \le \frac{\text{Var}(\bar{X}_n)}{\varepsilon^2} = \frac{\sigma^2}{n\varepsilon^2} \xrightarrow[n \to +\infty]{} 0 $$

Donc $\bar{X}_n \xrightarrow{P} \mu$.

### 
**Subtilit√©s**
*   Bienaym√©-Tchebychev est une cons√©quence de Markov (appliqu√© √† $(X-\mu)^2$).
*   L'in√©galit√© ne d√©pend que de la variance, pas de la forme de la loi : elle est universelle.
*   **Optimalit√© :** Pour $X$ prenant les valeurs $\mu \pm \varepsilon$ avec probabilit√©s $\frac{\sigma^2}{2\varepsilon^2}$ et $\mu$ avec probabilit√© $1 - \frac{\sigma^2}{\varepsilon^2}$ (quand $\sigma^2 \le \varepsilon^2$), l'in√©galit√© est une √©galit√©.

**Pi√®ges classiques**
*   Confondre $\varepsilon$ et $\varepsilon^2$ dans le d√©nominateur.
*   Appliquer B-T sans v√©rifier $X \in L^2$ (la variance doit √™tre finie).
*   Utiliser B-T quand on conna√Æt la loi explicite : dans ce cas, un calcul direct est plus pr√©cis.

---

## FLASHCARD 205 ‚Äî Th√©or√®me 61 : Loi faible des grands nombres

### RECTO
**Th√©or√®me 61 ‚Äî Loi faible des grands nombres (LFGN)**

Soit $(\Omega, \mathcal{A}, P)$ un espace probabilis√© et $(X_n)_{n \ge 1}$ une suite de variables al√©atoires r√©elles.

**Question :** √ânoncer la loi faible des grands nombres dans sa version la plus g√©n√©rale au programme MP, pr√©ciser les hypoth√®ses minimales et la conclusion.

### VERSO
**Hypoth√®ses**
*   **Version $L^2$ (Bienaym√©-Tchebychev) :**
    *   $(X_n)_{n \ge 1}$ deux √† deux non corr√©l√©es (suffit pour cette version)
    *   $\forall n, X_n \in L^2$ avec $E[X_n] = \mu$ et $\text{Var}(X_n) \le C < +\infty$ (variance uniform√©ment born√©e)
*   **Version i.i.d. $L^1$ (version classique) :**
    *   $(X_n)_{n \ge 1}$ ind√©pendantes et identiquement distribu√©es (i.i.d.)
    *   $X_1 \in L^1$ avec $E[X_1] = \mu$

**√ânonc√© formel**
Soit $\bar{X}_n = \frac{1}{n} \sum_{k=1}^n X_k$ la moyenne empirique.

$$ \bar{X}_n \xrightarrow[n \to +\infty]{P} \mu $$

c'est-√†-dire : $\forall \varepsilon > 0, P(|\bar{X}_n - \mu| \ge \varepsilon) \xrightarrow[n \to +\infty]{} 0$.

**D√©monstration (version $L^2$)**
$\text{Var}(\bar{X}_n) = \frac{1}{n^2} \sum_{k=1}^n \text{Var}(X_k) \le \frac{C}{n}$ (non-corr√©lation + variance born√©e).
Par Bienaym√©-Tchebychev :
$$ P(|\bar{X}_n - \mu| \ge \varepsilon) \le \frac{\text{Var}(\bar{X}_n)}{\varepsilon^2} \le \frac{C}{n\varepsilon^2} \to 0 $$

**Remarque sur la version $L^1$**
La version i.i.d. $L^1$ se d√©montre via la fonction caract√©ristique (th√©or√®me de Paul L√©vy) :
$\varphi_{\bar{X}_n}(t) = (\varphi_{X_1}(t/n))^n \to e^{i\mu t}$ (car $\varphi_{X_1}(t/n) = 1 + i\mu \frac{t}{n} + o(1/n)$).

### 
**Subtilit√©s**
*   **"Faible" = convergence en probabilit√©**, pas p.s. ni en $L^1$. La loi forte (convergence p.s.) requiert des hypoth√®ses suppl√©mentaires et est hors programme MP.
*   Version $L^2$ suffit en pratique au niveau MP et couvre la quasi-totalit√© des applications.
*   **Hypoth√®ses minimales pour la version $L^2$ :** Non-corr√©lation (plus faible que l'ind√©pendance) + $L^2$ + variance born√©e.
*   **Hypoth√®ses pour la version i.i.d. $L^1$ :** Strictement plus faible ($L^1$ suffit, pas besoin de $L^2$), mais la preuve utilise des outils plus avanc√©s.

**Extensions**
*   **Loi forte des grands nombres (Kolmogorov) :** i.i.d. $L^1 \implies \bar{X}_n \xrightarrow{p.s.} \mu$. Hors programme MP mais connue des meilleurs candidats.
*   **Th√©or√®me central limite :** $\sqrt{n}(\bar{X}_n - \mu) \xrightarrow{\mathcal{L}} N(0, \sigma^2)$ pour i.i.d. $L^2$. Hors programme MP strict.

**Pi√®ges classiques**
*   Confondre LFGN et loi forte : LFGN = convergence en probabilit√© ($\xrightarrow{P}$), loi forte = p.s.
*   Appliquer LFGN sans v√©rifier l'int√©grabilit√© : Il faut $E[X_1]$ d√©fini (i.e. $X_1 \in L^1$).
*   Croire que la variance doit √™tre finie pour la version $L^1$ : Non, la version $L^1$ i.i.d. ne requiert pas $L^2$.
*   Oublier que la convergence est en probabilit√© : $\bar{X}_n(\omega) \to \mu$ pour presque tout $\omega$ est la loi forte, plus forte.

---

</script>

<script src="data.js"></script>

<!-- MathJax loaded async -->
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<script>

/* --- CORE APP LOGIC --- */
const D = document, W = window, LS = localStorage, M = Math, KEY = 'flashcards9x16_data', APP_VER = '2026-03-19-04-v3';

const GRADES = ['unseen','echec','difficile','bien','facile'];
const GRADE_INIT = () => ({unseen:0,echec:0,difficile:0,bien:0,facile:0});
const GRADE_FILTERS = () => ({unseen:!0,echec:!0,difficile:!0,bien:!0,facile:!0});

const $ = (s,p=D) => p.querySelector(s), $$ = (s,p=D) => [...p.querySelectorAll(s)];
const clamp = (n,mn,mx) => n<mn?mn:n>mx?mx:n;

const slugify = s => s.toLowerCase().normalize('NFD').replace(/[\u0300-\u036f]/g,'').replace(/[^a-z0-9]+/g,'-').replace(/(^-|-$)/g,'');
const dateKey = d => `${d.getFullYear()}-${String(d.getMonth()+1).padStart(2,'0')}-${String(d.getDate()).padStart(2,'0')}`;
const todayKey = () => dateKey(new Date());
const getDayStart = () => { const d = new Date(); d.setHours(0,0,0,0); return d.getTime() };
const avg = a => !a?.length ? 0 : a.reduce((x,y)=>x+y,0)/a.length;
const deepClone = o => JSON.parse(JSON.stringify(o));
const isSucc = g => g==='facile'||g==='bien';
// ppLat removed/merged
const mathCache = new Set();
const clearMathCache = () => mathCache.clear();

// Optimisation: check regex avant d'appeler MathJax
const needsMath = s => /[$]|\\[(\[]|\\frac|\\sqrt|\\text/.test(s);
const tsLat = e => { 
  if(!W.MathJax?.typesetPromise || (e && !needsMath(e.innerHTML))) return Promise.resolve();
  const id = e?.id || (e?.dataset?.id) || null;
  if(id && mathCache.has(id)) return Promise.resolve();
  if(id) mathCache.add(id);
  return W.MathJax.typesetPromise(e?[e]:null).catch(()=>{});
};
const getEmoji = t => (typeof C_EMOJIS !== 'undefined' ? C_EMOJIS[t] : '') || '';

const parseMathData = (raw) => {
    if (!raw) return [];
    const result = []; let idCounter = 0;
    // D√©couper par chapitres : # CHAPITRE N ‚Äî Titre
    const chapSplit = raw.split(/^#\s+CHAPITRE\s+(\d+)\s*[‚Äî‚Äì-]\s*(.+)$/gm);
    // chapSplit: [preamble, num1, title1, content1, num2, title2, content2, ...]
    for (let i = 1; i + 2 < chapSplit.length; i += 3) {
        const chNum = chapSplit[i].trim();
        const chKey = 'CH' + chNum;
        const chTitle = (typeof MATH_MAP !== 'undefined' && MATH_MAP[chKey]) ? MATH_MAP[chKey].title : chapSplit[i+1].trim();
        const content = chapSplit[i+2];
        // D√©couper par flashcards : ## FLASHCARD N ‚Äî Titre
        const cardSplit = content.split(/^##\s+FLASHCARD\s+\d+\s*[‚Äî‚Äì-]\s*.+$/gm);
        for (let j = 1; j < cardSplit.length; j++) {
            const block = cardSplit[j];
            // Extraire RECTO, VERSO, L'≈íIL DE L'X
            const rectoMatch = block.match(/###\s+RECTO\s*\n([\s\S]*?)(?=###\s+VERSO|$)/);
            const versoMatch = block.match(/###\s+VERSO\s*\n([\s\S]*?)(?=###\s+L[''']≈íIL|---\s*$|$)/);
            const oeilMatch = block.match(/###\s+L[''']≈íIL DE L[''']X\s*\n([\s\S]*?)(?=---\s*$|$)/);
            if (!rectoMatch) continue;
            let front = rectoMatch[1].trim();
            let back = (versoMatch ? versoMatch[1].trim() : '');
            if (oeilMatch) back += '\n\n---\n\n**üîç L\'≈íil de l\'X :**\n\n' + oeilMatch[1].trim();
            // Convertir Markdown basique en HTML
            const md2html = (s) => {
                let h = s;
                h = h.replace(/\*\*(.+?)\*\*/g, '<strong>$1</strong>');
                h = h.replace(/(?<!\*)\*(?!\s)(.+?)(?<!\s)\*(?!\*)/g, '<em>$1</em>');
                h = h.replace(/^\s*[\*\-]\s{2,}/gm, '‚Ä¢ ');
                h = h.replace(/\n/g, '<br>');
                return h;
            };
            result.push({
                id: 'math-' + (idCounter++),
                front: md2html(front),
                back: md2html(back),
                chapter: chTitle
            });
        }
    }
    return result;
};
const extractId = c => String(c).match(/-(\d+)$/)?.[1]||null;
const getSides = (c,ch) => ch?.settings?.langSwap ? {f:c.back,b:c.front} : {f:c.front,b:c.back};
const fmtDur = ms => { const s=M.round(ms/1000); return`${M.floor(s/60)}:${String(s%60).padStart(2,'0')}` };
function fmtDayFR(k){ const [Y,M,D]=k.split('-').map(Number), d=new Date(Y,M-1,D); return`${['Dim','Lun','Mar','Mer','Jeu','Ven','Sam'][d.getDay()]} ${String(D).padStart(2,'0')} ${['janv.','f√©vr.','mars','avr.','mai','juin','juil.','ao√ªt','sept.','oct.','nov.','d√©c.'][M-1]} ${Y}` }

/* --- UI/UX HELPERS --- */
function toast(msg, type = 'info', duration = 2500) {
  let el = $('#toast'); if(!el) { el = D.createElement('div'); el.id = 'toast'; D.body.appendChild(el); }
  el.textContent = msg; el.className = `toast ${type}`;
  requestAnimationFrame(() => { el.classList.add('show'); setTimeout(() => el.classList.remove('show'), duration); });
}

const haptic = (style = 'light') => {
  if(!navigator.vibrate) return;
  const patterns = { light: 10, medium: 20, heavy: 30, success: [10, 50, 10], error: [30, 50, 30] };
  navigator.vibrate(patterns[style] || 10);
};

function getStreak(c) {
  let streak = 0; const today = new Date();
  for(let i = 0; i < 365; i++) {
    const d = new Date(today); d.setDate(today.getDate() - i);
    if((c.stats.dailyReviews[dateKey(d)] || 0) > 0) streak++; else if(i > 0) break;
  }
  return streak;
}

function bindPullRefresh(container, onRefresh) {
  let startY = 0, pulling = false, indicator = null;
  container.addEventListener('touchstart', e => { if(container.scrollTop <= 5) { startY = e.touches[0].clientY; pulling = true; } }, {passive:!0});
  container.addEventListener('touchmove', e => {
    if(!pulling) return; const delta = e.touches[0].clientY - startY;
    if(delta > 0 && delta < 120) {
      if(!indicator) { indicator = D.createElement('div'); indicator.innerHTML = '‚Üª'; indicator.style.cssText = 'text-align:center;padding:10px;color:var(--muted);font-size:20px;transition:transform 0.2s'; container.prepend(indicator); }
      indicator.style.transform = `rotate(${delta * 3}deg)`;
    }
  }, {passive:!0});
  container.addEventListener('touchend', e => {
    if(indicator) { if(e.changedTouches[0].clientY - startY > 80) { haptic('medium'); onRefresh(); } indicator.remove(); indicator = null; }
    pulling = false;
  });
}

function bindSwipeNav() {
  const wrap = $('.review-wrap'); if(!wrap) return;
  const card = wrap.querySelector('.review-card'); if(!card) return;
  const scroller = wrap.querySelector('.review-scroller');

  let startX = 0, startY = 0, deltaX = 0;
  let mode = 'idle'; // 'idle','undecided','swiping','scrolling','selecting','animating'

  const hasSelection = () => {
    const sel = window.getSelection();
    return sel && sel.toString().length > 0;
  };

  wrap.addEventListener('touchstart', e => {
    if(e.touches.length !== 1 || mode === 'animating') return;

    // Si du texte est d√©j√† s√©lectionn√© ‚Üí on bloque le swipe
    if(hasSelection()) { mode = 'selecting'; return; }

    startX = e.touches[0].clientX;
    startY = e.touches[0].clientY;
    deltaX = 0;
    mode = 'undecided';
    card.style.transition = 'none';
  }, {passive: true});

  wrap.addEventListener('touchmove', e => {
    if(e.touches.length !== 1) return;
    if(mode !== 'undecided' && mode !== 'swiping') return;

    const dx = e.touches[0].clientX - startX;
    const dy = e.touches[0].clientY - startY;

    if(mode === 'undecided') {
      // Si du texte a √©t√© s√©lectionn√© pendant le toucher ‚Üí mode s√©lection
      if(hasSelection()) { mode = 'selecting'; return; }

      // Mouvement vertical dominant ‚Üí scroll normal, pas de swipe
      if(Math.abs(dy) > 10 && Math.abs(dy) > Math.abs(dx)) {
        mode = 'scrolling';
        return;
      }
      // Mouvement horizontal suffisant ‚Üí c'est un swipe
      if(Math.abs(dx) > 12) {
        mode = 'swiping';
        // On emp√™che la s√©lection de texte pendant le swipe
        window.getSelection()?.removeAllRanges();
        if(scroller) {
          scroller.style.userSelect = 'none';
          scroller.style.webkitUserSelect = 'none';
        }
      }
    }

    if(mode !== 'swiping') return;

    deltaX = dx;
    const r = State.review;
    const canGoBack = r && r.history && r.history.length > 0;

    // Swipe droite suit le doigt (si possible), sinon r√©sistance
    // Swipe gauche = r√©sistance seulement (pas d'action)
    let tx = deltaX > 0
      ? (canGoBack ? deltaX : deltaX * 0.15)
      : deltaX * 0.15;

    card.style.transform = `translateX(${tx}px) rotate(${tx * 0.015}deg)`;
    card.style.opacity = String(Math.max(0.5, 1 - Math.abs(tx) / 500));
  }, {passive: true});

  wrap.addEventListener('touchend', () => {
    // Restaurer la s√©lection de texte
    if(scroller) {
      scroller.style.userSelect = '';
      scroller.style.webkitUserSelect = '';
    }

    if(mode === 'swiping') {
      const r = State.review;
      const canGoBack = r && r.history && r.history.length > 0;

      if(deltaX > 80 && canGoBack) {
        // La carte s'envole vers la droite (comme Reigns)
        mode = 'animating';
        card.style.transition = 'transform 0.25s ease-out, opacity 0.25s ease-out';
        card.style.transform = `translateX(${window.innerWidth + 100}px) rotate(12deg)`;
        card.style.opacity = '0';
        setTimeout(() => { haptic('medium'); undoRev(); }, 200);
      } else {
        // Snap-back √©lastique vers la position initiale
        card.style.transition = 'transform 0.3s cubic-bezier(0.34, 1.56, 0.64, 1), opacity 0.3s ease-out';
        card.style.transform = '';
        card.style.opacity = '';
        setTimeout(() => { card.style.transition = ''; }, 350);
        mode = 'idle';
      }
    } else {
      mode = 'idle';
    }

    deltaX = 0;
  });
}

// Optimized Debounce
const debouncedSave = (() => {
  let t; const c = W.cancelIdleCallback || clearTimeout, r = W.requestIdleCallback || (cb=>setTimeout(cb,2000));
  return () => { c(t); t = r(saveData); };
})();


W.MathJax = { tex:{inlineMath:[['$','$'],['\\(','\\)']], displayMath:[['$$','$$'],['\\[','\\]']], processEscapes:!0}, options:{skipHtmlTags:['script','style','textarea']}, startup:{typeset:!1} };

function formatText(text) {
    if (!text) return '';
    let formatted = text.replace(/(?:>>>|>>)?\s*\[IMAGE_ID:\s*(.+?)\](?:\s*<<<)?/g, (match, filename) => {
        return `<img src="images/${filename.trim()}" alt="Sch√©ma" loading="lazy">`;
    });
    formatted = formatted.replace(/\\\[\s*\\text\s*\{([^{}]+)\}\s*\\\]/g, (m, c) => c.includes(' ') ? c : m);
    formatted = formatted.replace(/\n|\\newline/g, '<br>').replace(/\[latex\]|\[\/latex\]/g, '').replace(/\[\$\]/g, '\\(').replace(/\[\/\$\]/g, '\\)');
    return formatted;
}

const parsePhysicsData = (rawData) => {
    if (!rawData) return [];
    const decks = rawData.split(/={10,}\s*DECK\s*:\s*/), result = []; let idCounter = 0;
    decks.forEach(deckBlock => {
        if (!deckBlock.trim()) return;
        const lines = deckBlock.split('\n'), deckCode = lines[0].trim(), deckName = (typeof PHY_MAP !== 'undefined' && PHY_MAP[deckCode]) ? PHY_MAP[deckCode].title : deckCode;
        deckBlock.substring(deckCode.length).replace(/^=+/gm, '').trim().split(/-{10,}/).forEach(rawCard => {
            if (!rawCard.trim()) return;
            const qMatch = rawCard.match(/Q:\s*([\s\S]*?)(?=R:)/), rMatch = rawCard.match(/R:\s*([\s\S]*)/);
            if (qMatch && rMatch) result.push({ id: 'phy-' + (idCounter++), front: formatText(qMatch[1].trim()), back: formatText(rMatch[1].trim()), chapter: deckName });
        });
    });
    return result;
};

/* --- LIGHTBOX --- */
const LB = { el:null, stage:null, cnv:null, img:null, cnt:null, imgs:[], idx:0, bw:0, bh:0, s:1, mnS:1, mxS:5, x:0, y:0, ptrs:new Map(), sDist:0, sS:1, sX:0, sY:0, psX:0, psY:0, tm:!1 };
function ensureLB(){
  if(LB.el)return LB.el; const el=D.createElement('div'); el.className='img-lightbox'; el.innerHTML='<div class="img-stage" id="lbStg" tabindex="-1"><div class="img-canvas" id="lbCnv"><img id="lbImg" alt=""></div></div><div class="img-counter" id="lbCnt">1/1</div>'; D.body.appendChild(el);
  LB.el=el; LB.stage=el.querySelector('#lbStg'); LB.cnv=el.querySelector('#lbCnv'); LB.img=el.querySelector('#lbImg'); LB.cnt=el.querySelector('#lbCnt');
  const pd=e=>{ LB.stage.setPointerCapture?.(e.pointerId); LB.ptrs.set(e.pointerId,{x:e.clientX,y:e.clientY}); if(LB.ptrs.size===1){LB.psX=LB.x;LB.psY=LB.y;LB.sX=e.clientX;LB.sY=e.clientY;LB.sS=LB.s;LB.tm=!1}else if(LB.ptrs.size===2){const p=[...LB.ptrs.values()];LB.sDist=M.hypot(p[0].x-p[1].x,p[0].y-p[1].y)||1;LB.sS=LB.s;LB.tm=!0} e.preventDefault() };
  const pm=e=>{ if(!LB.ptrs.has(e.pointerId))return; LB.ptrs.set(e.pointerId,{x:e.clientX,y:e.clientY}); const dx=e.clientX-LB.sX, dy=e.clientY-LB.sY; if(M.abs(dx)>6||M.abs(dy)>6)LB.tm=!0; if(LB.ptrs.size>=2){const p=[...LB.ptrs.values()];setLBScale(LB.sS*(M.hypot(p[0].x-p[1].x,p[0].y-p[1].y)/LB.sDist||1))}else setLBPan(LB.psX+dx,LB.psY+dy); e.preventDefault() };
  const pu=e=>{ if(LB.ptrs.has(e.pointerId))LB.ptrs.delete(e.pointerId); if(LB.ptrs.size===0){if(!LB.tm){const r=LB.img.getBoundingClientRect();if(!(e.clientX>=r.left&&e.clientX<=r.right&&e.clientY>=r.top&&e.clientY<=r.bottom))closeLB()}LB.sDist=0}else if(LB.ptrs.size===1){const p=[...LB.ptrs.values()][0];LB.sX=p.x;LB.sY=p.y;LB.psX=LB.x;LB.psY=LB.y;LB.sS=LB.s;LB.sDist=0} };
  let lt=0; LB.stage.addEventListener('pointerdown',e=>{pd(e);const n=Date.now();if(n-lt<250){setLBScale(LB.s>LB.mnS+0.001?LB.mnS:M.min(LB.mxS,LB.mnS*2.2));LB.tm=!0}lt=n});
  LB.stage.addEventListener('pointermove',pm); LB.stage.addEventListener('pointerup',pu); LB.stage.addEventListener('pointercancel',pu); LB.stage.addEventListener('lostpointercapture',pu);
  LB.stage.addEventListener('wheel',e=>{e.preventDefault();setLBScale(LB.s+(e.deltaY>0?-.15:.15)*LB.s)},{passive:!1}); W.addEventListener('resize',()=>{if(LB.el.classList.contains('open'))refitLB()}); return el;
}
function openLB(img,sc){ ensureLB(); const l=[...sc.querySelectorAll('img')]; LB.imgs=l.map(i=>({src:i.currentSrc||i.src,alt:i.alt||'',w:i.naturalWidth||800,h:i.naturalHeight||600})); LB.idx=M.max(0,l.indexOf(img)); LB.el.classList.add('open'); D.body.dataset._ov=D.body.style.overflow||''; D.body.style.overflow='hidden'; LB.el.focus?.(); showLB(LB.idx,!0) }
function closeLB(){ LB.el.classList.remove('open'); LB.imgs=[]; LB.idx=0; D.body.style.overflow=D.body.dataset._ov||'' }
function safeCloseLB(){ try{if(LB?.el?.classList.contains('open'))closeLB()}catch(e){} }
function showLB(i,init=!1){ if(!LB.imgs.length)return; LB.idx=(i+LB.imgs.length)%LB.imgs.length; const t=LB.imgs[LB.idx]; LB.img.src=t.src; LB.img.alt=t.alt; LB.bw=t.w; LB.bh=t.h; if(LB.cnt)LB.cnt.textContent=`${LB.idx+1}/${LB.imgs.length}`; refitLB(init) }
function refitLB(init=!1){ const sw=LB.stage.clientWidth, sh=LB.stage.clientHeight, fit=M.min(sw/LB.bw,sh/LB.bh); LB.mnS=fit; if(init){LB.s=fit;LB.x=(sw-LB.s*LB.bw)/2;LB.y=(sh-LB.s*LB.bh)/2;applyLB()}else setLBScale(fit,!0) }
function applyLB(){ const sw=LB.stage.clientWidth, sh=LB.stage.clientHeight, w=LB.s*LB.bw, h=LB.s*LB.bh; LB.x=w<=sw?(sw-w)/2:clamp(LB.x,sw-w,0); LB.y=h<=sh?(sh-h)/2:clamp(LB.y,sh-h,0); LB.cnv.style.width=LB.bw+'px'; LB.cnv.style.height=LB.bh+'px'; LB.cnv.style.transform=`translate(${LB.x}px,${LB.y}px) scale(${LB.s})` }
function setLBPan(nx,ny){ LB.x=nx; LB.y=ny; applyLB() }
function setLBScale(ns,f=!1){ const os=LB.s, s=clamp(ns,LB.mnS,LB.mxS); if(!f&&M.abs(s-os)<1e-4)return; const cx=LB.stage.clientWidth/2, cy=LB.stage.clientHeight/2; LB.s=s; LB.x=cx-s*((cx-LB.x)/os); LB.y=cy-s*((cy-LB.y)/os); applyLB() }

/* --- DATA LOADING --- */
const parseRaw = r => r.split(/\r?\n/).map(l=>{ const p=l.split('|'); return p.length!==4 ? null : {id:p[0].trim(),front:p[1].trim(),back:p[2].trim(),chapter:p[3].trim()} }).filter(Boolean);

const dataEN = parseRaw(RAW_EN);
const dataPHY = parsePhysicsData(RAW_PHY);
const RAW_MATH = document.getElementById('rawMath')?.textContent || '';
const dataMATH = parseMathData(RAW_MATH);

const Media = {
  db: null, cache: new Map(),
  async open(){ if(this.db)return this.db; this.db=await new Promise((s,j)=>{const r=indexedDB.open('flash9x16_media',1);r.onupgradeneeded=()=>{if(!r.result.objectStoreNames.contains('files'))r.result.createObjectStore('files',{keyPath:'key'})};r.onsuccess=()=>s(r.result);r.onerror=()=>j(r.error)}); return this.db },
  async save(k,b,m={}){ const d=await this.open(), tx=d.transaction('files','readwrite'); tx.objectStore('files').put({key:k,blob:b,meta:m,ts:Date.now()}); data.mediaIndex=data.mediaIndex||{}; data.mediaIndex[k]={name:m.name||k,type:b.type,size:b.size}; saveData() },
  async urlFor(k){ if(this.cache.has(k))return this.cache.get(k); const d=await this.open(); return new Promise((s,j)=>{const r=d.transaction('files','readonly').objectStore('files').get(k);r.onsuccess=()=>{if(!r.result?.blob)return j('Missing');const u=URL.createObjectURL(r.result.blob);this.cache.set(k,u);s(u)};r.onerror=()=>j(r.error)}) },
  revokeAll(){ for(const u of this.cache.values())URL.revokeObjectURL(u); this.cache.clear() },
  async clearAll(){ const d=await this.open(), tx=d.transaction('files','readwrite'); tx.objectStore('files').clear(); this.revokeAll(); data.mediaIndex={}; saveData() },
  rwHTML(h,m){ return String(h||'').replace(/(<img\b[^>]?\bsrc=["'])([^"']+)(["'][^>]*>)/gi,(x,p,src,s)=>{const k=m[src.replace(/^.*[\\\/]/,'').replace(/^_+/,'')]||null;return k?`${p}media://${k}${s}`:x}) },
  async resolve(el){ const i=[...el.querySelectorAll('img[src^="media://"]')]; await Promise.all(i.map(async x=>{try{x.src=await Media.urlFor(x.getAttribute('src').replace(/^media:\/\//,''))}catch{}})) }
};
const ensureSQL = (()=>{ let p; return ()=>{ if(!p)p=initSqlJs({locateFile:f=>`https://cdn.jsdelivr.net/npm/sql.js@1.10.2/dist/${f}`}); return p } })();

async function importFiles(fs){ for(const f of fs){ const n=f.name.toLowerCase(); if(n.endsWith('.apkg')) await impApkg(f); else if(n.endsWith('.csv')||n.endsWith('.tsv')) await impDelim(f); else if(n.endsWith('.json')) await impJSON(f) } }

// Lazy load JSZip
async function impApkg(f){
  try {
    if(!window.JSZip) {
      await new Promise((res, rej) => { const s=D.createElement('script'); s.src='https://cdn.jsdelivr.net/npm/jszip@3.10.1/dist/jszip.min.js'; s.onload=res; s.onerror=rej; D.head.appendChild(s); });
    }
    const b = await f.arrayBuffer();
    let z; try { z = await JSZip.loadAsync(b); } catch(e) { throw new Error("Ce fichier n'est pas un ZIP/APKG valide."); }
    let mm = {}; const me = z.file(/^media(\.json)?$/i)[0];
    if(me) { try { mm = JSON.parse(await me.async('string')); } catch(e) {} }
    const iId = `apkg-${slugify(f.name.replace(/\.[^.]+$/,''))}-${Date.now()}`;
    const mnk = {};
    for(const [ns,rn] of Object.entries(mm)){ const e = z.file(new RegExp(`^${ns}$`))[0]; if(!e) continue; const k = `${iId}/${rn||ns}`; await Media.save(k, await e.async('blob'), {name:rn||ns}); mnk[rn] = k; mnk[ns] = k; }
    let col = z.file("collection.anki2") || z.file(/collection\.anki2(1|\.db)?/i)[0];
    if(!col) throw new Error("Fichier de donn√©es introuvable.");
    const dbData = new Uint8Array(await col.async('uint8array'));
    const header = String.fromCharCode.apply(null, dbData.subarray(0, 50));
    if (!header.startsWith("SQLite")) { alert("Format inconnu."); return; }
    const SQL = await ensureSQL();
    let db; try { db = new SQL.Database(dbData); } catch(sqlErr) { throw new Error("Base de donn√©es corrompue."); }
    let dk = {}; try { const r = db.exec('select decks from col limit 1'); if(r[0]?.values[0]) dk = JSON.parse(r[0].values[0][0]||'{}'); } catch(e) {}
    let rows; try { rows = db.exec('select cards.id, cards.nid, cards.did, cards.ord, notes.flds from cards join notes on notes.id=cards.nid'); } catch(e) { db.close(); throw new Error("Erreur DB."); }
    if(!rows || !rows[0]) { db.close(); throw new Error("Paquet vide."); }
    const byD = new Map(), cols = rows[0].columns, vals = rows[0].values;
    for(const r of vals){ 
        const row = Object.fromEntries(cols.map((c,i) => [c,r[i]]));
        const dn = (dk[row.did]?.name || `Deck ${row.did}`).replace(/::/g,' ‚Ä∫ ');
        const fl = (row.flds||'').split('\x1f');
        let frontVal = fl[0] || 'Vide'; let backVal = fl[1] || '';
        if (row.ord == 1 && fl.length >= 2) { frontVal = fl[1]; backVal = fl[0]; } 
        if (fl.length > 2) { backVal += '<br><br>' + fl.slice(2).join('<br>'); }
        const ca = byD.get(dn) || []; 
        ca.push({ id: String(row.id), front: Media.rwHTML(frontVal, mnk), back: Media.rwHTML(backVal, mnk) }); 
        byD.set(dn, ca);
    }
    db.close();
    const chs = []; 
    for(const [n,arr] of byD){
      const cds = arr.map(r => ({ id: `${slugify(n)}-${r.id}`, front: r.front, back: r.back, grade: 'unseen', timesReviewed:0, lastReviewed:0, lastMs:0, avgMs:0, perfEma:.5, ef:2.5, intervalDays:0, dueAt:0, streak:0, successes:0, failures:0 }));
      chs.push({ id: 'chap-'+slugify(n), title: n, description: `${getEmoji(n)||'üì¶'} ${n}`, settings: {sessionSize:10, dailyGoal:10, reviewOrder:'front-first', langSwap:!1}, filters: {grades:GRADE_FILTERS()}, stats: {gradeCounts:{...GRADE_INIT(), unseen:cds.length}, totalReviews:0, dailyReviews:{}, dailyChanges:{}, dailyDurMs:{}, dailyDurCount:{}, dailyLog:{}}, cards: cds, imported: !0 });
    }
    const sj = { id: `import-${slugify(f.name)}`, title: f.name.replace(/\.[^.]+$/,''), chapters: chs, imported: !0 }; 
    data.subjects.push(sj); data.app.currentSubjectId = sj.id; saveData();
  } catch(e) { alert("Erreur import : " + e.message); }
}

async function impDelim(f){ const t=await f.text(), sep=t.includes('\t')?'\t':(t.includes(';')?';':','), l=t.split(/\r?\n/).filter(Boolean); let h=l[0].split(sep).map(s=>s.trim().toLowerCase()), st=0; if(!h.includes('front')) h=['front','back','chapter']; else st=1; const recs=[]; for(let i=st;i<l.length;i++){ const c=l[i].split(sep), r=Object.fromEntries(h.map((x,j)=>[x,c[j]||''])); recs.push({front:r.front||c[0]||'',back:r.back||c[1]||'',chapter:r.chapter||'G√©n√©ral'}) } await impSimpSub(f.name.replace(/\.[^.]+$/,''),recs) }
async function impJSON(f){ const o=JSON.parse(await f.text()); if(Array.isArray(o)) impSimpSub(f.name.replace(/\.[^.]+$/,''),o); else if(o.cards) impSimpSub(o.subject||f.name,o.cards) }
async function impSimpSub(n,l){
  const by={}; l.forEach(x=>{ const c=(x.chapter||'G√©n√©ral').trim()||'G√©n√©ral'; (by[c]=by[c]||[]).push({front:Media.rwHTML(String(x.front||''),{}),back:Media.rwHTML(String(x.back||''),{})}) });
  const chs=Object.entries(by).map(([cn,arr])=>{
    const cds=arr.map((r,i)=>({id:`${slugify(cn)}-${i}-${Date.now()}`,front:r.front,back:r.back,grade:'unseen',timesReviewed:0,lastReviewed:0,lastMs:0,avgMs:0,perfEma:.5,ef:2.5,intervalDays:0,dueAt:0,streak:0,successes:0,failures:0}));
    return{id:'chap-'+slugify(cn),title:cn,description:`üì¶ ${cn}`,settings:{sessionSize:10,dailyGoal:10,reviewOrder:'front-first',langSwap:!1},filters:{grades:GRADE_FILTERS()},stats:{gradeCounts:{...GRADE_INIT(), unseen:cds.length},totalReviews:0,dailyReviews:{},dailyChanges:{},dailyDurMs:{},dailyDurCount:{},dailyLog:{}},cards:cds,imported:!0}
  });
  const s={id:`import-${slugify(n)}-${Date.now()}`,title:n,chapters:chs,imported:!0}; data.subjects.push(s); data.app.currentSubjectId=s.id; saveData(); goDeck(!1)
}

let data;
const ChartHit={}, Bar7Hit={};
function buildChs(l){ 
  const by={}; 
  l.forEach(r=>{ const n=r.chapter||'Sans cat√©gorie'; (by[n]=by[n]||[]).push(r) }); 
  let sortedKeys = Object.keys(by);
    const orderMap = {};
  if(typeof PHY_MAP !== 'undefined') Object.values(PHY_MAP).forEach((v, i) => orderMap[v.title] = i);
  if(typeof MATH_MAP !== 'undefined') Object.values(MATH_MAP).forEach((v, i) => orderMap[v.title] = i);
  sortedKeys.sort((a, b) => {
      const idxA = orderMap[a] !== undefined ? orderMap[a] : 999;
      const idxB = orderMap[b] !== undefined ? orderMap[b] : 999;
      return idxA - idxB;
  });
  return {
      chapters: sortedKeys.map(n=>{ 
          const cds=by[n].map(r=>({ id:`${slugify(n)}-${r.id}`, front:r.front, back:r.back, grade:'unseen', timesReviewed:0, lastReviewed:0, lastMs:0, avgMs:0, perfEma:.5, ef:2.5, intervalDays:0, dueAt:0, streak:0, successes:0, failures:0 })); 
          return {
              id:'chap-'+slugify(n), title:n, description: getEmoji(n) ? `${getEmoji(n)} ${n}` : n, settings:{sessionSize:10,dailyGoal:10,reviewOrder:'front-first',langSwap:!1}, filters:{grades:GRADE_FILTERS()}, stats:{gradeCounts:{...GRADE_INIT(),unseen:cds.length},totalReviews:0,dailyReviews:{},dailyChanges:{},dailyDurMs:{},dailyDurCount:{},dailyLog:{}}, cards:cds
          } 
      }), 
      app:{currentChapterId:null,theme:'dark',prefs:{fsTerm:22,fsDef:24,accent:'indigo',showEmoji:!0,radius:14}}
  };
}
const buildSub=(t,l) => ({id:slugify(t),title:t,chapters:buildChs(l).chapters,groups:[]});
const buildMathSub = () => {
    const s = buildSub('Maths', dataMATH);
    s.emoji = '';
    if (s.chapters.length >= 1) {
        s.groups = [{
            id: 'g-math-all',
            chapIds: s.chapters.map(c => c.id),
            createdAt: Date.now(),
            title: 'R√©sum√© de Cours',
            emoji: 'üìñ',
            lastUsed: Date.now()
        }];
    }
    return s;
};
const buildCanon = () => [buildSub('Physique',dataPHY), buildMathSub(), buildSub('Anglais',dataEN)];


function loadData(){ try{const r=LS.getItem(KEY);if(r){const p=JSON.parse(r);if(p.subjects)return p;if(p.chapters)return{subjects:[{id:'anglais',title:'Anglais',chapters:p.chapters,groups:[]}],app:p.app||{theme:'light',currentSubjectId:'anglais'}}}}catch{} const s=buildCanon(); return{subjects:s,app:{currentSubjectId:s[0]?.id,theme:'light',prefs:{fsTerm:22,fsDef:24,accent:'indigo'}}} }
function saveData(){ try{LS.setItem(KEY,JSON.stringify(data))}catch{} }

function pruneStats(){ const c=new Date(); c.setDate(c.getDate()-180); const k=dateKey(c); data.subjects.forEach(s=>s.chapters.forEach(ch=>{ ['dailyReviews','dailyDurMs','dailyDurCount','dailyChanges','dailyLog'].forEach(x=>{const m=ch.stats[x]||{};Object.keys(m).forEach(d=>{if(d<k)delete m[d]})}); if(ch.stats.dailyLog)Object.values(ch.stats.dailyLog).forEach(a=>{if(a.length>200)a.splice(0,a.length-200)}) })) }
const getSub = () => data.subjects.find(x=>x.id===data.app.currentSubjectId)||data.subjects[0];
const setSub = id => { if(data.subjects.find(s=>s.id===id)){data.app.currentSubjectId=id;saveData()} };
const getChs = () => getSub()?.chapters||[];
const updChDesc = c => { 
  const e = c.emoji || getEmoji(c.title) || ''; 
  c.description = (e ? e + ' ' : '') + c.title; 
};
function uniqId(s,b){ const ids=new Set((s.chapters||[]).map(c=>c.id)); if(!ids.has(b))return b; let i=2,d=b; while(ids.has(d))d=b+'-'+i++; return d }
function moveCh(fid,cid,tid){ if(fid===tid)return!1; const f=data.subjects.find(s=>s.id===fid), t=data.subjects.find(s=>s.id===tid); if(!f||!t)return!1; const i=f.chapters.findIndex(c=>c.id===cid); if(i<0)return!1; const ch=f.chapters[i]; ensGrps(f).forEach(g=>g.chapIds=g.chapIds.filter(id=>id!==cid)); valGrps(f); f.chapters.splice(i,1); ch.id=uniqId(t,ch.id); (t.chapters=t.chapters||[]).push(ch); valGrps(t); if(f.chapters.length===0){data.subjects=data.subjects.filter(s=>s.id!==f.id);if(data.app.currentSubjectId===f.id)data.app.currentSubjectId=data.subjects[0]?.id} saveData(); return!0 }
function renSub(id,t,e){ const s=data.subjects.find(x=>x.id===id); if(!s)return!1; if(t)s.title=t.trim(); s.emoji=(e||'').trim(); saveData(); return!0 }
const ensGrps = s => { if(!Array.isArray(s.groups))s.groups=[]; return s.groups };
const findGrp = (s,id) => ensGrps(s).find(g=>g.id===id);
const findGrpCh = (s,cid) => ensGrps(s).find(g=>g.chapIds.includes(cid));
const grpEmojis = (s,g) => { const z=new Set(); g.chapIds.forEach(id=>{const c=s.chapters.find(x=>x.id===id),e=c?(c.emoji||getEmoji(c.title)||''):'';if(e)z.add(e)}); return[...z].join(', ') };
const valGrps = s => { const all=new Set(s.chapters.map(c=>c.id)); s.groups=ensGrps(s).map(g=>({...g,chapIds:g.chapIds.filter(x=>all.has(x))})).filter(g=>g.chapIds.length>=2) };

function buildGrpStats(s,g){
  const chs=g.chapIds.map(id=>s.chapters.find(c=>c.id===id)).filter(Boolean), c=GRADE_INIT();
  chs.forEach(ch=>{ const k=getLive(ch); for(let x in c)c[x]+=k[x] });
  const st={totalReviews:chs.reduce((a,b)=>a+(b.stats.totalReviews||0),0),dailyReviews:{},dailyDurMs:{},dailyDurCount:{},dailyChanges:{}}, base=new Date();
  for(let i=0;i<60;i++){
    const d=new Date(base); d.setDate(base.getDate()-i); const k=dateKey(d);
    st.dailyReviews[k]=chs.reduce((a,b)=>a+(b.stats.dailyReviews[k]||0),0); st.dailyDurMs[k]=chs.reduce((a,b)=>a+(b.stats.dailyDurMs[k]||0),0);
    st.dailyDurCount[k]=chs.reduce((a,b)=>a+(b.stats.dailyDurCount[k]||0),0);
    st.dailyChanges[k]=chs.reduce((acc,ch)=>{const v=ch.stats.dailyChanges[k];if(v){acc.changed+=v.changed||0;acc.total+=v.total||0}return acc},{changed:0,total:0})
  }
  return {counts:c, stats:st}
}
function buildVirt(s,g){
  const chs=g.chapIds.map(id=>s.chapters.find(c=>c.id===id)).filter(Boolean), cards=[];
  chs.forEach(ch=>ch.cards.forEach(c=>cards.push({...c,id:`virt-${ch.id}-${c.id}`,_origin:{chapId:ch.id,cardId:c.id}})));
  return {id:'group-'+g.id,_groupId:g.id,title:g.title||`Fichier (${grpEmojis(s,g)})`,emoji:g.emoji||'',description:(g.emoji?g.emoji+' ':'')+(g.title||'Fichier'),virtual:!0,_ids:g.chapIds.slice(),settings:{sessionSize:10,dailyGoal:10,reviewOrder:'front-first',langSwap:!1},filters:g.filters?deepClone(g.filters):{grades:GRADE_FILTERS()},stats:{gradeCounts:buildGrpStats(s,g).counts,...buildGrpStats(s,g).stats},cards,deadline:g.deadline,lastUsed:g.lastUsed}
}
function addGrp(s,ids){ const u=[...new Set(ids)].filter(Boolean); if(u.length<2)return; ensGrps(s).push({id:'g'+Date.now().toString(36),chapIds:u,createdAt:Date.now(),title:'',emoji:'',lastUsed:Date.now()}) }
function toGrp(s,gid,cid){ const g=findGrp(s,gid); if(g&&!g.chapIds.includes(cid))g.chapIds.push(cid) }
function remGrp(s,gid,ids){ const g=findGrp(s,gid); if(g)g.chapIds=g.chapIds.filter(x=>!ids.includes(x)) }
function delGrp(s,gid){ s.groups=ensGrps(s).filter(g=>g.id!==gid) }

const Nav = {
  stack: [], scrollPos: 0,
  push(){ this.scrollPos = $('#dL')?.scrollTop||0; this.stack.push(deepClone({view:State.view,chapterId:State.chapterId,review:State.review,dailyKey:State.dailyKey,scrollPos:this.scrollPos})) },
  back(){ 
    if(!this.stack.length)return; const p=this.stack.pop(); 
    if(!this.stack.length||(!p.chapterId?.startsWith('group-')))State.virtualChapter=null; 
    State.view=p.view; State.chapterId=p.chapterId; State.review=p.review; State.dailyKey=p.dailyKey; 
    this.scrollPos = p.scrollPos || 0; render(!1) 
  },
  clear(){ this.stack=[]; this.scrollPos=0 }
};

const State = { view:'deck', chapterId:null, review:null, cardsIndex:0, dailyKey:null, virtualChapter:null };
const _real = id => getChs().find(c=>c.id===id), getCh = id => (State.virtualChapter?.id===id) ? State.virtualChapter : _real(id);
function updFilt(ch,key){ let t=ch; if(ch.virtual&&ch._groupId){const g=findGrp(getSub(),ch._groupId);if(g){if(!g.filters)g.filters={grades:GRADE_FILTERS()};t=g}} togFilt(t,key); if(t!==ch)ch.filters=t.filters; saveData(); goChapter(ch.id,!1) }
const delImpCh = id => { const s=getSub(), i=s.chapters.findIndex(c=>c.id===id); if(i<0||!s.chapters[i].imported||!confirm('Supprimer ?'))return!1; ensGrps(s).forEach(g=>g.chapIds=g.chapIds.filter(x=>x!==id)); valGrps(s); s.chapters.splice(i,1); if(!s.chapters.length&&s.imported){data.subjects=data.subjects.filter(x=>x.id!==s.id);data.app.currentSubjectId=data.subjects[0]?.id} saveData(); return!0 };

/* --- DEADLINE & LOGIC --- */
function getDeckTint(item, type) {
    let k; if (type === 'chapter') k = item.stats.gradeCounts || getLive(item); else k = buildGrpStats(getSub(), item).counts;
    const totalGraded = k.echec + k.difficile + k.bien + k.facile;
    let r = 0, g = 0, b = 0, a = 0;
    if (totalGraded > 0) {
        const wRed = (k.echec + k.difficile) / totalGraded, wBlue = k.bien / totalGraded, wGreen = k.facile / totalGraded;
        r = (239 * wRed) + (59 * wBlue) + (34 * wGreen);
        g = (68 * wRed) + (130 * wBlue) + (197 * wGreen);
        b = (68 * wRed) + (246 * wBlue) + (94 * wGreen);
        a = 0.25;
    }
    if (item.deadline) {
        const now = new Date(); now.setHours(0,0,0,0); const ddl = new Date(item.deadline); ddl.setHours(0,0,0,0);
        const diff = (ddl - now) / 864e5; let urgency = 0;
        if (diff <= 0) urgency = 1; else if (diff <= 7) urgency = 1 - (diff / 7);
        if (urgency > 0) {
            const tR = 239, tG = 68, tB = 68;
            if (totalGraded === 0) { r = tR; g = tG; b = tB; a = 0.5 * urgency; } else { r = r * (1 - urgency) + tR * urgency; g = g * (1 - urgency) + tG * urgency; b = b * (1 - urgency) + tB * urgency; a = 0.25 + (0.25 * urgency); }
        }
    }
    if (a <= 0.01) return '';
    return `rgba(${Math.round(r)}, ${Math.round(g)}, ${Math.round(b)}, ${a})`;
}

function checkExpiredDates(list) {
    const now = new Date(); now.setHours(0,0,0,0); let changed = false;
    list.forEach(item => { if (item.deadline) { const ddl = new Date(item.deadline); ddl.setHours(0,0,0,0); if (ddl < now) { item.deadline = null; changed = true; } } });
    return changed;
}

function getDailyGoalCalc(ch) {
    if(!ch.deadline) return null;
    const now = new Date(); now.setHours(0,0,0,0); const ddl = new Date(ch.deadline); ddl.setHours(0,0,0,0);
    let days = Math.ceil((ddl - now) / 864e5); if (days <= 0) days = 1;
    const k = ch.stats.gradeCounts || getLive(ch);
    let pool = k.unseen + k.echec + k.difficile, label = "cartes (Mauvaises)";
    if (pool === 0) { pool = k.bien; label = "cartes (Bien)"; if (pool === 0) return { val: 0, text: "Objectif atteint !", pool: 0 }; }
    return { val: Math.ceil(pool / days), text: `${label} / jour`, pool: pool };
}

/* --- NAVIGATION & UI --- */
const backBtn=$('#backBtn'), titleEl=$('#title'), botAct=$('#bottomActions'), revBar=$('#revisionBar'), startBtn=$('#startReviewBtn');
const chipHtml = k => `<span class="chip">üü• ${k.echec}</span><span class="chip">üü® ${k.difficile}</span><span class="chip">üü¶ ${k.bien}</span><span class="chip">üü© ${k.facile}</span>`;

function renSubMenu(){
  let m=$('#subjectMenu'); if(!m){m=D.createElement('div');m.id='subjectMenu';m.className='subject-menu';D.body.appendChild(m)}
  m.innerHTML=data.subjects.map(s=>`<div class="subject-item" data-id="${s.id}"><div class="name">${s.emoji?s.emoji+' ':''}${s.title}</div><div class="meta">${s.chapters?.length||0} chap.</div>${s.id===data.app.currentSubjectId?'<div class="muted">‚úì</div>':''}<div class="subject-actions"><button class="btn btn--tiny rs">‚úèÔ∏è</button>${!(s.chapters?.length)?'<button class="btn btn--tiny ds">üóëÔ∏è</button>':''}</div></div>`).join('');
  $$('.subject-item',m).forEach(el=>{
    el.onclick=e=>{if(e.target.closest('button'))return;const id=el.dataset.id;if(id!==data.app.currentSubjectId){setSub(id);closeSubMenu();goDeck(!1)}else closeSubMenu();e.stopPropagation()};
    const r=el.querySelector('.rs'); if(r)r.onclick=e=>{e.stopPropagation();const id=el.dataset.id,s=data.subjects.find(x=>x.id===id),t=prompt('Nom:',s.title);if(t){renSub(id,t,prompt('Emoji:',s.emoji));renSubMenu();setTop({title:`Deck ‚Ä¢ ${getSub().title}`});goDeck(!1)}};
    const d=el.querySelector('.ds'); if(d)d.onclick=e=>{e.stopPropagation();const id=el.dataset.id;if(confirm('Supprimer ?')){data.subjects=data.subjects.filter(s=>s.id!==id);if(data.app.currentSubjectId===id)data.app.currentSubjectId=data.subjects[0]?.id;closeSubMenu();goDeck(!1);saveData()}}
  })
}
const openSubMenu = () => { renSubMenu(); const m=$('#subjectMenu'), r=titleEl.getBoundingClientRect(); m.style.top=`${r.bottom+6}px`; m.style.left=`${r.left}px`; m.style.display='block'; setTimeout(()=>D.addEventListener('click',clsOnOut),0) };
const closeSubMenu = () => { const m=$('#subjectMenu'); if(m)m.style.display='none'; D.removeEventListener('click',clsOnOut) };
const clsOnOut = e => { if(!$('#subjectMenu')?.contains(e.target)&&e.target!==titleEl)closeSubMenu() };

titleEl.onclick = () => { if(State.view!=='deck')goDeck(!1); else($('#subjectMenu')?.style.display==='block')?closeSubMenu():openSubMenu() };
backBtn.onclick = () => { if(State.view==='recap'){if(Nav.stack.length)Nav.stack.pop();const t=State.review?.chapterId||State.chapterId;State.review=null;hideRevAct();if(t?.startsWith('group-')){const g=findGrp(getSub(),t.replace('group-',''));if(g){State.virtualChapter=buildVirt(getSub(),g);goChapter(State.virtualChapter.id,!1)}else goDeck(!1)}else if(t)goChapter(t,!1);else goDeck(!1)}else{if(State.view==='review'&&State.review&&!State.review.end&&!confirm('Quitter la r√©vision ?'))return;Nav.back()} };
$('#cardsBtn').onclick = () => goCards(State.chapterId); $('#settingsBtn').onclick = () => openSet(State.chapterId); startBtn.onclick = () => startRev(State.chapterId);

function setTop({title,showBack}){ backBtn.classList.toggle('hidden',showBack===!1); if(title)titleEl.textContent=title }
function setBot({actions,revision,sz=10,en=true,av=null,cid=null}){ botAct.style.display=actions?'grid':'none'; revBar.style.display=revision?'block':'none'; $('#app').style.setProperty('--row-actions',actions?'52px':'0px'); $('#app').style.setProperty('--row-rev',revision?'64px':'0px'); if(av==null&&cid){const c=getCh(cid);av=c?cntAv(c):0} startBtn.textContent=`R√©vision ‚Ä¢ ${av>0?M.min(sz,av):sz} cartes${revision&&(av>0)?` ‚Ä¢ ${av} dispo`:''}`; startBtn.disabled=!en||(av||0)<=0 }
function render(push=true){ if(State.view==='deck')goDeck(push); else if(State.view==='chapter')goChapter(State.chapterId,push); else if(State.view==='cards')goCards(State.chapterId,push); else if(State.view==='review')goReview(push); else if(State.view==='recap')goRecap(push); else if(State.view==='settings')openSet(State.chapterId,push); else if(State.view==='daily')goDaily(State.chapterId,State.dailyKey,push) }
const hideRevAct = () => { $('#reviewActionsBar').style.display='none' };

function goDeck(push=true){
  safeCloseLB(); Media.revokeAll(); clearMathCache();
  if(push) Nav.push(); State.view='deck'; State.chapterId=null; 
  const s=getSub(); setTop({title:`Deck ‚Ä¢ ${s.emoji?s.emoji+' ':''}${s.title}`, showBack:!1}); setBot({actions:!1, revision:!1}); hideRevAct();
  let needsSave = false; if (checkExpiredDates(ensGrps(s))) needsSave = true; if (checkExpiredDates(s.chapters)) needsSave = true; if (needsSave) debouncedSave();

  const v=$('#view'), grps=ensGrps(s), chs=(s.chapters||[]), inG=new Set(grps.flatMap(g=>g.chapIds));
  const sorter = (a, b) => { if (a.deadline && !b.deadline) return -1; if (!a.deadline && b.deadline) return 1; if (a.deadline && b.deadline) { const diff = new Date(a.deadline) - new Date(b.deadline); if (diff !== 0) return diff; } return (b.lastUsed || 0) - (a.lastUsed || 0); };
  grps.sort(sorter); const visibleChs = chs.filter(c=>!inG.has(c.id)).sort(sorter);

  v.innerHTML=`<div class="card flexcol" style="flex:1"><div class="deck-head"><div class="section-title">Chapitres & Fichiers</div><div class="actions"><button class="btn btn--ghost btn--tiny" id="impB">Importer</button><input id="impI" type="file" class="hidden" accept="*/*" multiple/></div></div><div id="dL" class="scroll-y" style="flex:1;min-height:0;padding-right:4px"><div class="list">${grps.map(g=>{const{counts:c}=buildGrpStats(s,g),tot=Object.values(c).reduce((a,b)=>a+b,0),pct=tot?M.round((tot-c.unseen)*100/tot):0; const tint = getDeckTint(g, 'group'); return`<div class="deck-item" data-type="group" data-id="${g.id}" style="${tint?`background-color:${tint};transition:background-color 0.3s`:''}"><div class="slide"><div style="min-width:0;flex:1"><div class="title-line" style="font-weight:900;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;font-size:18px">${g.title?((g.emoji?g.emoji+' ':'')+g.title):`üìÅ Fichier (${grpEmojis(s,g)})`}</div><div class="mt6" style="display:flex;flex-wrap:wrap;gap:6px"><span class="chip-pie" style="--progress:${pct}%"></span>${chipHtml(c)}<span class="folder-badge">‚Ä¢ ${g.chapIds.length} chap.</span></div></div><div class="muted" style="font-size:18px;padding-left:8px">‚Ä∫</div></div></div>`}).join('')}${visibleChs.map(c=>{const k=getLive(c),tot=c.cards.length,pct=tot?M.round((tot-k.unseen)/tot*100):0; const tint = getDeckTint(c, 'chapter'); return`<div class="deck-item" data-type="chapter" data-id="${c.id}" style="${tint?`background-color:${tint};transition:background-color 0.3s`:''}">${c.imported?`<div class="right-action"><button class="btn btn--solid btn--red btn--tiny delCh" data-cid="${c.id}">Supprimer</button></div>`:''}<div class="slide"><div style="min-width:0;flex:1"><div class="title-line" style="font-weight:900;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;font-size:18px">${c.description||c.title}</div><div class="mt6" style="display:flex;flex-wrap:wrap;gap:6px"><span class="chip-pie" style="--progress:${pct}%"></span>${chipHtml(k)}</div></div><div class="muted" style="font-size:18px;padding-left:8px">‚Ä∫</div></div></div>`}).join('')}</div></div></div>`;
  
  $('#impB').onclick=()=>$('#impI').click(); 
  $('#impI').onchange = async e => { try { await importFiles([...e.target.files]); toast('Import termin√© !', 'success'); goDeck(!1); } catch(x) { toast('Erreur import', 'error'); } finally { e.target.value=''; } }; 
  if(!push && Nav.scrollPos > 0) { setTimeout(() => { const list = $('#dL'); if(list) list.scrollTop = Nav.scrollPos; }, 50); }
  const list = $('#dL'); if(list) bindPullRefresh(list, () => { toast('Actualisation...', 'info', 1000); goDeck(false); });
  bindDeck();
}

// Optimized Event Delegation for Deck List
function bindDeck(){
  const l=$('#dL'); if(!l)return; const sub=getSub();
  l.onclick=e=>{if(e.target.matches('.delCh')){e.stopPropagation();if(delImpCh(e.target.dataset.cid))goDeck(!1)}};

  let sx=0, sy=0, dx=0, dy=0, st='idle', tm, g, raf, sd=0, el=null, t=null, id=null;
  const auto=()=>{if(sd!==0)l.scrollTop+=6*sd;if(st==='dragging')raf=requestAnimationFrame(auto)};
  const mG=(x,y)=>{if(g)g.style.transform=`translate(${x-75}px,${y-75}px) scale(1.02)`};

  const onDown = e => {
      if(e.target.closest('button')) return;
      el = e.target.closest('.deck-item'); if(!el) return;
      t = el.dataset.type; id = el.dataset.id;
      sx=e.clientX; sy=e.clientY; dx=dy=0; st='pressed'; clearTimeout(tm);
      if(!/android/i.test(navigator.userAgent)) el.setPointerCapture?.(e.pointerId);

      if(t==='chapter') tm=setTimeout(()=>{
          st='dragging'; el.classList.add('dragging-origin'); D.body.classList.add('dragging-active'); l.classList.add('scroll-lock'); openSubMenu();
          g=el.cloneNode(!0); g.className='drag-ghost'; g.style.width=el.offsetWidth+'px'; D.body.appendChild(g); mG(sx,sy); raf=requestAnimationFrame(auto)
      }, 500);
      else if(t==='group') tm=setTimeout(()=>{ st='idle'; if(confirm("D√©composer ?")) { delGrp(sub,id); saveData(); goDeck(!1); } }, 700);
      
      l.addEventListener('pointermove', onMove); l.addEventListener('pointerup', onUp); l.addEventListener('pointercancel', onUp);
  };

  const onMove = e => {
      if(st==='idle'||st==='swiping') return;
      dx=e.clientX-sx; dy=e.clientY-sy;
      if(st==='pressed'&&M.abs(dx)>10){
          clearTimeout(tm);
          if(dx<0&&el.querySelector('.right-action')){ st='swiping'; el.classList.add('reveal-delete'); e.preventDefault(); }
      } else if(st==='dragging'){
          e.preventDefault(); mG(e.clientX,e.clientY); const r=l.getBoundingClientRect();
          sd = e.clientY<r.top+r.height*.2 ? -1 : (e.clientY>r.bottom-r.height*.2 ? 1 : 0);
          $$('.deck-item,.subject-item').forEach(n=>n.classList.remove('drop-target'));
          const tg=D.elementFromPoint(e.clientX,e.clientY)?.closest('.deck-item,.subject-item');
          if(tg&&tg!==el) tg.classList.add('drop-target');
      }
  };

  const onUp = e => {
      clearTimeout(tm);
      l.removeEventListener('pointermove', onMove); l.removeEventListener('pointerup', onUp); l.removeEventListener('pointercancel', onUp);

      if(st==='dragging'){
          const sEl=D.elementFromPoint(e.clientX,e.clientY)?.closest('.subject-item');
          if(sEl){ const to=sEl.dataset.id; if(to&&to!==sub.id&&moveCh(sub.id,id,to)) setSub(to); }
          else{ const tg=D.elementFromPoint(e.clientX,e.clientY)?.closest('.deck-item'); if(tg&&tg!==el) hDrop(sub,{type:t,id},{type:tg.dataset.type,id:tg.dataset.id}); }
          goDeck(!1);
      } else if(st==='pressed' && M.hypot(dx,dy)<8 && M.abs(dy)<6){
          if(t==='group') openGrp(sub,id); else goChapter(id);
      }
      cancelAnimationFrame(raf); st='idle'; if(g) g.remove(); g=null;
      if(el) el.classList.remove('dragging-origin'); 
      D.body.classList.remove('dragging-active'); l.classList.remove('scroll-lock');
      $$('.deck-item,.subject-item').forEach(n=>n.classList.remove('drop-target')); closeSubMenu();
      el = null;
  };
  
  l.addEventListener('pointerdown', onDown);
  l.onscroll=()=>{$$('.reveal-delete').forEach(n=>n.classList.remove('reveal-delete'))}
}
function hDrop(s,src,dst){
  if(src.type!=='chapter')return; const sG=findGrpCh(s,src.id);
  if(dst.type==='chapter'){if(src.id===dst.id)return;const dG=findGrpCh(s,dst.id);if(!sG&&!dG)addGrp(s,[src.id,dst.id]);else if(sG&&!dG)toGrp(s,sG.id,dst.id);else if(!sG&&dG)toGrp(s,dG.id,src.id);else if(sG!==dG){remGrp(s,sG.id,[src.id]);toGrp(s,dG.id,src.id)}}
  else if(dst.type==='group'){if(sG&&sG.id!==dst.id)remGrp(s,sG.id,[src.id]);toGrp(s,dst.id,src.id)} valGrps(s); saveData()
}
function openGrp(s,gid){ const g=findGrp(s,gid); if(g){State.virtualChapter=buildVirt(s,g);goChapter(State.virtualChapter.id)} }

function goChapter(id,push=true){
  safeCloseLB(); Media.revokeAll(); clearMathCache(); if(push)Nav.push(); State.view='chapter'; State.chapterId=id; const c=getCh(id); if(!c){Nav.back();return} setTop({title:c.title}); updRevBar(c); hideRevAct(); const k=c.stats.gradeCounts||getLive(c), sel=c.filters.grades, v=$('#view');
  const dailyCalc = getDailyGoalCalc(c);
  v.innerHTML=`<div class="card" style="flex:1;display:flex;flex-direction:column"><div class="section-title">${c.virtual?c.description:(getEmoji(c.title)?getEmoji(c.title)+' ':'')+'Statistiques'}</div><div class="kpi"><div class="k"><div class="label">Non vues</div><div class="value">${k.unseen}</div></div><div class="k"><div class="label">Total</div><div class="value">${c.cards.length}</div></div></div><div class="chart-wrap"><canvas id="gradeChart" width="180" height="180"></canvas></div><div class="legend" id="legend">${GRADES.map(x=>{const act = sel[x], color = x==='unseen'?'gray':(x==='echec'?'red':(x==='difficile'?'amber':(x==='bien'?'blue':'green'))), label = x.charAt(0).toUpperCase() + x.slice(1); return `<div class="legend-item ${act?'':'inactive'}" data-key="${x}"><span class="check-icon">${act?'‚úì':''}</span><span class="dot ${color}"></span><span style="flex:1">${label}</span><b class="count">${k[x]}</b></div>`}).join('')}</div><div class="kpi mt8"><div class="k"><div class="label">Auj.</div><div class="value">${getTod(c)}</div></div><div class="k"><div class="label">üî• Streak</div><div class="value">${getStreak(c)} j</div></div></div><div class="kpi mt8"><div class="k"><div class="label">R√©ussite</div><div class="value">${getSucc(c)}%</div></div><div class="k"><div class="label">Moy. 7j</div><div class="value">${get7dAvgMs(c)?M.round(get7dAvgMs(c)/100)/10+'s':'‚Äî'}</div></div></div><div class="mt8" style="padding:10px;background:var(--surface);border:1px solid var(--border);border-radius:10px;"><div style="display:flex;align-items:center;justify-content:space-between;"><span style="font-size:13px;font-weight:bold;color:var(--muted)">Date Limite:</span><input type="date" id="deadlineInput" class="input" style="width:auto;padding:4px 8px;" value="${c.deadline||''}"></div>${dailyCalc ? `<div class="mt6" style="font-size:13px;color:var(--primary);display:flex;justify-content:space-between"><span>Objectif fix√©: <b>${c._goalCache?.size || dailyCalc.val}</b>/jour</span><span>Reste: <b>${cntAv(c)}</b> dispo</span></div>` : ''}</div><div class="bar7-wrap mt8"><div class="label" style="color:var(--primary)">Activit√© 7j</div><canvas id="bar7" width="220" height="60"></canvas><div class="bar7-labels" id="bar7Labels"></div></div></div>`;
  drawChart('gradeChart',k,sel); $('#gradeChart').onclick=e=>hChartClk(e,'gradeChart',c); $$('.legend-item').forEach(el=>el.onclick=()=>updFilt(c,el.dataset.key)); drawBars('bar7',getLastN(c,7)); $('#bar7').onclick=e=>opDayBar(e,'bar7',c.id); $('#bar7Labels').innerHTML=getLbls(7).map((j,i)=>`<div onclick="goDaily('${c.id}','${dayKeyIdx(7,i)}')">${j.substring(0,3)}</div>`).join('');
  $('#deadlineInput').onchange = (e) => { const val = e.target.value; if (c.virtual && c._groupId) { const g = findGrp(getSub(), c._groupId); if (g) g.deadline = val; } else { c.deadline = val; } debouncedSave(); goChapter(c.id, false); };
}
function updRevBar(c){ const n=cntAv(c); setBot({actions:!0,revision:!0,sz:c.settings.sessionSize,en:c.cards.length>0,av:n,cid:c.id}) }

/* --- RECHERCHE --- */
async function goCards(cid,push=true){
  safeCloseLB(); Media.revokeAll(); if(push)Nav.push(); State.view='cards'; State.chapterId=cid; 
  const c=getCh(cid), pool=c.cards.filter(x=>c.filters.grades[x.grade||'unseen']), v=$('#view'); 
  setTop({title:`${c.title} ‚Ä¢ Cartes`}); setBot({actions:!1,revision:!1}); hideRevAct();
  v.innerHTML=`<div style="flex:1;display:flex;flex-direction:column;min-height:0"><div style="flex-shrink:0"><div class="section-title">Cartes (${pool.length})</div><div style="margin-bottom:10px"><input type="text" id="cardSearch" class="input" placeholder="Rechercher..." autocomplete="off" spellcheck="false"></div></div><div id="cardsGrid" class="scroll-y" style="flex:1;min-height:0;padding-right:4px"><div class="cards-grid" id="gridCont"></div></div></div>`;

  const render = async (q='') => {
    const norm = s => s.toLowerCase().normalize("NFD").replace(/[\u0300-\u036f]/g, ""), cleanQ = norm(q);
    let filtered = [];
    if (!cleanQ) { filtered = pool; } else {
        const scored = pool.map(x => {
            const {f,b} = getSides(x,c); const tf = norm(f); const tb = norm(b);
            const fStart = tf.startsWith(cleanQ), bStart = tb.startsWith(cleanQ), fIn = tf.includes(cleanQ), bIn = tb.includes(cleanQ);
            if (!fIn && !bIn) return null;
            let score = 2; let len = 100000; 
            if (fStart || bStart) { score = 1; len = Math.min(fStart ? tf.length : 100000, bStart ? tb.length : 100000); } else { score = 2; len = Math.min(fIn ? tf.length : 100000, bIn ? tb.length : 100000); }
            return { card: x, score, len };
        }).filter(x => x !== null);
        scored.sort((a, b) => { if (a.score !== b.score) return a.score - b.score; return a.len - b.len; });
        filtered = scored.map(s => s.card);
    }
    const grid = $('#gridCont'); grid.innerHTML = '';
    if(filtered.length === 0) { grid.innerHTML = `<div class="muted center" style="grid-column:1/-1;padding:20px">Aucune carte trouv√©e.</div>`; } 
    else {
       filtered.forEach(x => {
          const {f,b} = getSides(x,c), el = D.createElement('div');
          el.className = `card-block grade-${x.grade||'unseen'}`; el.dataset.id = x.id;
          el.innerHTML = `<div class="term">${formatText(f)}</div><div class="definition">${formatText(b)}</div>${x.avgMs?`<div class="cb-time">${fmtDur(x.avgMs)}</div>`:''}`;
          grid.appendChild(el);
       });
    }
    await Media.resolve(grid); await tsLat(grid);
  };
  await render(); 
  $('#cardSearch').oninput = (e) => render(e.target.value);
  $('#cardsGrid').onclick=e=>{ const b=e.target.closest('.card-block'); if(b){ $$('.card-block').forEach(x=>{if(x!==b)x.classList.remove('flipped')}); b.classList.toggle('flipped'); } };
}

async function goDaily(cid,k,push=true){
  safeCloseLB(); Media.revokeAll(); if(push)Nav.push(); State.view='daily'; State.chapterId=cid; State.dailyKey=k; const c=getCh(cid), sub=getSub(); setTop({title:`Activit√© ‚Ä¢ ${fmtDayFR(k)}`}); setBot({actions:!1,revision:!1});
  const log=c.virtual?(findGrp(sub,c._groupId)?getLogGrp(sub,findGrp(sub,c._groupId),k):[]):(c.stats.dailyLog[k]||[]), v=$('#view'); if(!log.length){v.innerHTML=`<div class="card"><div class="section-title">Activit√© ${fmtDayFR(k)}</div><div class="muted">Aucune donn√©e.</div></div>`;return}
  log.sort((a,b)=>a.ts-b.ts); const byC=new Map(); for(const e of log){const cur=byC.get(e.cardId)||{f:e.prev,l:e.next,ts:e.ts,lts:e.ts,_c:e._chapId};if(e.ts>cur.lts){cur.l=e.next;cur.lts=e.ts}byC.set(e.cardId,cur)}
  const rows=[...byC].map(([id,i])=>{const ch=c.virtual?_real(i._c):c,card=ch.cards.find(x=>x.id===id);return card?{t:formatText(getSides(card,ch).f),d:formatText(getSides(card,ch).b),b:i.f,a:i.l}:null}).filter(Boolean);
  v.innerHTML=`<div class="card" style="flex:1;display:flex;flex-direction:column;min-height:0"><div class="section-title">Activit√© ${fmtDayFR(k)}</div><div id="dayL" class="scroll-y" style="flex:1"><div class="list">${rows.map(r=>`<div class="grid2"><div class="card-block grade-${r.b}"><div class="term">${r.t}</div><div class="definition">${r.d}</div></div><div class="card-block grade-${r.a}"><div class="term">${r.t}</div><div class="definition">${r.d}</div></div></div>`).join('')}</div></div></div>`;
  await Media.resolve(v); await tsLat(v); $('#dayL').onclick=e=>{const b=e.target.closest('.card-block');if(b)b.classList.toggle('flipped')}
}
function getLogGrp(s,g,k){ return g.chapIds.flatMap(cid=>{const ch=s.chapters.find(c=>c.id===cid);return(ch?.stats?.dailyLog?.[k]||[]).map(e=>({...e,_chapId:cid}))}) }

function goReview(push=true){ safeCloseLB(); Media.revokeAll(); if(push)Nav.push(); State.view='review'; setTop({title:'R√©vision'}); setBot({actions:!1,revision:!0}); $('#revisionBar').style.display='none'; $('#reviewActionsBar').style.display='block'; $('#app').classList.toggle('focus-mode', data.app.prefs.focusMode); renRev() }

function renRev(){
  const v=$('#view'), r=State.review, {card,chap}=getCur(), idx=r.index+1, tot=r.queue.length, {f,b}=getSides(card,chap), ff=chap.settings.reviewOrder!=='back-first';
  const fT=formatText(f), bT=formatText(b), progress=((r.index)/tot)*100;
  const undoBtn = r.history.length ? `<button id="undoBtn" style="background:0 0;border:0;color:var(--muted);font-size:18px;padding:0 8px;cursor:pointer">‚Ü∫</button>` : '';
  
  v.innerHTML=`<div class="review-wrap">
    <div class="progress-bar" style="width:${progress}%"></div>
    <div class="review-top"><div style="display:flex;align-items:center">${undoBtn} ${r.mode==='multi'?'Multi ‚Ä¢ '+chap.title:chap.title}</div><div>${idx} / ${tot}</div></div>
    <div class="review-card"><div class="review-scroller">${!r.flipped ? `<div class="term" data-face="${ff?'front':'back'}">${fT}</div>` : `<div class="stack"><div class="term" data-face="front">${fT}</div><div class="definition" data-face="back" style="margin-top:20px;padding-top:20px;border-top:1px dashed var(--border)">${bT}</div></div>`}</div></div>
  </div>`;
  
  const scroller = v.querySelector('.review-scroller');
  const finishSetup = () => { Media.resolve(v); initGest(); bindSwipeNav(); };
  if(scroller) tsLat(scroller).then(finishSetup); else finishSetup();
  if(r.history.length) $('#undoBtn').onclick = undoRev; 
  
  let lastTap = 0;
  $('.review-scroller').addEventListener('click', e => {
    if(e.target.closest('img')) return;
    const now = Date.now();
    if(now - lastTap < 300 && !r.flipped) { haptic('light'); r.flipped = true; renRev(); }
    lastTap = now;
  });

  const bar=$('#reviewActionsBar');
  if(!r.flipped){
      bar.innerHTML=`<button class="btn btn--solid btn--primary" id="flipBtn">Retourner</button>`;
      $('#flipBtn').onclick=()=>{haptic('light');r.flipped=!0;renRev()}
  } else {
      bar.innerHTML=`<div class="row-4">${['echec','difficile','bien','facile'].map(g=>`<button class="btn btn--${g==='echec'?'red':(g==='difficile'?'amber':(g==='bien'?'blue':'green'))}" id="g_${g}">${g}</button>`).join('')}</div>`;
      ['echec','difficile','bien','facile'].forEach(g=>$('#g_'+g).onclick=()=>subG(g))
  }
}

function goRecap(push=true){
  safeCloseLB(); Media.revokeAll(); if(push)Nav.push(); State.view='recap'; const c=getCh(State.review.chapterId)||State.virtualChapter||getCh(State.review.multiChaps[0]); setTop({title:'R√©capitulatif'}); setBot({actions:!1,revision:!1}); hideRevAct();
  const dur=(State.review.answers||[]).reduce((s,a)=>s+(a.ms||0),0), n=State.review.answers.length;
  $('#view').innerHTML=`<div class="card recap" style="flex:1"><div><h2>R√©capitulatif</h2><div class="subtitle">${c.title}</div></div><div class="grid2"><div class="stat"><div class="label">Moy. 7j</div><div class="val">${get7dAvg(c)}</div></div><div class="stat"><div class="label">Changement</div><div class="val">${getTodCh(c).total>0?M.round(getTodCh(c).changed/getTodCh(c).total*100):0}%</div></div><div class="stat"><div class="label">Fait</div><div class="val">${getTod(c)}</div></div></div><div class="grid2"><div class="stat"><div class="label">Session</div><div class="val">${n}</div></div><div class="stat"><div class="label">Dur√©e</div><div class="val">${fmtDur(dur)}</div></div></div><div class="cta"><button class="btn btn--solid btn--primary" id="contBtn">Continuer</button></div></div>`;
  $('#contBtn').onclick=()=>startRev(c.id,!1,true)
}
function startRev(cid,push=true,isCont=false){
  if(!cid)return; const c=getCh(cid); 
  // Passer isCont √† startRevMulti
  if(c.virtual&&c._ids)return startRevMulti(c._ids,c.id,c.filters,push,isCont);
  
  if(c.deadline) {
      const dayStart = getDayStart();
      if(!c._goalCache || c._goalCache.day !== dayStart) { const calc = getDailyGoalCalc(c); c._goalCache = { day: dayStart, size: calc?.val || 10, pool: calc?.pool || 0 }; }
      c.settings.sessionSize = c._goalCache.size;
  }

  // Si continuation, on exclut les cartes d√©j√† pr√©sentes dans la queue actuelle
  let pool = c.cards.filter(x=>c.filters.grades[x.grade||'unseen']); 
  if(isCont && State.review && State.review.queue) {
      const seenIds = new Set(State.review.queue);
      pool = pool.filter(x => !seenIds.has(x.id));
  }

  if(!pool.length){alert('Plus de cartes disponibles dans ce filtre.'); return;}
  
  c.lastUsed = Date.now(); saveData();
  const q = bldQ(c,pool,c.settings.sessionSize); 
  const newIds = q.map(x=>x.id);

  if(isCont && State.review) {
      // On ajoute √† la session existante
      State.review.queue.push(...newIds);
      State.review.index++; // On passe √† la premi√®re des nouvelles cartes
      State.review.flipped = false;
      State.review.cardStart = Date.now();
      State.review.end = null;
  } else {
      // Nouvelle session (comportement d'origine)
      State.review={chapterId:cid,queue:newIds,index:0,flipped:!1,answers:[],history:[],start:Date.now(),end:null,cardStart:Date.now()}; 
  }
  goReview(push);
}
function startRevMulti(ids,vid,flt,push=true,isCont=false){
  const all=ids.map(_real).filter(Boolean), pool=[]; 
  
  // Si continuation, on r√©cup√®re les IDs d√©j√† pr√©sents
  const seenIds = (isCont && State.review) ? new Set(State.review.queue.map(item => item.cardId)) : new Set();

  all.forEach(ch=>ch.cards.forEach(c=>{
      if(flt.grades[c.grade||'unseen'] && !seenIds.has(c.id)) {
          pool.push({chapId:ch.id,card:c});
      }
  })); 
  
  if(!pool.length){alert('Plus de cartes disponibles.');return}

  const scored=pool.map(i=>{
      const g=i.card.grade||'unseen',
      base={unseen:6,echec:5,difficile:3.5,bien:2,facile:1}[g]||1,
      due=(i.card.dueAt&&i.card.dueAt>0)?(Date.now()-i.card.dueAt>0?(1+M.min(3,(Date.now()-i.card.dueAt)/864e5)):0.85):1.15;
      return {chapId:i.chapId,cardId:i.card.id,w:base*due*(1+(1-(i.card.perfEma||.5))*1.6)*(1+M.min(2,(i.card.avgMs||0)/3000))*(0.9+M.random()*.2)}
  }).sort((a,b)=>b.w-a.w);

  const sz=M.round(all.reduce((s,c)=>s+(c.settings.sessionSize||10),0)/all.length)||10;
  const newCards = scored.slice(0,sz);

  if(vid.startsWith('group-')){ const sub = getSub(); const g = findGrp(sub, vid.replace('group-','')); if(g) { g.lastUsed = Date.now(); saveData(); } }

  if(isCont && State.review) {
      State.review.queue.push(...newCards);
      State.review.index++;
      State.review.flipped = false;
      State.review.cardStart = Date.now();
      State.review.end = null;
  } else {
      State.review={mode:'multi',chapterId:vid,multiChaps:ids.slice(),queue:newCards,index:0,flipped:!1,answers:[],history:[],start:Date.now(),end:null,cardStart:Date.now()}; 
  }
  goReview(push);
}

function bldQ(c,pool,sz){
  const sh=a=>{for(let i=a.length-1;i>0;i--){const j=M.floor(M.random()*(i+1));[a[i],a[j]]=[a[j],a[i]]}return a};
  const nc=[], lc=[], dr=[], ot=[];
  pool.forEach(x=>{
      const g=x.grade||'unseen';
      if(g==='unseen') nc.push(x); else if(g==='echec'||g==='difficile') lc.push(x); else if(x.dueAt<=Date.now()) dr.push(x); else ot.push(x);
  });
  return [...sh(lc),...sh(dr),...sh(nc),...sh(ot)].slice(0,sz)
}

function getCur(){ const r=State.review; if(r.mode==='multi'){const i=r.queue[r.index],ch=_real(i.chapId);return{card:ch.cards.find(x=>x.id===i.cardId),chap:ch}}else{const ch=getCh(r.chapterId);return{card:ch.cards.find(x=>x.id===r.queue[r.index]),chap:ch}} }

function undoRev(){
  const r = State.review; if(!r.history.length) return;
  const snap = r.history.pop(); r.index = snap.idx;
  const {card, chap} = getCur(); Object.assign(card, snap.cardState); chap.stats = snap.statsState;
  if(r.answers.length > snap.ansIdx) r.answers.splice(snap.ansIdx);
  r.flipped = false;  // ‚Üê CORRIG√â : la carte appara√Æt c√¥t√© recto
  saveData(); renRev();
}
  
function subG(nxt){
  const r=State.review, now=Date.now(), {card,chap}=getCur(); if(!card||!chap){goDeck(!1);return}
  haptic(nxt === 'facile' ? 'success' : nxt === 'echec' ? 'error' : 'light'); 
  const cardEl = $('.review-card');
  if(cardEl) { cardEl.classList.remove('tint-facile', 'tint-bien', 'tint-difficile', 'tint-echec'); void cardEl.offsetWidth; cardEl.classList.add(`tint-${nxt}`); setTimeout(() => cardEl.classList.remove(`tint-${nxt}`), 400); }

  r.history.push({ idx: r.index, cardState: deepClone(card), statsState: deepClone(chap.stats), ansIdx: r.answers.length });
  const ms=M.max(0,now-(r.cardStart||now)), prev=card.grade||'unseen', wZ=!chap.stats.gradeCounts[nxt];
  card.grade=nxt; syncG(chap); card.perfEma=(1-.3)*(card.perfEma??.5)+.3*(nxt==='facile'?1:nxt==='bien'?0.75:nxt==='difficile'?0.35:0);
  schNx(card,nxt,now); card.lastReviewed=now; card.lastMs=ms; card.avgMs=card.avgMs?M.round(card.avgMs*.7+ms*.3):ms; card.timesReviewed++;
  if(isSucc(nxt))card.successes++;else card.failures++; chap.stats.totalReviews++; const k=todayKey();
  chap.stats.dailyReviews[k]=(chap.stats.dailyReviews[k]||0)+1; chap.stats.dailyDurMs[k]=(chap.stats.dailyDurMs[k]||0)+ms; chap.stats.dailyDurCount[k]=(chap.stats.dailyDurCount[k]||0)+1;
  const dc=chap.stats.dailyChanges[k]||{changed:0,total:0}; dc.total++; if(prev!==nxt)dc.changed++; chap.stats.dailyChanges[k]=dc;
  (chap.stats.dailyLog[k]=chap.stats.dailyLog[k]||[]).push({cardId:card.id,prev,next:nxt,ms,ts:now}); if(wZ&&nxt!=='unseen')chap.filters.grades[nxt]=!0;
  r.answers.push({cardId:card.id,prev,next:nxt,ms});
  if(r.index<r.queue.length-1){r.index++;r.flipped=!1;r.cardStart=Date.now();debouncedSave();renRev()}else{r.end=Date.now();debouncedSave();goRecap(!1)}
}
function schNx(c,g,now){
  const q={'facile':5,'bien':4,'difficile':2,'echec':1}[g]||0; let ef=c.ef||2.5; ef=ef+(0.1-(5-q)*(0.08+(5-q)*0.02)); if(ef<1.3)ef=1.3; c.ef=ef;
  if(q<3){c.intervalDays=(g==='echec')?0.02:0.5;c.streak=(c.streak<=0?c.streak-1:-1)}else{c.intervalDays=(c.intervalDays<1e-6)?1:(c.intervalDays<1.5?6:M.round(c.intervalDays*ef));c.streak=(c.streak>=0?c.streak+1:1)}
  c.streak=clamp(c.streak,-8,12); c.dueAt=now+c.intervalDays*864e5
}

const getLive=c=>{const o=GRADE_INIT();c.cards.forEach(x=>o[x.grade||'unseen']++);return o}, syncG=c=>c.stats.gradeCounts=getLive(c), getTod=c=>c.stats.dailyReviews[todayKey()]||0, getTodCh=c=>c.stats.dailyChanges[todayKey()]||{changed:0,total:0}, cntAv=c=>c.cards.filter(x=>c.filters.grades[x.grade||'unseen']).length;
const getSucc=c=>{const k=c.stats.gradeCounts,g=k.bien+k.facile,t=g+k.echec+k.difficile;return t?M.round(g/t*100):0}, get7dAvgMs=c=>{const b=new Date();let s=0,cnt=0;for(let i=0;i<7;i++){const d=new Date(b);d.setDate(b.getDate()-i);const k=dateKey(d);s+=(c.stats.dailyDurMs[k]||0);cnt+=(c.stats.dailyDurCount[k]||0)}return cnt?M.round(s/cnt):0}, get7dAvg=c=>{const b=new Date(),arr=[];for(let i=0;i<7;i++){const d=new Date(b);d.setDate(b.getDate()-i);arr.push(c.stats.dailyReviews[dateKey(d)]||0)}return M.round(avg(arr))}, getWk=c=>{const b=new Date();let s=0;for(let i=0;i<7;i++){const d=new Date(b);d.setDate(b.getDate()-i);s+=(c.stats.dailyReviews[dateKey(d)]||0)}return s}, getLastN=(c,n)=>{const a=[],b=new Date();for(let i=n-1;i>=0;i--){const d=new Date(b);d.setDate(b.getDate()-i);a.push(c.stats.dailyReviews[dateKey(d)]||0)}return a}, getLbls=n=>{const a=[],b=new Date();for(let i=n-1;i>=0;i--){const d=new Date(b);d.setDate(b.getDate()-i);a.push(['Dimanche','Lundi','Mardi','Mercredi','Jeudi','Vendredi','Samedi'][d.getDay()])}return a}, dayKeyIdx=(n,i)=>{const b=new Date();b.setDate(b.getDate()-((n-1)-i));return dateKey(b)};

function drawBars(cid,v){ const el=D.getElementById(cid); if(!el)return; const ctx=el.getContext('2d'), dpr=W.devicePixelRatio||1, w=el.clientWidth, h=60; el.width=w*dpr; el.height=h*dpr; ctx.scale(dpr,dpr); const max=M.max(1,...v), barW=M.floor((w-36)/7); ctx.fillStyle='#94a3b8'; ctx.fillRect(0,h-14,w,1); let x=0; const bars=[]; v.forEach(n=>{const bh=M.max(3,(n/max)*(h-20));ctx.fillStyle='#6366f1';ctx.fillRect(x,h-14-bh,barW,bh);ctx.fillStyle='#e2e8f0';ctx.fillText(n,x+barW/2-3,h);bars.push({x,w:barW});x+=barW+6}); Bar7Hit[cid]={cssW:w,bars} }
function opDayBar(e,id,cid){ const h=Bar7Hit[id]; if(!h)return; const x=e.clientX-e.target.getBoundingClientRect().left, i=h.bars.findIndex(b=>x>=b.x&&x<=b.x+b.w); if(i>=0)goDaily(cid,dayKeyIdx(7,i)) }
function drawChart(id,k,sel){ const el=D.getElementById(id); if(!el)return; const ctx=el.getContext('2d'), w=180, h=180, cx=90, cy=90, R=84, r=54; ctx.clearRect(0,0,w,h); const segs=[{k:'unseen',c:'#9ca3af'},{k:'echec',c:'#ef4444'},{k:'difficile',c:'#f59e0b'},{k:'bien',c:'#3b82f6'},{k:'facile',c:'#22c55e'}], tot=segs.reduce((s,x)=>s+(k[x.k]||0),0), arcs=[]; if(!tot){ctx.beginPath();ctx.arc(cx,cy,R,0,6.28);ctx.lineWidth=30;ctx.strokeStyle='#cbd5e1';ctx.stroke();ChartHit[id]={cx,cy,innerR:r,outerR:R,arcs:[]};return} let start=-1.57; segs.forEach(s=>{const v=k[s.k];if(!v)return;const ang=(v/tot)*6.28,end=start+ang,act=!sel||sel[s.k];ctx.beginPath();ctx.arc(cx,cy,69,start,end);ctx.lineWidth=30;ctx.strokeStyle=s.c;ctx.globalAlpha=act?0.9:0.2;ctx.stroke();ctx.globalAlpha=1;arcs.push({key:s.k,start,end});start=end}); ctx.fillStyle='#0ea5e9'; ctx.font='bold 18px sans-serif'; ctx.textAlign='center'; ctx.fillText(tot,cx,cy+5); ChartHit[id]={cx,cy,innerR:r,outerR:R,arcs} }
function hChartClk(e,id,ch){ const h=ChartHit[id]; if(!h)return; const r=e.target.getBoundingClientRect(), dx=(e.clientX-r.left)*(180/r.width)-h.cx, dy=(e.clientY-r.top)*(180/r.height)-h.cy, d=M.hypot(dx,dy); if(d<h.innerR||d>h.outerR)return; let a=M.atan2(dy,dx); if(a<-1.57)a+=6.28; const hit=h.arcs.find(s=>a>=s.start&&a<=s.end); if(hit)updFilt(ch,hit.key) }

function togFilt(c,k){ 
  const s=c.filters.grades, keys=Object.keys(s), actCnt=keys.reduce((n,x)=>n+(s[x]?1:0),0);
  if(actCnt===keys.length){ keys.forEach(x=>s[x]=(x===k)); }
  else if(actCnt===1&&s[k]){ keys.forEach(x=>s[x]=!0); }
  else { s[k]=!s[k]; if(!s[k]&&actCnt===1) s[k]=!0; }
}
const getPreviewTxt = () => {
    const phy = data.subjects.find(s => s.title.toLowerCase().includes('physique')) || data.subjects[0];
    const allCards = phy.chapters.flatMap(ch => ch.cards).filter(c => !c.front.includes('<img') && !c.back.includes('<img'));
    if (!allCards.length) return { f: "La constante de Planck", b: "h = 6,626 x 10‚Åª¬≥‚Å¥ J.s" };
    const r = allCards[M.floor(M.random() * allCards.length)];
    return { f: r.front.replace(/<br>/g, ' '), b: r.back.replace(/<br>/g, ' ') };
};
function openSet(cid,push=true){
  safeCloseLB(); Media.revokeAll(); if(!cid)cid=State.chapterId; const c=getCh(cid); if(!c)return; if(push)Nav.push(); State.view='settings'; setTop({title:'Param√®tres'}); setBot({actions:!1}); hideRevAct(); const v=$('#view'), P=data.app.prefs;
  const isDark = data.app.theme==='dark'; const prev = getPreviewTxt();
  
  v.innerHTML=`<div class="settings-page scroll-y" style="flex:1">
    <div class="settings-hero">Param√®tres</div>
    <div class="settings-section"><div class="section-title">Chapitre</div><div class="settings-row" id="rowTitle"><div class="s-icon dynamic">‚úèÔ∏è</div><div class="s-label"><div class="s-title">Nom du chapitre</div><div class="s-sub">${c.title}</div></div><div class="s-chevron">‚Ä∫</div></div><div class="settings-row" id="rowEmoji"><div class="s-icon dynamic">üòä</div><div class="s-label"><div class="s-title">Emoji</div></div><div class="s-value">${c.emoji || getEmoji(c.title) || 'Aucun'}</div><div class="s-chevron">‚Ä∫</div></div><div class="settings-row" id="rowLang"><div class="s-icon dynamic">üîÑ</div><div class="s-label"><div class="s-title">Ordre des langues</div><div class="s-sub">${c.settings.langSwap?'Verso ‚Üí Recto':'Recto ‚Üí Verso'}</div></div><div class="s-chevron">‚Ä∫</div></div></div>
    <div class="settings-section"><div class="section-title">Apparence</div><div class="settings-row" id="rowTheme"><div class="s-icon dynamic">üåì</div><div class="s-label"><div class="s-title">Mode sombre</div></div><div class="s-toggle ${isDark?'on':''}"></div></div><div class="settings-row" id="rowFocus"><div class="s-icon dynamic">üéØ</div><div class="s-label"><div class="s-title">Mode Immersion (Zen)</div><div class="s-sub">Interface invisible en r√©vision</div></div><div class="s-toggle ${P.focusMode?'on':''}"></div></div><div class="settings-row" style="cursor:default"><div class="s-icon dynamic">üé®</div><div class="s-label"><div class="s-title">Couleur</div></div><div class="swatches">${['indigo','blue','teal','emerald','rose','amber','violet'].map(x=>`<button class="swatch ${P.accent===x?'is-active':''}" data-accent="${x}" style="--sw:var(--${x==='indigo'?'primary':x})"></button>`).join('')}</div></div></div>
    <div class="settings-section"><div class="section-title">Typographie (Aper√ßu direct)</div><div class="preview-box"><div class="preview-recto" id="preT"></div><div class="preview-verso" id="preD"></div></div><div class="settings-row" style="cursor:default; border-bottom:none;"><div class="s-icon dynamic">Aa</div><div class="s-label"><div class="s-title">Taille Recto</div></div><div class="s-value" id="valT">${P.fsTerm}px</div></div><div class="s-control"><button class="step-btn" id="subT">-</button><div class="s-slider-container" style="margin:0 10px; flex:1"><input type="range" class="s-slider" id="sldT" min="12" max="60" value="${P.fsTerm}"></div><button class="step-btn" id="addT">+</button></div><div class="settings-row" style="cursor:default; border-bottom:none;"><div class="s-icon dynamic">Aa</div><div class="s-label"><div class="s-title">Taille Verso</div></div><div class="s-value" id="valD">${P.fsDef}px</div></div><div class="s-control"><button class="step-btn" id="subD">-</button><div class="s-slider-container" style="margin:0 10px; flex:1"><input type="range" class="s-slider" id="sldD" min="14" max="72" value="${P.fsDef}"></div><button class="step-btn" id="addD">+</button></div></div>
    <div class="settings-section"><div class="section-title">Session</div><div class="settings-row" style="cursor:default; border-bottom:none;"><div class="s-icon dynamic">üìö</div><div class="s-label"><div class="s-title">Taille session</div><div class="s-sub">Nombre de cartes par r√©vision</div></div><div class="s-value" id="valS">${c.settings.sessionSize}</div></div><div class="s-control"><button class="step-btn" id="subS">-</button><div class="s-slider-container" style="margin:0 10px; flex:1"><input type="range" class="s-slider" id="sldS" min="1" max="200" value="${c.settings.sessionSize}"></div><button class="step-btn" id="addS">+</button></div></div>
    <div class="settings-section"><div class="section-title">Donn√©es</div><div class="settings-row" id="rowExp"><div class="s-icon dynamic">üì§</div><div class="s-label"><div class="s-title">Exporter</div><div class="s-sub">Sauvegarder toutes les donn√©es</div></div><div class="s-chevron">‚Ä∫</div></div><div class="settings-row" id="rowImp"><div class="s-icon dynamic">üì•</div><div class="s-label"><div class="s-title">Importer</div><div class="s-sub">Restaurer une sauvegarde</div></div><div class="s-chevron">‚Ä∫</div></div><input type="file" id="impF" class="hidden"></div>
    <div class="settings-section"><div class="section-title">Zone dangereuse</div><div class="settings-row" id="rowRstC"><div class="s-icon dynamic">üîÑ</div><div class="s-label"><div class="s-title">R√©initialiser ce chapitre</div><div class="s-sub">Remettre toutes les cartes √† "Non vu"</div></div></div><div class="settings-row" id="rowRstA"><div class="s-icon danger">üí•</div><div class="s-label"><div class="s-title">R√©initialiser l'application</div><div class="s-sub">Supprimer toutes les donn√©es</div></div></div></div>
    <div class="settings-footer">Flashcards v${APP_VER}<br><span style="opacity: 0.7; font-size: 0.9em;">JB. C</span></div></div>`;

  const preBox = v.querySelector('.preview-box');
  $('#preT').innerHTML = formatText(prev.f); $('#preD').innerHTML = formatText(prev.b); Media.resolve(preBox); tsLat(preBox);
  const setupControl = (sldId, subId, addId, valId, obj, prop, suffix = '', cssVar = null, fontPrev = null) => {
      const sld = $(sldId), sub = $(subId), add = $(addId), val = $(valId), pre = fontPrev ? $(fontPrev) : null;
      const update = (v) => {
          v = parseInt(v); const min = parseInt(sld.min), max = parseInt(sld.max); if(v < min) v = min; if(v > max) v = max;
          obj[prop] = v; sld.value = v; val.textContent = v + suffix;
          if(cssVar) D.documentElement.style.setProperty(cssVar, v + 'px'); if(pre) pre.style.fontSize = v + 'px';
      };
      sld.oninput = () => update(sld.value); sld.onchange = () => { debouncedSave(); haptic('light'); };
      sub.onclick = (e) => { e.stopPropagation(); update(parseInt(sld.value) - 1); debouncedSave(); haptic('light'); };
      add.onclick = (e) => { e.stopPropagation(); update(parseInt(sld.value) + 1); debouncedSave(); haptic('light'); };
  };

  setupControl('#sldT', '#subT', '#addT', '#valT', P, 'fsTerm', 'px', '--fs-term', '#preT');
  setupControl('#sldD', '#subD', '#addD', '#valD', P, 'fsDef', 'px', '--fs-def', '#preD');
  setupControl('#sldS', '#subS', '#addS', '#valS', c.settings, 'sessionSize', '');

  $('#rowTitle').onclick=()=>{ const t=prompt('Nouveau titre:', c.title); if(t && t.trim()){ const newTitle = t.trim(); if(c.virtual && c._groupId){ const g = findGrp(getSub(), c._groupId); if(g) g.title = newTitle; c.title = newTitle; } else { const real = _real(c.id); if(real) real.title = newTitle; c.title = newTitle; } updChDesc(c); debouncedSave(); openSet(cid, !1); } };
  $('#rowEmoji').onclick=()=>{ const emojiActuel = c.emoji || getEmoji(c.title) || ''; const e = prompt('Emoji (laissez vide pour l\'√©moji par d√©faut) :', emojiActuel); if (e !== null) { const newEmoji = e.trim(); if (c.virtual && c._groupId) { const g = findGrp(getSub(), c._groupId); if (g) g.emoji = newEmoji; c.emoji = newEmoji; } else { const real = _real(c.id); if (real) real.emoji = newEmoji; c.emoji = newEmoji; } updChDesc(c); debouncedSave(); openSet(cid, !1); } };
  $('#rowLang').onclick=()=>{c.settings.langSwap=!c.settings.langSwap;debouncedSave();openSet(cid,!1)};
  $('#rowTheme').onclick=()=>{data.app.theme=isDark?'light':'dark';debouncedSave();applyTh();openSet(cid,!1)};
  $('#rowFocus').onclick=()=>{P.focusMode=!P.focusMode;debouncedSave();openSet(cid,!1)};
  $$('.swatch').forEach(b=>b.onclick=e=>{ e.stopPropagation(); P.accent=b.dataset.accent; debouncedSave(); applyUI(); $$('.swatch').forEach(x=>x.classList.toggle('is-active',x===b)); $$('.s-icon.dynamic').forEach(icon => { icon.style.background = `var(--primary)`; }); haptic('light'); });
  $('#rowExp').onclick=()=>{const a=D.createElement('a');a.href=URL.createObjectURL(new Blob([JSON.stringify(data)],{type:'application/json'}));a.download=`flashcards-${dateKey(new Date())}.json`;a.click()};
  $('#rowImp').onclick=()=>$('#impF').click();
  $('#impF').onchange=async e=>{if(confirm("√âcraser toutes les donn√©es ?")){data=JSON.parse(await e.target.files[0].text());upgrade();applyTh();applyUI();saveData();goDeck(!1)}};
  $('#rowRstC').onclick=()=>{if(confirm('R√©initialiser ce chapitre ?')){c.cards.forEach(x=>{x.grade='unseen';x.timesReviewed=0;x.ef=2.5;x.intervalDays=0;x.dueAt=0;x.streak=0});c.stats={gradeCounts:GRADE_INIT(),totalReviews:0,dailyReviews:{},dailyChanges:{},dailyDurMs:{},dailyDurCount:{},dailyLog:{}};saveData();openSet(cid,!1)}};
  $('#rowRstA').onclick=async()=>{if(confirm('‚ö†Ô∏è Supprimer TOUTES les donn√©es ?')){await Media.clearAll();LS.removeItem(KEY);location.reload()}};
}

function initGest(){ const s=$('.review-scroller'); if(s)$$('img',s).forEach(i=>i.onclick=e=>{e.preventDefault();openLB(i,s)}); bindSz() }
function bindSz() {
    const elements = $$('.review-card .term, .review-card .definition'); const getDist = (t) => Math.hypot(t[0].pageX - t[1].pageX, t[0].pageY - t[1].pageY);
    elements.forEach(el => {
        let startDist = 0; let startVal = 0; const isTerm = el.classList.contains('term');
        el.addEventListener('touchstart', (e) => { if (e.touches.length === 2) { if (e.cancelable) e.preventDefault(); startDist = getDist(e.touches); startVal = isTerm ? data.app.prefs.fsTerm : data.app.prefs.fsDef; } }, { passive: false });
        el.addEventListener('touchmove', (e) => { if (e.touches.length === 2 && startDist > 0) { if (e.cancelable) e.preventDefault(); const dist = getDist(e.touches); const scale = dist / startDist; const newVal = clamp(Math.round(startVal * scale), 12, 90); if (isTerm) { data.app.prefs.fsTerm = newVal; } else { data.app.prefs.fsDef = newVal; } applyUI(); } }, { passive: false });
        el.addEventListener('touchend', (e) => { if (e.touches.length < 2 && startDist > 0) { startDist = 0; saveData(); } });
    });
}

function applyTh(){ D.documentElement.dataset.theme=data.app.theme }
function applyUI(){ const p=data.app.prefs; D.documentElement.style.setProperty('--fs-term',p.fsTerm+'px'); D.documentElement.style.setProperty('--fs-def',p.fsDef+'px'); const pl={indigo:['#6366f1','#5457e6'],blue:['#3b82f6','#2563eb'],teal:['#14b8a6','#0d9488'],emerald:['#10b981','#059669'],rose:['#f43f5e','#e11d48'],amber:['#f59e0b','#d97706'],violet:['#8b5cf6','#7c3aed']}, c=pl[p.accent]||pl.indigo; D.documentElement.style.setProperty('--primary',c[0]); D.documentElement.style.setProperty('--primary-600',c[1]) }
function reconcile(){ const c=buildCanon(), o=data.subjects||[]; data.subjects=c.map(x=>{const old=o.find(z=>z.title===x.title)||{},chs=x.chapters.map(nc=>{const oc=(old.chapters||[]).find(z=>z.title===nc.title);return oc?{...nc,stats:{...oc.stats},cards:nc.cards.map(cd=>{const oldC=oc.cards.find(z=>extractId(z.id)===extractId(cd.id));return oldC?{...cd,grade:oldC.grade,ef:oldC.ef,intervalDays:oldC.intervalDays,dueAt:oldC.dueAt}:cd})}:nc});return{...x,chapters:chs,groups:old.groups||[]}}); o.forEach(x=>{if(!data.subjects.find(z=>z.id===x.id))data.subjects.push(x)}); if(!data.subjects.find(x=>x.id===data.app.currentSubjectId))data.app.currentSubjectId=data.subjects[0].id }
function upgrade(){ if(!data.app)data.app={theme:'dark'}; data.app.prefs={fsTerm:22,fsDef:24,accent:'indigo',radius:14,...(data.app.prefs||{})}; data.subjects.forEach(s=>{valGrps(s);s.emoji=s.emoji||'';s.chapters.forEach(c=>{c.emoji=c.emoji||'';updChDesc(c);c.stats.dailyLog=c.stats.dailyLog||{};syncG(c)})}) }
function init(){ 
  Media.open(); 
  setInterval(saveData, 30000); 
  data=loadData(); if(data.app?.version!==APP_VER){reconcile();data.app.version=APP_VER;saveData()} 
  pruneStats(); upgrade(); applyTh(); applyUI(); Nav.clear(); goDeck(!1) 
}

init();
</script>
</body>
</html>
